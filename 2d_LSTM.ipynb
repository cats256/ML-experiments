{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df232528",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Work on parallelizable, optimized 2d RNN version\n",
    "- Investigate applying attention between hidden state top, hidden state left, and x\n",
    "- Apply rotations/reflections (rotate 0/90/180/270, flip vertically/horizontally/diagonally/antidiagonally) and use the same LSTM with surrounding border hidden + cell state learnable\n",
    "- Investigate applying attention to final hidden state vectors\n",
    "- Investigate multilayer 2d LSTM\n",
    "- Investigate GRU vs LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "a7471fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "2fb20f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MDLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single 2D LSTM cell that takes input x_t, hidden+cell states from top (h1,c1)\n",
    "    and from left (h2,c2), and computes new (h, c).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # we'll compute 5 vectors: i, f1, f2, o, g\n",
    "        self.linear = nn.Linear(input_size + 2*hidden_size, 5*hidden_size)\n",
    "\n",
    "    def forward(self, x, h1, c1, h2, c2):\n",
    "        \"\"\"\n",
    "        x:      (B, input_size)\n",
    "        h1, c1: (B, hidden_size) from top\n",
    "        h2, c2: (B, hidden_size) from left\n",
    "        returns: (h, c) each (B, hidden_size)\n",
    "        \"\"\"\n",
    "        B = x.size(0)\n",
    "        # concat input and two hidden states\n",
    "        combined = torch.cat([x, h1, h2], dim=1)  # (B, input + 2*hidden)\n",
    "        gates = self.linear(combined)\n",
    "        # split into gates\n",
    "        i, f1, f2, o, g = gates.chunk(5, dim=1)\n",
    "\n",
    "        i  = torch.sigmoid(i)\n",
    "        f1 = torch.sigmoid(f1)\n",
    "        f2 = torch.sigmoid(f2)\n",
    "        o  = torch.sigmoid(o)\n",
    "        g  = torch.tanh(g)\n",
    "\n",
    "        # new cell: combine both prev cells\n",
    "        c = f1 * c1 + f2 * c2 + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class MDLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    2D LSTM module that applies MDLSTMCell over a 2D grid.\n",
    "    Input shape: (B, H, W, input_size)\n",
    "    Output:      (B, H, W, hidden_size) of hidden states\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = MDLSTMCell(input_size, hidden_size)\n",
    "        self.cell2 = MDLSTMCell(hidden_size, hidden_size)\n",
    "        self.h_top = nn.Parameter(torch.zeros(1, hidden_size))\n",
    "        self.c_top = nn.Parameter(torch.zeros(1, hidden_size))\n",
    "        self.h_left = nn.Parameter(torch.zeros(1, hidden_size))\n",
    "        self.c_left = nn.Parameter(torch.zeros(1, hidden_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, H, W, input_size)\n",
    "        returns: h_out of shape (B, H, W, hidden_size)\n",
    "        \"\"\"\n",
    "        B, H, W, _ = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        # We'll store hidden states row by row\n",
    "        h_rows = []\n",
    "        c_rows = []\n",
    "\n",
    "        for i in range(H):\n",
    "            h_row = []\n",
    "            c_row = []\n",
    "            for j in range(W):\n",
    "                x_ij = x[:, i, j, :]  # (B, input_size)\n",
    "\n",
    "                if i > 0:\n",
    "                    h1 = h_rows[i-1][j]\n",
    "                    c1 = c_rows[i-1][j]\n",
    "                else:\n",
    "                    h1 = self.h_top.expand(B, -1)\n",
    "                    c1 = self.c_top.expand(B, -1)\n",
    "\n",
    "                if j > 0:\n",
    "                    h2 = h_row[j-1]\n",
    "                    c2 = c_row[j-1]\n",
    "                else:\n",
    "                    h2 = self.h_left.expand(B, -1)\n",
    "                    c2 = self.c_left.expand(B, -1)\n",
    "\n",
    "                h_ij, c_ij = self.cell(x_ij, h1, c1, h2, c2)\n",
    "\n",
    "                h_row.append(h_ij)\n",
    "                c_row.append(c_ij)\n",
    "\n",
    "            h_rows.append(h_row)\n",
    "            c_rows.append(c_row)\n",
    "\n",
    "        # Stack everything to get shape (B, H, W, hidden_size)\n",
    "        h_out = torch.stack([torch.stack(row, dim=1) for row in h_rows], dim=1)\n",
    "        return h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "5e2afda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "ad1b9527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9e681c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset.data.to(device).float() / 255.0\n",
    "train_targets = train_dataset.targets.to(device)\n",
    "\n",
    "test_data = test_dataset.data.to(device).float() / 255.0\n",
    "test_targets = test_dataset.targets.to(device)\n",
    "\n",
    "train_data = train_data.unsqueeze(1)\n",
    "test_data = test_data.unsqueeze(1)\n",
    "\n",
    "def get_batches(data, targets, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size], targets[i:i + batch_size]\n",
    "\n",
    "batch_size = 5000\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "f32e921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST2DLSTMClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size=32, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mdlstm = MDLSTM(input_size=1, hidden_size=hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, 28, 28)\n",
    "        # reformat to (B, H, W, 1)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        # run the 2D‐LSTM\n",
    "        h = self.mdlstm(x)                # → (B, H, W, hidden_size)\n",
    "        # global average pool over all H×W cells\n",
    "        final_state = h[:, -1, -1, :].clone()\n",
    "    \n",
    "        logits = self.classifier(final_state)  # → (B, num_classes)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b58b878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 * 1\n",
    "epochs = 1000\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = MNIST2DLSTMClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "66bd9be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdlstm.h_top: 32 params, requires_grad=True\n",
      "mdlstm.c_top: 32 params, requires_grad=True\n",
      "mdlstm.h_left: 32 params, requires_grad=True\n",
      "mdlstm.c_left: 32 params, requires_grad=True\n",
      "mdlstm.cell.linear.weight: 10400 params, requires_grad=True\n",
      "mdlstm.cell.linear.bias: 160 params, requires_grad=True\n",
      "mdlstm.cell2.linear.weight: 15360 params, requires_grad=True\n",
      "mdlstm.cell2.linear.bias: 160 params, requires_grad=True\n",
      "classifier.weight: 320 params, requires_grad=True\n",
      "classifier.bias: 10 params, requires_grad=True\n",
      "\n",
      "26538\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} params, requires_grad={param.requires_grad}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print()\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b55f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss: 2.3001\n",
      "Epoch [1/1000], Validation Loss: 2.2396, Validation Accuracy: 20.27%\n",
      "Output Summary: Max=0.3599, Min=-0.6094, Median=-0.0569, Mean=-0.0638\n",
      "\n",
      "Epoch [2/1000], Training Loss: 2.2050\n",
      "Epoch [2/1000], Validation Loss: 2.1640, Validation Accuracy: 23.39%\n",
      "Output Summary: Max=0.3316, Min=-0.6136, Median=-0.0227, Mean=-0.0610\n",
      "\n",
      "Epoch [3/1000], Training Loss: 2.1200\n",
      "Epoch [3/1000], Validation Loss: 2.0804, Validation Accuracy: 31.36%\n",
      "Output Summary: Max=0.5538, Min=-0.6855, Median=0.0080, Mean=-0.0362\n",
      "\n",
      "Epoch [4/1000], Training Loss: 2.0162\n",
      "Epoch [4/1000], Validation Loss: 1.9488, Validation Accuracy: 36.34%\n",
      "Output Summary: Max=0.7731, Min=-0.8814, Median=0.0265, Mean=-0.0291\n",
      "\n",
      "Epoch [5/1000], Training Loss: 1.9062\n",
      "Epoch [5/1000], Validation Loss: 1.8494, Validation Accuracy: 38.83%\n",
      "Output Summary: Max=1.0234, Min=-1.1161, Median=0.0303, Mean=-0.0249\n",
      "\n",
      "Epoch [6/1000], Training Loss: 1.8918\n",
      "Epoch [6/1000], Validation Loss: 2.1495, Validation Accuracy: 19.37%\n",
      "Output Summary: Max=1.3188, Min=-1.4826, Median=-0.0996, Mean=-0.0798\n",
      "\n",
      "Epoch [7/1000], Training Loss: 1.8673\n",
      "Epoch [7/1000], Validation Loss: 1.7994, Validation Accuracy: 34.20%\n",
      "Output Summary: Max=1.3912, Min=-1.5443, Median=0.2268, Mean=0.0072\n",
      "\n",
      "Epoch [8/1000], Training Loss: 1.7564\n",
      "Epoch [8/1000], Validation Loss: 1.6945, Validation Accuracy: 42.57%\n",
      "Output Summary: Max=1.4840, Min=-1.6544, Median=0.1520, Mean=0.0090\n",
      "\n",
      "Epoch [9/1000], Training Loss: 1.6537\n",
      "Epoch [9/1000], Validation Loss: 1.5962, Validation Accuracy: 44.05%\n",
      "Output Summary: Max=1.5657, Min=-1.7848, Median=0.1514, Mean=0.0115\n",
      "\n",
      "Epoch [10/1000], Training Loss: 1.5764\n",
      "Epoch [10/1000], Validation Loss: 1.6294, Validation Accuracy: 39.12%\n",
      "Output Summary: Max=1.8454, Min=-1.9311, Median=0.1255, Mean=-0.0008\n",
      "\n",
      "Epoch [11/1000], Training Loss: 1.5422\n",
      "Epoch [11/1000], Validation Loss: 1.4797, Validation Accuracy: 45.90%\n",
      "Output Summary: Max=2.0648, Min=-2.0864, Median=0.1608, Mean=0.0185\n",
      "\n",
      "Epoch [12/1000], Training Loss: 1.4890\n",
      "Epoch [12/1000], Validation Loss: 1.4581, Validation Accuracy: 46.42%\n",
      "Output Summary: Max=2.3268, Min=-2.1875, Median=0.2198, Mean=0.0232\n",
      "\n",
      "Epoch [13/1000], Training Loss: 1.5210\n",
      "Epoch [13/1000], Validation Loss: 1.5541, Validation Accuracy: 37.04%\n",
      "Output Summary: Max=2.4449, Min=-2.3267, Median=0.1195, Mean=-0.0090\n",
      "\n",
      "Epoch [14/1000], Training Loss: 1.4735\n",
      "Epoch [14/1000], Validation Loss: 1.4582, Validation Accuracy: 44.21%\n",
      "Output Summary: Max=2.8299, Min=-2.4190, Median=0.2361, Mean=0.0425\n",
      "\n",
      "Epoch [15/1000], Training Loss: 1.4231\n",
      "Epoch [15/1000], Validation Loss: 1.3697, Validation Accuracy: 50.32%\n",
      "Output Summary: Max=3.0226, Min=-2.5158, Median=0.2083, Mean=0.0516\n",
      "\n",
      "Epoch [16/1000], Training Loss: 1.3417\n",
      "Epoch [16/1000], Validation Loss: 1.3200, Validation Accuracy: 50.73%\n",
      "Output Summary: Max=3.1745, Min=-2.6131, Median=0.1172, Mean=0.0323\n",
      "\n",
      "Epoch [17/1000], Training Loss: 1.2986\n",
      "Epoch [17/1000], Validation Loss: 1.2935, Validation Accuracy: 50.55%\n",
      "Output Summary: Max=3.2723, Min=-2.7141, Median=0.1351, Mean=0.0368\n",
      "\n",
      "Epoch [18/1000], Training Loss: 1.2637\n",
      "Epoch [18/1000], Validation Loss: 1.2552, Validation Accuracy: 51.44%\n",
      "Output Summary: Max=3.4327, Min=-2.7964, Median=0.1038, Mean=0.0417\n",
      "\n",
      "Epoch [19/1000], Training Loss: 1.2285\n",
      "Epoch [19/1000], Validation Loss: 1.2197, Validation Accuracy: 54.81%\n",
      "Output Summary: Max=3.5995, Min=-2.8532, Median=0.0555, Mean=0.0346\n",
      "\n",
      "Epoch [20/1000], Training Loss: 1.1950\n",
      "Epoch [20/1000], Validation Loss: 1.1859, Validation Accuracy: 57.57%\n",
      "Output Summary: Max=3.7473, Min=-2.9038, Median=0.0254, Mean=0.0401\n",
      "\n",
      "Epoch [21/1000], Training Loss: 1.1631\n",
      "Epoch [21/1000], Validation Loss: 1.1668, Validation Accuracy: 57.18%\n",
      "Output Summary: Max=3.8826, Min=-2.9981, Median=-0.0339, Mean=0.0360\n",
      "\n",
      "Epoch [22/1000], Training Loss: 1.2308\n",
      "Epoch [22/1000], Validation Loss: 1.5703, Validation Accuracy: 47.05%\n",
      "Output Summary: Max=3.9649, Min=-3.1107, Median=-0.2412, Mean=-0.0144\n",
      "\n",
      "Epoch [23/1000], Training Loss: 1.3902\n",
      "Epoch [23/1000], Validation Loss: 1.2833, Validation Accuracy: 56.03%\n",
      "Output Summary: Max=3.9443, Min=-3.1730, Median=-0.0550, Mean=0.0590\n",
      "\n",
      "Epoch [24/1000], Training Loss: 1.2312\n",
      "Epoch [24/1000], Validation Loss: 1.1954, Validation Accuracy: 56.92%\n",
      "Output Summary: Max=4.1147, Min=-3.2570, Median=-0.0144, Mean=0.0620\n",
      "\n",
      "Epoch [25/1000], Training Loss: 1.1484\n",
      "Epoch [25/1000], Validation Loss: 1.1312, Validation Accuracy: 60.40%\n",
      "Output Summary: Max=4.2525, Min=-3.3310, Median=0.0023, Mean=0.0629\n",
      "\n",
      "Epoch [26/1000], Training Loss: 1.0940\n",
      "Epoch [26/1000], Validation Loss: 1.0972, Validation Accuracy: 61.66%\n",
      "Output Summary: Max=4.3486, Min=-3.3343, Median=0.0175, Mean=0.0628\n",
      "\n",
      "Epoch [27/1000], Training Loss: 1.0642\n",
      "Epoch [27/1000], Validation Loss: 1.0675, Validation Accuracy: 63.70%\n",
      "Output Summary: Max=4.4163, Min=-3.4758, Median=0.0186, Mean=0.0572\n",
      "\n",
      "Epoch [28/1000], Training Loss: 1.4533\n",
      "Epoch [28/1000], Validation Loss: 2.5330, Validation Accuracy: 21.24%\n",
      "Output Summary: Max=4.3623, Min=-3.5202, Median=0.1692, Mean=0.2093\n",
      "\n",
      "Epoch [29/1000], Training Loss: 1.9916\n",
      "Epoch [29/1000], Validation Loss: 1.6888, Validation Accuracy: 24.10%\n",
      "Output Summary: Max=3.0424, Min=-2.6743, Median=0.1655, Mean=0.0809\n",
      "\n",
      "Epoch [30/1000], Training Loss: 1.6430\n",
      "Epoch [30/1000], Validation Loss: 1.6006, Validation Accuracy: 30.91%\n",
      "Output Summary: Max=2.5838, Min=-2.6883, Median=0.2543, Mean=0.0716\n",
      "\n",
      "Epoch [31/1000], Training Loss: 1.5366\n",
      "Epoch [31/1000], Validation Loss: 1.4992, Validation Accuracy: 39.63%\n",
      "Output Summary: Max=2.5502, Min=-2.7820, Median=0.0033, Mean=0.0445\n",
      "\n",
      "Epoch [32/1000], Training Loss: 1.6117\n",
      "Epoch [32/1000], Validation Loss: 1.5485, Validation Accuracy: 36.23%\n",
      "Output Summary: Max=2.9262, Min=-2.5677, Median=0.3625, Mean=0.0361\n",
      "\n",
      "Epoch [33/1000], Training Loss: 1.4981\n",
      "Epoch [33/1000], Validation Loss: 1.4236, Validation Accuracy: 49.03%\n",
      "Output Summary: Max=3.0037, Min=-3.1969, Median=0.4044, Mean=0.0639\n",
      "\n",
      "Epoch [34/1000], Training Loss: 1.3741\n",
      "Epoch [34/1000], Validation Loss: 1.3466, Validation Accuracy: 50.74%\n",
      "Output Summary: Max=3.1881, Min=-3.3868, Median=0.3135, Mean=0.0714\n",
      "\n",
      "Epoch [35/1000], Training Loss: 1.3032\n",
      "Epoch [35/1000], Validation Loss: 1.2843, Validation Accuracy: 53.48%\n",
      "Output Summary: Max=3.4133, Min=-3.4617, Median=0.1807, Mean=0.0729\n",
      "\n",
      "Epoch [36/1000], Training Loss: 1.2510\n",
      "Epoch [36/1000], Validation Loss: 1.2309, Validation Accuracy: 56.62%\n",
      "Output Summary: Max=3.5248, Min=-3.5253, Median=0.1918, Mean=0.0612\n",
      "\n",
      "Epoch [37/1000], Training Loss: 1.1953\n",
      "Epoch [37/1000], Validation Loss: 1.1790, Validation Accuracy: 57.71%\n",
      "Output Summary: Max=3.6078, Min=-3.6483, Median=0.2491, Mean=0.0656\n",
      "\n",
      "Epoch [38/1000], Training Loss: 1.1453\n",
      "Epoch [38/1000], Validation Loss: 1.1384, Validation Accuracy: 60.74%\n",
      "Output Summary: Max=3.7742, Min=-3.7476, Median=0.2444, Mean=0.0610\n",
      "\n",
      "Epoch [39/1000], Training Loss: 1.1079\n",
      "Epoch [39/1000], Validation Loss: 1.1073, Validation Accuracy: 61.98%\n",
      "Output Summary: Max=3.9478, Min=-3.8615, Median=0.2597, Mean=0.0700\n",
      "\n",
      "Epoch [40/1000], Training Loss: 1.0886\n",
      "Epoch [40/1000], Validation Loss: 1.0875, Validation Accuracy: 64.00%\n",
      "Output Summary: Max=4.0668, Min=-3.9347, Median=0.2347, Mean=0.0582\n",
      "\n",
      "Epoch [41/1000], Training Loss: 1.2231\n",
      "Epoch [41/1000], Validation Loss: 1.1795, Validation Accuracy: 59.01%\n",
      "Output Summary: Max=4.3086, Min=-3.9289, Median=0.1772, Mean=0.0642\n",
      "\n",
      "Epoch [42/1000], Training Loss: 1.0984\n",
      "Epoch [42/1000], Validation Loss: 1.0761, Validation Accuracy: 61.63%\n",
      "Output Summary: Max=4.4060, Min=-3.9198, Median=0.1660, Mean=0.0675\n",
      "\n",
      "Epoch [43/1000], Training Loss: 1.0570\n",
      "Epoch [43/1000], Validation Loss: 1.0576, Validation Accuracy: 62.60%\n",
      "Output Summary: Max=4.4920, Min=-4.0837, Median=0.1680, Mean=0.0675\n",
      "\n",
      "Epoch [44/1000], Training Loss: 1.0134\n",
      "Epoch [44/1000], Validation Loss: 1.0029, Validation Accuracy: 66.19%\n",
      "Output Summary: Max=4.5888, Min=-4.1637, Median=0.1820, Mean=0.0746\n",
      "\n",
      "Epoch [45/1000], Training Loss: 0.9816\n",
      "Epoch [45/1000], Validation Loss: 0.9789, Validation Accuracy: 67.45%\n",
      "Output Summary: Max=4.6778, Min=-4.2058, Median=0.1491, Mean=0.0718\n",
      "\n",
      "Epoch [46/1000], Training Loss: 0.9586\n",
      "Epoch [46/1000], Validation Loss: 0.9809, Validation Accuracy: 66.55%\n",
      "Output Summary: Max=4.7336, Min=-4.2602, Median=0.1521, Mean=0.0751\n",
      "\n",
      "Epoch [47/1000], Training Loss: 0.9529\n",
      "Epoch [47/1000], Validation Loss: 0.9497, Validation Accuracy: 68.36%\n",
      "Output Summary: Max=4.8380, Min=-4.3261, Median=0.0751, Mean=0.0640\n",
      "\n",
      "Epoch [48/1000], Training Loss: 0.9256\n",
      "Epoch [48/1000], Validation Loss: 0.9308, Validation Accuracy: 68.66%\n",
      "Output Summary: Max=4.9344, Min=-4.3579, Median=0.1487, Mean=0.0790\n",
      "\n",
      "Epoch [49/1000], Training Loss: 0.9925\n",
      "Epoch [49/1000], Validation Loss: 0.9555, Validation Accuracy: 66.84%\n",
      "Output Summary: Max=4.9367, Min=-4.3565, Median=0.1257, Mean=0.0689\n",
      "\n",
      "Epoch [50/1000], Training Loss: 0.9301\n",
      "Epoch [50/1000], Validation Loss: 0.9267, Validation Accuracy: 68.47%\n",
      "Output Summary: Max=4.9837, Min=-4.4532, Median=0.0728, Mean=0.0671\n",
      "\n",
      "Epoch [51/1000], Training Loss: 0.8955\n",
      "Epoch [51/1000], Validation Loss: 0.8950, Validation Accuracy: 69.92%\n",
      "Output Summary: Max=5.0330, Min=-4.4857, Median=0.1731, Mean=0.0806\n",
      "\n",
      "Epoch [52/1000], Training Loss: 0.8730\n",
      "Epoch [52/1000], Validation Loss: 0.8824, Validation Accuracy: 70.06%\n",
      "Output Summary: Max=5.1062, Min=-4.5687, Median=0.1626, Mean=0.0832\n",
      "\n",
      "Epoch [53/1000], Training Loss: 0.8558\n",
      "Epoch [53/1000], Validation Loss: 0.8639, Validation Accuracy: 70.63%\n",
      "Output Summary: Max=5.1481, Min=-4.6083, Median=0.1503, Mean=0.0840\n",
      "\n",
      "Epoch [54/1000], Training Loss: 0.8546\n",
      "Epoch [54/1000], Validation Loss: 0.9107, Validation Accuracy: 68.08%\n",
      "Output Summary: Max=5.2038, Min=-4.6388, Median=0.0442, Mean=0.0695\n",
      "\n",
      "Epoch [55/1000], Training Loss: 0.8704\n",
      "Epoch [55/1000], Validation Loss: 0.8573, Validation Accuracy: 70.66%\n",
      "Output Summary: Max=5.2550, Min=-4.7161, Median=0.1207, Mean=0.0879\n",
      "\n",
      "Epoch [56/1000], Training Loss: 0.8408\n",
      "Epoch [56/1000], Validation Loss: 0.8344, Validation Accuracy: 71.15%\n",
      "Output Summary: Max=5.3000, Min=-4.7503, Median=0.0908, Mean=0.0812\n",
      "\n",
      "Epoch [57/1000], Training Loss: 0.8326\n",
      "Epoch [57/1000], Validation Loss: 0.8359, Validation Accuracy: 71.57%\n",
      "Output Summary: Max=5.3604, Min=-4.7953, Median=0.0624, Mean=0.0789\n",
      "\n",
      "Epoch [58/1000], Training Loss: 0.8139\n",
      "Epoch [58/1000], Validation Loss: 0.8236, Validation Accuracy: 71.80%\n",
      "Output Summary: Max=5.4138, Min=-4.8239, Median=0.0846, Mean=0.0846\n",
      "\n",
      "Epoch [59/1000], Training Loss: 0.8018\n",
      "Epoch [59/1000], Validation Loss: 0.8155, Validation Accuracy: 71.64%\n",
      "Output Summary: Max=5.5348, Min=-4.8526, Median=0.1417, Mean=0.0929\n",
      "\n",
      "Epoch [60/1000], Training Loss: 0.8268\n",
      "Epoch [60/1000], Validation Loss: 1.4778, Validation Accuracy: 50.83%\n",
      "Output Summary: Max=5.6773, Min=-4.8880, Median=-0.2430, Mean=0.0577\n",
      "\n",
      "Epoch [61/1000], Training Loss: 1.6982\n",
      "Epoch [61/1000], Validation Loss: 1.4242, Validation Accuracy: 48.82%\n",
      "Output Summary: Max=4.8962, Min=-4.8998, Median=0.1244, Mean=0.1561\n",
      "\n",
      "Epoch [62/1000], Training Loss: 1.2788\n",
      "Epoch [62/1000], Validation Loss: 1.1438, Validation Accuracy: 60.57%\n",
      "Output Summary: Max=5.1232, Min=-4.8170, Median=0.2322, Mean=0.1404\n",
      "\n",
      "Epoch [63/1000], Training Loss: 1.0798\n",
      "Epoch [63/1000], Validation Loss: 1.0370, Validation Accuracy: 63.24%\n",
      "Output Summary: Max=4.9395, Min=-4.7755, Median=0.1553, Mean=0.1347\n",
      "\n",
      "Epoch [64/1000], Training Loss: 0.9904\n",
      "Epoch [64/1000], Validation Loss: 0.9746, Validation Accuracy: 66.16%\n",
      "Output Summary: Max=5.0326, Min=-4.8060, Median=0.1346, Mean=0.1349\n",
      "\n",
      "Epoch [65/1000], Training Loss: 0.9388\n",
      "Epoch [65/1000], Validation Loss: 0.9294, Validation Accuracy: 67.82%\n",
      "Output Summary: Max=4.9181, Min=-4.8340, Median=0.1538, Mean=0.1453\n",
      "\n",
      "Epoch [66/1000], Training Loss: 0.9022\n",
      "Epoch [66/1000], Validation Loss: 0.9045, Validation Accuracy: 69.26%\n",
      "Output Summary: Max=4.9915, Min=-4.7492, Median=0.1409, Mean=0.1467\n",
      "\n",
      "Epoch [67/1000], Training Loss: 0.8781\n",
      "Epoch [67/1000], Validation Loss: 0.8786, Validation Accuracy: 70.35%\n",
      "Output Summary: Max=5.0711, Min=-4.8041, Median=0.1607, Mean=0.1412\n",
      "\n",
      "Epoch [68/1000], Training Loss: 0.8550\n",
      "Epoch [68/1000], Validation Loss: 0.8619, Validation Accuracy: 70.69%\n",
      "Output Summary: Max=5.1501, Min=-4.8090, Median=0.1627, Mean=0.1398\n",
      "\n",
      "Epoch [69/1000], Training Loss: 0.8367\n",
      "Epoch [69/1000], Validation Loss: 0.8442, Validation Accuracy: 71.30%\n",
      "Output Summary: Max=5.2846, Min=-4.8524, Median=0.1412, Mean=0.1417\n",
      "\n",
      "Epoch [70/1000], Training Loss: 0.8224\n",
      "Epoch [70/1000], Validation Loss: 0.8303, Validation Accuracy: 71.39%\n",
      "Output Summary: Max=5.3833, Min=-4.8969, Median=0.1404, Mean=0.1400\n",
      "\n",
      "Epoch [71/1000], Training Loss: 0.8088\n",
      "Epoch [71/1000], Validation Loss: 0.8190, Validation Accuracy: 71.65%\n",
      "Output Summary: Max=5.4729, Min=-4.9437, Median=0.1490, Mean=0.1446\n",
      "\n",
      "Epoch [72/1000], Training Loss: 0.7971\n",
      "Epoch [72/1000], Validation Loss: 0.8081, Validation Accuracy: 71.79%\n",
      "Output Summary: Max=5.5702, Min=-5.0186, Median=0.1195, Mean=0.1432\n",
      "\n",
      "Epoch [73/1000], Training Loss: 0.7885\n",
      "Epoch [73/1000], Validation Loss: 0.8018, Validation Accuracy: 72.00%\n",
      "Output Summary: Max=5.6568, Min=-5.0492, Median=0.1210, Mean=0.1458\n",
      "\n",
      "Epoch [74/1000], Training Loss: 0.7843\n",
      "Epoch [74/1000], Validation Loss: 0.7974, Validation Accuracy: 71.90%\n",
      "Output Summary: Max=5.7475, Min=-5.0734, Median=0.1209, Mean=0.1495\n",
      "\n",
      "Epoch [75/1000], Training Loss: 0.7779\n",
      "Epoch [75/1000], Validation Loss: 0.8015, Validation Accuracy: 71.48%\n",
      "Output Summary: Max=5.8243, Min=-5.1084, Median=0.1204, Mean=0.1522\n",
      "\n",
      "Epoch [76/1000], Training Loss: 0.7746\n",
      "Epoch [76/1000], Validation Loss: 0.7974, Validation Accuracy: 71.50%\n",
      "Output Summary: Max=5.8835, Min=-5.1588, Median=0.1131, Mean=0.1549\n",
      "\n",
      "Epoch [77/1000], Training Loss: 0.7681\n",
      "Epoch [77/1000], Validation Loss: 0.7766, Validation Accuracy: 72.56%\n",
      "Output Summary: Max=5.9485, Min=-5.1808, Median=0.1030, Mean=0.1507\n",
      "\n",
      "Epoch [78/1000], Training Loss: 0.7574\n",
      "Epoch [78/1000], Validation Loss: 0.7774, Validation Accuracy: 72.49%\n",
      "Output Summary: Max=6.1260, Min=-5.2451, Median=0.0767, Mean=0.1467\n",
      "\n",
      "Epoch [79/1000], Training Loss: 0.7478\n",
      "Epoch [79/1000], Validation Loss: 0.7678, Validation Accuracy: 72.57%\n",
      "Output Summary: Max=6.0253, Min=-5.3384, Median=0.0685, Mean=0.1463\n",
      "\n",
      "Epoch [80/1000], Training Loss: 0.7435\n",
      "Epoch [80/1000], Validation Loss: 0.7709, Validation Accuracy: 72.43%\n",
      "Output Summary: Max=6.1058, Min=-5.2971, Median=0.0372, Mean=0.1516\n",
      "\n",
      "Epoch [81/1000], Training Loss: 0.7407\n",
      "Epoch [81/1000], Validation Loss: 0.7815, Validation Accuracy: 71.46%\n",
      "Output Summary: Max=6.1672, Min=-5.3575, Median=0.0879, Mean=0.1573\n",
      "\n",
      "Epoch [82/1000], Training Loss: 0.7460\n",
      "Epoch [82/1000], Validation Loss: 0.7732, Validation Accuracy: 72.37%\n",
      "Output Summary: Max=6.2179, Min=-5.4201, Median=0.0531, Mean=0.1543\n",
      "\n",
      "Epoch [83/1000], Training Loss: 0.7419\n",
      "Epoch [83/1000], Validation Loss: 0.7628, Validation Accuracy: 72.07%\n",
      "Output Summary: Max=6.2693, Min=-5.4235, Median=0.1485, Mean=0.1538\n",
      "\n",
      "Epoch [84/1000], Training Loss: 0.7311\n",
      "Epoch [84/1000], Validation Loss: 0.7425, Validation Accuracy: 73.57%\n",
      "Output Summary: Max=6.4036, Min=-5.4929, Median=0.0813, Mean=0.1475\n",
      "\n",
      "Epoch [85/1000], Training Loss: 0.7239\n",
      "Epoch [85/1000], Validation Loss: 0.7452, Validation Accuracy: 73.30%\n",
      "Output Summary: Max=6.5897, Min=-5.4312, Median=0.0603, Mean=0.1418\n",
      "\n",
      "Epoch [86/1000], Training Loss: 0.7172\n",
      "Epoch [86/1000], Validation Loss: 0.7366, Validation Accuracy: 73.68%\n",
      "Output Summary: Max=6.6239, Min=-5.4860, Median=0.0694, Mean=0.1453\n",
      "\n",
      "Epoch [87/1000], Training Loss: 0.7107\n",
      "Epoch [87/1000], Validation Loss: 0.7288, Validation Accuracy: 73.86%\n",
      "Output Summary: Max=6.6842, Min=-5.4769, Median=0.0346, Mean=0.1418\n",
      "\n",
      "Epoch [88/1000], Training Loss: 0.7037\n",
      "Epoch [88/1000], Validation Loss: 0.7257, Validation Accuracy: 73.92%\n",
      "Output Summary: Max=6.7290, Min=-5.5544, Median=0.0506, Mean=0.1470\n",
      "\n",
      "Epoch [89/1000], Training Loss: 0.7000\n",
      "Epoch [89/1000], Validation Loss: 0.7342, Validation Accuracy: 73.15%\n",
      "Output Summary: Max=6.7810, Min=-5.5945, Median=0.0805, Mean=0.1510\n",
      "\n",
      "Epoch [90/1000], Training Loss: 0.6996\n",
      "Epoch [90/1000], Validation Loss: 0.7179, Validation Accuracy: 73.96%\n",
      "Output Summary: Max=6.7929, Min=-5.6347, Median=0.0463, Mean=0.1413\n",
      "\n",
      "Epoch [91/1000], Training Loss: 0.6914\n",
      "Epoch [91/1000], Validation Loss: 0.7174, Validation Accuracy: 74.25%\n",
      "Output Summary: Max=6.8324, Min=-5.6606, Median=0.0033, Mean=0.1379\n",
      "\n",
      "Epoch [92/1000], Training Loss: 0.6886\n",
      "Epoch [92/1000], Validation Loss: 0.7134, Validation Accuracy: 74.20%\n",
      "Output Summary: Max=6.8762, Min=-5.6931, Median=0.0116, Mean=0.1363\n",
      "\n",
      "Epoch [93/1000], Training Loss: 0.6914\n",
      "Epoch [93/1000], Validation Loss: 0.7295, Validation Accuracy: 73.54%\n",
      "Output Summary: Max=6.9368, Min=-5.6822, Median=0.0380, Mean=0.1330\n",
      "\n",
      "Epoch [94/1000], Training Loss: 0.6899\n",
      "Epoch [94/1000], Validation Loss: 0.7103, Validation Accuracy: 74.56%\n",
      "Output Summary: Max=6.9139, Min=-5.6916, Median=-0.0014, Mean=0.1401\n",
      "\n",
      "Epoch [95/1000], Training Loss: 0.6887\n",
      "Epoch [95/1000], Validation Loss: 0.7317, Validation Accuracy: 73.33%\n",
      "Output Summary: Max=7.0115, Min=-5.7252, Median=-0.0427, Mean=0.1438\n",
      "\n",
      "Epoch [96/1000], Training Loss: 0.6899\n",
      "Epoch [96/1000], Validation Loss: 0.7078, Validation Accuracy: 74.03%\n",
      "Output Summary: Max=7.0406, Min=-5.7850, Median=0.0484, Mean=0.1391\n",
      "\n",
      "Epoch [97/1000], Training Loss: 0.6795\n",
      "Epoch [97/1000], Validation Loss: 0.7002, Validation Accuracy: 74.77%\n",
      "Output Summary: Max=6.9831, Min=-5.7384, Median=0.0077, Mean=0.1335\n",
      "\n",
      "Epoch [98/1000], Training Loss: 0.6808\n",
      "Epoch [98/1000], Validation Loss: 0.7000, Validation Accuracy: 74.79%\n",
      "Output Summary: Max=7.0377, Min=-5.8063, Median=-0.0488, Mean=0.1348\n",
      "\n",
      "Epoch [99/1000], Training Loss: 0.6671\n",
      "Epoch [99/1000], Validation Loss: 0.6958, Validation Accuracy: 74.57%\n",
      "Output Summary: Max=7.1446, Min=-5.8070, Median=0.0183, Mean=0.1385\n",
      "\n"
     ]
    }
   ],
   "source": [
    "patience = 1000\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb722e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
