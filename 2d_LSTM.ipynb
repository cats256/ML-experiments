{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "df232528",
   "metadata": {},
   "source": [
    "TODO:\n",
    "- Work on parallelizable, optimized 2d RNN version\n",
    "- Investigate applying attention between hidden state top, hidden state left, and x\n",
    "- Apply rotations/reflections (rotate 0/90/180/270, flip vertically/horizontally/diagonally/antidiagonally) and use the same LSTM with surrounding border hidden + cell state learnable\n",
    "- Investigate applying attention to final hidden state vectors\n",
    "- Investigate multilayer 2d LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "98602d3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTM2DCell(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM2DCell, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        # Gates: input, forget (horizontal and vertical), output, and candidate cell\n",
    "        self.W = nn.Linear(input_size + 2 * hidden_size, 5 * hidden_size)\n",
    "\n",
    "    def forward(self, x, h_left, c_left, h_top, c_top):\n",
    "        combined = torch.cat([x, h_left, h_top], dim=1)  # concatenate along features\n",
    "        gates = self.W(combined)\n",
    "\n",
    "        i, f_left, f_top, o, g = gates.chunk(5, dim=1)\n",
    "        i = torch.sigmoid(i)\n",
    "        f_left = torch.sigmoid(f_left)\n",
    "        f_top = torch.sigmoid(f_top)\n",
    "        o = torch.sigmoid(o)\n",
    "        g = torch.tanh(g)\n",
    "\n",
    "        # Combine memory from left and top\n",
    "        c = i * g + f_left * c_left + f_top * c_top\n",
    "        h = o * torch.tanh(c)\n",
    "\n",
    "        return h, c\n",
    "\n",
    "class LSTM2D(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(LSTM2D, self).__init__()\n",
    "        self.cell = LSTM2DCell(input_size, hidden_size)\n",
    "\n",
    "    def forward(self, input_grid):\n",
    "        \"\"\"\n",
    "        input_grid: Tensor of shape (H, W, B, input_size)\n",
    "        Returns:\n",
    "            h_grid: Tensor of shape (H, W, B, hidden_size)\n",
    "        \"\"\"\n",
    "        H, W, B, _ = input_grid.shape\n",
    "        device = input_grid.device\n",
    "        h_grid = torch.zeros(H, W, B, self.cell.hidden_size, device=device)\n",
    "        c_grid = torch.zeros(H, W, B, self.cell.hidden_size, device=device)\n",
    "\n",
    "        for i in range(H):\n",
    "            for j in range(W):\n",
    "                x = input_grid[i, j]\n",
    "                h_left = h_grid[i, j - 1] if j > 0 else torch.zeros(B, self.cell.hidden_size, device=device)\n",
    "                c_left = c_grid[i, j - 1] if j > 0 else torch.zeros(B, self.cell.hidden_size, device=device)\n",
    "                h_top = h_grid[i - 1, j] if i > 0 else torch.zeros(B, self.cell.hidden_size, device=device)\n",
    "                c_top = c_grid[i - 1, j] if i > 0 else torch.zeros(B, self.cell.hidden_size, device=device)\n",
    "\n",
    "                h, c = self.cell(x, h_left, c_left, h_top, c_top)\n",
    "                h_grid[i, j] = h\n",
    "                c_grid[i, j] = c\n",
    "\n",
    "        return h_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ac5cd988",
   "metadata": {},
   "outputs": [],
   "source": [
    "H, W, B, input_size, hidden_size = 10, 10, 4, 16, 32\n",
    "input_grid = torch.randn(H, W, B, input_size)\n",
    "\n",
    "model = LSTM2D(input_size, hidden_size)\n",
    "output = model(input_grid)  # output shape: (H, W, B, hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7471fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4c9dc28",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import annotations\n",
    "\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# -----------------------------\n",
    "#  2‑D LSTM building blocks\n",
    "# -----------------------------\n",
    "\n",
    "class RowCol2DLSTM(nn.Module):\n",
    "    \"\"\"A simple 2‑D LSTM composed of a row LSTM followed by a column LSTM.\n",
    "\n",
    "    Args:\n",
    "        row_hidden: Hidden units in the row LSTM (×2 when bidirectional).\n",
    "        col_hidden: Hidden units in the column LSTM (×2 when bidirectional).\n",
    "        num_classes: Output classes.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, *, row_hidden: int = 8, col_hidden: int = 8, num_classes: int = 10):\n",
    "        super().__init__()\n",
    "        self.row_hidden = row_hidden\n",
    "        self.col_hidden = col_hidden\n",
    "\n",
    "        # Processes each *row* as a sequence of W pixels → (B, H, W, 2·row_hidden)\n",
    "        self.row_lstm = nn.LSTM(\n",
    "            input_size=1,\n",
    "            hidden_size=row_hidden,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # Processes each *column* as a sequence of H row features → (B, W, 2·col_hidden)\n",
    "        self.col_lstm = nn.LSTM(\n",
    "            input_size=row_hidden * 2,\n",
    "            hidden_size=col_hidden,\n",
    "            num_layers=1,\n",
    "            bidirectional=True,\n",
    "            batch_first=True,\n",
    "        )\n",
    "\n",
    "        # Global representation → logits\n",
    "        self.classifier = nn.Linear(col_hidden * 2, num_classes)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"x shape = (B, 1, H, W) (MNIST uses H=W=28).\"\"\"\n",
    "        b, c, h, w = x.shape\n",
    "        assert c == 1, \"Expect single‑channel greyscale images\"\n",
    "\n",
    "        # ── Row pass ────────────────────────────────────────────────────────────\n",
    "        x = x.squeeze(1)  # (B, H, W)\n",
    "        row_feats = []\n",
    "        for i in range(h):\n",
    "            row_seq = x[:, i, :].unsqueeze(-1)  # (B, W, 1)\n",
    "            out, _ = self.row_lstm(row_seq)     # (B, W, 2·row_hidden)\n",
    "            row_feats.append(out)\n",
    "        row_feats = torch.stack(row_feats, dim=1)  # (B, H, W, 2·row_hidden)\n",
    "\n",
    "        # ── Column pass ─────────────────────────────────────────────────────────\n",
    "        col_feats = []\n",
    "        for j in range(w):\n",
    "            col_seq = row_feats[:, :, j, :]                # (B, H, 2·row_hidden)\n",
    "            out, _ = self.col_lstm(col_seq)                # (B, H, 2·col_hidden)\n",
    "            col_feats.append(out[:, -1, :])                # last step along column\n",
    "        col_feats = torch.stack(col_feats, dim=1)          # (B, W, 2·col_hidden)\n",
    "\n",
    "        # ── Classification head ────────────────────────────────────────────────\n",
    "        global_feat = col_feats.mean(dim=1)                # (B, 2·col_hidden)\n",
    "        logits = self.classifier(global_feat)              # (B, num_classes)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fb20f07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class MDLSTMCell(nn.Module):\n",
    "    \"\"\"\n",
    "    A single 2D LSTM cell that takes input x_t, hidden+cell states from top (h1,c1)\n",
    "    and from left (h2,c2), and computes new (h, c).\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        # we'll compute 5 vectors: i, f1, f2, o, g\n",
    "        self.linear = nn.Linear(input_size + 2*hidden_size, 5*hidden_size)\n",
    "\n",
    "    def forward(self, x, h1, c1, h2, c2):\n",
    "        \"\"\"\n",
    "        x:      (B, input_size)\n",
    "        h1, c1: (B, hidden_size) from top\n",
    "        h2, c2: (B, hidden_size) from left\n",
    "        returns: (h, c) each (B, hidden_size)\n",
    "        \"\"\"\n",
    "        B = x.size(0)\n",
    "        # concat input and two hidden states\n",
    "        combined = torch.cat([x, h1, h2], dim=1)  # (B, input + 2*hidden)\n",
    "        gates = self.linear(combined)\n",
    "        # split into gates\n",
    "        i, f1, f2, o, g = gates.chunk(5, dim=1)\n",
    "\n",
    "        i  = torch.sigmoid(i)\n",
    "        f1 = torch.sigmoid(f1)\n",
    "        f2 = torch.sigmoid(f2)\n",
    "        o  = torch.sigmoid(o)\n",
    "        g  = torch.tanh(g)\n",
    "\n",
    "        # new cell: combine both prev cells\n",
    "        c = f1 * c1 + f2 * c2 + i * g\n",
    "        h = o * torch.tanh(c)\n",
    "        return h, c\n",
    "\n",
    "\n",
    "class MDLSTM(nn.Module):\n",
    "    \"\"\"\n",
    "    2D LSTM module that applies MDLSTMCell over a 2D grid.\n",
    "    Input shape: (B, H, W, input_size)\n",
    "    Output:      (B, H, W, hidden_size) of hidden states\n",
    "    \"\"\"\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super().__init__()\n",
    "        self.input_size  = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.cell = MDLSTMCell(input_size, hidden_size)\n",
    "        self.cell2 = MDLSTMCell(hidden_size, hidden_size)\n",
    "        self.h_top = nn.Parameter(torch.zeros(1, hidden_size))\n",
    "        self.c_top = nn.Parameter(torch.zeros(1, hidden_size))\n",
    "        self.h_left = nn.Parameter(torch.zeros(1, hidden_size))\n",
    "        self.c_left = nn.Parameter(torch.zeros(1, hidden_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        x: (B, H, W, input_size)\n",
    "        returns: h_out of shape (B, H, W, hidden_size)\n",
    "        \"\"\"\n",
    "        B, H, W, _ = x.size()\n",
    "        device = x.device\n",
    "\n",
    "        # We'll store hidden states row by row\n",
    "        h_rows = []\n",
    "        c_rows = []\n",
    "\n",
    "        for i in range(H):\n",
    "            h_row = []\n",
    "            c_row = []\n",
    "            for j in range(W):\n",
    "                x_ij = x[:, i, j, :]  # (B, input_size)\n",
    "\n",
    "                if i > 0:\n",
    "                    h1 = h_rows[i-1][j]\n",
    "                    c1 = c_rows[i-1][j]\n",
    "                else:\n",
    "                    h1 = self.h_top.expand(B, -1)\n",
    "                    c1 = self.c_top.expand(B, -1)\n",
    "\n",
    "                if j > 0:\n",
    "                    h2 = h_row[j-1]\n",
    "                    c2 = c_row[j-1]\n",
    "                else:\n",
    "                    h2 = self.h_left.expand(B, -1)\n",
    "                    c2 = self.c_left.expand(B, -1)\n",
    "\n",
    "                h_ij, c_ij = self.cell(x_ij, h1, c1, h2, c2)\n",
    "\n",
    "                h_row.append(h_ij)\n",
    "                c_row.append(c_ij)\n",
    "\n",
    "            h_rows.append(h_row)\n",
    "            c_rows.append(c_row)\n",
    "\n",
    "        # Stack everything to get shape (B, H, W, hidden_size)\n",
    "        h_out = torch.stack([torch.stack(row, dim=1) for row in h_rows], dim=1)\n",
    "        return h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "5e2afda0",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "ad1b9527",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9e681c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset.data.to(device).float() / 255.0\n",
    "train_targets = train_dataset.targets.to(device)\n",
    "\n",
    "test_data = test_dataset.data.to(device).float() / 255.0\n",
    "test_targets = test_dataset.targets.to(device)\n",
    "\n",
    "train_data = train_data.unsqueeze(1)\n",
    "test_data = test_data.unsqueeze(1)\n",
    "\n",
    "def get_batches(data, targets, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size], targets[i:i + batch_size]\n",
    "\n",
    "batch_size = 5000\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f32e921b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNIST2DLSTMClassifier(nn.Module):\n",
    "    def __init__(self, hidden_size=32, num_classes=10):\n",
    "        super().__init__()\n",
    "\n",
    "        self.mdlstm = MDLSTM(input_size=1, hidden_size=hidden_size)\n",
    "        self.classifier = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B, 1, 28, 28)\n",
    "        # reformat to (B, H, W, 1)\n",
    "        x = x.permute(0, 2, 3, 1).contiguous()\n",
    "        # run the 2D‐LSTM\n",
    "        h = self.mdlstm(x)                # → (B, H, W, hidden_size)\n",
    "        # global average pool over all H×W cells\n",
    "        final_state = h[:, -1, -1, :].clone()\n",
    "    \n",
    "        logits = self.classifier(final_state)  # → (B, num_classes)\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "b58b878f",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 * 1\n",
    "epochs = 1000\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = MNIST2DLSTMClassifier().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "66bd9be2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mdlstm.cell.linear.weight: 10400 params, requires_grad=True\n",
      "mdlstm.cell.linear.bias: 160 params, requires_grad=True\n",
      "classifier.weight: 320 params, requires_grad=True\n",
      "classifier.bias: 10 params, requires_grad=True\n",
      "\n",
      "10890\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} params, requires_grad={param.requires_grad}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print()\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11b55f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss: 2.2957\n",
      "Epoch [1/1000], Validation Loss: 2.2898, Validation Accuracy: 13.75%\n",
      "Output Summary: Max=0.4475, Min=-0.3677, Median=0.0605, Mean=0.0795\n",
      "\n",
      "Epoch [2/1000], Training Loss: 2.2215\n",
      "Epoch [2/1000], Validation Loss: 2.1714, Validation Accuracy: 19.55%\n",
      "Output Summary: Max=0.5182, Min=-0.3746, Median=0.1035, Mean=0.0700\n",
      "\n",
      "Epoch [3/1000], Training Loss: 2.1153\n",
      "Epoch [3/1000], Validation Loss: 2.0406, Validation Accuracy: 22.57%\n",
      "Output Summary: Max=0.7091, Min=-0.6550, Median=0.0728, Mean=0.0765\n",
      "\n",
      "Epoch [4/1000], Training Loss: 2.0633\n",
      "Epoch [4/1000], Validation Loss: 2.0161, Validation Accuracy: 25.48%\n",
      "Output Summary: Max=0.9221, Min=-0.8647, Median=0.0966, Mean=0.1004\n",
      "\n",
      "Epoch [5/1000], Training Loss: 1.9554\n",
      "Epoch [5/1000], Validation Loss: 1.9014, Validation Accuracy: 22.25%\n",
      "Output Summary: Max=1.0513, Min=-1.0341, Median=0.0903, Mean=0.0891\n",
      "\n",
      "Epoch [6/1000], Training Loss: 1.8490\n",
      "Epoch [6/1000], Validation Loss: 1.7864, Validation Accuracy: 29.71%\n",
      "Output Summary: Max=1.1756, Min=-1.1956, Median=0.1397, Mean=0.0948\n",
      "\n",
      "Epoch [7/1000], Training Loss: 1.7395\n",
      "Epoch [7/1000], Validation Loss: 1.6810, Validation Accuracy: 31.95%\n",
      "Output Summary: Max=1.4208, Min=-1.3932, Median=0.1120, Mean=0.0955\n",
      "\n",
      "Epoch [8/1000], Training Loss: 1.7300\n",
      "Epoch [8/1000], Validation Loss: 1.7793, Validation Accuracy: 27.35%\n",
      "Output Summary: Max=1.5246, Min=-1.6036, Median=0.1645, Mean=0.1578\n",
      "\n",
      "Epoch [9/1000], Training Loss: 1.6829\n",
      "Epoch [9/1000], Validation Loss: 1.6000, Validation Accuracy: 35.94%\n",
      "Output Summary: Max=1.9982, Min=-1.7768, Median=0.0760, Mean=0.1306\n",
      "\n",
      "Epoch [10/1000], Training Loss: 1.5668\n",
      "Epoch [10/1000], Validation Loss: 1.5220, Validation Accuracy: 40.92%\n",
      "Output Summary: Max=2.2126, Min=-1.9380, Median=0.0762, Mean=0.1263\n",
      "\n",
      "Epoch [11/1000], Training Loss: 1.4729\n",
      "Epoch [11/1000], Validation Loss: 1.4363, Validation Accuracy: 43.84%\n",
      "Output Summary: Max=2.4421, Min=-2.1081, Median=0.0564, Mean=0.1192\n",
      "\n",
      "Epoch [12/1000], Training Loss: 1.4049\n",
      "Epoch [12/1000], Validation Loss: 1.3893, Validation Accuracy: 45.34%\n",
      "Output Summary: Max=2.7125, Min=-2.2676, Median=0.0344, Mean=0.1237\n",
      "\n",
      "Epoch [13/1000], Training Loss: 1.3545\n",
      "Epoch [13/1000], Validation Loss: 1.3226, Validation Accuracy: 49.86%\n",
      "Output Summary: Max=2.9949, Min=-2.4485, Median=0.0238, Mean=0.1335\n",
      "\n",
      "Epoch [14/1000], Training Loss: 1.3326\n",
      "Epoch [14/1000], Validation Loss: 1.4384, Validation Accuracy: 43.67%\n",
      "Output Summary: Max=3.2529, Min=-2.5551, Median=-0.0348, Mean=0.0939\n",
      "\n",
      "Epoch [15/1000], Training Loss: 1.3602\n",
      "Epoch [15/1000], Validation Loss: 1.3189, Validation Accuracy: 46.83%\n",
      "Output Summary: Max=3.5174, Min=-2.6516, Median=-0.0522, Mean=0.1137\n",
      "\n",
      "Epoch [16/1000], Training Loss: 1.2651\n",
      "Epoch [16/1000], Validation Loss: 1.2504, Validation Accuracy: 50.05%\n",
      "Output Summary: Max=3.6601, Min=-2.7208, Median=0.0041, Mean=0.1407\n",
      "\n",
      "Epoch [17/1000], Training Loss: 1.2101\n",
      "Epoch [17/1000], Validation Loss: 1.1980, Validation Accuracy: 55.69%\n",
      "Output Summary: Max=3.7662, Min=-2.8144, Median=-0.0031, Mean=0.1292\n",
      "\n",
      "Epoch [18/1000], Training Loss: 1.1658\n",
      "Epoch [18/1000], Validation Loss: 1.1563, Validation Accuracy: 60.79%\n",
      "Output Summary: Max=3.8695, Min=-2.9148, Median=0.0211, Mean=0.1318\n",
      "\n",
      "Epoch [19/1000], Training Loss: 1.1387\n",
      "Epoch [19/1000], Validation Loss: 1.1461, Validation Accuracy: 60.45%\n",
      "Output Summary: Max=3.9882, Min=-3.0370, Median=-0.0268, Mean=0.1559\n",
      "\n",
      "Epoch [20/1000], Training Loss: 1.1159\n",
      "Epoch [20/1000], Validation Loss: 1.0952, Validation Accuracy: 63.41%\n",
      "Output Summary: Max=4.1196, Min=-3.1297, Median=0.0498, Mean=0.1520\n",
      "\n",
      "Epoch [21/1000], Training Loss: 1.0663\n",
      "Epoch [21/1000], Validation Loss: 1.0655, Validation Accuracy: 63.50%\n",
      "Output Summary: Max=4.2195, Min=-3.2639, Median=0.0020, Mean=0.1636\n",
      "\n",
      "Epoch [22/1000], Training Loss: 1.0736\n",
      "Epoch [22/1000], Validation Loss: 1.1013, Validation Accuracy: 59.48%\n",
      "Output Summary: Max=4.2843, Min=-3.3311, Median=-0.0725, Mean=0.1554\n",
      "\n",
      "Epoch [23/1000], Training Loss: 1.1512\n",
      "Epoch [23/1000], Validation Loss: 1.1007, Validation Accuracy: 58.29%\n",
      "Output Summary: Max=4.4816, Min=-3.2311, Median=-0.0792, Mean=0.1666\n",
      "\n",
      "Epoch [24/1000], Training Loss: 1.0448\n",
      "Epoch [24/1000], Validation Loss: 1.0206, Validation Accuracy: 65.40%\n",
      "Output Summary: Max=4.5068, Min=-3.3901, Median=-0.0239, Mean=0.1749\n",
      "\n",
      "Epoch [25/1000], Training Loss: 0.9858\n",
      "Epoch [25/1000], Validation Loss: 0.9761, Validation Accuracy: 66.93%\n",
      "Output Summary: Max=4.5130, Min=-3.5126, Median=-0.0216, Mean=0.1756\n",
      "\n",
      "Epoch [26/1000], Training Loss: 0.9477\n",
      "Epoch [26/1000], Validation Loss: 0.9422, Validation Accuracy: 68.35%\n",
      "Output Summary: Max=4.5864, Min=-3.6043, Median=-0.0450, Mean=0.1802\n",
      "\n",
      "Epoch [27/1000], Training Loss: 0.9203\n",
      "Epoch [27/1000], Validation Loss: 0.9233, Validation Accuracy: 68.43%\n",
      "Output Summary: Max=4.6861, Min=-3.7060, Median=-0.0115, Mean=0.1919\n",
      "\n",
      "Epoch [28/1000], Training Loss: 0.9230\n",
      "Epoch [28/1000], Validation Loss: 0.9176, Validation Accuracy: 68.22%\n",
      "Output Summary: Max=4.8000, Min=-3.7035, Median=-0.0392, Mean=0.1899\n",
      "\n",
      "Epoch [29/1000], Training Loss: 0.9059\n",
      "Epoch [29/1000], Validation Loss: 0.9257, Validation Accuracy: 67.41%\n",
      "Output Summary: Max=4.9482, Min=-3.7520, Median=-0.0811, Mean=0.1782\n",
      "\n",
      "Epoch [30/1000], Training Loss: 0.8866\n",
      "Epoch [30/1000], Validation Loss: 0.8778, Validation Accuracy: 68.87%\n",
      "Output Summary: Max=5.0675, Min=-3.8470, Median=-0.0060, Mean=0.1937\n",
      "\n",
      "Epoch [31/1000], Training Loss: 0.8510\n",
      "Epoch [31/1000], Validation Loss: 0.8597, Validation Accuracy: 70.05%\n",
      "Output Summary: Max=5.1166, Min=-3.7754, Median=0.0091, Mean=0.2069\n",
      "\n",
      "Epoch [32/1000], Training Loss: 0.8309\n",
      "Epoch [32/1000], Validation Loss: 0.8373, Validation Accuracy: 71.04%\n",
      "Output Summary: Max=5.1932, Min=-3.8610, Median=-0.0019, Mean=0.2026\n",
      "\n",
      "Epoch [33/1000], Training Loss: 0.8157\n",
      "Epoch [33/1000], Validation Loss: 0.8326, Validation Accuracy: 70.79%\n",
      "Output Summary: Max=5.2609, Min=-3.9987, Median=0.0236, Mean=0.2225\n",
      "\n",
      "Epoch [34/1000], Training Loss: 0.8125\n",
      "Epoch [34/1000], Validation Loss: 0.8560, Validation Accuracy: 68.57%\n",
      "Output Summary: Max=5.3859, Min=-4.1149, Median=-0.0439, Mean=0.2185\n",
      "\n",
      "Epoch [35/1000], Training Loss: 0.8016\n",
      "Epoch [35/1000], Validation Loss: 0.8092, Validation Accuracy: 71.30%\n",
      "Output Summary: Max=5.4442, Min=-4.0001, Median=-0.0499, Mean=0.2073\n",
      "\n",
      "Epoch [36/1000], Training Loss: 0.7766\n",
      "Epoch [36/1000], Validation Loss: 0.7969, Validation Accuracy: 70.89%\n",
      "Output Summary: Max=5.5114, Min=-4.3279, Median=-0.0601, Mean=0.2046\n",
      "\n",
      "Epoch [37/1000], Training Loss: 0.7797\n",
      "Epoch [37/1000], Validation Loss: 0.7948, Validation Accuracy: 71.44%\n",
      "Output Summary: Max=5.5440, Min=-4.0269, Median=-0.0484, Mean=0.2081\n",
      "\n",
      "Epoch [38/1000], Training Loss: 0.7809\n",
      "Epoch [38/1000], Validation Loss: 0.7931, Validation Accuracy: 71.54%\n",
      "Output Summary: Max=5.5239, Min=-4.0452, Median=-0.0804, Mean=0.2144\n",
      "\n",
      "Epoch [39/1000], Training Loss: 0.7629\n",
      "Epoch [39/1000], Validation Loss: 0.7779, Validation Accuracy: 70.75%\n",
      "Output Summary: Max=5.5641, Min=-4.3051, Median=-0.0994, Mean=0.2030\n",
      "\n",
      "Epoch [40/1000], Training Loss: 0.7529\n",
      "Epoch [40/1000], Validation Loss: 0.7667, Validation Accuracy: 72.83%\n",
      "Output Summary: Max=5.5762, Min=-3.9628, Median=-0.0493, Mean=0.2297\n",
      "\n",
      "Epoch [41/1000], Training Loss: 0.7567\n",
      "Epoch [41/1000], Validation Loss: 0.7703, Validation Accuracy: 72.60%\n",
      "Output Summary: Max=5.6897, Min=-4.0195, Median=-0.0533, Mean=0.2323\n",
      "\n",
      "Epoch [42/1000], Training Loss: 0.7456\n",
      "Epoch [42/1000], Validation Loss: 0.7676, Validation Accuracy: 72.37%\n",
      "Output Summary: Max=5.8996, Min=-4.3183, Median=-0.0356, Mean=0.2183\n",
      "\n",
      "Epoch [43/1000], Training Loss: 0.7345\n",
      "Epoch [43/1000], Validation Loss: 0.7513, Validation Accuracy: 72.89%\n",
      "Output Summary: Max=6.0042, Min=-4.2381, Median=-0.0564, Mean=0.2159\n",
      "\n",
      "Epoch [44/1000], Training Loss: 0.7288\n",
      "Epoch [44/1000], Validation Loss: 0.7500, Validation Accuracy: 73.30%\n",
      "Output Summary: Max=6.0308, Min=-4.1945, Median=-0.1174, Mean=0.2055\n",
      "\n",
      "Epoch [45/1000], Training Loss: 0.7359\n",
      "Epoch [45/1000], Validation Loss: 0.7525, Validation Accuracy: 72.47%\n",
      "Output Summary: Max=6.0730, Min=-4.2256, Median=-0.0865, Mean=0.2145\n",
      "\n",
      "Epoch [46/1000], Training Loss: 0.7270\n",
      "Epoch [46/1000], Validation Loss: 0.7398, Validation Accuracy: 72.67%\n",
      "Output Summary: Max=6.1638, Min=-4.3035, Median=-0.0835, Mean=0.2175\n",
      "\n",
      "Epoch [47/1000], Training Loss: 0.7099\n",
      "Epoch [47/1000], Validation Loss: 0.7513, Validation Accuracy: 72.45%\n",
      "Output Summary: Max=6.1679, Min=-4.2957, Median=-0.0304, Mean=0.2339\n",
      "\n",
      "Epoch [48/1000], Training Loss: 0.7170\n",
      "Epoch [48/1000], Validation Loss: 0.7388, Validation Accuracy: 73.38%\n",
      "Output Summary: Max=6.2181, Min=-4.4290, Median=-0.1445, Mean=0.2111\n",
      "\n",
      "Epoch [49/1000], Training Loss: 0.7083\n",
      "Epoch [49/1000], Validation Loss: 0.7205, Validation Accuracy: 73.66%\n",
      "Output Summary: Max=6.2605, Min=-4.2910, Median=-0.1544, Mean=0.2011\n",
      "\n",
      "Epoch [50/1000], Training Loss: 0.6969\n",
      "Epoch [50/1000], Validation Loss: 0.7372, Validation Accuracy: 72.71%\n",
      "Output Summary: Max=6.2487, Min=-4.3158, Median=-0.1753, Mean=0.2094\n",
      "\n",
      "Epoch [51/1000], Training Loss: 0.6987\n",
      "Epoch [51/1000], Validation Loss: 0.7174, Validation Accuracy: 73.92%\n",
      "Output Summary: Max=6.2087, Min=-4.3205, Median=-0.1671, Mean=0.2105\n",
      "\n",
      "Epoch [52/1000], Training Loss: 0.6883\n",
      "Epoch [52/1000], Validation Loss: 0.7179, Validation Accuracy: 73.81%\n",
      "Output Summary: Max=6.1827, Min=-4.4404, Median=-0.2284, Mean=0.2028\n",
      "\n",
      "Epoch [53/1000], Training Loss: 0.6810\n",
      "Epoch [53/1000], Validation Loss: 0.7018, Validation Accuracy: 74.90%\n",
      "Output Summary: Max=6.1273, Min=-4.5651, Median=-0.1917, Mean=0.2115\n",
      "\n",
      "Epoch [54/1000], Training Loss: 0.7055\n",
      "Epoch [54/1000], Validation Loss: 0.7190, Validation Accuracy: 73.70%\n",
      "Output Summary: Max=6.1585, Min=-4.4206, Median=-0.2588, Mean=0.1940\n",
      "\n",
      "Epoch [55/1000], Training Loss: 0.6843\n",
      "Epoch [55/1000], Validation Loss: 0.7002, Validation Accuracy: 74.22%\n",
      "Output Summary: Max=6.2137, Min=-4.4321, Median=-0.1829, Mean=0.2123\n",
      "\n",
      "Epoch [56/1000], Training Loss: 0.6734\n",
      "Epoch [56/1000], Validation Loss: 0.6997, Validation Accuracy: 74.55%\n",
      "Output Summary: Max=6.2552, Min=-4.4476, Median=-0.2207, Mean=0.1957\n",
      "\n",
      "Epoch [57/1000], Training Loss: 0.6788\n",
      "Epoch [57/1000], Validation Loss: 0.7100, Validation Accuracy: 73.96%\n",
      "Output Summary: Max=6.3297, Min=-4.5435, Median=-0.1924, Mean=0.2108\n",
      "\n",
      "Epoch [58/1000], Training Loss: 0.6805\n",
      "Epoch [58/1000], Validation Loss: 0.6943, Validation Accuracy: 74.82%\n",
      "Output Summary: Max=6.3748, Min=-4.4784, Median=-0.1942, Mean=0.2109\n",
      "\n",
      "Epoch [59/1000], Training Loss: 0.6660\n",
      "Epoch [59/1000], Validation Loss: 0.6874, Validation Accuracy: 74.77%\n",
      "Output Summary: Max=6.4636, Min=-4.4634, Median=-0.2136, Mean=0.2057\n",
      "\n",
      "Epoch [60/1000], Training Loss: 0.6607\n",
      "Epoch [60/1000], Validation Loss: 0.6906, Validation Accuracy: 74.71%\n",
      "Output Summary: Max=6.5117, Min=-4.5188, Median=-0.2718, Mean=0.2072\n",
      "\n",
      "Epoch [61/1000], Training Loss: 0.6572\n",
      "Epoch [61/1000], Validation Loss: 0.6761, Validation Accuracy: 75.25%\n",
      "Output Summary: Max=6.5402, Min=-4.5145, Median=-0.2687, Mean=0.2000\n",
      "\n",
      "Epoch [62/1000], Training Loss: 0.6507\n",
      "Epoch [62/1000], Validation Loss: 0.6707, Validation Accuracy: 75.73%\n",
      "Output Summary: Max=6.5147, Min=-4.5908, Median=-0.2973, Mean=0.1972\n",
      "\n",
      "Epoch [63/1000], Training Loss: 0.6385\n",
      "Epoch [63/1000], Validation Loss: 0.6676, Validation Accuracy: 75.19%\n",
      "Output Summary: Max=6.5197, Min=-4.5821, Median=-0.2373, Mean=0.2154\n",
      "\n",
      "Epoch [64/1000], Training Loss: 0.6329\n",
      "Epoch [64/1000], Validation Loss: 0.6673, Validation Accuracy: 75.55%\n",
      "Output Summary: Max=6.5098, Min=-4.6752, Median=-0.2756, Mean=0.1966\n",
      "\n",
      "Epoch [65/1000], Training Loss: 0.6324\n",
      "Epoch [65/1000], Validation Loss: 0.6836, Validation Accuracy: 74.82%\n",
      "Output Summary: Max=6.4981, Min=-4.6796, Median=-0.1825, Mean=0.2153\n",
      "\n",
      "Epoch [66/1000], Training Loss: 0.6683\n",
      "Epoch [66/1000], Validation Loss: 0.6657, Validation Accuracy: 75.09%\n",
      "Output Summary: Max=6.5726, Min=-4.6463, Median=-0.2610, Mean=0.2116\n",
      "\n",
      "Epoch [67/1000], Training Loss: 0.6523\n",
      "Epoch [67/1000], Validation Loss: 0.6966, Validation Accuracy: 74.75%\n",
      "Output Summary: Max=6.5946, Min=-4.6585, Median=-0.2967, Mean=0.2065\n",
      "\n",
      "Epoch [68/1000], Training Loss: 0.6586\n",
      "Epoch [68/1000], Validation Loss: 0.6683, Validation Accuracy: 75.11%\n",
      "Output Summary: Max=6.6159, Min=-4.7110, Median=-0.2415, Mean=0.2166\n",
      "\n",
      "Epoch [69/1000], Training Loss: 0.6443\n",
      "Epoch [69/1000], Validation Loss: 0.6788, Validation Accuracy: 75.35%\n",
      "Output Summary: Max=6.6772, Min=-4.8284, Median=-0.3405, Mean=0.1876\n",
      "\n",
      "Epoch [70/1000], Training Loss: 0.6362\n",
      "Epoch [70/1000], Validation Loss: 0.6643, Validation Accuracy: 75.74%\n",
      "Output Summary: Max=6.6808, Min=-4.8277, Median=-0.2775, Mean=0.2103\n",
      "\n",
      "Epoch [71/1000], Training Loss: 0.6265\n",
      "Epoch [71/1000], Validation Loss: 0.6804, Validation Accuracy: 74.88%\n",
      "Output Summary: Max=6.6896, Min=-4.7208, Median=-0.1610, Mean=0.2317\n",
      "\n",
      "Epoch [72/1000], Training Loss: 0.6337\n",
      "Epoch [72/1000], Validation Loss: 0.6488, Validation Accuracy: 76.15%\n",
      "Output Summary: Max=6.7159, Min=-4.8028, Median=-0.2551, Mean=0.2102\n",
      "\n",
      "Epoch [73/1000], Training Loss: 0.6116\n",
      "Epoch [73/1000], Validation Loss: 0.6425, Validation Accuracy: 76.22%\n",
      "Output Summary: Max=6.7276, Min=-4.7799, Median=-0.2423, Mean=0.2117\n",
      "\n",
      "Epoch [74/1000], Training Loss: 0.6086\n",
      "Epoch [74/1000], Validation Loss: 0.6439, Validation Accuracy: 76.47%\n",
      "Output Summary: Max=6.8173, Min=-4.9255, Median=-0.2519, Mean=0.1988\n",
      "\n",
      "Epoch [75/1000], Training Loss: 0.6066\n",
      "Epoch [75/1000], Validation Loss: 0.6373, Validation Accuracy: 76.58%\n",
      "Output Summary: Max=6.8955, Min=-4.7929, Median=-0.2491, Mean=0.2007\n",
      "\n",
      "Epoch [76/1000], Training Loss: 0.5987\n",
      "Epoch [76/1000], Validation Loss: 0.6283, Validation Accuracy: 76.96%\n",
      "Output Summary: Max=6.8775, Min=-4.7277, Median=-0.2011, Mean=0.2120\n",
      "\n",
      "Epoch [77/1000], Training Loss: 0.6072\n",
      "Epoch [77/1000], Validation Loss: 0.6598, Validation Accuracy: 75.51%\n",
      "Output Summary: Max=6.9124, Min=-4.9634, Median=-0.3076, Mean=0.1963\n",
      "\n",
      "Epoch [78/1000], Training Loss: 0.6225\n",
      "Epoch [78/1000], Validation Loss: 0.6468, Validation Accuracy: 75.73%\n",
      "Output Summary: Max=7.0324, Min=-4.7343, Median=-0.2000, Mean=0.2155\n",
      "\n",
      "Epoch [79/1000], Training Loss: 0.6107\n",
      "Epoch [79/1000], Validation Loss: 0.6407, Validation Accuracy: 76.59%\n",
      "Output Summary: Max=6.9610, Min=-4.7623, Median=-0.2032, Mean=0.2247\n",
      "\n",
      "Epoch [80/1000], Training Loss: 0.6243\n",
      "Epoch [80/1000], Validation Loss: 0.6471, Validation Accuracy: 75.74%\n",
      "Output Summary: Max=7.0436, Min=-4.8355, Median=-0.1294, Mean=0.2256\n",
      "\n",
      "Epoch [81/1000], Training Loss: 0.6035\n",
      "Epoch [81/1000], Validation Loss: 0.6319, Validation Accuracy: 76.11%\n",
      "Output Summary: Max=7.1012, Min=-4.8464, Median=-0.2798, Mean=0.2083\n",
      "\n",
      "Epoch [82/1000], Training Loss: 0.5969\n",
      "Epoch [82/1000], Validation Loss: 0.6189, Validation Accuracy: 77.34%\n",
      "Output Summary: Max=7.0929, Min=-4.7329, Median=-0.2329, Mean=0.2027\n",
      "\n",
      "Epoch [83/1000], Training Loss: 0.5928\n",
      "Epoch [83/1000], Validation Loss: 0.6594, Validation Accuracy: 75.12%\n",
      "Output Summary: Max=7.1269, Min=-5.0104, Median=-0.3147, Mean=0.1894\n",
      "\n",
      "Epoch [84/1000], Training Loss: 0.6019\n",
      "Epoch [84/1000], Validation Loss: 0.6160, Validation Accuracy: 77.47%\n",
      "Output Summary: Max=7.1045, Min=-4.7335, Median=-0.2180, Mean=0.2115\n",
      "\n",
      "Epoch [85/1000], Training Loss: 0.5869\n",
      "Epoch [85/1000], Validation Loss: 0.6081, Validation Accuracy: 77.22%\n",
      "Output Summary: Max=7.1421, Min=-4.8780, Median=-0.2719, Mean=0.1981\n",
      "\n",
      "Epoch [86/1000], Training Loss: 0.5763\n",
      "Epoch [86/1000], Validation Loss: 0.6021, Validation Accuracy: 77.99%\n",
      "Output Summary: Max=7.2015, Min=-4.7787, Median=-0.2536, Mean=0.1973\n",
      "\n",
      "Epoch [87/1000], Training Loss: 0.5800\n",
      "Epoch [87/1000], Validation Loss: 0.6154, Validation Accuracy: 76.74%\n",
      "Output Summary: Max=7.2614, Min=-4.9629, Median=-0.3079, Mean=0.1901\n",
      "\n",
      "Epoch [88/1000], Training Loss: 0.5737\n",
      "Epoch [88/1000], Validation Loss: 0.6039, Validation Accuracy: 78.01%\n",
      "Output Summary: Max=7.2430, Min=-4.8061, Median=-0.2249, Mean=0.2041\n",
      "\n",
      "Epoch [89/1000], Training Loss: 0.6002\n",
      "Epoch [89/1000], Validation Loss: 0.6349, Validation Accuracy: 76.42%\n",
      "Output Summary: Max=7.3232, Min=-5.0843, Median=-0.1670, Mean=0.1988\n",
      "\n",
      "Epoch [90/1000], Training Loss: 0.5868\n",
      "Epoch [90/1000], Validation Loss: 0.6152, Validation Accuracy: 77.69%\n",
      "Output Summary: Max=7.4692, Min=-4.8890, Median=-0.1439, Mean=0.2081\n",
      "\n",
      "Epoch [91/1000], Training Loss: 0.5747\n",
      "Epoch [91/1000], Validation Loss: 0.5936, Validation Accuracy: 77.71%\n",
      "Output Summary: Max=7.5078, Min=-5.0468, Median=-0.2062, Mean=0.1917\n",
      "\n",
      "Epoch [92/1000], Training Loss: 0.5640\n",
      "Epoch [92/1000], Validation Loss: 0.6012, Validation Accuracy: 77.99%\n",
      "Output Summary: Max=7.5353, Min=-4.9632, Median=-0.2099, Mean=0.1911\n",
      "\n",
      "Epoch [93/1000], Training Loss: 0.5700\n",
      "Epoch [93/1000], Validation Loss: 0.6013, Validation Accuracy: 77.66%\n",
      "Output Summary: Max=7.5875, Min=-4.8950, Median=-0.1779, Mean=0.2074\n",
      "\n",
      "Epoch [94/1000], Training Loss: 0.5568\n",
      "Epoch [94/1000], Validation Loss: 0.5918, Validation Accuracy: 77.88%\n",
      "Output Summary: Max=7.6136, Min=-4.9984, Median=-0.2187, Mean=0.1995\n",
      "\n",
      "Epoch [95/1000], Training Loss: 0.5550\n",
      "Epoch [95/1000], Validation Loss: 0.5897, Validation Accuracy: 78.23%\n",
      "Output Summary: Max=7.6480, Min=-5.0251, Median=-0.2578, Mean=0.1915\n",
      "\n",
      "Epoch [96/1000], Training Loss: 0.5528\n",
      "Epoch [96/1000], Validation Loss: 0.5834, Validation Accuracy: 78.56%\n",
      "Output Summary: Max=7.6297, Min=-5.0576, Median=-0.2330, Mean=0.1908\n",
      "\n",
      "Epoch [97/1000], Training Loss: 0.5499\n",
      "Epoch [97/1000], Validation Loss: 0.5851, Validation Accuracy: 78.34%\n",
      "Output Summary: Max=7.6337, Min=-5.0323, Median=-0.2254, Mean=0.2011\n",
      "\n",
      "Epoch [98/1000], Training Loss: 0.5527\n",
      "Epoch [98/1000], Validation Loss: 0.5973, Validation Accuracy: 78.00%\n",
      "Output Summary: Max=7.6090, Min=-5.1195, Median=-0.2429, Mean=0.2096\n",
      "\n",
      "Epoch [99/1000], Training Loss: 0.5591\n",
      "Epoch [99/1000], Validation Loss: 0.6090, Validation Accuracy: 76.89%\n",
      "Output Summary: Max=7.5946, Min=-5.1502, Median=-0.2791, Mean=0.1886\n",
      "\n",
      "Epoch [100/1000], Training Loss: 0.5529\n",
      "Epoch [100/1000], Validation Loss: 0.5919, Validation Accuracy: 77.77%\n",
      "Output Summary: Max=7.6077, Min=-5.1354, Median=-0.2790, Mean=0.1861\n",
      "\n",
      "Epoch [101/1000], Training Loss: 0.5544\n",
      "Epoch [101/1000], Validation Loss: 0.5775, Validation Accuracy: 79.01%\n",
      "Output Summary: Max=7.6447, Min=-5.1646, Median=-0.2676, Mean=0.1890\n",
      "\n",
      "Epoch [102/1000], Training Loss: 0.5412\n",
      "Epoch [102/1000], Validation Loss: 0.5697, Validation Accuracy: 79.07%\n",
      "Output Summary: Max=7.6278, Min=-5.2783, Median=-0.2696, Mean=0.1914\n",
      "\n",
      "Epoch [103/1000], Training Loss: 0.5334\n",
      "Epoch [103/1000], Validation Loss: 0.5681, Validation Accuracy: 79.00%\n",
      "Output Summary: Max=7.6621, Min=-5.2196, Median=-0.2565, Mean=0.1986\n",
      "\n",
      "Epoch [104/1000], Training Loss: 0.5342\n",
      "Epoch [104/1000], Validation Loss: 0.5779, Validation Accuracy: 78.47%\n",
      "Output Summary: Max=7.7115, Min=-5.3512, Median=-0.2047, Mean=0.2066\n",
      "\n",
      "Epoch [105/1000], Training Loss: 0.5349\n",
      "Epoch [105/1000], Validation Loss: 0.5855, Validation Accuracy: 78.42%\n",
      "Output Summary: Max=7.7496, Min=-5.3058, Median=-0.2507, Mean=0.2067\n",
      "\n",
      "Epoch [106/1000], Training Loss: 0.5385\n",
      "Epoch [106/1000], Validation Loss: 0.5585, Validation Accuracy: 79.61%\n",
      "Output Summary: Max=7.7824, Min=-5.2198, Median=-0.2914, Mean=0.1827\n",
      "\n",
      "Epoch [107/1000], Training Loss: 0.5317\n",
      "Epoch [107/1000], Validation Loss: 0.5720, Validation Accuracy: 78.66%\n",
      "Output Summary: Max=7.7761, Min=-5.3047, Median=-0.2946, Mean=0.1904\n",
      "\n",
      "Epoch [108/1000], Training Loss: 0.5303\n",
      "Epoch [108/1000], Validation Loss: 0.5687, Validation Accuracy: 79.01%\n",
      "Output Summary: Max=7.8324, Min=-5.2851, Median=-0.2735, Mean=0.1962\n",
      "\n",
      "Epoch [109/1000], Training Loss: 0.5264\n",
      "Epoch [109/1000], Validation Loss: 0.5631, Validation Accuracy: 79.35%\n",
      "Output Summary: Max=7.8587, Min=-5.3478, Median=-0.3306, Mean=0.1781\n",
      "\n",
      "Epoch [110/1000], Training Loss: 0.5246\n",
      "Epoch [110/1000], Validation Loss: 0.5614, Validation Accuracy: 79.31%\n",
      "Output Summary: Max=7.8379, Min=-5.4437, Median=-0.3054, Mean=0.1780\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m     12\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m data, target \u001b[38;5;129;01min\u001b[39;00m get_batches(train_data, train_targets, batch_size):\n\u001b[32m     13\u001b[39m     optimizer.zero_grad()\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m     output = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m     loss = criterion(output, target)\n\u001b[32m     16\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 13\u001b[39m, in \u001b[36mMNIST2DLSTMClassifier.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     11\u001b[39m x = x.permute(\u001b[32m0\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m1\u001b[39m).contiguous()\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# run the 2D‐LSTM\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m h = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmdlstm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m                \u001b[38;5;66;03m# → (B, H, W, hidden_size)\u001b[39;00m\n\u001b[32m     14\u001b[39m \u001b[38;5;66;03m# global average pool over all H×W cells\u001b[39;00m\n\u001b[32m     15\u001b[39m final_state = h[:, -\u001b[32m1\u001b[39m, -\u001b[32m1\u001b[39m, :].clone()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[79]\u001b[39m\u001b[32m, line 86\u001b[39m, in \u001b[36mMDLSTM.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m     83\u001b[39m     h2 = torch.zeros(B, \u001b[38;5;28mself\u001b[39m.hidden_size, device=device)\n\u001b[32m     84\u001b[39m     c2 = torch.zeros(B, \u001b[38;5;28mself\u001b[39m.hidden_size, device=device)\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m h_ij, c_ij = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcell\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_ij\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mh2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     88\u001b[39m h_row.append(h_ij)\n\u001b[32m     89\u001b[39m c_row.append(c_ij)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "patience = 1000\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb722e18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
