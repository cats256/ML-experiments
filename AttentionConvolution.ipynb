{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "200a22b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix attention to more closely mimic standard or GPT transformer block "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "6832cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class TransformerBlock(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        # self.norm1 = nn.LayerNorm(dim)\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=dim, num_heads=1, batch_first=True)\n",
    "\n",
    "        # self.norm2 = nn.LayerNorm(dim)\n",
    "\n",
    "        # hidden_dim = int(dim * 4)\n",
    "        # self.mlp = nn.Sequential(\n",
    "        #     nn.Linear(dim, hidden_dim),\n",
    "        #     nn.GELU(),\n",
    "        #     nn.Linear(hidden_dim, dim),\n",
    "        # )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (B*L, 5, C)\n",
    "        \n",
    "        # Attention block\n",
    "        # x_norm = self.norm1(x)\n",
    "        # attn_output, _ = self.attn(x_norm, x_norm, x_norm)  # self-attention\n",
    "        # x = x + attn_output  # residual\n",
    "\n",
    "        # # MLP block\n",
    "        # x_norm = self.norm2(x)\n",
    "        # x = x + self.mlp(x_norm)  # residual\n",
    "\n",
    "        # return x\n",
    "\n",
    "        attn_output, _ = self.attn(x, x, x)  # self-attention\n",
    "        return attn_output\n",
    "\n",
    "class AttentionTanhConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, patch_size=2):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = in_channels\n",
    "\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=in_channels, num_heads=1, batch_first=True)\n",
    "        self.pos_embed = nn.Parameter(torch.randn(4, in_channels))\n",
    "        self.stride_embed = nn.Parameter(torch.randn(4, in_channels))\n",
    "\n",
    "        self.summary_token = nn.Parameter(torch.randn(1, in_channels))\n",
    "        self.blocks = nn.ModuleList([\n",
    "            TransformerBlock(dim=in_channels)\n",
    "            for _ in range(1)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x, stride=1, patch_size=2):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Unfold to get 2x2 patches: shape (B, C*4, L) where L = num patches\n",
    "        patches = F.unfold(x, kernel_size=patch_size, stride=stride)\n",
    "        L = patches.shape[-1]\n",
    "        \n",
    "        # Reshape to (B, L, 4, C)\n",
    "        patches = patches.transpose(1, 2).reshape(B, L, patch_size * patch_size, C)\n",
    "        \n",
    "        # (B*L, 4, C) for attention\n",
    "        tokens = patches.reshape(B * L, 4, C)\n",
    "        tokens = tokens + self.pos_embed.unsqueeze(0)\n",
    "\n",
    "        if stride == 2:\n",
    "            tokens = tokens + self.stride_embed\n",
    "\n",
    "        # Append summary token: (B*L, 5, C)\n",
    "        summary = self.summary_token.expand(B * L, 1, C)\n",
    "        tokens = torch.cat([summary, tokens], dim=1)\n",
    "\n",
    "        for block in self.blocks:\n",
    "            tokens = block(tokens)  # Each block does LayerNorm + Attention + MLP + Residual\n",
    "\n",
    "        # Extract the summary output: (B*L, C)\n",
    "        out = tokens[:, 0, :]\n",
    "        \n",
    "        # Reshape to (B, out_channels, H_out, W_out)\n",
    "        H_out = (H - patch_size) // stride + 1\n",
    "        W_out = (W - patch_size) // stride + 1\n",
    "        out = out.view(B, H_out, W_out, self.out_channels).permute(0, 3, 1, 2)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "f0a886df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f94be421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5fa4979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "afcd05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset.data.to(device).float() / 255.0\n",
    "train_targets = train_dataset.targets.to(device)\n",
    "\n",
    "test_data = test_dataset.data.to(device).float() / 255.0\n",
    "test_targets = test_dataset.targets.to(device)\n",
    "\n",
    "train_data = train_data.unsqueeze(1)\n",
    "test_data = test_data.unsqueeze(1)\n",
    "\n",
    "def get_batches(data, targets, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size], targets[i:i + batch_size]\n",
    "\n",
    "batch_size = 1000\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "34a85092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTAttentionGRUCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=2, stride=2, padding=1)\n",
    "        # self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=2, padding=1)\n",
    "        # self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        # self.weights = nn.Parameter(torch.randn(16, 1, 1))\n",
    "        # self.channel_projector = nn.Conv2d(in_channels=1, out_channels=8, kernel_size=1)\n",
    "        self.attn_gru_conv = AttentionTanhConv2d(in_channels=16, patch_size=2)\n",
    "        # self.fc1 = nn.Linear(16, 10)\n",
    "        # self.fc2 = nn.Linear(7 * 7 * 16, 10)\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 16, kernel_size=2, stride=2, padding=1)  # 28x28 -> 15x15\n",
    "        self.conv2 = nn.Conv2d(16, 16, kernel_size=3, stride=2, padding=1) # 15x15 -> 8x8\n",
    "        # self.conv3 = nn.Conv2d(16, 16, kernel_size=4, stride=1, padding=1) # 8x8   -> 7x7\n",
    "        # self.conv3 = nn.Conv2d(16, 16, kernel_size=2, stride=1, padding=0) # 8x8   -> 7x7\n",
    "        self.conv4 = nn.Conv2d(16, 16, kernel_size=5, stride=1, padding=1) # 7x7   -> 5x5\n",
    "        self.conv5 = nn.Conv2d(16, 16, kernel_size=5, stride=1, padding=0) # 5x5   -> 1x1\n",
    "\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.fc1 = nn.Linear(16, 10)\n",
    "\n",
    "    def forward(self, x): # (B, 1, 28, 28)\n",
    "        x = self.relu(self.conv1(x))\n",
    "        x = self.relu(self.conv2(x))\n",
    "        # x = self.relu(self.conv3(x))\n",
    "        x = self.attn_gru_conv(x)\n",
    "        x = x.contiguous()\n",
    "        x = self.relu(self.conv4(x))\n",
    "        x = self.relu(self.conv5(x))\n",
    "\n",
    "        # x = self.channel_projector(x)\n",
    "        # x = F.relu(x)\n",
    "\n",
    "        # x = self.attn_gru_conv(x, 2) # (B, ... , 14)\n",
    "        # x2 = self.attn_gru_conv(x, 2) # (B, ... , 7)\n",
    "        # x = self.attn_gru_conv(x2, 1) # (B, ... , 6)\n",
    "        # x = self.attn_gru_conv(x, 2) # (B, ... , 3)\n",
    "        # x = self.attn_gru_conv(x, 1) # (B, ... , 2)\n",
    "        # x = self.attn_gru_conv(x, 1) # (B, ... , 1)\n",
    "\n",
    "        # x = self.conv1(x) # (B, 16, 15, 15)\n",
    "        # x = self.conv2(x) # (B, 16, 8, 8)\n",
    "        # x = self.conv3(x) # (B, 16, 5, 5)\n",
    "        # x = self.attn_gru_conv(x) # (B, 16, 4, 4)\n",
    "        # x = self.attn_gru_conv(x) # (B, 16, 3, 3)\n",
    "        # x = self.attn_gru_conv(x) # (B, 16, 2, 2)\n",
    "        # x = self.attn_gru_conv(x) # (B, 16, 1, 1)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = x.reshape(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "d812474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 * 1\n",
    "epochs = 500\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = MNISTAttentionGRUCNN().to(device)\n",
    "# model = torch.compile(MNIST2DLSTMClassifier()).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d7ebaf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_gru_conv.pos_embed: 64 params, requires_grad=True\n",
      "attn_gru_conv.stride_embed: 64 params, requires_grad=True\n",
      "attn_gru_conv.summary_token: 16 params, requires_grad=True\n",
      "attn_gru_conv.attn.in_proj_weight: 768 params, requires_grad=True\n",
      "attn_gru_conv.attn.in_proj_bias: 48 params, requires_grad=True\n",
      "attn_gru_conv.attn.out_proj.weight: 256 params, requires_grad=True\n",
      "attn_gru_conv.attn.out_proj.bias: 16 params, requires_grad=True\n",
      "attn_gru_conv.blocks.0.attn.in_proj_weight: 768 params, requires_grad=True\n",
      "attn_gru_conv.blocks.0.attn.in_proj_bias: 48 params, requires_grad=True\n",
      "attn_gru_conv.blocks.0.attn.out_proj.weight: 256 params, requires_grad=True\n",
      "attn_gru_conv.blocks.0.attn.out_proj.bias: 16 params, requires_grad=True\n",
      "conv1.weight: 64 params, requires_grad=True\n",
      "conv1.bias: 16 params, requires_grad=True\n",
      "conv2.weight: 2304 params, requires_grad=True\n",
      "conv2.bias: 16 params, requires_grad=True\n",
      "conv4.weight: 6400 params, requires_grad=True\n",
      "conv4.bias: 16 params, requires_grad=True\n",
      "conv5.weight: 6400 params, requires_grad=True\n",
      "conv5.bias: 16 params, requires_grad=True\n",
      "fc1.weight: 160 params, requires_grad=True\n",
      "fc1.bias: 10 params, requires_grad=True\n",
      "\n",
      "17722\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} params, requires_grad={param.requires_grad}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print()\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8b0a7bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 2.1117\n",
      "Epoch [1/500], Validation Loss: 1.3833, Validation Accuracy: 52.37%\n",
      "Output Summary: Max=8.1235, Min=-12.0908, Median=-0.2159, Mean=-0.2843\n",
      "\n",
      "Epoch [2/500], Training Loss: 0.9710\n",
      "Epoch [2/500], Validation Loss: 0.7537, Validation Accuracy: 72.05%\n",
      "Output Summary: Max=16.1052, Min=-18.1718, Median=-0.6576, Mean=-0.9242\n",
      "\n",
      "Epoch [3/500], Training Loss: 0.6722\n",
      "Epoch [3/500], Validation Loss: 0.6347, Validation Accuracy: 76.07%\n",
      "Output Summary: Max=17.8981, Min=-18.3741, Median=-0.7355, Mean=-1.0063\n",
      "\n",
      "Epoch [4/500], Training Loss: 0.5974\n",
      "Epoch [4/500], Validation Loss: 0.5839, Validation Accuracy: 77.83%\n",
      "Output Summary: Max=19.8420, Min=-19.6280, Median=-0.7308, Mean=-1.0446\n",
      "\n",
      "Epoch [5/500], Training Loss: 0.5491\n",
      "Epoch [5/500], Validation Loss: 0.5402, Validation Accuracy: 79.40%\n",
      "Output Summary: Max=21.4533, Min=-20.2688, Median=-0.9171, Mean=-0.9980\n",
      "\n",
      "Epoch [6/500], Training Loss: 0.5049\n",
      "Epoch [6/500], Validation Loss: 0.5017, Validation Accuracy: 81.42%\n",
      "Output Summary: Max=23.2444, Min=-20.7919, Median=-1.0770, Mean=-1.0178\n",
      "\n",
      "Epoch [7/500], Training Loss: 0.4705\n",
      "Epoch [7/500], Validation Loss: 0.4752, Validation Accuracy: 82.71%\n",
      "Output Summary: Max=23.8525, Min=-21.7822, Median=-1.1619, Mean=-1.0822\n",
      "\n",
      "Epoch [8/500], Training Loss: 0.4441\n",
      "Epoch [8/500], Validation Loss: 0.4564, Validation Accuracy: 83.41%\n",
      "Output Summary: Max=23.6983, Min=-22.7299, Median=-1.1740, Mean=-1.1356\n",
      "\n",
      "Epoch [9/500], Training Loss: 0.4245\n",
      "Epoch [9/500], Validation Loss: 0.4421, Validation Accuracy: 83.78%\n",
      "Output Summary: Max=24.0312, Min=-22.7768, Median=-1.2051, Mean=-1.1408\n",
      "\n",
      "Epoch [10/500], Training Loss: 0.4078\n",
      "Epoch [10/500], Validation Loss: 0.4304, Validation Accuracy: 84.25%\n",
      "Output Summary: Max=25.5376, Min=-22.9905, Median=-1.1918, Mean=-1.1616\n",
      "\n",
      "Epoch [11/500], Training Loss: 0.3951\n",
      "Epoch [11/500], Validation Loss: 0.4221, Validation Accuracy: 84.49%\n",
      "Output Summary: Max=26.6594, Min=-23.3299, Median=-1.1562, Mean=-1.1655\n",
      "\n",
      "Epoch [12/500], Training Loss: 0.3855\n",
      "Epoch [12/500], Validation Loss: 0.4152, Validation Accuracy: 84.81%\n",
      "Output Summary: Max=27.8017, Min=-23.7196, Median=-1.0948, Mean=-1.1654\n",
      "\n",
      "Epoch [13/500], Training Loss: 0.3775\n",
      "Epoch [13/500], Validation Loss: 0.4102, Validation Accuracy: 85.05%\n",
      "Output Summary: Max=28.6316, Min=-23.8701, Median=-1.0364, Mean=-1.1446\n",
      "\n",
      "Epoch [14/500], Training Loss: 0.3708\n",
      "Epoch [14/500], Validation Loss: 0.4052, Validation Accuracy: 85.05%\n",
      "Output Summary: Max=29.5776, Min=-23.9853, Median=-0.9604, Mean=-1.1097\n",
      "\n",
      "Epoch [15/500], Training Loss: 0.3646\n",
      "Epoch [15/500], Validation Loss: 0.4022, Validation Accuracy: 85.25%\n",
      "Output Summary: Max=30.3160, Min=-24.1769, Median=-0.8967, Mean=-1.0891\n",
      "\n",
      "Epoch [16/500], Training Loss: 0.3595\n",
      "Epoch [16/500], Validation Loss: 0.3996, Validation Accuracy: 85.40%\n",
      "Output Summary: Max=30.8710, Min=-24.0457, Median=-0.8700, Mean=-1.0476\n",
      "\n",
      "Epoch [17/500], Training Loss: 0.3547\n",
      "Epoch [17/500], Validation Loss: 0.3973, Validation Accuracy: 85.57%\n",
      "Output Summary: Max=31.4606, Min=-24.1467, Median=-0.8731, Mean=-1.0357\n",
      "\n",
      "Epoch [18/500], Training Loss: 0.3509\n",
      "Epoch [18/500], Validation Loss: 0.3950, Validation Accuracy: 85.75%\n",
      "Output Summary: Max=31.8643, Min=-23.9082, Median=-0.8760, Mean=-1.0278\n",
      "\n",
      "Epoch [19/500], Training Loss: 0.3477\n",
      "Epoch [19/500], Validation Loss: 0.3886, Validation Accuracy: 85.88%\n",
      "Output Summary: Max=32.3791, Min=-23.4799, Median=-0.9118, Mean=-0.9908\n",
      "\n",
      "Epoch [20/500], Training Loss: 0.3439\n",
      "Epoch [20/500], Validation Loss: 0.3824, Validation Accuracy: 86.15%\n",
      "Output Summary: Max=32.9841, Min=-23.0515, Median=-0.9233, Mean=-0.9707\n",
      "\n",
      "Epoch [21/500], Training Loss: 0.3399\n",
      "Epoch [21/500], Validation Loss: 0.3794, Validation Accuracy: 86.34%\n",
      "Output Summary: Max=33.6615, Min=-22.8785, Median=-0.9466, Mean=-0.9786\n",
      "\n",
      "Epoch [22/500], Training Loss: 0.3363\n",
      "Epoch [22/500], Validation Loss: 0.3771, Validation Accuracy: 86.40%\n",
      "Output Summary: Max=34.3180, Min=-22.8395, Median=-0.9609, Mean=-0.9834\n",
      "\n",
      "Epoch [23/500], Training Loss: 0.3334\n",
      "Epoch [23/500], Validation Loss: 0.3748, Validation Accuracy: 86.49%\n",
      "Output Summary: Max=34.9607, Min=-22.9583, Median=-0.9788, Mean=-0.9944\n",
      "\n",
      "Epoch [24/500], Training Loss: 0.3308\n",
      "Epoch [24/500], Validation Loss: 0.3729, Validation Accuracy: 86.40%\n",
      "Output Summary: Max=35.4440, Min=-23.0301, Median=-0.9842, Mean=-1.0159\n",
      "\n",
      "Epoch [25/500], Training Loss: 0.3281\n",
      "Epoch [25/500], Validation Loss: 0.3697, Validation Accuracy: 86.48%\n",
      "Output Summary: Max=35.8770, Min=-23.1402, Median=-0.9968, Mean=-1.0280\n",
      "\n",
      "Epoch [26/500], Training Loss: 0.3250\n",
      "Epoch [26/500], Validation Loss: 0.3663, Validation Accuracy: 86.54%\n",
      "Output Summary: Max=36.4349, Min=-23.4143, Median=-1.0265, Mean=-1.0677\n",
      "\n",
      "Epoch [27/500], Training Loss: 0.3219\n",
      "Epoch [27/500], Validation Loss: 0.3634, Validation Accuracy: 86.57%\n",
      "Output Summary: Max=36.7576, Min=-23.6668, Median=-1.0622, Mean=-1.0956\n",
      "\n",
      "Epoch [28/500], Training Loss: 0.3189\n",
      "Epoch [28/500], Validation Loss: 0.3608, Validation Accuracy: 86.62%\n",
      "Output Summary: Max=37.1923, Min=-23.9641, Median=-1.0686, Mean=-1.1226\n",
      "\n",
      "Epoch [29/500], Training Loss: 0.3162\n",
      "Epoch [29/500], Validation Loss: 0.3582, Validation Accuracy: 86.72%\n",
      "Output Summary: Max=37.8259, Min=-24.2970, Median=-1.0908, Mean=-1.1465\n",
      "\n",
      "Epoch [30/500], Training Loss: 0.3136\n",
      "Epoch [30/500], Validation Loss: 0.3563, Validation Accuracy: 86.74%\n",
      "Output Summary: Max=38.0928, Min=-24.5789, Median=-1.1078, Mean=-1.1780\n",
      "\n",
      "Epoch [31/500], Training Loss: 0.3110\n",
      "Epoch [31/500], Validation Loss: 0.3540, Validation Accuracy: 86.74%\n",
      "Output Summary: Max=38.3843, Min=-25.0242, Median=-1.1287, Mean=-1.2194\n",
      "\n",
      "Epoch [32/500], Training Loss: 0.3084\n",
      "Epoch [32/500], Validation Loss: 0.3520, Validation Accuracy: 86.78%\n",
      "Output Summary: Max=38.8795, Min=-25.3113, Median=-1.1428, Mean=-1.2486\n",
      "\n",
      "Epoch [33/500], Training Loss: 0.3059\n",
      "Epoch [33/500], Validation Loss: 0.3500, Validation Accuracy: 86.96%\n",
      "Output Summary: Max=39.4006, Min=-25.6601, Median=-1.1627, Mean=-1.2930\n",
      "\n",
      "Epoch [34/500], Training Loss: 0.3037\n",
      "Epoch [34/500], Validation Loss: 0.3484, Validation Accuracy: 87.10%\n",
      "Output Summary: Max=39.6401, Min=-25.8853, Median=-1.2083, Mean=-1.3169\n",
      "\n",
      "Epoch [35/500], Training Loss: 0.3015\n",
      "Epoch [35/500], Validation Loss: 0.3467, Validation Accuracy: 87.19%\n",
      "Output Summary: Max=40.0843, Min=-26.2446, Median=-1.2254, Mean=-1.3518\n",
      "\n",
      "Epoch [36/500], Training Loss: 0.2992\n",
      "Epoch [36/500], Validation Loss: 0.3455, Validation Accuracy: 87.21%\n",
      "Output Summary: Max=40.5238, Min=-26.5765, Median=-1.2535, Mean=-1.3847\n",
      "\n",
      "Epoch [37/500], Training Loss: 0.2972\n",
      "Epoch [37/500], Validation Loss: 0.3440, Validation Accuracy: 87.31%\n",
      "Output Summary: Max=40.8000, Min=-26.7466, Median=-1.2813, Mean=-1.4158\n",
      "\n",
      "Epoch [38/500], Training Loss: 0.2955\n",
      "Epoch [38/500], Validation Loss: 0.3427, Validation Accuracy: 87.36%\n",
      "Output Summary: Max=41.0077, Min=-26.8745, Median=-1.2913, Mean=-1.4403\n",
      "\n",
      "Epoch [39/500], Training Loss: 0.2940\n",
      "Epoch [39/500], Validation Loss: 0.3412, Validation Accuracy: 87.54%\n",
      "Output Summary: Max=41.0520, Min=-26.9270, Median=-1.3191, Mean=-1.4642\n",
      "\n",
      "Epoch [40/500], Training Loss: 0.2924\n",
      "Epoch [40/500], Validation Loss: 0.3407, Validation Accuracy: 87.46%\n",
      "Output Summary: Max=41.3845, Min=-27.0418, Median=-1.3446, Mean=-1.4753\n",
      "\n",
      "Epoch [41/500], Training Loss: 0.2909\n",
      "Epoch [41/500], Validation Loss: 0.3398, Validation Accuracy: 87.47%\n",
      "Output Summary: Max=41.7115, Min=-27.4337, Median=-1.3758, Mean=-1.5084\n",
      "\n",
      "Epoch [42/500], Training Loss: 0.2895\n",
      "Epoch [42/500], Validation Loss: 0.3393, Validation Accuracy: 87.55%\n",
      "Output Summary: Max=41.9173, Min=-27.9927, Median=-1.4215, Mean=-1.5556\n",
      "\n",
      "Epoch [43/500], Training Loss: 0.2881\n",
      "Epoch [43/500], Validation Loss: 0.3389, Validation Accuracy: 87.57%\n",
      "Output Summary: Max=42.2126, Min=-28.4544, Median=-1.4490, Mean=-1.5836\n",
      "\n",
      "Epoch [44/500], Training Loss: 0.2864\n",
      "Epoch [44/500], Validation Loss: 0.3388, Validation Accuracy: 87.52%\n",
      "Output Summary: Max=42.6204, Min=-28.8139, Median=-1.4923, Mean=-1.6052\n",
      "\n",
      "Epoch [45/500], Training Loss: 0.2848\n",
      "Epoch [45/500], Validation Loss: 0.3386, Validation Accuracy: 87.61%\n",
      "Output Summary: Max=42.8980, Min=-29.1392, Median=-1.5101, Mean=-1.6246\n",
      "\n",
      "Epoch [46/500], Training Loss: 0.2833\n",
      "Epoch [46/500], Validation Loss: 0.3388, Validation Accuracy: 87.67%\n",
      "Output Summary: Max=43.3548, Min=-29.4965, Median=-1.5481, Mean=-1.6387\n",
      "\n",
      "Epoch [47/500], Training Loss: 0.2815\n",
      "Epoch [47/500], Validation Loss: 0.3384, Validation Accuracy: 87.64%\n",
      "Output Summary: Max=43.8086, Min=-30.0541, Median=-1.5655, Mean=-1.6627\n",
      "\n",
      "Epoch [48/500], Training Loss: 0.2799\n",
      "Epoch [48/500], Validation Loss: 0.3372, Validation Accuracy: 87.74%\n",
      "Output Summary: Max=44.2094, Min=-30.3813, Median=-1.5847, Mean=-1.6874\n",
      "\n",
      "Epoch [49/500], Training Loss: 0.2786\n",
      "Epoch [49/500], Validation Loss: 0.3365, Validation Accuracy: 87.78%\n",
      "Output Summary: Max=44.7916, Min=-30.9052, Median=-1.5978, Mean=-1.7149\n",
      "\n",
      "Epoch [50/500], Training Loss: 0.2766\n",
      "Epoch [50/500], Validation Loss: 0.3345, Validation Accuracy: 87.80%\n",
      "Output Summary: Max=44.9413, Min=-31.4239, Median=-1.6296, Mean=-1.7697\n",
      "\n",
      "Epoch [51/500], Training Loss: 0.2754\n",
      "Epoch [51/500], Validation Loss: 0.3339, Validation Accuracy: 87.83%\n",
      "Output Summary: Max=45.3200, Min=-31.6530, Median=-1.6424, Mean=-1.7841\n",
      "\n",
      "Epoch [52/500], Training Loss: 0.2743\n",
      "Epoch [52/500], Validation Loss: 0.3336, Validation Accuracy: 87.88%\n",
      "Output Summary: Max=45.8030, Min=-31.9731, Median=-1.6399, Mean=-1.7947\n",
      "\n",
      "Epoch [53/500], Training Loss: 0.2728\n",
      "Epoch [53/500], Validation Loss: 0.3326, Validation Accuracy: 87.88%\n",
      "Output Summary: Max=46.2018, Min=-32.4069, Median=-1.6572, Mean=-1.8252\n",
      "\n",
      "Epoch [54/500], Training Loss: 0.2714\n",
      "Epoch [54/500], Validation Loss: 0.3322, Validation Accuracy: 87.88%\n",
      "Output Summary: Max=46.5937, Min=-32.7548, Median=-1.6774, Mean=-1.8584\n",
      "\n",
      "Epoch [55/500], Training Loss: 0.2700\n",
      "Epoch [55/500], Validation Loss: 0.3307, Validation Accuracy: 87.83%\n",
      "Output Summary: Max=46.8357, Min=-33.0951, Median=-1.6937, Mean=-1.8982\n",
      "\n",
      "Epoch [56/500], Training Loss: 0.2686\n",
      "Epoch [56/500], Validation Loss: 0.3304, Validation Accuracy: 87.85%\n",
      "Output Summary: Max=47.3300, Min=-33.4270, Median=-1.7066, Mean=-1.9223\n",
      "\n",
      "Epoch [57/500], Training Loss: 0.2673\n",
      "Epoch [57/500], Validation Loss: 0.3296, Validation Accuracy: 87.87%\n",
      "Output Summary: Max=47.5250, Min=-33.6656, Median=-1.7359, Mean=-1.9621\n",
      "\n",
      "Epoch [58/500], Training Loss: 0.2658\n",
      "Epoch [58/500], Validation Loss: 0.3294, Validation Accuracy: 87.90%\n",
      "Output Summary: Max=48.1909, Min=-33.9324, Median=-1.7572, Mean=-1.9877\n",
      "\n",
      "Epoch [59/500], Training Loss: 0.2646\n",
      "Epoch [59/500], Validation Loss: 0.3292, Validation Accuracy: 87.87%\n",
      "Output Summary: Max=48.6207, Min=-34.1438, Median=-1.7806, Mean=-2.0238\n",
      "\n",
      "Epoch [60/500], Training Loss: 0.2632\n",
      "Epoch [60/500], Validation Loss: 0.3294, Validation Accuracy: 87.92%\n",
      "Output Summary: Max=49.0490, Min=-34.4916, Median=-1.7940, Mean=-2.0580\n",
      "\n",
      "Epoch [61/500], Training Loss: 0.2620\n",
      "Epoch [61/500], Validation Loss: 0.3294, Validation Accuracy: 87.89%\n",
      "Output Summary: Max=49.3516, Min=-34.7547, Median=-1.8217, Mean=-2.1066\n",
      "\n",
      "Epoch [62/500], Training Loss: 0.2610\n",
      "Epoch [62/500], Validation Loss: 0.3303, Validation Accuracy: 88.04%\n",
      "Output Summary: Max=50.2322, Min=-35.6904, Median=-1.8564, Mean=-2.1273\n",
      "\n",
      "Epoch [63/500], Training Loss: 0.2601\n",
      "Epoch [63/500], Validation Loss: 0.3299, Validation Accuracy: 87.98%\n",
      "Output Summary: Max=50.5585, Min=-36.1181, Median=-1.8756, Mean=-2.1659\n",
      "\n",
      "Epoch [64/500], Training Loss: 0.2590\n",
      "Epoch [64/500], Validation Loss: 0.3301, Validation Accuracy: 88.10%\n",
      "Output Summary: Max=51.1535, Min=-36.7635, Median=-1.9129, Mean=-2.2031\n",
      "\n",
      "Epoch [65/500], Training Loss: 0.2581\n",
      "Epoch [65/500], Validation Loss: 0.3296, Validation Accuracy: 88.01%\n",
      "Output Summary: Max=51.6259, Min=-37.4708, Median=-1.9516, Mean=-2.2333\n",
      "\n",
      "Epoch [66/500], Training Loss: 0.2568\n",
      "Epoch [66/500], Validation Loss: 0.3295, Validation Accuracy: 88.03%\n",
      "Output Summary: Max=52.1610, Min=-37.8961, Median=-1.9758, Mean=-2.2629\n",
      "\n",
      "Epoch [67/500], Training Loss: 0.2557\n",
      "Epoch [67/500], Validation Loss: 0.3294, Validation Accuracy: 88.14%\n",
      "Output Summary: Max=52.5432, Min=-38.5932, Median=-2.0158, Mean=-2.3116\n",
      "\n",
      "Epoch [68/500], Training Loss: 0.2547\n",
      "Epoch [68/500], Validation Loss: 0.3299, Validation Accuracy: 88.16%\n",
      "Output Summary: Max=53.0932, Min=-39.2493, Median=-2.0352, Mean=-2.3457\n",
      "\n",
      "Epoch [69/500], Training Loss: 0.2538\n",
      "Epoch [69/500], Validation Loss: 0.3303, Validation Accuracy: 88.15%\n",
      "Output Summary: Max=53.4927, Min=-40.0409, Median=-2.0595, Mean=-2.3641\n",
      "\n",
      "Epoch [70/500], Training Loss: 0.2530\n",
      "Epoch [70/500], Validation Loss: 0.3307, Validation Accuracy: 88.15%\n",
      "Output Summary: Max=53.9089, Min=-40.4303, Median=-2.0870, Mean=-2.4049\n",
      "\n",
      "Epoch [71/500], Training Loss: 0.2521\n",
      "Epoch [71/500], Validation Loss: 0.3306, Validation Accuracy: 88.17%\n",
      "Output Summary: Max=53.9576, Min=-40.7471, Median=-2.0928, Mean=-2.4157\n",
      "\n",
      "Epoch [72/500], Training Loss: 0.2512\n",
      "Epoch [72/500], Validation Loss: 0.3304, Validation Accuracy: 88.11%\n",
      "Output Summary: Max=54.3861, Min=-41.0594, Median=-2.1215, Mean=-2.4514\n",
      "\n",
      "Epoch [73/500], Training Loss: 0.2504\n",
      "Epoch [73/500], Validation Loss: 0.3304, Validation Accuracy: 88.07%\n",
      "Output Summary: Max=54.9004, Min=-41.6350, Median=-2.1415, Mean=-2.4836\n",
      "\n",
      "Epoch [74/500], Training Loss: 0.2494\n",
      "Epoch [74/500], Validation Loss: 0.3293, Validation Accuracy: 88.16%\n",
      "Output Summary: Max=55.1549, Min=-42.2143, Median=-2.1683, Mean=-2.5179\n",
      "\n",
      "Epoch [75/500], Training Loss: 0.2485\n",
      "Epoch [75/500], Validation Loss: 0.3294, Validation Accuracy: 88.20%\n",
      "Output Summary: Max=55.3380, Min=-42.6728, Median=-2.1910, Mean=-2.5487\n",
      "\n",
      "Epoch [76/500], Training Loss: 0.2476\n",
      "Epoch [76/500], Validation Loss: 0.3296, Validation Accuracy: 88.22%\n",
      "Output Summary: Max=55.6440, Min=-42.9964, Median=-2.2175, Mean=-2.5936\n",
      "\n",
      "Epoch [77/500], Training Loss: 0.2467\n",
      "Epoch [77/500], Validation Loss: 0.3296, Validation Accuracy: 88.20%\n",
      "Output Summary: Max=56.3088, Min=-43.5325, Median=-2.2500, Mean=-2.6306\n",
      "\n",
      "Epoch [78/500], Training Loss: 0.2458\n",
      "Epoch [78/500], Validation Loss: 0.3301, Validation Accuracy: 88.16%\n",
      "Output Summary: Max=56.7427, Min=-44.0236, Median=-2.2587, Mean=-2.6479\n",
      "\n",
      "Epoch [79/500], Training Loss: 0.2453\n",
      "Epoch [79/500], Validation Loss: 0.3300, Validation Accuracy: 88.21%\n",
      "Output Summary: Max=57.1404, Min=-44.1608, Median=-2.2915, Mean=-2.6724\n",
      "\n",
      "Epoch [80/500], Training Loss: 0.2443\n",
      "Epoch [80/500], Validation Loss: 0.3290, Validation Accuracy: 88.16%\n",
      "Output Summary: Max=57.1222, Min=-44.7300, Median=-2.3351, Mean=-2.7381\n",
      "\n",
      "Epoch [81/500], Training Loss: 0.2434\n",
      "Epoch [81/500], Validation Loss: 0.3296, Validation Accuracy: 88.19%\n",
      "Output Summary: Max=58.0445, Min=-45.3057, Median=-2.3762, Mean=-2.7808\n",
      "\n",
      "Epoch [82/500], Training Loss: 0.2426\n",
      "Epoch [82/500], Validation Loss: 0.3297, Validation Accuracy: 88.25%\n",
      "Output Summary: Max=58.1432, Min=-45.7120, Median=-2.4029, Mean=-2.8063\n",
      "\n",
      "Epoch [83/500], Training Loss: 0.2421\n",
      "Epoch [83/500], Validation Loss: 0.3301, Validation Accuracy: 88.23%\n",
      "Output Summary: Max=58.7200, Min=-46.1629, Median=-2.4338, Mean=-2.8464\n",
      "\n",
      "Epoch [84/500], Training Loss: 0.2412\n",
      "Epoch [84/500], Validation Loss: 0.3298, Validation Accuracy: 88.21%\n",
      "Output Summary: Max=59.1440, Min=-46.9037, Median=-2.4631, Mean=-2.9007\n",
      "\n",
      "Epoch [85/500], Training Loss: 0.2404\n",
      "Epoch [85/500], Validation Loss: 0.3300, Validation Accuracy: 88.17%\n",
      "Output Summary: Max=59.6972, Min=-47.7400, Median=-2.4943, Mean=-2.9538\n",
      "\n",
      "Epoch [86/500], Training Loss: 0.2396\n",
      "Epoch [86/500], Validation Loss: 0.3298, Validation Accuracy: 88.20%\n",
      "Output Summary: Max=60.0119, Min=-48.4201, Median=-2.5237, Mean=-3.0025\n",
      "\n",
      "Epoch [87/500], Training Loss: 0.2390\n",
      "Epoch [87/500], Validation Loss: 0.3299, Validation Accuracy: 88.21%\n",
      "Output Summary: Max=60.1496, Min=-49.1102, Median=-2.5438, Mean=-3.0387\n",
      "\n",
      "Epoch [88/500], Training Loss: 0.2382\n",
      "Epoch [88/500], Validation Loss: 0.3303, Validation Accuracy: 88.15%\n",
      "Output Summary: Max=60.5732, Min=-49.9290, Median=-2.5836, Mean=-3.0907\n",
      "\n",
      "Epoch [89/500], Training Loss: 0.2375\n",
      "Epoch [89/500], Validation Loss: 0.3309, Validation Accuracy: 88.17%\n",
      "Output Summary: Max=60.8123, Min=-50.1451, Median=-2.6255, Mean=-3.1377\n",
      "\n",
      "Epoch [90/500], Training Loss: 0.2368\n",
      "Epoch [90/500], Validation Loss: 0.3308, Validation Accuracy: 88.25%\n",
      "Output Summary: Max=61.2490, Min=-51.1067, Median=-2.6624, Mean=-3.1933\n",
      "\n",
      "Epoch [91/500], Training Loss: 0.2361\n",
      "Epoch [91/500], Validation Loss: 0.3306, Validation Accuracy: 88.26%\n",
      "Output Summary: Max=61.6539, Min=-51.0202, Median=-2.6703, Mean=-3.2165\n",
      "\n",
      "Epoch [92/500], Training Loss: 0.2354\n",
      "Epoch [92/500], Validation Loss: 0.3306, Validation Accuracy: 88.36%\n",
      "Output Summary: Max=62.0900, Min=-51.9245, Median=-2.7012, Mean=-3.2557\n",
      "\n",
      "Epoch [93/500], Training Loss: 0.2346\n",
      "Epoch [93/500], Validation Loss: 0.3309, Validation Accuracy: 88.37%\n",
      "Output Summary: Max=62.6322, Min=-52.8240, Median=-2.7316, Mean=-3.2964\n",
      "\n",
      "Epoch [94/500], Training Loss: 0.2339\n",
      "Epoch [94/500], Validation Loss: 0.3305, Validation Accuracy: 88.32%\n",
      "Output Summary: Max=63.1293, Min=-53.5003, Median=-2.7522, Mean=-3.3331\n",
      "\n",
      "Epoch [95/500], Training Loss: 0.2333\n",
      "Epoch [95/500], Validation Loss: 0.3308, Validation Accuracy: 88.34%\n",
      "Output Summary: Max=63.5229, Min=-53.7855, Median=-2.7715, Mean=-3.3821\n",
      "\n",
      "Epoch [96/500], Training Loss: 0.2327\n",
      "Epoch [96/500], Validation Loss: 0.3309, Validation Accuracy: 88.43%\n",
      "Output Summary: Max=63.8004, Min=-54.8452, Median=-2.8051, Mean=-3.4350\n",
      "\n",
      "Epoch [97/500], Training Loss: 0.2321\n",
      "Epoch [97/500], Validation Loss: 0.3311, Validation Accuracy: 88.42%\n",
      "Output Summary: Max=64.3360, Min=-55.3799, Median=-2.8084, Mean=-3.4508\n",
      "\n",
      "Epoch [98/500], Training Loss: 0.2317\n",
      "Epoch [98/500], Validation Loss: 0.3308, Validation Accuracy: 88.42%\n",
      "Output Summary: Max=64.5919, Min=-56.4053, Median=-2.8353, Mean=-3.4877\n",
      "\n",
      "Epoch [99/500], Training Loss: 0.2311\n",
      "Epoch [99/500], Validation Loss: 0.3313, Validation Accuracy: 88.36%\n",
      "Output Summary: Max=64.7211, Min=-56.6815, Median=-2.8502, Mean=-3.5297\n",
      "\n",
      "Epoch [100/500], Training Loss: 0.2307\n",
      "Epoch [100/500], Validation Loss: 0.3315, Validation Accuracy: 88.36%\n",
      "Output Summary: Max=65.1702, Min=-57.7210, Median=-2.8589, Mean=-3.5692\n",
      "\n",
      "Epoch [101/500], Training Loss: 0.2303\n",
      "Epoch [101/500], Validation Loss: 0.3319, Validation Accuracy: 88.41%\n",
      "Output Summary: Max=65.0289, Min=-58.6546, Median=-2.8996, Mean=-3.5990\n",
      "\n",
      "Epoch [102/500], Training Loss: 0.2300\n",
      "Epoch [102/500], Validation Loss: 0.3323, Validation Accuracy: 88.36%\n",
      "Output Summary: Max=64.8877, Min=-59.0370, Median=-2.9265, Mean=-3.6479\n",
      "\n",
      "Epoch [103/500], Training Loss: 0.2296\n",
      "Epoch [103/500], Validation Loss: 0.3325, Validation Accuracy: 88.35%\n",
      "Output Summary: Max=65.2576, Min=-59.8384, Median=-2.9410, Mean=-3.6836\n",
      "\n",
      "Epoch [104/500], Training Loss: 0.2293\n",
      "Epoch [104/500], Validation Loss: 0.3324, Validation Accuracy: 88.43%\n",
      "Output Summary: Max=65.2476, Min=-59.9844, Median=-2.9565, Mean=-3.7169\n",
      "\n",
      "Epoch [105/500], Training Loss: 0.2292\n",
      "Epoch [105/500], Validation Loss: 0.3344, Validation Accuracy: 88.38%\n",
      "Output Summary: Max=65.3044, Min=-60.5892, Median=-2.9785, Mean=-3.7498\n",
      "\n",
      "Epoch [106/500], Training Loss: 0.2287\n",
      "Epoch [106/500], Validation Loss: 0.3347, Validation Accuracy: 88.33%\n",
      "Output Summary: Max=65.9083, Min=-61.2871, Median=-2.9908, Mean=-3.7925\n",
      "\n",
      "Epoch [107/500], Training Loss: 0.2286\n",
      "Epoch [107/500], Validation Loss: 0.3319, Validation Accuracy: 88.53%\n",
      "Output Summary: Max=66.7369, Min=-61.3008, Median=-2.9997, Mean=-3.8203\n",
      "\n",
      "Epoch [108/500], Training Loss: 0.2280\n",
      "Epoch [108/500], Validation Loss: 0.3317, Validation Accuracy: 88.50%\n",
      "Output Summary: Max=67.1723, Min=-61.9251, Median=-3.0110, Mean=-3.8668\n",
      "\n",
      "Epoch [109/500], Training Loss: 0.2272\n",
      "Epoch [109/500], Validation Loss: 0.3317, Validation Accuracy: 88.50%\n",
      "Output Summary: Max=66.8692, Min=-61.7399, Median=-3.0520, Mean=-3.8944\n",
      "\n",
      "Epoch [110/500], Training Loss: 0.2268\n",
      "Epoch [110/500], Validation Loss: 0.3326, Validation Accuracy: 88.43%\n",
      "Output Summary: Max=66.8736, Min=-61.7883, Median=-3.0914, Mean=-3.9262\n",
      "\n",
      "Epoch [111/500], Training Loss: 0.2266\n",
      "Epoch [111/500], Validation Loss: 0.3334, Validation Accuracy: 88.39%\n",
      "Output Summary: Max=66.8762, Min=-62.0117, Median=-3.0955, Mean=-3.9349\n",
      "\n",
      "Epoch [112/500], Training Loss: 0.2264\n",
      "Epoch [112/500], Validation Loss: 0.3342, Validation Accuracy: 88.35%\n",
      "Output Summary: Max=66.7836, Min=-61.2120, Median=-3.1258, Mean=-3.9566\n",
      "\n",
      "Epoch [113/500], Training Loss: 0.2266\n",
      "Epoch [113/500], Validation Loss: 0.3351, Validation Accuracy: 88.29%\n",
      "Output Summary: Max=66.7546, Min=-61.5544, Median=-3.1401, Mean=-3.9819\n",
      "\n",
      "Epoch [114/500], Training Loss: 0.2269\n",
      "Epoch [114/500], Validation Loss: 0.3363, Validation Accuracy: 88.24%\n",
      "Output Summary: Max=66.6062, Min=-61.1658, Median=-3.1365, Mean=-3.9867\n",
      "\n",
      "Epoch [115/500], Training Loss: 0.2274\n",
      "Epoch [115/500], Validation Loss: 0.3383, Validation Accuracy: 88.19%\n",
      "Output Summary: Max=66.3778, Min=-61.4070, Median=-3.1696, Mean=-4.0104\n",
      "\n",
      "Epoch [116/500], Training Loss: 0.2278\n",
      "Epoch [116/500], Validation Loss: 0.3373, Validation Accuracy: 88.16%\n",
      "Output Summary: Max=66.2188, Min=-61.8507, Median=-3.1774, Mean=-4.0161\n",
      "\n",
      "Epoch [117/500], Training Loss: 0.2275\n",
      "Epoch [117/500], Validation Loss: 0.3353, Validation Accuracy: 88.27%\n",
      "Output Summary: Max=66.8955, Min=-62.0874, Median=-3.1855, Mean=-4.0594\n",
      "\n",
      "Epoch [118/500], Training Loss: 0.2260\n",
      "Epoch [118/500], Validation Loss: 0.3339, Validation Accuracy: 88.43%\n",
      "Output Summary: Max=67.3053, Min=-61.7062, Median=-3.1867, Mean=-4.0575\n",
      "\n",
      "Epoch [119/500], Training Loss: 0.2241\n",
      "Epoch [119/500], Validation Loss: 0.3338, Validation Accuracy: 88.42%\n",
      "Output Summary: Max=67.8835, Min=-62.0780, Median=-3.2308, Mean=-4.1462\n",
      "\n",
      "Epoch [120/500], Training Loss: 0.2230\n",
      "Epoch [120/500], Validation Loss: 0.3332, Validation Accuracy: 88.44%\n",
      "Output Summary: Max=67.9777, Min=-62.9066, Median=-3.2844, Mean=-4.2091\n",
      "\n",
      "Early stopping triggered after 120 epochs.\n",
      "0.32904804348945615\n"
     ]
    }
   ],
   "source": [
    "\n",
    "patience = 40\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        print(best_val_loss)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "5e290f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 1.9182\n",
      "Epoch [1/500], Validation Loss: 1.2326, Validation Accuracy: 56.59%\n",
      "Output Summary: Max=11.2913, Min=-14.3222, Median=0.5692, Mean=0.3573\n",
      "\n",
      "Epoch [2/500], Training Loss: 0.8644\n",
      "Epoch [2/500], Validation Loss: 0.7375, Validation Accuracy: 72.58%\n",
      "Output Summary: Max=20.4001, Min=-20.5289, Median=2.7531, Mean=2.7068\n",
      "\n",
      "Epoch [3/500], Training Loss: 0.6860\n",
      "Epoch [3/500], Validation Loss: 0.6699, Validation Accuracy: 75.01%\n",
      "Output Summary: Max=21.3139, Min=-21.5421, Median=3.3929, Mean=3.0213\n",
      "\n",
      "Epoch [4/500], Training Loss: 0.6417\n",
      "Epoch [4/500], Validation Loss: 0.6359, Validation Accuracy: 76.19%\n",
      "Output Summary: Max=22.2096, Min=-21.9511, Median=3.9949, Mean=3.3501\n",
      "\n",
      "Epoch [5/500], Training Loss: 0.6117\n",
      "Epoch [5/500], Validation Loss: 0.6099, Validation Accuracy: 77.13%\n",
      "Output Summary: Max=22.9944, Min=-21.2470, Median=4.3341, Mean=3.5689\n",
      "\n",
      "Epoch [6/500], Training Loss: 0.5858\n",
      "Epoch [6/500], Validation Loss: 0.5880, Validation Accuracy: 78.20%\n",
      "Output Summary: Max=23.7946, Min=-20.6494, Median=4.5503, Mean=3.6931\n",
      "\n",
      "Epoch [7/500], Training Loss: 0.5609\n",
      "Epoch [7/500], Validation Loss: 0.5656, Validation Accuracy: 79.17%\n",
      "Output Summary: Max=24.2572, Min=-20.1642, Median=4.8555, Mean=3.8644\n",
      "\n",
      "Epoch [8/500], Training Loss: 0.5388\n",
      "Epoch [8/500], Validation Loss: 0.5458, Validation Accuracy: 79.87%\n",
      "Output Summary: Max=25.3845, Min=-20.3101, Median=5.1118, Mean=3.9938\n",
      "\n",
      "Epoch [9/500], Training Loss: 0.5188\n",
      "Epoch [9/500], Validation Loss: 0.5291, Validation Accuracy: 80.50%\n",
      "Output Summary: Max=25.8612, Min=-20.6201, Median=5.2993, Mean=4.1232\n",
      "\n",
      "Epoch [10/500], Training Loss: 0.5009\n",
      "Epoch [10/500], Validation Loss: 0.5128, Validation Accuracy: 81.20%\n",
      "Output Summary: Max=26.0658, Min=-21.0107, Median=5.5071, Mean=4.2497\n",
      "\n",
      "Epoch [11/500], Training Loss: 0.4853\n",
      "Epoch [11/500], Validation Loss: 0.5005, Validation Accuracy: 81.74%\n",
      "Output Summary: Max=26.2685, Min=-21.0944, Median=5.5725, Mean=4.2720\n",
      "\n",
      "Epoch [12/500], Training Loss: 0.4724\n",
      "Epoch [12/500], Validation Loss: 0.4911, Validation Accuracy: 82.17%\n",
      "Output Summary: Max=26.6199, Min=-20.9635, Median=5.6164, Mean=4.2634\n",
      "\n",
      "Epoch [13/500], Training Loss: 0.4609\n",
      "Epoch [13/500], Validation Loss: 0.4827, Validation Accuracy: 82.43%\n",
      "Output Summary: Max=27.2001, Min=-21.1504, Median=5.6346, Mean=4.2364\n",
      "\n",
      "Epoch [14/500], Training Loss: 0.4513\n",
      "Epoch [14/500], Validation Loss: 0.4761, Validation Accuracy: 82.72%\n",
      "Output Summary: Max=27.5859, Min=-21.7225, Median=5.6310, Mean=4.1991\n",
      "\n",
      "Epoch [15/500], Training Loss: 0.4427\n",
      "Epoch [15/500], Validation Loss: 0.4697, Validation Accuracy: 83.00%\n",
      "Output Summary: Max=28.0661, Min=-22.1245, Median=5.5987, Mean=4.1427\n",
      "\n",
      "Epoch [16/500], Training Loss: 0.4349\n",
      "Epoch [16/500], Validation Loss: 0.4630, Validation Accuracy: 83.11%\n",
      "Output Summary: Max=28.5148, Min=-22.2990, Median=5.5229, Mean=4.0651\n",
      "\n",
      "Epoch [17/500], Training Loss: 0.4273\n",
      "Epoch [17/500], Validation Loss: 0.4575, Validation Accuracy: 83.40%\n",
      "Output Summary: Max=28.9177, Min=-22.7378, Median=5.3832, Mean=3.9531\n",
      "\n",
      "Epoch [18/500], Training Loss: 0.4199\n",
      "Epoch [18/500], Validation Loss: 0.4514, Validation Accuracy: 83.65%\n",
      "Output Summary: Max=29.3071, Min=-23.2197, Median=5.3558, Mean=3.9217\n",
      "\n",
      "Epoch [19/500], Training Loss: 0.4133\n",
      "Epoch [19/500], Validation Loss: 0.4459, Validation Accuracy: 83.90%\n",
      "Output Summary: Max=29.4742, Min=-23.7353, Median=5.2812, Mean=3.8743\n",
      "\n",
      "Epoch [20/500], Training Loss: 0.4071\n",
      "Epoch [20/500], Validation Loss: 0.4401, Validation Accuracy: 84.19%\n",
      "Output Summary: Max=29.6223, Min=-24.2650, Median=5.2110, Mean=3.8335\n",
      "\n",
      "Epoch [21/500], Training Loss: 0.4015\n",
      "Epoch [21/500], Validation Loss: 0.4336, Validation Accuracy: 84.32%\n",
      "Output Summary: Max=29.7449, Min=-24.5052, Median=5.0824, Mean=3.7564\n",
      "\n",
      "Epoch [22/500], Training Loss: 0.3959\n",
      "Epoch [22/500], Validation Loss: 0.4290, Validation Accuracy: 84.44%\n",
      "Output Summary: Max=29.9477, Min=-24.6530, Median=4.9960, Mean=3.7005\n",
      "\n",
      "Epoch [23/500], Training Loss: 0.3907\n",
      "Epoch [23/500], Validation Loss: 0.4239, Validation Accuracy: 84.66%\n",
      "Output Summary: Max=30.1107, Min=-24.7686, Median=4.9024, Mean=3.6261\n",
      "\n",
      "Epoch [24/500], Training Loss: 0.3857\n",
      "Epoch [24/500], Validation Loss: 0.4196, Validation Accuracy: 84.87%\n",
      "Output Summary: Max=30.1587, Min=-24.8039, Median=4.7789, Mean=3.5312\n",
      "\n",
      "Epoch [25/500], Training Loss: 0.3808\n",
      "Epoch [25/500], Validation Loss: 0.4162, Validation Accuracy: 84.97%\n",
      "Output Summary: Max=30.2983, Min=-24.9828, Median=4.6654, Mean=3.4484\n",
      "\n",
      "Epoch [26/500], Training Loss: 0.3760\n",
      "Epoch [26/500], Validation Loss: 0.4124, Validation Accuracy: 84.95%\n",
      "Output Summary: Max=30.4409, Min=-25.2251, Median=4.5813, Mean=3.3978\n",
      "\n",
      "Epoch [27/500], Training Loss: 0.3715\n",
      "Epoch [27/500], Validation Loss: 0.4090, Validation Accuracy: 85.03%\n",
      "Output Summary: Max=30.3382, Min=-25.5354, Median=4.4905, Mean=3.3289\n",
      "\n",
      "Epoch [28/500], Training Loss: 0.3670\n",
      "Epoch [28/500], Validation Loss: 0.4057, Validation Accuracy: 85.20%\n",
      "Output Summary: Max=30.2601, Min=-25.7690, Median=4.4076, Mean=3.2623\n",
      "\n",
      "Epoch [29/500], Training Loss: 0.3630\n",
      "Epoch [29/500], Validation Loss: 0.4029, Validation Accuracy: 85.27%\n",
      "Output Summary: Max=30.3439, Min=-26.2002, Median=4.3346, Mean=3.2076\n",
      "\n",
      "Epoch [30/500], Training Loss: 0.3588\n",
      "Epoch [30/500], Validation Loss: 0.3995, Validation Accuracy: 85.35%\n",
      "Output Summary: Max=30.2111, Min=-26.4558, Median=4.2547, Mean=3.1321\n",
      "\n",
      "Epoch [31/500], Training Loss: 0.3553\n",
      "Epoch [31/500], Validation Loss: 0.3965, Validation Accuracy: 85.47%\n",
      "Output Summary: Max=30.1454, Min=-26.8791, Median=4.2014, Mean=3.0662\n",
      "\n",
      "Epoch [32/500], Training Loss: 0.3516\n",
      "Epoch [32/500], Validation Loss: 0.3928, Validation Accuracy: 85.61%\n",
      "Output Summary: Max=30.0756, Min=-27.1871, Median=4.1272, Mean=3.0060\n",
      "\n",
      "Epoch [33/500], Training Loss: 0.3481\n",
      "Epoch [33/500], Validation Loss: 0.3887, Validation Accuracy: 85.78%\n",
      "Output Summary: Max=29.9308, Min=-27.4137, Median=4.0346, Mean=2.9186\n",
      "\n",
      "Epoch [34/500], Training Loss: 0.3446\n",
      "Epoch [34/500], Validation Loss: 0.3848, Validation Accuracy: 85.89%\n",
      "Output Summary: Max=29.8792, Min=-27.7669, Median=3.9502, Mean=2.8578\n",
      "\n",
      "Epoch [35/500], Training Loss: 0.3414\n",
      "Epoch [35/500], Validation Loss: 0.3818, Validation Accuracy: 86.06%\n",
      "Output Summary: Max=29.9069, Min=-28.4036, Median=3.8944, Mean=2.8028\n",
      "\n",
      "Epoch [36/500], Training Loss: 0.3381\n",
      "Epoch [36/500], Validation Loss: 0.3783, Validation Accuracy: 86.20%\n",
      "Output Summary: Max=29.9001, Min=-29.0081, Median=3.8503, Mean=2.7470\n",
      "\n",
      "Epoch [37/500], Training Loss: 0.3350\n",
      "Epoch [37/500], Validation Loss: 0.3764, Validation Accuracy: 86.29%\n",
      "Output Summary: Max=29.9633, Min=-29.5513, Median=3.7643, Mean=2.6855\n",
      "\n",
      "Epoch [38/500], Training Loss: 0.3323\n",
      "Epoch [38/500], Validation Loss: 0.3742, Validation Accuracy: 86.39%\n",
      "Output Summary: Max=29.8016, Min=-29.9396, Median=3.7045, Mean=2.6251\n",
      "\n",
      "Epoch [39/500], Training Loss: 0.3293\n",
      "Epoch [39/500], Validation Loss: 0.3719, Validation Accuracy: 86.48%\n",
      "Output Summary: Max=29.9352, Min=-30.5299, Median=3.6730, Mean=2.5832\n",
      "\n",
      "Epoch [40/500], Training Loss: 0.3265\n",
      "Epoch [40/500], Validation Loss: 0.3700, Validation Accuracy: 86.57%\n",
      "Output Summary: Max=29.9373, Min=-30.8646, Median=3.5978, Mean=2.5244\n",
      "\n",
      "Epoch [41/500], Training Loss: 0.3238\n",
      "Epoch [41/500], Validation Loss: 0.3679, Validation Accuracy: 86.61%\n",
      "Output Summary: Max=30.1740, Min=-31.2048, Median=3.5496, Mean=2.4952\n",
      "\n",
      "Epoch [42/500], Training Loss: 0.3214\n",
      "Epoch [42/500], Validation Loss: 0.3659, Validation Accuracy: 86.72%\n",
      "Output Summary: Max=30.1644, Min=-31.3924, Median=3.4884, Mean=2.4470\n",
      "\n",
      "Epoch [43/500], Training Loss: 0.3188\n",
      "Epoch [43/500], Validation Loss: 0.3640, Validation Accuracy: 86.72%\n",
      "Output Summary: Max=30.2775, Min=-31.7576, Median=3.4306, Mean=2.3997\n",
      "\n",
      "Epoch [44/500], Training Loss: 0.3164\n",
      "Epoch [44/500], Validation Loss: 0.3625, Validation Accuracy: 86.75%\n",
      "Output Summary: Max=30.4304, Min=-32.1436, Median=3.3673, Mean=2.3435\n",
      "\n",
      "Epoch [45/500], Training Loss: 0.3142\n",
      "Epoch [45/500], Validation Loss: 0.3613, Validation Accuracy: 86.85%\n",
      "Output Summary: Max=30.4383, Min=-32.4626, Median=3.3144, Mean=2.2953\n",
      "\n",
      "Epoch [46/500], Training Loss: 0.3120\n",
      "Epoch [46/500], Validation Loss: 0.3591, Validation Accuracy: 86.92%\n",
      "Output Summary: Max=30.5088, Min=-32.6280, Median=3.2537, Mean=2.2602\n",
      "\n",
      "Epoch [47/500], Training Loss: 0.3097\n",
      "Epoch [47/500], Validation Loss: 0.3575, Validation Accuracy: 87.00%\n",
      "Output Summary: Max=30.5635, Min=-33.0450, Median=3.1840, Mean=2.2033\n",
      "\n",
      "Epoch [48/500], Training Loss: 0.3077\n",
      "Epoch [48/500], Validation Loss: 0.3560, Validation Accuracy: 87.11%\n",
      "Output Summary: Max=30.5635, Min=-33.2594, Median=3.1247, Mean=2.1563\n",
      "\n",
      "Epoch [49/500], Training Loss: 0.3054\n",
      "Epoch [49/500], Validation Loss: 0.3550, Validation Accuracy: 87.19%\n",
      "Output Summary: Max=30.4091, Min=-33.5174, Median=3.0448, Mean=2.1119\n",
      "\n",
      "Epoch [50/500], Training Loss: 0.3038\n",
      "Epoch [50/500], Validation Loss: 0.3531, Validation Accuracy: 87.18%\n",
      "Output Summary: Max=30.3601, Min=-33.6827, Median=2.9546, Mean=2.0355\n",
      "\n",
      "Epoch [51/500], Training Loss: 0.3018\n",
      "Epoch [51/500], Validation Loss: 0.3514, Validation Accuracy: 87.29%\n",
      "Output Summary: Max=30.3903, Min=-34.2403, Median=2.9041, Mean=1.9901\n",
      "\n",
      "Epoch [52/500], Training Loss: 0.2998\n",
      "Epoch [52/500], Validation Loss: 0.3501, Validation Accuracy: 87.37%\n",
      "Output Summary: Max=30.3460, Min=-34.5007, Median=2.8376, Mean=1.9502\n",
      "\n",
      "Epoch [53/500], Training Loss: 0.2980\n",
      "Epoch [53/500], Validation Loss: 0.3482, Validation Accuracy: 87.39%\n",
      "Output Summary: Max=30.4767, Min=-34.9120, Median=2.7882, Mean=1.9186\n",
      "\n",
      "Epoch [54/500], Training Loss: 0.2963\n",
      "Epoch [54/500], Validation Loss: 0.3477, Validation Accuracy: 87.40%\n",
      "Output Summary: Max=30.4761, Min=-35.4143, Median=2.7535, Mean=1.8763\n",
      "\n",
      "Epoch [55/500], Training Loss: 0.2945\n",
      "Epoch [55/500], Validation Loss: 0.3464, Validation Accuracy: 87.43%\n",
      "Output Summary: Max=30.5366, Min=-35.9956, Median=2.7136, Mean=1.8341\n",
      "\n",
      "Epoch [56/500], Training Loss: 0.2927\n",
      "Epoch [56/500], Validation Loss: 0.3450, Validation Accuracy: 87.44%\n",
      "Output Summary: Max=30.5003, Min=-36.2980, Median=2.6673, Mean=1.7949\n",
      "\n",
      "Epoch [57/500], Training Loss: 0.2911\n",
      "Epoch [57/500], Validation Loss: 0.3433, Validation Accuracy: 87.50%\n",
      "Output Summary: Max=30.4876, Min=-36.7115, Median=2.6252, Mean=1.7537\n",
      "\n",
      "Epoch [58/500], Training Loss: 0.2895\n",
      "Epoch [58/500], Validation Loss: 0.3419, Validation Accuracy: 87.54%\n",
      "Output Summary: Max=30.5339, Min=-37.1435, Median=2.5852, Mean=1.7084\n",
      "\n",
      "Epoch [59/500], Training Loss: 0.2878\n",
      "Epoch [59/500], Validation Loss: 0.3410, Validation Accuracy: 87.56%\n",
      "Output Summary: Max=30.4552, Min=-37.3700, Median=2.5352, Mean=1.6617\n",
      "\n",
      "Epoch [60/500], Training Loss: 0.2861\n",
      "Epoch [60/500], Validation Loss: 0.3395, Validation Accuracy: 87.61%\n",
      "Output Summary: Max=30.3804, Min=-37.6666, Median=2.4777, Mean=1.6196\n",
      "\n",
      "Epoch [61/500], Training Loss: 0.2846\n",
      "Epoch [61/500], Validation Loss: 0.3382, Validation Accuracy: 87.66%\n",
      "Output Summary: Max=30.4159, Min=-38.2860, Median=2.4340, Mean=1.5751\n",
      "\n",
      "Epoch [62/500], Training Loss: 0.2829\n",
      "Epoch [62/500], Validation Loss: 0.3371, Validation Accuracy: 87.70%\n",
      "Output Summary: Max=30.3145, Min=-38.6690, Median=2.3841, Mean=1.5211\n",
      "\n",
      "Epoch [63/500], Training Loss: 0.2814\n",
      "Epoch [63/500], Validation Loss: 0.3362, Validation Accuracy: 87.76%\n",
      "Output Summary: Max=30.2032, Min=-38.9330, Median=2.3318, Mean=1.4750\n",
      "\n",
      "Epoch [64/500], Training Loss: 0.2798\n",
      "Epoch [64/500], Validation Loss: 0.3347, Validation Accuracy: 87.73%\n",
      "Output Summary: Max=30.1222, Min=-39.0978, Median=2.2632, Mean=1.4452\n",
      "\n",
      "Epoch [65/500], Training Loss: 0.2782\n",
      "Epoch [65/500], Validation Loss: 0.3333, Validation Accuracy: 87.77%\n",
      "Output Summary: Max=30.1188, Min=-39.4719, Median=2.2389, Mean=1.4144\n",
      "\n",
      "Epoch [66/500], Training Loss: 0.2768\n",
      "Epoch [66/500], Validation Loss: 0.3322, Validation Accuracy: 87.84%\n",
      "Output Summary: Max=30.0503, Min=-39.8637, Median=2.1791, Mean=1.3601\n",
      "\n",
      "Epoch [67/500], Training Loss: 0.2752\n",
      "Epoch [67/500], Validation Loss: 0.3312, Validation Accuracy: 87.89%\n",
      "Output Summary: Max=30.1221, Min=-40.1450, Median=2.1288, Mean=1.3191\n",
      "\n",
      "Epoch [68/500], Training Loss: 0.2736\n",
      "Epoch [68/500], Validation Loss: 0.3304, Validation Accuracy: 87.91%\n",
      "Output Summary: Max=30.1661, Min=-40.5453, Median=2.0945, Mean=1.2871\n",
      "\n",
      "Epoch [69/500], Training Loss: 0.2722\n",
      "Epoch [69/500], Validation Loss: 0.3296, Validation Accuracy: 87.88%\n",
      "Output Summary: Max=30.2458, Min=-40.9947, Median=2.0444, Mean=1.2465\n",
      "\n",
      "Epoch [70/500], Training Loss: 0.2709\n",
      "Epoch [70/500], Validation Loss: 0.3289, Validation Accuracy: 87.93%\n",
      "Output Summary: Max=30.3249, Min=-41.5480, Median=1.9949, Mean=1.2118\n",
      "\n",
      "Epoch [71/500], Training Loss: 0.2694\n",
      "Epoch [71/500], Validation Loss: 0.3278, Validation Accuracy: 88.07%\n",
      "Output Summary: Max=30.2308, Min=-41.9660, Median=1.9495, Mean=1.1633\n",
      "\n",
      "Epoch [72/500], Training Loss: 0.2682\n",
      "Epoch [72/500], Validation Loss: 0.3272, Validation Accuracy: 88.12%\n",
      "Output Summary: Max=30.1888, Min=-42.1887, Median=1.9037, Mean=1.1213\n",
      "\n",
      "Epoch [73/500], Training Loss: 0.2668\n",
      "Epoch [73/500], Validation Loss: 0.3267, Validation Accuracy: 88.14%\n",
      "Output Summary: Max=30.1415, Min=-42.5310, Median=1.8610, Mean=1.0684\n",
      "\n",
      "Epoch [74/500], Training Loss: 0.2656\n",
      "Epoch [74/500], Validation Loss: 0.3261, Validation Accuracy: 88.08%\n",
      "Output Summary: Max=30.1324, Min=-42.8068, Median=1.8086, Mean=1.0250\n",
      "\n",
      "Epoch [75/500], Training Loss: 0.2642\n",
      "Epoch [75/500], Validation Loss: 0.3248, Validation Accuracy: 88.18%\n",
      "Output Summary: Max=30.1273, Min=-43.1055, Median=1.7733, Mean=0.9749\n",
      "\n",
      "Epoch [76/500], Training Loss: 0.2629\n",
      "Epoch [76/500], Validation Loss: 0.3239, Validation Accuracy: 88.16%\n",
      "Output Summary: Max=29.9751, Min=-43.5555, Median=1.7224, Mean=0.9224\n",
      "\n",
      "Epoch [77/500], Training Loss: 0.2614\n",
      "Epoch [77/500], Validation Loss: 0.3232, Validation Accuracy: 88.23%\n",
      "Output Summary: Max=30.0749, Min=-44.2310, Median=1.6796, Mean=0.8751\n",
      "\n",
      "Epoch [78/500], Training Loss: 0.2600\n",
      "Epoch [78/500], Validation Loss: 0.3220, Validation Accuracy: 88.32%\n",
      "Output Summary: Max=30.1008, Min=-44.8437, Median=1.6636, Mean=0.8390\n",
      "\n",
      "Epoch [79/500], Training Loss: 0.2587\n",
      "Epoch [79/500], Validation Loss: 0.3216, Validation Accuracy: 88.40%\n",
      "Output Summary: Max=30.2383, Min=-45.0101, Median=1.6389, Mean=0.8132\n",
      "\n",
      "Epoch [80/500], Training Loss: 0.2573\n",
      "Epoch [80/500], Validation Loss: 0.3209, Validation Accuracy: 88.43%\n",
      "Output Summary: Max=30.1819, Min=-45.4289, Median=1.6028, Mean=0.7841\n",
      "\n",
      "Epoch [81/500], Training Loss: 0.2559\n",
      "Epoch [81/500], Validation Loss: 0.3199, Validation Accuracy: 88.44%\n",
      "Output Summary: Max=30.3185, Min=-45.9954, Median=1.5870, Mean=0.7552\n",
      "\n",
      "Epoch [82/500], Training Loss: 0.2545\n",
      "Epoch [82/500], Validation Loss: 0.3197, Validation Accuracy: 88.38%\n",
      "Output Summary: Max=30.3986, Min=-46.0551, Median=1.5398, Mean=0.7141\n",
      "\n",
      "Epoch [83/500], Training Loss: 0.2532\n",
      "Epoch [83/500], Validation Loss: 0.3196, Validation Accuracy: 88.38%\n",
      "Output Summary: Max=30.4347, Min=-46.4176, Median=1.5133, Mean=0.6846\n",
      "\n",
      "Epoch [84/500], Training Loss: 0.2520\n",
      "Epoch [84/500], Validation Loss: 0.3193, Validation Accuracy: 88.35%\n",
      "Output Summary: Max=30.5837, Min=-46.7249, Median=1.4877, Mean=0.6585\n",
      "\n",
      "Epoch [85/500], Training Loss: 0.2509\n",
      "Epoch [85/500], Validation Loss: 0.3190, Validation Accuracy: 88.34%\n",
      "Output Summary: Max=30.7323, Min=-46.8031, Median=1.4428, Mean=0.6196\n",
      "\n",
      "Epoch [86/500], Training Loss: 0.2497\n",
      "Epoch [86/500], Validation Loss: 0.3181, Validation Accuracy: 88.39%\n",
      "Output Summary: Max=30.8653, Min=-47.1620, Median=1.4267, Mean=0.5977\n",
      "\n",
      "Epoch [87/500], Training Loss: 0.2489\n",
      "Epoch [87/500], Validation Loss: 0.3182, Validation Accuracy: 88.43%\n",
      "Output Summary: Max=30.9784, Min=-47.1449, Median=1.3852, Mean=0.5653\n",
      "\n",
      "Epoch [88/500], Training Loss: 0.2476\n",
      "Epoch [88/500], Validation Loss: 0.3181, Validation Accuracy: 88.39%\n",
      "Output Summary: Max=31.0424, Min=-47.4216, Median=1.3671, Mean=0.5348\n",
      "\n",
      "Epoch [89/500], Training Loss: 0.2464\n",
      "Epoch [89/500], Validation Loss: 0.3178, Validation Accuracy: 88.46%\n",
      "Output Summary: Max=31.1034, Min=-47.9128, Median=1.3519, Mean=0.5229\n",
      "\n",
      "Epoch [90/500], Training Loss: 0.2455\n",
      "Epoch [90/500], Validation Loss: 0.3175, Validation Accuracy: 88.43%\n",
      "Output Summary: Max=31.2194, Min=-48.1618, Median=1.3282, Mean=0.4986\n",
      "\n",
      "Epoch [91/500], Training Loss: 0.2446\n",
      "Epoch [91/500], Validation Loss: 0.3179, Validation Accuracy: 88.48%\n",
      "Output Summary: Max=31.2937, Min=-48.4654, Median=1.3019, Mean=0.4665\n",
      "\n",
      "Epoch [92/500], Training Loss: 0.2434\n",
      "Epoch [92/500], Validation Loss: 0.3184, Validation Accuracy: 88.51%\n",
      "Output Summary: Max=31.4662, Min=-48.5808, Median=1.2727, Mean=0.4373\n",
      "\n",
      "Epoch [93/500], Training Loss: 0.2424\n",
      "Epoch [93/500], Validation Loss: 0.3183, Validation Accuracy: 88.50%\n",
      "Output Summary: Max=31.5604, Min=-48.9421, Median=1.2502, Mean=0.4047\n",
      "\n",
      "Epoch [94/500], Training Loss: 0.2418\n",
      "Epoch [94/500], Validation Loss: 0.3191, Validation Accuracy: 88.50%\n",
      "Output Summary: Max=31.6209, Min=-49.2324, Median=1.2283, Mean=0.3753\n",
      "\n",
      "Epoch [95/500], Training Loss: 0.2411\n",
      "Epoch [95/500], Validation Loss: 0.3190, Validation Accuracy: 88.55%\n",
      "Output Summary: Max=31.6920, Min=-49.4287, Median=1.1946, Mean=0.3324\n",
      "\n",
      "Epoch [96/500], Training Loss: 0.2403\n",
      "Epoch [96/500], Validation Loss: 0.3189, Validation Accuracy: 88.52%\n",
      "Output Summary: Max=31.6894, Min=-49.5690, Median=1.1406, Mean=0.2890\n",
      "\n",
      "Epoch [97/500], Training Loss: 0.2395\n",
      "Epoch [97/500], Validation Loss: 0.3182, Validation Accuracy: 88.56%\n",
      "Output Summary: Max=31.6413, Min=-49.7377, Median=1.1090, Mean=0.2587\n",
      "\n",
      "Epoch [98/500], Training Loss: 0.2387\n",
      "Epoch [98/500], Validation Loss: 0.3159, Validation Accuracy: 88.64%\n",
      "Output Summary: Max=31.5669, Min=-49.9128, Median=1.0834, Mean=0.2246\n",
      "\n",
      "Epoch [99/500], Training Loss: 0.2378\n",
      "Epoch [99/500], Validation Loss: 0.3132, Validation Accuracy: 88.85%\n",
      "Output Summary: Max=31.5485, Min=-49.8541, Median=1.0520, Mean=0.1989\n",
      "\n",
      "Epoch [100/500], Training Loss: 0.2368\n",
      "Epoch [100/500], Validation Loss: 0.3114, Validation Accuracy: 88.89%\n",
      "Output Summary: Max=31.4451, Min=-50.3108, Median=1.0403, Mean=0.1735\n",
      "\n",
      "Epoch [101/500], Training Loss: 0.2353\n",
      "Epoch [101/500], Validation Loss: 0.3104, Validation Accuracy: 88.99%\n",
      "Output Summary: Max=31.5810, Min=-50.5583, Median=1.0211, Mean=0.1477\n",
      "\n",
      "Epoch [102/500], Training Loss: 0.2339\n",
      "Epoch [102/500], Validation Loss: 0.3110, Validation Accuracy: 88.87%\n",
      "Output Summary: Max=31.6298, Min=-51.1261, Median=1.0059, Mean=0.1088\n",
      "\n",
      "Epoch [103/500], Training Loss: 0.2327\n",
      "Epoch [103/500], Validation Loss: 0.3111, Validation Accuracy: 88.85%\n",
      "Output Summary: Max=31.8632, Min=-51.2360, Median=0.9625, Mean=0.0766\n",
      "\n",
      "Epoch [104/500], Training Loss: 0.2317\n",
      "Epoch [104/500], Validation Loss: 0.3110, Validation Accuracy: 88.91%\n",
      "Output Summary: Max=31.8163, Min=-51.5764, Median=0.9347, Mean=0.0392\n",
      "\n",
      "Epoch [105/500], Training Loss: 0.2307\n",
      "Epoch [105/500], Validation Loss: 0.3109, Validation Accuracy: 88.89%\n",
      "Output Summary: Max=31.9510, Min=-51.8169, Median=0.8979, Mean=-0.0011\n",
      "\n",
      "Epoch [106/500], Training Loss: 0.2298\n",
      "Epoch [106/500], Validation Loss: 0.3105, Validation Accuracy: 88.96%\n",
      "Output Summary: Max=32.1102, Min=-52.0782, Median=0.8652, Mean=-0.0294\n",
      "\n",
      "Epoch [107/500], Training Loss: 0.2287\n",
      "Epoch [107/500], Validation Loss: 0.3102, Validation Accuracy: 88.95%\n",
      "Output Summary: Max=32.2359, Min=-52.3856, Median=0.8403, Mean=-0.0582\n",
      "\n",
      "Epoch [108/500], Training Loss: 0.2277\n",
      "Epoch [108/500], Validation Loss: 0.3089, Validation Accuracy: 88.99%\n",
      "Output Summary: Max=32.1894, Min=-52.2446, Median=0.8301, Mean=-0.0882\n",
      "\n",
      "Epoch [109/500], Training Loss: 0.2267\n",
      "Epoch [109/500], Validation Loss: 0.3094, Validation Accuracy: 89.03%\n",
      "Output Summary: Max=32.3740, Min=-52.5322, Median=0.7929, Mean=-0.1304\n",
      "\n",
      "Epoch [110/500], Training Loss: 0.2258\n",
      "Epoch [110/500], Validation Loss: 0.3093, Validation Accuracy: 89.07%\n",
      "Output Summary: Max=32.6483, Min=-52.7151, Median=0.7696, Mean=-0.1513\n",
      "\n",
      "Epoch [111/500], Training Loss: 0.2248\n",
      "Epoch [111/500], Validation Loss: 0.3090, Validation Accuracy: 89.02%\n",
      "Output Summary: Max=32.7847, Min=-52.7534, Median=0.7288, Mean=-0.1837\n",
      "\n",
      "Epoch [112/500], Training Loss: 0.2239\n",
      "Epoch [112/500], Validation Loss: 0.3079, Validation Accuracy: 89.02%\n",
      "Output Summary: Max=32.9760, Min=-52.8182, Median=0.7058, Mean=-0.2072\n",
      "\n",
      "Epoch [113/500], Training Loss: 0.2232\n",
      "Epoch [113/500], Validation Loss: 0.3077, Validation Accuracy: 89.07%\n",
      "Output Summary: Max=33.0879, Min=-52.8604, Median=0.6786, Mean=-0.2308\n",
      "\n",
      "Epoch [114/500], Training Loss: 0.2225\n",
      "Epoch [114/500], Validation Loss: 0.3069, Validation Accuracy: 89.13%\n",
      "Output Summary: Max=33.2168, Min=-52.5793, Median=0.6562, Mean=-0.2489\n",
      "\n",
      "Epoch [115/500], Training Loss: 0.2219\n",
      "Epoch [115/500], Validation Loss: 0.3057, Validation Accuracy: 89.18%\n",
      "Output Summary: Max=33.0700, Min=-52.7425, Median=0.6485, Mean=-0.2615\n",
      "\n",
      "Epoch [116/500], Training Loss: 0.2212\n",
      "Epoch [116/500], Validation Loss: 0.3052, Validation Accuracy: 89.29%\n",
      "Output Summary: Max=33.2575, Min=-52.9504, Median=0.6290, Mean=-0.2860\n",
      "\n",
      "Epoch [117/500], Training Loss: 0.2202\n",
      "Epoch [117/500], Validation Loss: 0.3053, Validation Accuracy: 89.28%\n",
      "Output Summary: Max=33.3592, Min=-53.0890, Median=0.6131, Mean=-0.3116\n",
      "\n",
      "Epoch [118/500], Training Loss: 0.2194\n",
      "Epoch [118/500], Validation Loss: 0.3048, Validation Accuracy: 89.26%\n",
      "Output Summary: Max=33.3942, Min=-53.3228, Median=0.5855, Mean=-0.3438\n",
      "\n",
      "Epoch [119/500], Training Loss: 0.2186\n",
      "Epoch [119/500], Validation Loss: 0.3050, Validation Accuracy: 89.30%\n",
      "Output Summary: Max=33.6339, Min=-53.5678, Median=0.5658, Mean=-0.3713\n",
      "\n",
      "Epoch [120/500], Training Loss: 0.2176\n",
      "Epoch [120/500], Validation Loss: 0.3044, Validation Accuracy: 89.28%\n",
      "Output Summary: Max=33.7087, Min=-53.5368, Median=0.5466, Mean=-0.3921\n",
      "\n",
      "Epoch [121/500], Training Loss: 0.2165\n",
      "Epoch [121/500], Validation Loss: 0.3040, Validation Accuracy: 89.35%\n",
      "Output Summary: Max=33.8954, Min=-53.5858, Median=0.5273, Mean=-0.4199\n",
      "\n",
      "Epoch [122/500], Training Loss: 0.2155\n",
      "Epoch [122/500], Validation Loss: 0.3046, Validation Accuracy: 89.23%\n",
      "Output Summary: Max=33.9907, Min=-53.4610, Median=0.4966, Mean=-0.4364\n",
      "\n",
      "Epoch [123/500], Training Loss: 0.2144\n",
      "Epoch [123/500], Validation Loss: 0.3043, Validation Accuracy: 89.25%\n",
      "Output Summary: Max=34.0456, Min=-53.2841, Median=0.4629, Mean=-0.4708\n",
      "\n",
      "Epoch [124/500], Training Loss: 0.2135\n",
      "Epoch [124/500], Validation Loss: 0.3037, Validation Accuracy: 89.33%\n",
      "Output Summary: Max=34.1190, Min=-53.2079, Median=0.4442, Mean=-0.4886\n",
      "\n",
      "Epoch [125/500], Training Loss: 0.2126\n",
      "Epoch [125/500], Validation Loss: 0.3039, Validation Accuracy: 89.30%\n",
      "Output Summary: Max=34.3191, Min=-53.6113, Median=0.4158, Mean=-0.5253\n",
      "\n",
      "Epoch [126/500], Training Loss: 0.2115\n",
      "Epoch [126/500], Validation Loss: 0.3041, Validation Accuracy: 89.30%\n",
      "Output Summary: Max=34.3943, Min=-53.7230, Median=0.3992, Mean=-0.5501\n",
      "\n",
      "Epoch [127/500], Training Loss: 0.2107\n",
      "Epoch [127/500], Validation Loss: 0.3040, Validation Accuracy: 89.36%\n",
      "Output Summary: Max=34.2924, Min=-53.7468, Median=0.3579, Mean=-0.5937\n",
      "\n",
      "Epoch [128/500], Training Loss: 0.2099\n",
      "Epoch [128/500], Validation Loss: 0.3036, Validation Accuracy: 89.35%\n",
      "Output Summary: Max=34.3079, Min=-53.9737, Median=0.3338, Mean=-0.6141\n",
      "\n",
      "Epoch [129/500], Training Loss: 0.2089\n",
      "Epoch [129/500], Validation Loss: 0.3042, Validation Accuracy: 89.35%\n",
      "Output Summary: Max=34.5498, Min=-54.2696, Median=0.3067, Mean=-0.6416\n",
      "\n",
      "Epoch [130/500], Training Loss: 0.2081\n",
      "Epoch [130/500], Validation Loss: 0.3051, Validation Accuracy: 89.36%\n",
      "Output Summary: Max=34.5535, Min=-54.3945, Median=0.2702, Mean=-0.6879\n",
      "\n",
      "Epoch [131/500], Training Loss: 0.2074\n",
      "Epoch [131/500], Validation Loss: 0.3048, Validation Accuracy: 89.35%\n",
      "Output Summary: Max=34.5601, Min=-54.5154, Median=0.2285, Mean=-0.7415\n",
      "\n",
      "Epoch [132/500], Training Loss: 0.2067\n",
      "Epoch [132/500], Validation Loss: 0.3045, Validation Accuracy: 89.39%\n",
      "Output Summary: Max=34.5167, Min=-54.7571, Median=0.2022, Mean=-0.7699\n",
      "\n",
      "Epoch [133/500], Training Loss: 0.2059\n",
      "Epoch [133/500], Validation Loss: 0.3049, Validation Accuracy: 89.48%\n",
      "Output Summary: Max=34.5359, Min=-54.8197, Median=0.1795, Mean=-0.7940\n",
      "\n",
      "Epoch [134/500], Training Loss: 0.2052\n",
      "Epoch [134/500], Validation Loss: 0.3048, Validation Accuracy: 89.45%\n",
      "Output Summary: Max=34.6328, Min=-55.0934, Median=0.1676, Mean=-0.8164\n",
      "\n",
      "Epoch [135/500], Training Loss: 0.2045\n",
      "Epoch [135/500], Validation Loss: 0.3052, Validation Accuracy: 89.38%\n",
      "Output Summary: Max=34.6139, Min=-55.2124, Median=0.1399, Mean=-0.8450\n",
      "\n",
      "Epoch [136/500], Training Loss: 0.2038\n",
      "Epoch [136/500], Validation Loss: 0.3055, Validation Accuracy: 89.37%\n",
      "Output Summary: Max=34.5697, Min=-55.3815, Median=0.1194, Mean=-0.8835\n",
      "\n",
      "Epoch [137/500], Training Loss: 0.2033\n",
      "Epoch [137/500], Validation Loss: 0.3055, Validation Accuracy: 89.39%\n",
      "Output Summary: Max=34.5729, Min=-55.7488, Median=0.0978, Mean=-0.9199\n",
      "\n",
      "Epoch [138/500], Training Loss: 0.2028\n",
      "Epoch [138/500], Validation Loss: 0.3059, Validation Accuracy: 89.43%\n",
      "Output Summary: Max=34.6375, Min=-55.9446, Median=0.0654, Mean=-0.9521\n",
      "\n",
      "Epoch [139/500], Training Loss: 0.2025\n",
      "Epoch [139/500], Validation Loss: 0.3065, Validation Accuracy: 89.47%\n",
      "Output Summary: Max=34.7044, Min=-56.0242, Median=0.0317, Mean=-0.9929\n",
      "\n",
      "Epoch [140/500], Training Loss: 0.2016\n",
      "Epoch [140/500], Validation Loss: 0.3061, Validation Accuracy: 89.47%\n",
      "Output Summary: Max=34.7276, Min=-56.4025, Median=0.0153, Mean=-1.0255\n",
      "\n",
      "Epoch [141/500], Training Loss: 0.2009\n",
      "Epoch [141/500], Validation Loss: 0.3054, Validation Accuracy: 89.56%\n",
      "Output Summary: Max=34.8265, Min=-56.7999, Median=-0.0102, Mean=-1.0613\n",
      "\n",
      "Epoch [142/500], Training Loss: 0.2003\n",
      "Epoch [142/500], Validation Loss: 0.3060, Validation Accuracy: 89.55%\n",
      "Output Summary: Max=34.9743, Min=-57.0822, Median=-0.0451, Mean=-1.1066\n",
      "\n",
      "Epoch [143/500], Training Loss: 0.1998\n",
      "Epoch [143/500], Validation Loss: 0.3062, Validation Accuracy: 89.58%\n",
      "Output Summary: Max=35.1245, Min=-57.3930, Median=-0.0666, Mean=-1.1431\n",
      "\n",
      "Epoch [144/500], Training Loss: 0.1993\n",
      "Epoch [144/500], Validation Loss: 0.3063, Validation Accuracy: 89.54%\n",
      "Output Summary: Max=35.2936, Min=-57.4874, Median=-0.0809, Mean=-1.1597\n",
      "\n",
      "Epoch [145/500], Training Loss: 0.1986\n",
      "Epoch [145/500], Validation Loss: 0.3063, Validation Accuracy: 89.53%\n",
      "Output Summary: Max=35.3625, Min=-57.5849, Median=-0.1144, Mean=-1.2055\n",
      "\n",
      "Epoch [146/500], Training Loss: 0.1978\n",
      "Epoch [146/500], Validation Loss: 0.3060, Validation Accuracy: 89.48%\n",
      "Output Summary: Max=35.2680, Min=-57.7121, Median=-0.1419, Mean=-1.2401\n",
      "\n",
      "Epoch [147/500], Training Loss: 0.1967\n",
      "Epoch [147/500], Validation Loss: 0.3055, Validation Accuracy: 89.59%\n",
      "Output Summary: Max=35.2733, Min=-57.9073, Median=-0.1507, Mean=-1.2645\n",
      "\n",
      "Epoch [148/500], Training Loss: 0.1955\n",
      "Epoch [148/500], Validation Loss: 0.3058, Validation Accuracy: 89.58%\n",
      "Output Summary: Max=35.4675, Min=-58.1026, Median=-0.1693, Mean=-1.2925\n",
      "\n",
      "Epoch [149/500], Training Loss: 0.1947\n",
      "Epoch [149/500], Validation Loss: 0.3062, Validation Accuracy: 89.65%\n",
      "Output Summary: Max=35.8664, Min=-58.4797, Median=-0.1914, Mean=-1.3332\n",
      "\n",
      "Epoch [150/500], Training Loss: 0.1939\n",
      "Epoch [150/500], Validation Loss: 0.3063, Validation Accuracy: 89.63%\n",
      "Output Summary: Max=36.0539, Min=-58.7817, Median=-0.2073, Mean=-1.3573\n",
      "\n",
      "Epoch [151/500], Training Loss: 0.1930\n",
      "Epoch [151/500], Validation Loss: 0.3074, Validation Accuracy: 89.57%\n",
      "Output Summary: Max=36.2070, Min=-58.9293, Median=-0.2600, Mean=-1.3910\n",
      "\n",
      "Epoch [152/500], Training Loss: 0.1924\n",
      "Epoch [152/500], Validation Loss: 0.3077, Validation Accuracy: 89.62%\n",
      "Output Summary: Max=36.2901, Min=-59.2051, Median=-0.2939, Mean=-1.4510\n",
      "\n",
      "Epoch [153/500], Training Loss: 0.1915\n",
      "Epoch [153/500], Validation Loss: 0.3074, Validation Accuracy: 89.52%\n",
      "Output Summary: Max=36.5642, Min=-59.4448, Median=-0.3083, Mean=-1.4722\n",
      "\n",
      "Epoch [154/500], Training Loss: 0.1908\n",
      "Epoch [154/500], Validation Loss: 0.3086, Validation Accuracy: 89.55%\n",
      "Output Summary: Max=36.7181, Min=-59.6690, Median=-0.3246, Mean=-1.5133\n",
      "\n",
      "Epoch [155/500], Training Loss: 0.1899\n",
      "Epoch [155/500], Validation Loss: 0.3078, Validation Accuracy: 89.58%\n",
      "Output Summary: Max=37.0898, Min=-60.0500, Median=-0.3548, Mean=-1.5558\n",
      "\n",
      "Epoch [156/500], Training Loss: 0.1892\n",
      "Epoch [156/500], Validation Loss: 0.3085, Validation Accuracy: 89.57%\n",
      "Output Summary: Max=37.3603, Min=-60.4059, Median=-0.3777, Mean=-1.5940\n",
      "\n",
      "Epoch [157/500], Training Loss: 0.1886\n",
      "Epoch [157/500], Validation Loss: 0.3088, Validation Accuracy: 89.61%\n",
      "Output Summary: Max=37.5724, Min=-60.8497, Median=-0.4131, Mean=-1.6430\n",
      "\n",
      "Epoch [158/500], Training Loss: 0.1878\n",
      "Epoch [158/500], Validation Loss: 0.3093, Validation Accuracy: 89.68%\n",
      "Output Summary: Max=37.7769, Min=-61.2836, Median=-0.4430, Mean=-1.6831\n",
      "\n",
      "Epoch [159/500], Training Loss: 0.1870\n",
      "Epoch [159/500], Validation Loss: 0.3100, Validation Accuracy: 89.57%\n",
      "Output Summary: Max=38.0009, Min=-61.7659, Median=-0.4693, Mean=-1.7103\n",
      "\n",
      "Epoch [160/500], Training Loss: 0.1865\n",
      "Epoch [160/500], Validation Loss: 0.3106, Validation Accuracy: 89.55%\n",
      "Output Summary: Max=38.2337, Min=-61.9033, Median=-0.4936, Mean=-1.7564\n",
      "\n",
      "Epoch [161/500], Training Loss: 0.1860\n",
      "Epoch [161/500], Validation Loss: 0.3112, Validation Accuracy: 89.59%\n",
      "Output Summary: Max=38.4747, Min=-62.3806, Median=-0.5303, Mean=-1.8138\n",
      "\n",
      "Epoch [162/500], Training Loss: 0.1853\n",
      "Epoch [162/500], Validation Loss: 0.3109, Validation Accuracy: 89.55%\n",
      "Output Summary: Max=38.7885, Min=-62.7587, Median=-0.5507, Mean=-1.8397\n",
      "\n",
      "Epoch [163/500], Training Loss: 0.1845\n",
      "Epoch [163/500], Validation Loss: 0.3107, Validation Accuracy: 89.67%\n",
      "Output Summary: Max=39.0946, Min=-63.1292, Median=-0.5650, Mean=-1.8639\n",
      "\n",
      "Epoch [164/500], Training Loss: 0.1839\n",
      "Epoch [164/500], Validation Loss: 0.3116, Validation Accuracy: 89.58%\n",
      "Output Summary: Max=39.3387, Min=-63.4471, Median=-0.5823, Mean=-1.8918\n",
      "\n",
      "Epoch [165/500], Training Loss: 0.1834\n",
      "Epoch [165/500], Validation Loss: 0.3120, Validation Accuracy: 89.64%\n",
      "Output Summary: Max=39.7674, Min=-63.8551, Median=-0.5743, Mean=-1.8924\n",
      "\n",
      "Epoch [166/500], Training Loss: 0.1829\n",
      "Epoch [166/500], Validation Loss: 0.3129, Validation Accuracy: 89.64%\n",
      "Output Summary: Max=39.9357, Min=-64.2568, Median=-0.6130, Mean=-1.9360\n",
      "\n",
      "Epoch [167/500], Training Loss: 0.1822\n",
      "Epoch [167/500], Validation Loss: 0.3130, Validation Accuracy: 89.55%\n",
      "Output Summary: Max=40.0906, Min=-64.6948, Median=-0.6193, Mean=-1.9718\n",
      "\n",
      "Epoch [168/500], Training Loss: 0.1816\n",
      "Epoch [168/500], Validation Loss: 0.3140, Validation Accuracy: 89.57%\n",
      "Output Summary: Max=40.5014, Min=-65.3380, Median=-0.6230, Mean=-1.9902\n",
      "\n",
      "Early stopping triggered after 168 epochs.\n",
      "0.3035567343235016\n"
     ]
    }
   ],
   "source": [
    "\n",
    "patience = 40\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        print(best_val_loss)\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b5baa566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 2.1232\n",
      "Epoch [1/500], Validation Loss: 1.4701, Validation Accuracy: 40.80%\n",
      "Output Summary: Max=10.2939, Min=-10.7633, Median=0.2907, Mean=0.1655\n",
      "\n",
      "Epoch [2/500], Training Loss: 0.9177\n",
      "Epoch [2/500], Validation Loss: 0.7180, Validation Accuracy: 72.62%\n",
      "Output Summary: Max=31.6700, Min=-34.7090, Median=-0.2609, Mean=0.0209\n",
      "\n",
      "Epoch [3/500], Training Loss: 0.6307\n",
      "Epoch [3/500], Validation Loss: 0.5989, Validation Accuracy: 78.11%\n",
      "Output Summary: Max=30.9822, Min=-30.8298, Median=0.0657, Mean=-0.0007\n",
      "\n",
      "Epoch [4/500], Training Loss: 0.5357\n",
      "Epoch [4/500], Validation Loss: 0.5289, Validation Accuracy: 80.80%\n",
      "Output Summary: Max=33.5743, Min=-31.3023, Median=0.1645, Mean=-0.0661\n",
      "\n",
      "Epoch [5/500], Training Loss: 0.4897\n",
      "Epoch [5/500], Validation Loss: 0.4936, Validation Accuracy: 81.92%\n",
      "Output Summary: Max=34.3337, Min=-29.7314, Median=0.3283, Mean=-0.0808\n",
      "\n",
      "Epoch [6/500], Training Loss: 0.4611\n",
      "Epoch [6/500], Validation Loss: 0.4706, Validation Accuracy: 82.56%\n",
      "Output Summary: Max=33.8375, Min=-27.8360, Median=0.2717, Mean=-0.1704\n",
      "\n",
      "Epoch [7/500], Training Loss: 0.4400\n",
      "Epoch [7/500], Validation Loss: 0.4506, Validation Accuracy: 83.27%\n",
      "Output Summary: Max=32.9549, Min=-26.1321, Median=0.1779, Mean=-0.2718\n",
      "\n",
      "Epoch [8/500], Training Loss: 0.4238\n",
      "Epoch [8/500], Validation Loss: 0.4401, Validation Accuracy: 83.47%\n",
      "Output Summary: Max=32.1440, Min=-24.7785, Median=0.0673, Mean=-0.3546\n",
      "\n",
      "Epoch [9/500], Training Loss: 0.4103\n",
      "Epoch [9/500], Validation Loss: 0.4306, Validation Accuracy: 83.79%\n",
      "Output Summary: Max=31.4333, Min=-23.6075, Median=-0.0171, Mean=-0.4334\n",
      "\n",
      "Epoch [10/500], Training Loss: 0.3996\n",
      "Epoch [10/500], Validation Loss: 0.4229, Validation Accuracy: 84.10%\n",
      "Output Summary: Max=30.8992, Min=-22.7418, Median=-0.1225, Mean=-0.5071\n",
      "\n",
      "Epoch [11/500], Training Loss: 0.3897\n",
      "Epoch [11/500], Validation Loss: 0.4140, Validation Accuracy: 84.57%\n",
      "Output Summary: Max=30.0275, Min=-22.4922, Median=-0.1894, Mean=-0.5860\n",
      "\n",
      "Epoch [12/500], Training Loss: 0.3807\n",
      "Epoch [12/500], Validation Loss: 0.4061, Validation Accuracy: 84.87%\n",
      "Output Summary: Max=29.4795, Min=-23.0791, Median=-0.2405, Mean=-0.6595\n",
      "\n",
      "Epoch [13/500], Training Loss: 0.3726\n",
      "Epoch [13/500], Validation Loss: 0.3980, Validation Accuracy: 85.17%\n",
      "Output Summary: Max=29.0726, Min=-23.3526, Median=-0.2994, Mean=-0.7260\n",
      "\n",
      "Epoch [14/500], Training Loss: 0.3666\n",
      "Epoch [14/500], Validation Loss: 0.3946, Validation Accuracy: 85.44%\n",
      "Output Summary: Max=29.0231, Min=-23.5231, Median=-0.3315, Mean=-0.7927\n",
      "\n",
      "Epoch [15/500], Training Loss: 0.3611\n",
      "Epoch [15/500], Validation Loss: 0.3897, Validation Accuracy: 85.71%\n",
      "Output Summary: Max=28.7511, Min=-23.4406, Median=-0.3805, Mean=-0.8454\n",
      "\n",
      "Epoch [16/500], Training Loss: 0.3554\n",
      "Epoch [16/500], Validation Loss: 0.3859, Validation Accuracy: 85.90%\n",
      "Output Summary: Max=28.3648, Min=-23.5449, Median=-0.4127, Mean=-0.8805\n",
      "\n",
      "Epoch [17/500], Training Loss: 0.3504\n",
      "Epoch [17/500], Validation Loss: 0.3834, Validation Accuracy: 86.07%\n",
      "Output Summary: Max=28.2359, Min=-24.0323, Median=-0.4167, Mean=-0.9279\n",
      "\n",
      "Epoch [18/500], Training Loss: 0.3452\n",
      "Epoch [18/500], Validation Loss: 0.3800, Validation Accuracy: 86.21%\n",
      "Output Summary: Max=28.2823, Min=-24.7471, Median=-0.4406, Mean=-0.9567\n",
      "\n",
      "Epoch [19/500], Training Loss: 0.3408\n",
      "Epoch [19/500], Validation Loss: 0.3778, Validation Accuracy: 86.25%\n",
      "Output Summary: Max=28.3462, Min=-25.2441, Median=-0.4896, Mean=-1.0231\n",
      "\n",
      "Epoch [20/500], Training Loss: 0.3371\n",
      "Epoch [20/500], Validation Loss: 0.3754, Validation Accuracy: 86.32%\n",
      "Output Summary: Max=28.4905, Min=-25.7015, Median=-0.5131, Mean=-1.0532\n",
      "\n",
      "Epoch [21/500], Training Loss: 0.3336\n",
      "Epoch [21/500], Validation Loss: 0.3721, Validation Accuracy: 86.54%\n",
      "Output Summary: Max=28.6296, Min=-26.2353, Median=-0.5316, Mean=-1.0929\n",
      "\n",
      "Epoch [22/500], Training Loss: 0.3300\n",
      "Epoch [22/500], Validation Loss: 0.3701, Validation Accuracy: 86.61%\n",
      "Output Summary: Max=29.2048, Min=-27.0041, Median=-0.5582, Mean=-1.1285\n",
      "\n",
      "Epoch [23/500], Training Loss: 0.3265\n",
      "Epoch [23/500], Validation Loss: 0.3691, Validation Accuracy: 86.50%\n",
      "Output Summary: Max=29.3238, Min=-27.6866, Median=-0.5830, Mean=-1.1749\n",
      "\n",
      "Epoch [24/500], Training Loss: 0.3236\n",
      "Epoch [24/500], Validation Loss: 0.3684, Validation Accuracy: 86.53%\n",
      "Output Summary: Max=29.5346, Min=-28.1633, Median=-0.6091, Mean=-1.2048\n",
      "\n",
      "Epoch [25/500], Training Loss: 0.3209\n",
      "Epoch [25/500], Validation Loss: 0.3657, Validation Accuracy: 86.58%\n",
      "Output Summary: Max=29.8784, Min=-28.7723, Median=-0.6445, Mean=-1.2424\n",
      "\n",
      "Epoch [26/500], Training Loss: 0.3184\n",
      "Epoch [26/500], Validation Loss: 0.3615, Validation Accuracy: 86.82%\n",
      "Output Summary: Max=30.2447, Min=-29.3136, Median=-0.6959, Mean=-1.2612\n",
      "\n",
      "Epoch [27/500], Training Loss: 0.3156\n",
      "Epoch [27/500], Validation Loss: 0.3587, Validation Accuracy: 87.05%\n",
      "Output Summary: Max=30.1157, Min=-29.4422, Median=-0.7721, Mean=-1.2831\n",
      "\n",
      "Epoch [28/500], Training Loss: 0.3127\n",
      "Epoch [28/500], Validation Loss: 0.3569, Validation Accuracy: 86.99%\n",
      "Output Summary: Max=30.3360, Min=-30.0483, Median=-0.8011, Mean=-1.3176\n",
      "\n",
      "Epoch [29/500], Training Loss: 0.3093\n",
      "Epoch [29/500], Validation Loss: 0.3552, Validation Accuracy: 86.99%\n",
      "Output Summary: Max=30.7122, Min=-30.8444, Median=-0.8674, Mean=-1.3640\n",
      "\n",
      "Epoch [30/500], Training Loss: 0.3067\n",
      "Epoch [30/500], Validation Loss: 0.3546, Validation Accuracy: 87.04%\n",
      "Output Summary: Max=30.7341, Min=-31.4065, Median=-0.9153, Mean=-1.3956\n",
      "\n",
      "Epoch [31/500], Training Loss: 0.3042\n",
      "Epoch [31/500], Validation Loss: 0.3534, Validation Accuracy: 87.09%\n",
      "Output Summary: Max=30.9191, Min=-32.0868, Median=-0.9732, Mean=-1.4556\n",
      "\n",
      "Epoch [32/500], Training Loss: 0.3016\n",
      "Epoch [32/500], Validation Loss: 0.3516, Validation Accuracy: 87.02%\n",
      "Output Summary: Max=31.3269, Min=-32.8875, Median=-0.9921, Mean=-1.5024\n",
      "\n",
      "Epoch [33/500], Training Loss: 0.2996\n",
      "Epoch [33/500], Validation Loss: 0.3500, Validation Accuracy: 87.13%\n",
      "Output Summary: Max=31.8134, Min=-33.7632, Median=-1.0098, Mean=-1.5273\n",
      "\n",
      "Epoch [34/500], Training Loss: 0.2972\n",
      "Epoch [34/500], Validation Loss: 0.3492, Validation Accuracy: 87.19%\n",
      "Output Summary: Max=32.2243, Min=-34.4699, Median=-1.0218, Mean=-1.5636\n",
      "\n",
      "Epoch [35/500], Training Loss: 0.2948\n",
      "Epoch [35/500], Validation Loss: 0.3475, Validation Accuracy: 87.23%\n",
      "Output Summary: Max=32.4959, Min=-35.3683, Median=-1.0352, Mean=-1.6061\n",
      "\n",
      "Epoch [36/500], Training Loss: 0.2932\n",
      "Epoch [36/500], Validation Loss: 0.3460, Validation Accuracy: 87.28%\n",
      "Output Summary: Max=32.8225, Min=-36.1765, Median=-1.0370, Mean=-1.6340\n",
      "\n",
      "Epoch [37/500], Training Loss: 0.2912\n",
      "Epoch [37/500], Validation Loss: 0.3454, Validation Accuracy: 87.24%\n",
      "Output Summary: Max=33.2138, Min=-36.9852, Median=-1.0342, Mean=-1.6589\n",
      "\n",
      "Epoch [38/500], Training Loss: 0.2893\n",
      "Epoch [38/500], Validation Loss: 0.3446, Validation Accuracy: 87.28%\n",
      "Output Summary: Max=33.3666, Min=-37.5557, Median=-1.0365, Mean=-1.6856\n",
      "\n",
      "Epoch [39/500], Training Loss: 0.2872\n",
      "Epoch [39/500], Validation Loss: 0.3430, Validation Accuracy: 87.27%\n",
      "Output Summary: Max=33.2107, Min=-37.9495, Median=-1.0435, Mean=-1.7231\n",
      "\n",
      "Epoch [40/500], Training Loss: 0.2858\n",
      "Epoch [40/500], Validation Loss: 0.3432, Validation Accuracy: 87.24%\n",
      "Output Summary: Max=33.3697, Min=-38.9027, Median=-1.0515, Mean=-1.7580\n",
      "\n",
      "Epoch [41/500], Training Loss: 0.2841\n",
      "Epoch [41/500], Validation Loss: 0.3433, Validation Accuracy: 87.34%\n",
      "Output Summary: Max=33.9263, Min=-39.7390, Median=-1.1027, Mean=-1.8583\n",
      "\n",
      "Epoch [42/500], Training Loss: 0.2835\n",
      "Epoch [42/500], Validation Loss: 0.3445, Validation Accuracy: 87.27%\n",
      "Output Summary: Max=33.5839, Min=-40.4092, Median=-1.0426, Mean=-1.8433\n",
      "\n",
      "Epoch [43/500], Training Loss: 0.2825\n",
      "Epoch [43/500], Validation Loss: 0.3422, Validation Accuracy: 87.33%\n",
      "Output Summary: Max=33.9233, Min=-41.1040, Median=-1.0558, Mean=-1.8690\n",
      "\n",
      "Epoch [44/500], Training Loss: 0.2811\n",
      "Epoch [44/500], Validation Loss: 0.3412, Validation Accuracy: 87.50%\n",
      "Output Summary: Max=34.4459, Min=-41.7231, Median=-1.0744, Mean=-1.8856\n",
      "\n",
      "Epoch [45/500], Training Loss: 0.2812\n",
      "Epoch [45/500], Validation Loss: 0.3436, Validation Accuracy: 87.47%\n",
      "Output Summary: Max=34.7123, Min=-42.0538, Median=-1.0849, Mean=-1.9051\n",
      "\n",
      "Epoch [46/500], Training Loss: 0.2813\n",
      "Epoch [46/500], Validation Loss: 0.3430, Validation Accuracy: 87.42%\n",
      "Output Summary: Max=34.2364, Min=-42.7012, Median=-1.0640, Mean=-1.9557\n",
      "\n",
      "Epoch [47/500], Training Loss: 0.2788\n",
      "Epoch [47/500], Validation Loss: 0.3417, Validation Accuracy: 87.49%\n",
      "Output Summary: Max=34.4763, Min=-43.6110, Median=-1.0539, Mean=-1.9821\n",
      "\n",
      "Epoch [48/500], Training Loss: 0.2775\n",
      "Epoch [48/500], Validation Loss: 0.3419, Validation Accuracy: 87.49%\n",
      "Output Summary: Max=34.8730, Min=-44.1967, Median=-1.0796, Mean=-2.0234\n",
      "\n",
      "Epoch [49/500], Training Loss: 0.2759\n",
      "Epoch [49/500], Validation Loss: 0.3425, Validation Accuracy: 87.49%\n",
      "Output Summary: Max=34.8411, Min=-44.5231, Median=-1.0791, Mean=-2.0578\n",
      "\n",
      "Epoch [50/500], Training Loss: 0.2750\n",
      "Epoch [50/500], Validation Loss: 0.3453, Validation Accuracy: 87.51%\n",
      "Output Summary: Max=34.5183, Min=-44.6120, Median=-1.0865, Mean=-2.0813\n",
      "\n",
      "Epoch [51/500], Training Loss: 0.2746\n",
      "Epoch [51/500], Validation Loss: 0.3447, Validation Accuracy: 87.51%\n",
      "Output Summary: Max=34.8239, Min=-45.0488, Median=-1.1036, Mean=-2.1246\n",
      "\n",
      "Epoch [52/500], Training Loss: 0.2731\n",
      "Epoch [52/500], Validation Loss: 0.3393, Validation Accuracy: 87.67%\n",
      "Output Summary: Max=35.0726, Min=-45.6789, Median=-1.1351, Mean=-2.1531\n",
      "\n",
      "Epoch [53/500], Training Loss: 0.2713\n",
      "Epoch [53/500], Validation Loss: 0.3378, Validation Accuracy: 87.83%\n",
      "Output Summary: Max=35.4092, Min=-46.5446, Median=-1.1919, Mean=-2.2015\n",
      "\n",
      "Epoch [54/500], Training Loss: 0.2689\n",
      "Epoch [54/500], Validation Loss: 0.3362, Validation Accuracy: 88.02%\n",
      "Output Summary: Max=36.1137, Min=-47.5837, Median=-1.2207, Mean=-2.2434\n",
      "\n",
      "Epoch [55/500], Training Loss: 0.2672\n",
      "Epoch [55/500], Validation Loss: 0.3342, Validation Accuracy: 88.05%\n",
      "Output Summary: Max=36.3333, Min=-48.2557, Median=-1.2299, Mean=-2.2909\n",
      "\n",
      "Epoch [56/500], Training Loss: 0.2658\n",
      "Epoch [56/500], Validation Loss: 0.3342, Validation Accuracy: 88.27%\n",
      "Output Summary: Max=36.0207, Min=-48.3943, Median=-1.2213, Mean=-2.3157\n",
      "\n",
      "Epoch [57/500], Training Loss: 0.2645\n",
      "Epoch [57/500], Validation Loss: 0.3344, Validation Accuracy: 88.07%\n",
      "Output Summary: Max=36.9301, Min=-49.4442, Median=-1.2348, Mean=-2.3817\n",
      "\n",
      "Epoch [58/500], Training Loss: 0.2628\n",
      "Epoch [58/500], Validation Loss: 0.3337, Validation Accuracy: 88.26%\n",
      "Output Summary: Max=37.1766, Min=-49.8810, Median=-1.2693, Mean=-2.4462\n",
      "\n",
      "Epoch [59/500], Training Loss: 0.2612\n",
      "Epoch [59/500], Validation Loss: 0.3335, Validation Accuracy: 88.23%\n",
      "Output Summary: Max=37.3561, Min=-50.4286, Median=-1.2771, Mean=-2.4708\n",
      "\n",
      "Epoch [60/500], Training Loss: 0.2602\n",
      "Epoch [60/500], Validation Loss: 0.3366, Validation Accuracy: 88.10%\n",
      "Output Summary: Max=36.9387, Min=-51.0292, Median=-1.2384, Mean=-2.5064\n",
      "\n",
      "Epoch [61/500], Training Loss: 0.2592\n",
      "Epoch [61/500], Validation Loss: 0.3390, Validation Accuracy: 87.96%\n",
      "Output Summary: Max=36.9513, Min=-51.3843, Median=-1.2144, Mean=-2.5101\n",
      "\n",
      "Epoch [62/500], Training Loss: 0.2589\n",
      "Epoch [62/500], Validation Loss: 0.3422, Validation Accuracy: 87.96%\n",
      "Output Summary: Max=37.1339, Min=-51.7567, Median=-1.1973, Mean=-2.5088\n",
      "\n",
      "Epoch [63/500], Training Loss: 0.2579\n",
      "Epoch [63/500], Validation Loss: 0.3400, Validation Accuracy: 88.05%\n",
      "Output Summary: Max=37.1026, Min=-52.0865, Median=-1.1844, Mean=-2.5433\n",
      "\n",
      "Epoch [64/500], Training Loss: 0.2565\n",
      "Epoch [64/500], Validation Loss: 0.3379, Validation Accuracy: 88.21%\n",
      "Output Summary: Max=37.3701, Min=-52.5828, Median=-1.1984, Mean=-2.5734\n",
      "\n",
      "Epoch [65/500], Training Loss: 0.2555\n",
      "Epoch [65/500], Validation Loss: 0.3381, Validation Accuracy: 88.26%\n",
      "Output Summary: Max=37.5694, Min=-53.2528, Median=-1.1780, Mean=-2.5944\n",
      "\n",
      "Epoch [66/500], Training Loss: 0.2546\n",
      "Epoch [66/500], Validation Loss: 0.3383, Validation Accuracy: 88.24%\n",
      "Output Summary: Max=38.0627, Min=-53.8987, Median=-1.1282, Mean=-2.6215\n",
      "\n",
      "Epoch [67/500], Training Loss: 0.2540\n",
      "Epoch [67/500], Validation Loss: 0.3355, Validation Accuracy: 88.26%\n",
      "Output Summary: Max=38.4755, Min=-53.8420, Median=-1.1615, Mean=-2.6348\n",
      "\n",
      "Epoch [68/500], Training Loss: 0.2534\n",
      "Epoch [68/500], Validation Loss: 0.3334, Validation Accuracy: 88.39%\n",
      "Output Summary: Max=39.1898, Min=-54.7996, Median=-1.1686, Mean=-2.6526\n",
      "\n",
      "Epoch [69/500], Training Loss: 0.2532\n",
      "Epoch [69/500], Validation Loss: 0.3318, Validation Accuracy: 88.53%\n",
      "Output Summary: Max=39.6911, Min=-55.7941, Median=-1.2088, Mean=-2.6862\n",
      "\n",
      "Epoch [70/500], Training Loss: 0.2517\n",
      "Epoch [70/500], Validation Loss: 0.3316, Validation Accuracy: 88.60%\n",
      "Output Summary: Max=39.8529, Min=-56.8491, Median=-1.2432, Mean=-2.7382\n",
      "\n",
      "Epoch [71/500], Training Loss: 0.2498\n",
      "Epoch [71/500], Validation Loss: 0.3308, Validation Accuracy: 88.53%\n",
      "Output Summary: Max=39.6164, Min=-56.7567, Median=-1.2427, Mean=-2.7752\n",
      "\n",
      "Epoch [72/500], Training Loss: 0.2484\n",
      "Epoch [72/500], Validation Loss: 0.3316, Validation Accuracy: 88.57%\n",
      "Output Summary: Max=40.5390, Min=-57.5214, Median=-1.2408, Mean=-2.7796\n",
      "\n",
      "Epoch [73/500], Training Loss: 0.2469\n",
      "Epoch [73/500], Validation Loss: 0.3314, Validation Accuracy: 88.64%\n",
      "Output Summary: Max=40.7083, Min=-58.4421, Median=-1.2474, Mean=-2.8394\n",
      "\n",
      "Epoch [74/500], Training Loss: 0.2458\n",
      "Epoch [74/500], Validation Loss: 0.3320, Validation Accuracy: 88.62%\n",
      "Output Summary: Max=40.9483, Min=-59.1084, Median=-1.2739, Mean=-2.8850\n",
      "\n",
      "Epoch [75/500], Training Loss: 0.2447\n",
      "Epoch [75/500], Validation Loss: 0.3322, Validation Accuracy: 88.51%\n",
      "Output Summary: Max=41.2239, Min=-59.8099, Median=-1.2796, Mean=-2.9131\n",
      "\n",
      "Epoch [76/500], Training Loss: 0.2439\n",
      "Epoch [76/500], Validation Loss: 0.3319, Validation Accuracy: 88.61%\n",
      "Output Summary: Max=41.4403, Min=-60.2624, Median=-1.2962, Mean=-2.9556\n",
      "\n",
      "Epoch [77/500], Training Loss: 0.2439\n",
      "Epoch [77/500], Validation Loss: 0.3317, Validation Accuracy: 88.57%\n",
      "Output Summary: Max=41.1665, Min=-60.5911, Median=-1.3092, Mean=-2.9756\n",
      "\n",
      "Epoch [78/500], Training Loss: 0.2449\n",
      "Epoch [78/500], Validation Loss: 0.3356, Validation Accuracy: 88.35%\n",
      "Output Summary: Max=40.9479, Min=-60.5948, Median=-1.3192, Mean=-2.9510\n",
      "\n",
      "Epoch [79/500], Training Loss: 0.2453\n",
      "Epoch [79/500], Validation Loss: 0.3314, Validation Accuracy: 88.58%\n",
      "Output Summary: Max=41.1410, Min=-60.8268, Median=-1.3587, Mean=-2.9946\n",
      "\n",
      "Epoch [80/500], Training Loss: 0.2422\n",
      "Epoch [80/500], Validation Loss: 0.3326, Validation Accuracy: 88.56%\n",
      "Output Summary: Max=41.1431, Min=-61.5888, Median=-1.3679, Mean=-3.0804\n",
      "\n",
      "Epoch [81/500], Training Loss: 0.2395\n",
      "Epoch [81/500], Validation Loss: 0.3328, Validation Accuracy: 88.54%\n",
      "Output Summary: Max=41.4238, Min=-61.5122, Median=-1.3812, Mean=-3.1260\n",
      "\n",
      "Epoch [82/500], Training Loss: 0.2378\n",
      "Epoch [82/500], Validation Loss: 0.3337, Validation Accuracy: 88.60%\n",
      "Output Summary: Max=42.7607, Min=-62.8150, Median=-1.4144, Mean=-3.2021\n",
      "\n",
      "Epoch [83/500], Training Loss: 0.2359\n",
      "Epoch [83/500], Validation Loss: 0.3354, Validation Accuracy: 88.59%\n",
      "Output Summary: Max=43.2002, Min=-63.3609, Median=-1.4543, Mean=-3.2304\n",
      "\n",
      "Epoch [84/500], Training Loss: 0.2346\n",
      "Epoch [84/500], Validation Loss: 0.3366, Validation Accuracy: 88.71%\n",
      "Output Summary: Max=43.9123, Min=-64.3652, Median=-1.4858, Mean=-3.3351\n",
      "\n",
      "Epoch [85/500], Training Loss: 0.2341\n",
      "Epoch [85/500], Validation Loss: 0.3351, Validation Accuracy: 88.74%\n",
      "Output Summary: Max=44.1400, Min=-64.7659, Median=-1.4782, Mean=-3.3310\n",
      "\n",
      "Epoch [86/500], Training Loss: 0.2325\n",
      "Epoch [86/500], Validation Loss: 0.3350, Validation Accuracy: 88.70%\n",
      "Output Summary: Max=44.1311, Min=-65.5137, Median=-1.5243, Mean=-3.3375\n",
      "\n",
      "Epoch [87/500], Training Loss: 0.2314\n",
      "Epoch [87/500], Validation Loss: 0.3368, Validation Accuracy: 88.59%\n",
      "Output Summary: Max=44.6763, Min=-66.2911, Median=-1.5376, Mean=-3.3903\n",
      "\n",
      "Epoch [88/500], Training Loss: 0.2303\n",
      "Epoch [88/500], Validation Loss: 0.3365, Validation Accuracy: 88.70%\n",
      "Output Summary: Max=44.7084, Min=-66.9405, Median=-1.4751, Mean=-3.4902\n",
      "\n",
      "Epoch [89/500], Training Loss: 0.2298\n",
      "Epoch [89/500], Validation Loss: 0.3349, Validation Accuracy: 88.70%\n",
      "Output Summary: Max=44.6409, Min=-68.1478, Median=-1.5279, Mean=-3.4675\n",
      "\n",
      "Epoch [90/500], Training Loss: 0.2291\n",
      "Epoch [90/500], Validation Loss: 0.3381, Validation Accuracy: 88.64%\n",
      "Output Summary: Max=45.1119, Min=-68.7524, Median=-1.4825, Mean=-3.5423\n",
      "\n",
      "Epoch [91/500], Training Loss: 0.2274\n",
      "Epoch [91/500], Validation Loss: 0.3402, Validation Accuracy: 88.50%\n",
      "Output Summary: Max=45.8365, Min=-69.9848, Median=-1.5373, Mean=-3.5944\n",
      "\n",
      "Epoch [92/500], Training Loss: 0.2263\n",
      "Epoch [92/500], Validation Loss: 0.3395, Validation Accuracy: 88.43%\n",
      "Output Summary: Max=46.2556, Min=-70.7950, Median=-1.5656, Mean=-3.6671\n",
      "\n",
      "Epoch [93/500], Training Loss: 0.2253\n",
      "Epoch [93/500], Validation Loss: 0.3394, Validation Accuracy: 88.44%\n",
      "Output Summary: Max=47.1370, Min=-71.6474, Median=-1.6066, Mean=-3.7192\n",
      "\n",
      "Epoch [94/500], Training Loss: 0.2234\n",
      "Epoch [94/500], Validation Loss: 0.3383, Validation Accuracy: 88.65%\n",
      "Output Summary: Max=47.3081, Min=-71.9345, Median=-1.6089, Mean=-3.7657\n",
      "\n",
      "Epoch [95/500], Training Loss: 0.2228\n",
      "Epoch [95/500], Validation Loss: 0.3395, Validation Accuracy: 88.61%\n",
      "Output Summary: Max=47.9397, Min=-73.1661, Median=-1.6529, Mean=-3.7781\n",
      "\n",
      "Epoch [96/500], Training Loss: 0.2218\n",
      "Epoch [96/500], Validation Loss: 0.3417, Validation Accuracy: 88.54%\n",
      "Output Summary: Max=48.4108, Min=-74.1053, Median=-1.7223, Mean=-3.7991\n",
      "\n",
      "Epoch [97/500], Training Loss: 0.2213\n",
      "Epoch [97/500], Validation Loss: 0.3401, Validation Accuracy: 88.81%\n",
      "Output Summary: Max=48.5173, Min=-74.4949, Median=-1.7272, Mean=-3.9334\n",
      "\n",
      "Epoch [98/500], Training Loss: 0.2204\n",
      "Epoch [98/500], Validation Loss: 0.3397, Validation Accuracy: 88.65%\n",
      "Output Summary: Max=49.4014, Min=-75.9466, Median=-1.7579, Mean=-4.0261\n",
      "\n",
      "Epoch [99/500], Training Loss: 0.2198\n",
      "Epoch [99/500], Validation Loss: 0.3403, Validation Accuracy: 88.62%\n",
      "Output Summary: Max=49.9778, Min=-76.6637, Median=-1.8014, Mean=-4.0976\n",
      "\n",
      "Epoch [100/500], Training Loss: 0.2191\n",
      "Epoch [100/500], Validation Loss: 0.3417, Validation Accuracy: 88.60%\n",
      "Output Summary: Max=50.0734, Min=-77.4371, Median=-1.8060, Mean=-4.1555\n",
      "\n",
      "Epoch [101/500], Training Loss: 0.2185\n",
      "Epoch [101/500], Validation Loss: 0.3421, Validation Accuracy: 88.68%\n",
      "Output Summary: Max=50.4762, Min=-78.1368, Median=-1.8058, Mean=-4.2291\n",
      "\n",
      "Epoch [102/500], Training Loss: 0.2183\n",
      "Epoch [102/500], Validation Loss: 0.3422, Validation Accuracy: 88.72%\n",
      "Output Summary: Max=50.3707, Min=-78.8092, Median=-1.8147, Mean=-4.2849\n",
      "\n",
      "Epoch [103/500], Training Loss: 0.2172\n",
      "Epoch [103/500], Validation Loss: 0.3429, Validation Accuracy: 88.83%\n",
      "Output Summary: Max=50.6169, Min=-79.2418, Median=-1.8211, Mean=-4.2604\n",
      "\n",
      "Epoch [104/500], Training Loss: 0.2165\n",
      "Epoch [104/500], Validation Loss: 0.3442, Validation Accuracy: 88.73%\n",
      "Output Summary: Max=50.7225, Min=-79.5588, Median=-1.8276, Mean=-4.3067\n",
      "\n",
      "Epoch [105/500], Training Loss: 0.2162\n",
      "Epoch [105/500], Validation Loss: 0.3431, Validation Accuracy: 88.83%\n",
      "Output Summary: Max=51.0349, Min=-80.0256, Median=-1.8645, Mean=-4.3547\n",
      "\n",
      "Epoch [106/500], Training Loss: 0.2156\n",
      "Epoch [106/500], Validation Loss: 0.3430, Validation Accuracy: 88.68%\n",
      "Output Summary: Max=51.6075, Min=-80.5443, Median=-1.9427, Mean=-4.4450\n",
      "\n",
      "Epoch [107/500], Training Loss: 0.2153\n",
      "Epoch [107/500], Validation Loss: 0.3454, Validation Accuracy: 88.67%\n",
      "Output Summary: Max=52.5011, Min=-81.6967, Median=-1.9576, Mean=-4.4744\n",
      "\n",
      "Epoch [108/500], Training Loss: 0.2153\n",
      "Epoch [108/500], Validation Loss: 0.3443, Validation Accuracy: 88.84%\n",
      "Output Summary: Max=53.0230, Min=-82.3603, Median=-2.0057, Mean=-4.5238\n",
      "\n",
      "Epoch [109/500], Training Loss: 0.2173\n",
      "Epoch [109/500], Validation Loss: 0.3396, Validation Accuracy: 88.98%\n",
      "Output Summary: Max=53.1083, Min=-82.5262, Median=-1.9316, Mean=-4.5040\n",
      "\n",
      "Epoch [110/500], Training Loss: 0.2193\n",
      "Epoch [110/500], Validation Loss: 0.3402, Validation Accuracy: 88.65%\n",
      "Output Summary: Max=52.6902, Min=-81.1982, Median=-1.9893, Mean=-4.6141\n",
      "\n",
      "Epoch [111/500], Training Loss: 0.2169\n",
      "Epoch [111/500], Validation Loss: 0.3438, Validation Accuracy: 88.63%\n",
      "Output Summary: Max=52.5482, Min=-81.2142, Median=-2.0638, Mean=-4.6982\n",
      "\n",
      "Early stopping triggered after 111 epochs.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "patience = 40\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "7b580680",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Training Loss: 2.3282\n",
      "Epoch [1/500], Validation Loss: 2.3035, Validation Accuracy: 10.28%\n",
      "Output Summary: Max=0.4745, Min=0.0816, Median=0.2738, Mean=0.2726\n",
      "\n",
      "Epoch [2/500], Training Loss: 2.3005\n",
      "Epoch [2/500], Validation Loss: 2.2889, Validation Accuracy: 10.28%\n",
      "Output Summary: Max=0.4730, Min=0.0296, Median=0.2607, Mean=0.2452\n",
      "\n",
      "Epoch [3/500], Training Loss: 1.1786\n",
      "Epoch [3/500], Validation Loss: 0.4489, Validation Accuracy: 85.79%\n",
      "Output Summary: Max=17.3885, Min=-16.1064, Median=0.8293, Mean=0.9764\n",
      "\n",
      "Epoch [4/500], Training Loss: 0.3915\n",
      "Epoch [4/500], Validation Loss: 0.3475, Validation Accuracy: 89.59%\n",
      "Output Summary: Max=17.1890, Min=-14.7909, Median=0.8270, Mean=1.0324\n",
      "\n",
      "Epoch [5/500], Training Loss: 0.3467\n",
      "Epoch [5/500], Validation Loss: 0.3206, Validation Accuracy: 90.50%\n",
      "Output Summary: Max=18.5099, Min=-15.6053, Median=0.8729, Mean=1.0608\n",
      "\n",
      "Epoch [6/500], Training Loss: 0.3244\n",
      "Epoch [6/500], Validation Loss: 0.3039, Validation Accuracy: 91.03%\n",
      "Output Summary: Max=19.3918, Min=-16.9650, Median=0.9503, Mean=1.0836\n",
      "\n",
      "Epoch [7/500], Training Loss: 0.3071\n",
      "Epoch [7/500], Validation Loss: 0.2868, Validation Accuracy: 91.68%\n",
      "Output Summary: Max=19.7010, Min=-17.5729, Median=0.9654, Mean=1.0384\n",
      "\n",
      "Epoch [8/500], Training Loss: 0.2905\n",
      "Epoch [8/500], Validation Loss: 0.2703, Validation Accuracy: 92.39%\n",
      "Output Summary: Max=19.5549, Min=-17.5288, Median=0.9078, Mean=0.9583\n",
      "\n",
      "Epoch [9/500], Training Loss: 0.2742\n",
      "Epoch [9/500], Validation Loss: 0.2561, Validation Accuracy: 92.86%\n",
      "Output Summary: Max=19.9333, Min=-18.0781, Median=0.9108, Mean=0.9575\n",
      "\n",
      "Epoch [10/500], Training Loss: 0.2568\n",
      "Epoch [10/500], Validation Loss: 0.2400, Validation Accuracy: 93.19%\n",
      "Output Summary: Max=20.3225, Min=-18.5249, Median=0.9310, Mean=0.9690\n",
      "\n",
      "Epoch [11/500], Training Loss: 0.2366\n",
      "Epoch [11/500], Validation Loss: 0.2190, Validation Accuracy: 93.64%\n",
      "Output Summary: Max=20.2899, Min=-18.6706, Median=0.9183, Mean=0.9544\n",
      "\n",
      "Epoch [12/500], Training Loss: 0.2149\n",
      "Epoch [12/500], Validation Loss: 0.2005, Validation Accuracy: 94.16%\n",
      "Output Summary: Max=20.3525, Min=-19.2181, Median=0.8784, Mean=0.9373\n",
      "\n",
      "Epoch [13/500], Training Loss: 0.1955\n",
      "Epoch [13/500], Validation Loss: 0.1834, Validation Accuracy: 94.65%\n",
      "Output Summary: Max=20.9941, Min=-20.0631, Median=0.8386, Mean=0.9186\n",
      "\n",
      "Epoch [14/500], Training Loss: 0.1794\n",
      "Epoch [14/500], Validation Loss: 0.1702, Validation Accuracy: 94.91%\n",
      "Output Summary: Max=22.2881, Min=-21.3361, Median=0.8566, Mean=0.9585\n",
      "\n",
      "Epoch [15/500], Training Loss: 0.1676\n",
      "Epoch [15/500], Validation Loss: 0.1580, Validation Accuracy: 95.40%\n",
      "Output Summary: Max=22.5286, Min=-22.1352, Median=0.8190, Mean=0.9508\n",
      "\n",
      "Epoch [16/500], Training Loss: 0.1590\n",
      "Epoch [16/500], Validation Loss: 0.1529, Validation Accuracy: 95.54%\n",
      "Output Summary: Max=22.7620, Min=-22.5319, Median=0.7180, Mean=0.8654\n",
      "\n",
      "Epoch [17/500], Training Loss: 0.1523\n",
      "Epoch [17/500], Validation Loss: 0.1437, Validation Accuracy: 95.77%\n",
      "Output Summary: Max=22.8327, Min=-22.7985, Median=0.6070, Mean=0.7483\n",
      "\n",
      "Epoch [18/500], Training Loss: 0.1448\n",
      "Epoch [18/500], Validation Loss: 0.1408, Validation Accuracy: 95.93%\n",
      "Output Summary: Max=23.8367, Min=-23.8896, Median=0.6599, Mean=0.8582\n",
      "\n",
      "Epoch [19/500], Training Loss: 0.1391\n",
      "Epoch [19/500], Validation Loss: 0.1352, Validation Accuracy: 96.07%\n",
      "Output Summary: Max=24.0719, Min=-24.2365, Median=0.5705, Mean=0.7651\n",
      "\n",
      "Epoch [20/500], Training Loss: 0.1338\n",
      "Epoch [20/500], Validation Loss: 0.1319, Validation Accuracy: 96.17%\n",
      "Output Summary: Max=24.2558, Min=-24.6024, Median=0.5256, Mean=0.7268\n",
      "\n",
      "Epoch [21/500], Training Loss: 0.1279\n",
      "Epoch [21/500], Validation Loss: 0.1303, Validation Accuracy: 96.17%\n",
      "Output Summary: Max=24.4722, Min=-24.9184, Median=0.5077, Mean=0.7335\n",
      "\n",
      "Epoch [22/500], Training Loss: 0.1230\n",
      "Epoch [22/500], Validation Loss: 0.1262, Validation Accuracy: 96.31%\n",
      "Output Summary: Max=24.4853, Min=-25.0870, Median=0.4323, Mean=0.6655\n",
      "\n",
      "Epoch [23/500], Training Loss: 0.1185\n",
      "Epoch [23/500], Validation Loss: 0.1228, Validation Accuracy: 96.41%\n",
      "Output Summary: Max=24.6795, Min=-25.2834, Median=0.3981, Mean=0.6403\n",
      "\n",
      "Epoch [24/500], Training Loss: 0.1142\n",
      "Epoch [24/500], Validation Loss: 0.1193, Validation Accuracy: 96.45%\n",
      "Output Summary: Max=24.9119, Min=-25.4620, Median=0.3722, Mean=0.6195\n",
      "\n",
      "Epoch [25/500], Training Loss: 0.1101\n",
      "Epoch [25/500], Validation Loss: 0.1151, Validation Accuracy: 96.61%\n",
      "Output Summary: Max=25.1545, Min=-25.5907, Median=0.3468, Mean=0.5980\n",
      "\n",
      "Epoch [26/500], Training Loss: 0.1065\n",
      "Epoch [26/500], Validation Loss: 0.1115, Validation Accuracy: 96.71%\n",
      "Output Summary: Max=25.4786, Min=-26.0499, Median=0.3356, Mean=0.5900\n",
      "\n",
      "Epoch [27/500], Training Loss: 0.1034\n",
      "Epoch [27/500], Validation Loss: 0.1097, Validation Accuracy: 96.79%\n",
      "Output Summary: Max=25.9280, Min=-26.6973, Median=0.3454, Mean=0.6078\n",
      "\n",
      "Epoch [28/500], Training Loss: 0.1006\n",
      "Epoch [28/500], Validation Loss: 0.1125, Validation Accuracy: 96.67%\n",
      "Output Summary: Max=26.5533, Min=-27.8258, Median=0.3486, Mean=0.6419\n",
      "\n",
      "Epoch [29/500], Training Loss: 0.0987\n",
      "Epoch [29/500], Validation Loss: 0.1037, Validation Accuracy: 97.00%\n",
      "Output Summary: Max=26.2170, Min=-27.2618, Median=0.2543, Mean=0.4670\n",
      "\n",
      "Epoch [30/500], Training Loss: 0.0963\n",
      "Epoch [30/500], Validation Loss: 0.1030, Validation Accuracy: 96.90%\n",
      "Output Summary: Max=26.0820, Min=-27.0814, Median=0.2096, Mean=0.4035\n",
      "\n",
      "Epoch [31/500], Training Loss: 0.0943\n",
      "Epoch [31/500], Validation Loss: 0.1050, Validation Accuracy: 96.78%\n",
      "Output Summary: Max=26.1362, Min=-27.7171, Median=0.1972, Mean=0.3900\n",
      "\n",
      "Epoch [32/500], Training Loss: 0.0932\n",
      "Epoch [32/500], Validation Loss: 0.1059, Validation Accuracy: 96.87%\n",
      "Output Summary: Max=26.2022, Min=-28.0476, Median=0.1778, Mean=0.3674\n",
      "\n",
      "Epoch [33/500], Training Loss: 0.0901\n",
      "Epoch [33/500], Validation Loss: 0.1008, Validation Accuracy: 96.92%\n",
      "Output Summary: Max=26.8143, Min=-28.4271, Median=0.1524, Mean=0.3494\n",
      "\n",
      "Epoch [34/500], Training Loss: 0.0873\n",
      "Epoch [34/500], Validation Loss: 0.0944, Validation Accuracy: 97.07%\n",
      "Output Summary: Max=27.7577, Min=-29.0659, Median=0.1498, Mean=0.3525\n",
      "\n",
      "Epoch [35/500], Training Loss: 0.0854\n",
      "Epoch [35/500], Validation Loss: 0.0946, Validation Accuracy: 97.08%\n",
      "Output Summary: Max=27.9651, Min=-29.2921, Median=0.1186, Mean=0.3211\n",
      "\n",
      "Epoch [36/500], Training Loss: 0.0843\n",
      "Epoch [36/500], Validation Loss: 0.0963, Validation Accuracy: 97.01%\n",
      "Output Summary: Max=27.8138, Min=-29.5234, Median=0.1225, Mean=0.3128\n",
      "\n",
      "Epoch [37/500], Training Loss: 0.0835\n",
      "Epoch [37/500], Validation Loss: 0.0913, Validation Accuracy: 97.24%\n",
      "Output Summary: Max=29.2174, Min=-30.9791, Median=0.1961, Mean=0.3867\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[51]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m output = model(data)\n\u001b[32m     15\u001b[39m loss = criterion(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     19\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "patience = 10000\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d368f265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch version: 2.6.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Metal Backend device or CPU device\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    tensor = torch.empty(4, 2, 40, 40).to(device)\n",
    "    unfolded_tensor = F.unfold(input=tensor, kernel_size=3, padding=1, stride=1)\n",
    "    print(\"torch version:\", torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bd6633d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m output = model(data)\n\u001b[32m     15\u001b[39m loss = criterion(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     19\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "patience = 10000\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051facb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss: 2.1728\n",
      "Epoch [1/1000], Validation Loss: 1.6802, Validation Accuracy: 56.44%\n",
      "Output Summary: Max=2.3652, Min=-2.7602, Median=0.0619, Mean=0.0334\n",
      "\n",
      "Epoch [2/1000], Training Loss: 1.2055\n",
      "Epoch [2/1000], Validation Loss: 0.7723, Validation Accuracy: 84.77%\n",
      "Output Summary: Max=4.2014, Min=-2.8849, Median=-0.0332, Mean=0.1487\n",
      "\n",
      "Epoch [3/1000], Training Loss: 0.5983\n",
      "Epoch [3/1000], Validation Loss: 0.4247, Validation Accuracy: 90.35%\n",
      "Output Summary: Max=5.0898, Min=-3.8560, Median=-0.2723, Mean=0.0734\n",
      "\n",
      "Epoch [4/1000], Training Loss: 0.3736\n",
      "Epoch [4/1000], Validation Loss: 0.3020, Validation Accuracy: 92.28%\n",
      "Output Summary: Max=5.7756, Min=-4.4066, Median=-0.3293, Mean=0.0801\n",
      "\n",
      "Epoch [5/1000], Training Loss: 0.2840\n",
      "Epoch [5/1000], Validation Loss: 0.2441, Validation Accuracy: 93.43%\n",
      "Output Summary: Max=6.2063, Min=-4.4058, Median=-0.3786, Mean=0.0622\n",
      "\n",
      "Epoch [6/1000], Training Loss: 0.2379\n",
      "Epoch [6/1000], Validation Loss: 0.2234, Validation Accuracy: 93.91%\n",
      "Output Summary: Max=6.5239, Min=-4.3245, Median=-0.4296, Mean=0.0490\n",
      "\n",
      "Epoch [7/1000], Training Loss: 0.2079\n",
      "Epoch [7/1000], Validation Loss: 0.1812, Validation Accuracy: 94.93%\n",
      "Output Summary: Max=6.8355, Min=-4.6146, Median=-0.4494, Mean=0.0545\n",
      "\n",
      "Epoch [8/1000], Training Loss: 0.1808\n",
      "Epoch [8/1000], Validation Loss: 0.1662, Validation Accuracy: 95.19%\n",
      "Output Summary: Max=7.1174, Min=-4.9086, Median=-0.4761, Mean=0.0455\n",
      "\n",
      "Epoch [9/1000], Training Loss: 0.1652\n",
      "Epoch [9/1000], Validation Loss: 0.1636, Validation Accuracy: 95.09%\n",
      "Output Summary: Max=7.3874, Min=-5.2530, Median=-0.5107, Mean=0.0381\n",
      "\n",
      "Epoch [10/1000], Training Loss: 0.1505\n",
      "Epoch [10/1000], Validation Loss: 0.1426, Validation Accuracy: 95.78%\n",
      "Output Summary: Max=7.5930, Min=-5.3871, Median=-0.5220, Mean=0.0402\n",
      "\n",
      "Epoch [11/1000], Training Loss: 0.1359\n",
      "Epoch [11/1000], Validation Loss: 0.1319, Validation Accuracy: 96.00%\n",
      "Output Summary: Max=7.7295, Min=-5.4846, Median=-0.5167, Mean=0.0383\n",
      "\n",
      "Epoch [12/1000], Training Loss: 0.1244\n",
      "Epoch [12/1000], Validation Loss: 0.1294, Validation Accuracy: 96.13%\n",
      "Output Summary: Max=7.9654, Min=-5.4952, Median=-0.5451, Mean=0.0209\n",
      "\n",
      "Epoch [13/1000], Training Loss: 0.1180\n",
      "Epoch [13/1000], Validation Loss: 0.1303, Validation Accuracy: 96.07%\n",
      "Output Summary: Max=8.1762, Min=-5.6126, Median=-0.5553, Mean=0.0201\n",
      "\n",
      "Epoch [14/1000], Training Loss: 0.1142\n",
      "Epoch [14/1000], Validation Loss: 0.1294, Validation Accuracy: 95.97%\n",
      "Output Summary: Max=8.3446, Min=-5.6060, Median=-0.5568, Mean=0.0321\n",
      "\n",
      "Epoch [15/1000], Training Loss: 0.1124\n",
      "Epoch [15/1000], Validation Loss: 0.1206, Validation Accuracy: 96.40%\n",
      "Output Summary: Max=8.4717, Min=-5.7592, Median=-0.5660, Mean=0.0417\n",
      "\n",
      "Epoch [16/1000], Training Loss: 0.1048\n",
      "Epoch [16/1000], Validation Loss: 0.1145, Validation Accuracy: 96.51%\n",
      "Output Summary: Max=8.5843, Min=-5.8777, Median=-0.6180, Mean=0.0225\n",
      "\n",
      "Epoch [17/1000], Training Loss: 0.0982\n",
      "Epoch [17/1000], Validation Loss: 0.1113, Validation Accuracy: 96.67%\n",
      "Output Summary: Max=8.7467, Min=-5.8984, Median=-0.6447, Mean=0.0291\n",
      "\n",
      "Epoch [18/1000], Training Loss: 0.0940\n",
      "Epoch [18/1000], Validation Loss: 0.1050, Validation Accuracy: 96.72%\n",
      "Output Summary: Max=8.8430, Min=-6.1705, Median=-0.6686, Mean=0.0259\n",
      "\n",
      "Epoch [19/1000], Training Loss: 0.0902\n",
      "Epoch [19/1000], Validation Loss: 0.1046, Validation Accuracy: 96.77%\n",
      "Output Summary: Max=8.9194, Min=-6.4006, Median=-0.6721, Mean=0.0154\n",
      "\n",
      "Epoch [20/1000], Training Loss: 0.0857\n",
      "Epoch [20/1000], Validation Loss: 0.1024, Validation Accuracy: 96.72%\n",
      "Output Summary: Max=9.0450, Min=-6.5288, Median=-0.6733, Mean=0.0255\n",
      "\n",
      "Epoch [21/1000], Training Loss: 0.0818\n",
      "Epoch [21/1000], Validation Loss: 0.0995, Validation Accuracy: 96.86%\n",
      "Output Summary: Max=9.1618, Min=-6.5422, Median=-0.6707, Mean=0.0251\n",
      "\n",
      "Epoch [22/1000], Training Loss: 0.0792\n",
      "Epoch [22/1000], Validation Loss: 0.0978, Validation Accuracy: 96.83%\n",
      "Output Summary: Max=9.2800, Min=-6.5878, Median=-0.6792, Mean=0.0216\n",
      "\n",
      "Epoch [23/1000], Training Loss: 0.0759\n",
      "Epoch [23/1000], Validation Loss: 0.0966, Validation Accuracy: 97.02%\n",
      "Output Summary: Max=9.4086, Min=-6.5017, Median=-0.6841, Mean=0.0296\n",
      "\n",
      "Epoch [24/1000], Training Loss: 0.0742\n",
      "Epoch [24/1000], Validation Loss: 0.0987, Validation Accuracy: 96.88%\n",
      "Output Summary: Max=9.5017, Min=-6.5046, Median=-0.6904, Mean=0.0354\n",
      "\n",
      "Epoch [25/1000], Training Loss: 0.0725\n",
      "Epoch [25/1000], Validation Loss: 0.1007, Validation Accuracy: 96.74%\n",
      "Output Summary: Max=9.6110, Min=-6.4603, Median=-0.6961, Mean=0.0277\n",
      "\n",
      "Epoch [26/1000], Training Loss: 0.0717\n",
      "Epoch [26/1000], Validation Loss: 0.1009, Validation Accuracy: 96.85%\n",
      "Output Summary: Max=9.6989, Min=-6.4628, Median=-0.7266, Mean=0.0048\n",
      "\n",
      "Epoch [27/1000], Training Loss: 0.0725\n",
      "Epoch [27/1000], Validation Loss: 0.0989, Validation Accuracy: 96.99%\n",
      "Output Summary: Max=9.8213, Min=-6.5125, Median=-0.7501, Mean=-0.0177\n",
      "\n",
      "Epoch [28/1000], Training Loss: 0.0705\n",
      "Epoch [28/1000], Validation Loss: 0.0927, Validation Accuracy: 97.21%\n",
      "Output Summary: Max=9.8318, Min=-6.7442, Median=-0.8026, Mean=-0.0252\n",
      "\n",
      "Epoch [29/1000], Training Loss: 0.0663\n",
      "Epoch [29/1000], Validation Loss: 0.0997, Validation Accuracy: 96.94%\n",
      "Output Summary: Max=9.8854, Min=-6.9025, Median=-0.8087, Mean=-0.0195\n",
      "\n",
      "Epoch [30/1000], Training Loss: 0.0665\n",
      "Epoch [30/1000], Validation Loss: 0.0972, Validation Accuracy: 96.93%\n",
      "Output Summary: Max=10.0583, Min=-6.8231, Median=-0.7923, Mean=-0.0029\n",
      "\n",
      "Epoch [31/1000], Training Loss: 0.0697\n",
      "Epoch [31/1000], Validation Loss: 0.0944, Validation Accuracy: 97.06%\n",
      "Output Summary: Max=10.2344, Min=-6.8620, Median=-0.7900, Mean=0.0148\n",
      "\n",
      "Epoch [32/1000], Training Loss: 0.0703\n",
      "Epoch [32/1000], Validation Loss: 0.0991, Validation Accuracy: 96.94%\n",
      "Output Summary: Max=10.3505, Min=-6.9325, Median=-0.8118, Mean=-0.0018\n",
      "\n",
      "Epoch [33/1000], Training Loss: 0.0636\n",
      "Epoch [33/1000], Validation Loss: 0.0884, Validation Accuracy: 97.28%\n",
      "Output Summary: Max=10.4497, Min=-6.8347, Median=-0.8048, Mean=0.0015\n",
      "\n",
      "Epoch [34/1000], Training Loss: 0.0563\n",
      "Epoch [34/1000], Validation Loss: 0.0919, Validation Accuracy: 97.18%\n",
      "Output Summary: Max=10.5809, Min=-7.0894, Median=-0.7911, Mean=0.0219\n",
      "\n",
      "Epoch [35/1000], Training Loss: 0.0550\n",
      "Epoch [35/1000], Validation Loss: 0.0936, Validation Accuracy: 97.05%\n",
      "Output Summary: Max=10.6922, Min=-7.1479, Median=-0.7590, Mean=0.0466\n",
      "\n",
      "Epoch [36/1000], Training Loss: 0.0535\n",
      "Epoch [36/1000], Validation Loss: 0.0951, Validation Accuracy: 97.09%\n",
      "Output Summary: Max=10.7877, Min=-7.1210, Median=-0.7771, Mean=0.0415\n",
      "\n",
      "Epoch [37/1000], Training Loss: 0.0530\n",
      "Epoch [37/1000], Validation Loss: 0.0943, Validation Accuracy: 97.20%\n",
      "Output Summary: Max=10.8276, Min=-7.2380, Median=-0.7842, Mean=0.0359\n",
      "\n",
      "Epoch [38/1000], Training Loss: 0.0542\n",
      "Epoch [38/1000], Validation Loss: 0.0981, Validation Accuracy: 97.04%\n",
      "Output Summary: Max=11.0254, Min=-7.1811, Median=-0.7889, Mean=0.0486\n",
      "\n",
      "Epoch [39/1000], Training Loss: 0.0551\n",
      "Epoch [39/1000], Validation Loss: 0.1044, Validation Accuracy: 96.81%\n",
      "Output Summary: Max=11.1295, Min=-7.3534, Median=-0.8006, Mean=0.0510\n",
      "\n",
      "Epoch [40/1000], Training Loss: 0.0588\n",
      "Epoch [40/1000], Validation Loss: 0.1032, Validation Accuracy: 96.82%\n",
      "Output Summary: Max=11.1361, Min=-7.4994, Median=-0.7978, Mean=0.0138\n",
      "\n",
      "Epoch [41/1000], Training Loss: 0.0620\n",
      "Epoch [41/1000], Validation Loss: 0.0931, Validation Accuracy: 97.26%\n",
      "Output Summary: Max=11.2896, Min=-7.2789, Median=-0.8555, Mean=0.0133\n",
      "\n",
      "Epoch [42/1000], Training Loss: 0.0583\n",
      "Epoch [42/1000], Validation Loss: 0.0931, Validation Accuracy: 97.38%\n",
      "Output Summary: Max=11.0681, Min=-7.5015, Median=-0.8486, Mean=-0.0089\n",
      "\n",
      "Epoch [43/1000], Training Loss: 0.0519\n",
      "Epoch [43/1000], Validation Loss: 0.0945, Validation Accuracy: 97.26%\n",
      "Output Summary: Max=11.2365, Min=-7.4009, Median=-0.8513, Mean=-0.0093\n",
      "\n",
      "Epoch [44/1000], Training Loss: 0.0502\n",
      "Epoch [44/1000], Validation Loss: 0.0917, Validation Accuracy: 97.25%\n",
      "Output Summary: Max=11.3010, Min=-7.3891, Median=-0.8856, Mean=-0.0032\n",
      "\n",
      "Epoch [45/1000], Training Loss: 0.0489\n",
      "Epoch [45/1000], Validation Loss: 0.0870, Validation Accuracy: 97.51%\n",
      "Output Summary: Max=11.5009, Min=-7.3833, Median=-0.8607, Mean=0.0085\n",
      "\n",
      "Epoch [46/1000], Training Loss: 0.0462\n",
      "Epoch [46/1000], Validation Loss: 0.0959, Validation Accuracy: 97.13%\n",
      "Output Summary: Max=11.5134, Min=-7.6977, Median=-0.8021, Mean=0.0371\n",
      "\n",
      "Epoch [47/1000], Training Loss: 0.0469\n",
      "Epoch [47/1000], Validation Loss: 0.0967, Validation Accuracy: 97.14%\n",
      "Output Summary: Max=11.4097, Min=-7.5674, Median=-0.8227, Mean=0.0383\n",
      "\n",
      "Epoch [48/1000], Training Loss: 0.0457\n",
      "Epoch [48/1000], Validation Loss: 0.0902, Validation Accuracy: 97.41%\n",
      "Output Summary: Max=11.6211, Min=-7.5597, Median=-0.8753, Mean=0.0020\n",
      "\n",
      "Epoch [49/1000], Training Loss: 0.0435\n",
      "Epoch [49/1000], Validation Loss: 0.0876, Validation Accuracy: 97.47%\n",
      "Output Summary: Max=11.6925, Min=-7.4945, Median=-0.9321, Mean=-0.0151\n",
      "\n",
      "Epoch [50/1000], Training Loss: 0.0410\n",
      "Epoch [50/1000], Validation Loss: 0.0883, Validation Accuracy: 97.41%\n",
      "Output Summary: Max=11.8444, Min=-7.7209, Median=-0.9107, Mean=-0.0117\n",
      "\n",
      "Epoch [51/1000], Training Loss: 0.0398\n",
      "Epoch [51/1000], Validation Loss: 0.0946, Validation Accuracy: 97.29%\n",
      "Output Summary: Max=11.9335, Min=-7.8987, Median=-0.8728, Mean=0.0175\n",
      "\n",
      "Epoch [52/1000], Training Loss: 0.0383\n",
      "Epoch [52/1000], Validation Loss: 0.0946, Validation Accuracy: 97.30%\n",
      "Output Summary: Max=12.1229, Min=-7.8371, Median=-0.8612, Mean=0.0397\n",
      "\n",
      "Epoch [53/1000], Training Loss: 0.0369\n",
      "Epoch [53/1000], Validation Loss: 0.0885, Validation Accuracy: 97.35%\n",
      "Output Summary: Max=12.1397, Min=-7.6347, Median=-0.9340, Mean=-0.0014\n",
      "\n",
      "Epoch [54/1000], Training Loss: 0.0366\n",
      "Epoch [54/1000], Validation Loss: 0.0868, Validation Accuracy: 97.43%\n",
      "Output Summary: Max=12.2123, Min=-7.5949, Median=-0.9636, Mean=-0.0270\n",
      "\n",
      "Epoch [55/1000], Training Loss: 0.0380\n",
      "Epoch [55/1000], Validation Loss: 0.0910, Validation Accuracy: 97.27%\n",
      "Output Summary: Max=12.2781, Min=-8.0569, Median=-0.9430, Mean=-0.0147\n",
      "\n",
      "Epoch [56/1000], Training Loss: 0.0389\n",
      "Epoch [56/1000], Validation Loss: 0.0928, Validation Accuracy: 97.33%\n",
      "Output Summary: Max=12.4728, Min=-8.3573, Median=-0.9395, Mean=-0.0105\n",
      "\n",
      "Epoch [57/1000], Training Loss: 0.0387\n",
      "Epoch [57/1000], Validation Loss: 0.0982, Validation Accuracy: 97.32%\n",
      "Output Summary: Max=12.4614, Min=-8.1134, Median=-0.9698, Mean=-0.0276\n",
      "\n",
      "Epoch [58/1000], Training Loss: 0.0368\n",
      "Epoch [58/1000], Validation Loss: 0.0927, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=12.6151, Min=-8.0701, Median=-0.9418, Mean=-0.0346\n",
      "\n",
      "Epoch [59/1000], Training Loss: 0.0372\n",
      "Epoch [59/1000], Validation Loss: 0.0890, Validation Accuracy: 97.49%\n",
      "Output Summary: Max=12.6990, Min=-7.9741, Median=-0.9641, Mean=-0.0287\n",
      "\n",
      "Epoch [60/1000], Training Loss: 0.0337\n",
      "Epoch [60/1000], Validation Loss: 0.0954, Validation Accuracy: 97.22%\n",
      "Output Summary: Max=12.6910, Min=-8.6531, Median=-0.9872, Mean=-0.0285\n",
      "\n",
      "Epoch [61/1000], Training Loss: 0.0342\n",
      "Epoch [61/1000], Validation Loss: 0.0919, Validation Accuracy: 97.34%\n",
      "Output Summary: Max=12.8049, Min=-8.6825, Median=-1.0018, Mean=-0.0530\n",
      "\n",
      "Epoch [62/1000], Training Loss: 0.0332\n",
      "Epoch [62/1000], Validation Loss: 0.0899, Validation Accuracy: 97.43%\n",
      "Output Summary: Max=12.8785, Min=-8.9294, Median=-1.0242, Mean=-0.0628\n",
      "\n",
      "Epoch [63/1000], Training Loss: 0.0318\n",
      "Epoch [63/1000], Validation Loss: 0.0901, Validation Accuracy: 97.46%\n",
      "Output Summary: Max=12.8318, Min=-8.9788, Median=-1.0205, Mean=-0.0392\n",
      "\n",
      "Epoch [64/1000], Training Loss: 0.0321\n",
      "Epoch [64/1000], Validation Loss: 0.0931, Validation Accuracy: 97.38%\n",
      "Output Summary: Max=13.0109, Min=-8.8523, Median=-1.0569, Mean=-0.0347\n",
      "\n",
      "Epoch [65/1000], Training Loss: 0.0344\n",
      "Epoch [65/1000], Validation Loss: 0.0919, Validation Accuracy: 97.38%\n",
      "Output Summary: Max=13.0059, Min=-9.0876, Median=-1.0971, Mean=-0.0707\n",
      "\n",
      "Epoch [66/1000], Training Loss: 0.0355\n",
      "Epoch [66/1000], Validation Loss: 0.0931, Validation Accuracy: 97.46%\n",
      "Output Summary: Max=13.0936, Min=-8.5528, Median=-1.0200, Mean=-0.0441\n",
      "\n",
      "Epoch [67/1000], Training Loss: 0.0388\n",
      "Epoch [67/1000], Validation Loss: 0.0991, Validation Accuracy: 97.16%\n",
      "Output Summary: Max=13.1281, Min=-8.4518, Median=-0.9710, Mean=-0.0141\n",
      "\n",
      "Epoch [68/1000], Training Loss: 0.0362\n",
      "Epoch [68/1000], Validation Loss: 0.0943, Validation Accuracy: 97.42%\n",
      "Output Summary: Max=13.0996, Min=-9.0450, Median=-0.9971, Mean=-0.0498\n",
      "\n",
      "Epoch [69/1000], Training Loss: 0.0335\n",
      "Epoch [69/1000], Validation Loss: 0.0919, Validation Accuracy: 97.41%\n",
      "Output Summary: Max=13.4769, Min=-9.1692, Median=-1.0347, Mean=-0.0699\n",
      "\n",
      "Epoch [70/1000], Training Loss: 0.0332\n",
      "Epoch [70/1000], Validation Loss: 0.0926, Validation Accuracy: 97.30%\n",
      "Output Summary: Max=13.3822, Min=-8.8529, Median=-1.0423, Mean=-0.0728\n",
      "\n",
      "Epoch [71/1000], Training Loss: 0.0335\n",
      "Epoch [71/1000], Validation Loss: 0.0971, Validation Accuracy: 97.24%\n",
      "Output Summary: Max=13.3468, Min=-8.8995, Median=-1.0575, Mean=-0.0714\n",
      "\n",
      "Epoch [72/1000], Training Loss: 0.0327\n",
      "Epoch [72/1000], Validation Loss: 0.0998, Validation Accuracy: 97.22%\n",
      "Output Summary: Max=13.2974, Min=-9.1148, Median=-1.0367, Mean=-0.0419\n",
      "\n",
      "Epoch [73/1000], Training Loss: 0.0317\n",
      "Epoch [73/1000], Validation Loss: 0.0952, Validation Accuracy: 97.29%\n",
      "Output Summary: Max=13.5873, Min=-9.3448, Median=-1.0820, Mean=-0.0688\n",
      "\n",
      "Epoch [74/1000], Training Loss: 0.0313\n",
      "Epoch [74/1000], Validation Loss: 0.0945, Validation Accuracy: 97.45%\n",
      "Output Summary: Max=13.6028, Min=-9.1699, Median=-1.1096, Mean=-0.1063\n",
      "\n",
      "Epoch [75/1000], Training Loss: 0.0300\n",
      "Epoch [75/1000], Validation Loss: 0.0915, Validation Accuracy: 97.48%\n",
      "Output Summary: Max=13.4924, Min=-9.0652, Median=-1.1189, Mean=-0.1070\n",
      "\n",
      "Epoch [76/1000], Training Loss: 0.0317\n",
      "Epoch [76/1000], Validation Loss: 0.0866, Validation Accuracy: 97.43%\n",
      "Output Summary: Max=13.5623, Min=-9.0681, Median=-1.0982, Mean=-0.0892\n",
      "\n",
      "Epoch [77/1000], Training Loss: 0.0296\n",
      "Epoch [77/1000], Validation Loss: 0.0923, Validation Accuracy: 97.53%\n",
      "Output Summary: Max=13.4825, Min=-9.2321, Median=-1.0598, Mean=-0.0745\n",
      "\n",
      "Epoch [78/1000], Training Loss: 0.0297\n",
      "Epoch [78/1000], Validation Loss: 0.0897, Validation Accuracy: 97.61%\n",
      "Output Summary: Max=13.6956, Min=-9.0953, Median=-1.0780, Mean=-0.0681\n",
      "\n",
      "Epoch [79/1000], Training Loss: 0.0285\n",
      "Epoch [79/1000], Validation Loss: 0.1007, Validation Accuracy: 97.32%\n",
      "Output Summary: Max=13.7199, Min=-8.8306, Median=-1.1155, Mean=-0.0835\n",
      "\n",
      "Epoch [80/1000], Training Loss: 0.0270\n",
      "Epoch [80/1000], Validation Loss: 0.0968, Validation Accuracy: 97.46%\n",
      "Output Summary: Max=13.8284, Min=-8.9541, Median=-1.0869, Mean=-0.0690\n",
      "\n",
      "Epoch [81/1000], Training Loss: 0.0274\n",
      "Epoch [81/1000], Validation Loss: 0.0946, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=13.9136, Min=-9.3440, Median=-1.0733, Mean=-0.0761\n",
      "\n",
      "Epoch [82/1000], Training Loss: 0.0279\n",
      "Epoch [82/1000], Validation Loss: 0.0942, Validation Accuracy: 97.44%\n",
      "Output Summary: Max=13.8833, Min=-9.5722, Median=-1.1130, Mean=-0.1122\n",
      "\n",
      "Epoch [83/1000], Training Loss: 0.0274\n",
      "Epoch [83/1000], Validation Loss: 0.1016, Validation Accuracy: 97.15%\n",
      "Output Summary: Max=14.0920, Min=-9.6347, Median=-1.1071, Mean=-0.1003\n",
      "\n",
      "Epoch [84/1000], Training Loss: 0.0245\n",
      "Epoch [84/1000], Validation Loss: 0.1003, Validation Accuracy: 97.30%\n",
      "Output Summary: Max=14.2412, Min=-9.5708, Median=-1.1368, Mean=-0.1017\n",
      "\n",
      "Epoch [85/1000], Training Loss: 0.0250\n",
      "Epoch [85/1000], Validation Loss: 0.0947, Validation Accuracy: 97.47%\n",
      "Output Summary: Max=14.2319, Min=-9.4515, Median=-1.1642, Mean=-0.1185\n",
      "\n",
      "Epoch [86/1000], Training Loss: 0.0241\n",
      "Epoch [86/1000], Validation Loss: 0.0926, Validation Accuracy: 97.52%\n",
      "Output Summary: Max=14.4435, Min=-9.4571, Median=-1.1482, Mean=-0.1164\n",
      "\n",
      "Epoch [87/1000], Training Loss: 0.0249\n",
      "Epoch [87/1000], Validation Loss: 0.0977, Validation Accuracy: 97.42%\n",
      "Output Summary: Max=14.4689, Min=-9.8711, Median=-1.1928, Mean=-0.1456\n",
      "\n",
      "Epoch [88/1000], Training Loss: 0.0248\n",
      "Epoch [88/1000], Validation Loss: 0.0989, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=14.4494, Min=-9.6918, Median=-1.1873, Mean=-0.1180\n",
      "\n",
      "Epoch [89/1000], Training Loss: 0.0266\n",
      "Epoch [89/1000], Validation Loss: 0.0988, Validation Accuracy: 97.35%\n",
      "Output Summary: Max=14.5364, Min=-9.6785, Median=-1.1632, Mean=-0.0945\n",
      "\n",
      "Epoch [90/1000], Training Loss: 0.0275\n",
      "Epoch [90/1000], Validation Loss: 0.0992, Validation Accuracy: 97.27%\n",
      "Output Summary: Max=14.5605, Min=-9.5079, Median=-1.1834, Mean=-0.1270\n",
      "\n",
      "Epoch [91/1000], Training Loss: 0.0263\n",
      "Epoch [91/1000], Validation Loss: 0.1105, Validation Accuracy: 97.10%\n",
      "Output Summary: Max=14.6148, Min=-10.4695, Median=-1.1972, Mean=-0.1547\n",
      "\n",
      "Epoch [92/1000], Training Loss: 0.0265\n",
      "Epoch [92/1000], Validation Loss: 0.1079, Validation Accuracy: 97.24%\n",
      "Output Summary: Max=14.8617, Min=-10.1197, Median=-1.1997, Mean=-0.1167\n",
      "\n",
      "Epoch [93/1000], Training Loss: 0.0229\n",
      "Epoch [93/1000], Validation Loss: 0.1002, Validation Accuracy: 97.23%\n",
      "Output Summary: Max=14.6584, Min=-10.6847, Median=-1.2236, Mean=-0.1212\n",
      "\n",
      "Epoch [94/1000], Training Loss: 0.0207\n",
      "Epoch [94/1000], Validation Loss: 0.1056, Validation Accuracy: 97.23%\n",
      "Output Summary: Max=14.8711, Min=-10.1510, Median=-1.2301, Mean=-0.1349\n",
      "\n",
      "Epoch [95/1000], Training Loss: 0.0201\n",
      "Epoch [95/1000], Validation Loss: 0.1010, Validation Accuracy: 97.41%\n",
      "Output Summary: Max=14.8139, Min=-10.9317, Median=-1.2354, Mean=-0.1340\n",
      "\n",
      "Epoch [96/1000], Training Loss: 0.0202\n",
      "Epoch [96/1000], Validation Loss: 0.1036, Validation Accuracy: 97.24%\n",
      "Output Summary: Max=14.8886, Min=-10.8927, Median=-1.2390, Mean=-0.1404\n",
      "\n",
      "Epoch [97/1000], Training Loss: 0.0192\n",
      "Epoch [97/1000], Validation Loss: 0.1010, Validation Accuracy: 97.35%\n",
      "Output Summary: Max=15.0154, Min=-11.0666, Median=-1.2143, Mean=-0.1155\n",
      "\n",
      "Epoch [98/1000], Training Loss: 0.0201\n",
      "Epoch [98/1000], Validation Loss: 0.1015, Validation Accuracy: 97.30%\n",
      "Output Summary: Max=15.1089, Min=-11.2775, Median=-1.2062, Mean=-0.1210\n",
      "\n",
      "Epoch [99/1000], Training Loss: 0.0206\n",
      "Epoch [99/1000], Validation Loss: 0.1069, Validation Accuracy: 97.28%\n",
      "Output Summary: Max=15.3332, Min=-11.8412, Median=-1.1772, Mean=-0.1064\n",
      "\n",
      "Epoch [100/1000], Training Loss: 0.0211\n",
      "Epoch [100/1000], Validation Loss: 0.1026, Validation Accuracy: 97.34%\n",
      "Output Summary: Max=15.2368, Min=-11.0973, Median=-1.1714, Mean=-0.0818\n",
      "\n",
      "Epoch [101/1000], Training Loss: 0.0211\n",
      "Epoch [101/1000], Validation Loss: 0.0980, Validation Accuracy: 97.36%\n",
      "Output Summary: Max=15.2773, Min=-10.0776, Median=-1.1584, Mean=-0.0549\n",
      "\n",
      "Epoch [102/1000], Training Loss: 0.0208\n",
      "Epoch [102/1000], Validation Loss: 0.0982, Validation Accuracy: 97.39%\n",
      "Output Summary: Max=15.2767, Min=-9.9072, Median=-1.1241, Mean=-0.0516\n",
      "\n",
      "Epoch [103/1000], Training Loss: 0.0233\n",
      "Epoch [103/1000], Validation Loss: 0.1045, Validation Accuracy: 97.31%\n",
      "Output Summary: Max=15.3681, Min=-10.1942, Median=-1.1363, Mean=-0.0617\n",
      "\n",
      "Epoch [104/1000], Training Loss: 0.0241\n",
      "Epoch [104/1000], Validation Loss: 0.1014, Validation Accuracy: 97.49%\n",
      "Output Summary: Max=15.3843, Min=-10.6590, Median=-1.1673, Mean=-0.0558\n",
      "\n",
      "Epoch [105/1000], Training Loss: 0.0260\n",
      "Epoch [105/1000], Validation Loss: 0.1004, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=15.5286, Min=-10.8609, Median=-1.1943, Mean=-0.0841\n",
      "\n",
      "Epoch [106/1000], Training Loss: 0.0263\n",
      "Epoch [106/1000], Validation Loss: 0.1035, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=15.6243, Min=-10.6246, Median=-1.1704, Mean=-0.0881\n",
      "\n",
      "Epoch [107/1000], Training Loss: 0.0257\n",
      "Epoch [107/1000], Validation Loss: 0.0935, Validation Accuracy: 97.63%\n",
      "Output Summary: Max=15.6488, Min=-10.2008, Median=-1.2230, Mean=-0.1015\n",
      "\n",
      "Epoch [108/1000], Training Loss: 0.0239\n",
      "Epoch [108/1000], Validation Loss: 0.1134, Validation Accuracy: 97.12%\n",
      "Output Summary: Max=15.6033, Min=-10.6922, Median=-1.1900, Mean=-0.0859\n",
      "\n",
      "Epoch [109/1000], Training Loss: 0.0241\n",
      "Epoch [109/1000], Validation Loss: 0.1051, Validation Accuracy: 97.41%\n",
      "Output Summary: Max=15.5088, Min=-10.4996, Median=-1.2202, Mean=-0.0960\n",
      "\n",
      "Epoch [110/1000], Training Loss: 0.0215\n",
      "Epoch [110/1000], Validation Loss: 0.1021, Validation Accuracy: 97.32%\n",
      "Output Summary: Max=15.6356, Min=-10.9439, Median=-1.2382, Mean=-0.1102\n",
      "\n",
      "Epoch [111/1000], Training Loss: 0.0227\n",
      "Epoch [111/1000], Validation Loss: 0.0990, Validation Accuracy: 97.45%\n",
      "Output Summary: Max=15.7722, Min=-10.4421, Median=-1.2293, Mean=-0.1214\n",
      "\n",
      "Epoch [112/1000], Training Loss: 0.0208\n",
      "Epoch [112/1000], Validation Loss: 0.1055, Validation Accuracy: 97.36%\n",
      "Output Summary: Max=15.7875, Min=-11.7397, Median=-1.2289, Mean=-0.1120\n",
      "\n",
      "Epoch [113/1000], Training Loss: 0.0199\n",
      "Epoch [113/1000], Validation Loss: 0.1030, Validation Accuracy: 97.54%\n",
      "Output Summary: Max=15.7173, Min=-10.6845, Median=-1.2037, Mean=-0.0905\n",
      "\n",
      "Epoch [114/1000], Training Loss: 0.0194\n",
      "Epoch [114/1000], Validation Loss: 0.1032, Validation Accuracy: 97.33%\n",
      "Output Summary: Max=15.9317, Min=-10.4251, Median=-1.2600, Mean=-0.1268\n",
      "\n",
      "Epoch [115/1000], Training Loss: 0.0178\n",
      "Epoch [115/1000], Validation Loss: 0.1035, Validation Accuracy: 97.41%\n",
      "Output Summary: Max=15.6726, Min=-11.2333, Median=-1.2362, Mean=-0.1177\n",
      "\n",
      "Epoch [116/1000], Training Loss: 0.0168\n",
      "Epoch [116/1000], Validation Loss: 0.0963, Validation Accuracy: 97.69%\n",
      "Output Summary: Max=15.7996, Min=-10.9472, Median=-1.2583, Mean=-0.1028\n",
      "\n",
      "Epoch [117/1000], Training Loss: 0.0180\n",
      "Epoch [117/1000], Validation Loss: 0.1010, Validation Accuracy: 97.48%\n",
      "Output Summary: Max=15.9358, Min=-11.0758, Median=-1.2510, Mean=-0.0813\n",
      "\n",
      "Epoch [118/1000], Training Loss: 0.0168\n",
      "Epoch [118/1000], Validation Loss: 0.1052, Validation Accuracy: 97.32%\n",
      "Output Summary: Max=15.9324, Min=-11.4128, Median=-1.3062, Mean=-0.1258\n",
      "\n",
      "Epoch [119/1000], Training Loss: 0.0165\n",
      "Epoch [119/1000], Validation Loss: 0.0984, Validation Accuracy: 97.39%\n",
      "Output Summary: Max=16.1286, Min=-10.9345, Median=-1.3225, Mean=-0.1322\n",
      "\n",
      "Epoch [120/1000], Training Loss: 0.0179\n",
      "Epoch [120/1000], Validation Loss: 0.0976, Validation Accuracy: 97.54%\n",
      "Output Summary: Max=16.3500, Min=-10.9331, Median=-1.2617, Mean=-0.0912\n",
      "\n",
      "Epoch [121/1000], Training Loss: 0.0168\n",
      "Epoch [121/1000], Validation Loss: 0.1081, Validation Accuracy: 97.37%\n",
      "Output Summary: Max=16.3691, Min=-10.9909, Median=-1.2884, Mean=-0.1155\n",
      "\n",
      "Epoch [122/1000], Training Loss: 0.0179\n",
      "Epoch [122/1000], Validation Loss: 0.0969, Validation Accuracy: 97.50%\n",
      "Output Summary: Max=16.5648, Min=-10.8193, Median=-1.3808, Mean=-0.1509\n",
      "\n",
      "Epoch [123/1000], Training Loss: 0.0179\n",
      "Epoch [123/1000], Validation Loss: 0.1002, Validation Accuracy: 97.57%\n",
      "Output Summary: Max=16.5867, Min=-10.9284, Median=-1.3728, Mean=-0.1516\n",
      "\n",
      "Epoch [124/1000], Training Loss: 0.0190\n",
      "Epoch [124/1000], Validation Loss: 0.1078, Validation Accuracy: 97.39%\n",
      "Output Summary: Max=16.5856, Min=-11.0356, Median=-1.3993, Mean=-0.1630\n",
      "\n",
      "Epoch [125/1000], Training Loss: 0.0201\n",
      "Epoch [125/1000], Validation Loss: 0.1102, Validation Accuracy: 97.35%\n",
      "Output Summary: Max=16.8329, Min=-11.6264, Median=-1.3823, Mean=-0.1477\n",
      "\n",
      "Epoch [126/1000], Training Loss: 0.0202\n",
      "Epoch [126/1000], Validation Loss: 0.1058, Validation Accuracy: 97.39%\n",
      "Output Summary: Max=16.8171, Min=-11.6717, Median=-1.3121, Mean=-0.1153\n",
      "\n",
      "Epoch [127/1000], Training Loss: 0.0173\n",
      "Epoch [127/1000], Validation Loss: 0.1015, Validation Accuracy: 97.51%\n",
      "Output Summary: Max=17.0340, Min=-11.3307, Median=-1.3034, Mean=-0.1144\n",
      "\n",
      "Epoch [128/1000], Training Loss: 0.0148\n",
      "Epoch [128/1000], Validation Loss: 0.1032, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=16.9007, Min=-11.6722, Median=-1.3310, Mean=-0.1065\n",
      "\n",
      "Epoch [129/1000], Training Loss: 0.0154\n",
      "Epoch [129/1000], Validation Loss: 0.1050, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=16.9465, Min=-11.3485, Median=-1.3625, Mean=-0.1307\n",
      "\n",
      "Epoch [130/1000], Training Loss: 0.0155\n",
      "Epoch [130/1000], Validation Loss: 0.0998, Validation Accuracy: 97.67%\n",
      "Output Summary: Max=17.3341, Min=-11.2833, Median=-1.4199, Mean=-0.1588\n",
      "\n",
      "Epoch [131/1000], Training Loss: 0.0148\n",
      "Epoch [131/1000], Validation Loss: 0.1097, Validation Accuracy: 97.37%\n",
      "Output Summary: Max=17.2120, Min=-11.2292, Median=-1.4271, Mean=-0.1548\n",
      "\n",
      "Epoch [132/1000], Training Loss: 0.0148\n",
      "Epoch [132/1000], Validation Loss: 0.1062, Validation Accuracy: 97.51%\n",
      "Output Summary: Max=17.1840, Min=-11.2441, Median=-1.4403, Mean=-0.1557\n",
      "\n",
      "Epoch [133/1000], Training Loss: 0.0140\n",
      "Epoch [133/1000], Validation Loss: 0.1058, Validation Accuracy: 97.52%\n",
      "Output Summary: Max=17.3001, Min=-11.0586, Median=-1.4385, Mean=-0.1662\n",
      "\n",
      "Epoch [134/1000], Training Loss: 0.0139\n",
      "Epoch [134/1000], Validation Loss: 0.1019, Validation Accuracy: 97.62%\n",
      "Output Summary: Max=17.2685, Min=-11.4366, Median=-1.4481, Mean=-0.2020\n",
      "\n",
      "Epoch [135/1000], Training Loss: 0.0132\n",
      "Epoch [135/1000], Validation Loss: 0.0950, Validation Accuracy: 97.67%\n",
      "Output Summary: Max=17.3935, Min=-11.6239, Median=-1.4303, Mean=-0.1658\n",
      "\n",
      "Epoch [136/1000], Training Loss: 0.0141\n",
      "Epoch [136/1000], Validation Loss: 0.1006, Validation Accuracy: 97.48%\n",
      "Output Summary: Max=17.5772, Min=-11.7369, Median=-1.4251, Mean=-0.1588\n",
      "\n",
      "Epoch [137/1000], Training Loss: 0.0121\n",
      "Epoch [137/1000], Validation Loss: 0.1073, Validation Accuracy: 97.49%\n",
      "Output Summary: Max=17.5962, Min=-11.6642, Median=-1.4656, Mean=-0.1909\n",
      "\n",
      "Epoch [138/1000], Training Loss: 0.0119\n",
      "Epoch [138/1000], Validation Loss: 0.1041, Validation Accuracy: 97.67%\n",
      "Output Summary: Max=17.7271, Min=-11.9781, Median=-1.4859, Mean=-0.1655\n",
      "\n",
      "Epoch [139/1000], Training Loss: 0.0105\n",
      "Epoch [139/1000], Validation Loss: 0.0960, Validation Accuracy: 97.80%\n",
      "Output Summary: Max=17.6974, Min=-11.8392, Median=-1.4727, Mean=-0.1582\n",
      "\n",
      "Epoch [140/1000], Training Loss: 0.0093\n",
      "Epoch [140/1000], Validation Loss: 0.1003, Validation Accuracy: 97.72%\n",
      "Output Summary: Max=17.7805, Min=-11.8017, Median=-1.4756, Mean=-0.1682\n",
      "\n",
      "Epoch [141/1000], Training Loss: 0.0088\n",
      "Epoch [141/1000], Validation Loss: 0.1065, Validation Accuracy: 97.52%\n",
      "Output Summary: Max=17.7400, Min=-11.9905, Median=-1.5046, Mean=-0.1956\n",
      "\n",
      "Epoch [142/1000], Training Loss: 0.0090\n",
      "Epoch [142/1000], Validation Loss: 0.0999, Validation Accuracy: 97.57%\n",
      "Output Summary: Max=17.9757, Min=-11.8751, Median=-1.4745, Mean=-0.1737\n",
      "\n",
      "Epoch [143/1000], Training Loss: 0.0087\n",
      "Epoch [143/1000], Validation Loss: 0.1026, Validation Accuracy: 97.62%\n",
      "Output Summary: Max=17.8090, Min=-12.1053, Median=-1.4331, Mean=-0.1346\n",
      "\n",
      "Epoch [144/1000], Training Loss: 0.0084\n",
      "Epoch [144/1000], Validation Loss: 0.1043, Validation Accuracy: 97.43%\n",
      "Output Summary: Max=18.0040, Min=-11.6675, Median=-1.4804, Mean=-0.1673\n",
      "\n",
      "Epoch [145/1000], Training Loss: 0.0083\n",
      "Epoch [145/1000], Validation Loss: 0.1056, Validation Accuracy: 97.46%\n",
      "Output Summary: Max=18.2225, Min=-12.1070, Median=-1.4832, Mean=-0.1627\n",
      "\n",
      "Epoch [146/1000], Training Loss: 0.0071\n",
      "Epoch [146/1000], Validation Loss: 0.1074, Validation Accuracy: 97.56%\n",
      "Output Summary: Max=18.3306, Min=-12.4332, Median=-1.4871, Mean=-0.1694\n",
      "\n",
      "Epoch [147/1000], Training Loss: 0.0074\n",
      "Epoch [147/1000], Validation Loss: 0.1055, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=18.3427, Min=-12.3386, Median=-1.5490, Mean=-0.1886\n",
      "\n",
      "Epoch [148/1000], Training Loss: 0.0069\n",
      "Epoch [148/1000], Validation Loss: 0.1112, Validation Accuracy: 97.56%\n",
      "Output Summary: Max=18.2728, Min=-12.9448, Median=-1.5308, Mean=-0.1800\n",
      "\n",
      "Epoch [149/1000], Training Loss: 0.0073\n",
      "Epoch [149/1000], Validation Loss: 0.1124, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=18.2214, Min=-13.0488, Median=-1.5478, Mean=-0.1809\n",
      "\n",
      "Epoch [150/1000], Training Loss: 0.0080\n",
      "Epoch [150/1000], Validation Loss: 0.1142, Validation Accuracy: 97.55%\n",
      "Output Summary: Max=18.4118, Min=-12.9070, Median=-1.5574, Mean=-0.1903\n",
      "\n",
      "Epoch [151/1000], Training Loss: 0.0071\n",
      "Epoch [151/1000], Validation Loss: 0.1140, Validation Accuracy: 97.59%\n",
      "Output Summary: Max=18.4447, Min=-13.4573, Median=-1.5885, Mean=-0.2233\n",
      "\n",
      "Epoch [152/1000], Training Loss: 0.0075\n",
      "Epoch [152/1000], Validation Loss: 0.1088, Validation Accuracy: 97.57%\n",
      "Output Summary: Max=18.6761, Min=-12.7780, Median=-1.5924, Mean=-0.2079\n",
      "\n",
      "Epoch [153/1000], Training Loss: 0.0074\n",
      "Epoch [153/1000], Validation Loss: 0.1155, Validation Accuracy: 97.37%\n",
      "Output Summary: Max=18.6961, Min=-13.1374, Median=-1.5692, Mean=-0.2035\n",
      "\n",
      "Epoch [154/1000], Training Loss: 0.0071\n",
      "Epoch [154/1000], Validation Loss: 0.1137, Validation Accuracy: 97.45%\n",
      "Output Summary: Max=18.6925, Min=-12.9520, Median=-1.5587, Mean=-0.1898\n",
      "\n",
      "Epoch [155/1000], Training Loss: 0.0111\n",
      "Epoch [155/1000], Validation Loss: 0.1263, Validation Accuracy: 97.24%\n",
      "Output Summary: Max=18.9389, Min=-13.0564, Median=-1.5389, Mean=-0.1920\n",
      "\n",
      "Epoch [156/1000], Training Loss: 0.0109\n",
      "Epoch [156/1000], Validation Loss: 0.1122, Validation Accuracy: 97.42%\n",
      "Output Summary: Max=18.9547, Min=-13.0151, Median=-1.5913, Mean=-0.1990\n",
      "\n",
      "Epoch [157/1000], Training Loss: 0.0102\n",
      "Epoch [157/1000], Validation Loss: 0.1192, Validation Accuracy: 97.41%\n",
      "Output Summary: Max=18.9968, Min=-12.9712, Median=-1.5234, Mean=-0.1840\n",
      "\n",
      "Epoch [158/1000], Training Loss: 0.0090\n",
      "Epoch [158/1000], Validation Loss: 0.1083, Validation Accuracy: 97.67%\n",
      "Output Summary: Max=18.9780, Min=-12.6689, Median=-1.6134, Mean=-0.2239\n",
      "\n",
      "Epoch [159/1000], Training Loss: 0.0091\n",
      "Epoch [159/1000], Validation Loss: 0.1152, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=19.1635, Min=-13.4064, Median=-1.5799, Mean=-0.2077\n",
      "\n",
      "Epoch [160/1000], Training Loss: 0.0076\n",
      "Epoch [160/1000], Validation Loss: 0.1167, Validation Accuracy: 97.42%\n",
      "Output Summary: Max=19.2584, Min=-13.2219, Median=-1.5945, Mean=-0.2115\n",
      "\n",
      "Epoch [161/1000], Training Loss: 0.0076\n",
      "Epoch [161/1000], Validation Loss: 0.1161, Validation Accuracy: 97.45%\n",
      "Output Summary: Max=19.2838, Min=-12.4927, Median=-1.6245, Mean=-0.2084\n",
      "\n",
      "Epoch [162/1000], Training Loss: 0.0082\n",
      "Epoch [162/1000], Validation Loss: 0.1304, Validation Accuracy: 97.20%\n",
      "Output Summary: Max=19.4580, Min=-13.2350, Median=-1.5997, Mean=-0.2148\n",
      "\n",
      "Epoch [163/1000], Training Loss: 0.0085\n",
      "Epoch [163/1000], Validation Loss: 0.1125, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=19.5583, Min=-12.8718, Median=-1.5766, Mean=-0.1866\n",
      "\n",
      "Epoch [164/1000], Training Loss: 0.0077\n",
      "Epoch [164/1000], Validation Loss: 0.1128, Validation Accuracy: 97.64%\n",
      "Output Summary: Max=19.5169, Min=-13.8505, Median=-1.6604, Mean=-0.2404\n",
      "\n",
      "Epoch [165/1000], Training Loss: 0.0071\n",
      "Epoch [165/1000], Validation Loss: 0.1220, Validation Accuracy: 97.30%\n",
      "Output Summary: Max=19.5808, Min=-13.5190, Median=-1.6446, Mean=-0.2389\n",
      "\n",
      "Epoch [166/1000], Training Loss: 0.0078\n",
      "Epoch [166/1000], Validation Loss: 0.1291, Validation Accuracy: 97.16%\n",
      "Output Summary: Max=19.4179, Min=-13.9619, Median=-1.7136, Mean=-0.2855\n",
      "\n",
      "Epoch [167/1000], Training Loss: 0.0072\n",
      "Epoch [167/1000], Validation Loss: 0.1300, Validation Accuracy: 97.19%\n",
      "Output Summary: Max=19.5512, Min=-13.6100, Median=-1.6946, Mean=-0.2748\n",
      "\n",
      "Epoch [168/1000], Training Loss: 0.0080\n",
      "Epoch [168/1000], Validation Loss: 0.1263, Validation Accuracy: 97.32%\n",
      "Output Summary: Max=19.6659, Min=-13.6996, Median=-1.6691, Mean=-0.2514\n",
      "\n",
      "Epoch [169/1000], Training Loss: 0.0088\n",
      "Epoch [169/1000], Validation Loss: 0.1257, Validation Accuracy: 97.33%\n",
      "Output Summary: Max=19.6909, Min=-13.4954, Median=-1.6895, Mean=-0.2217\n",
      "\n",
      "Epoch [170/1000], Training Loss: 0.0086\n",
      "Epoch [170/1000], Validation Loss: 0.1223, Validation Accuracy: 97.59%\n",
      "Output Summary: Max=19.9737, Min=-14.1728, Median=-1.6636, Mean=-0.2381\n",
      "\n",
      "Epoch [171/1000], Training Loss: 0.0098\n",
      "Epoch [171/1000], Validation Loss: 0.1116, Validation Accuracy: 97.63%\n",
      "Output Summary: Max=20.0210, Min=-13.7148, Median=-1.6479, Mean=-0.2187\n",
      "\n",
      "Epoch [172/1000], Training Loss: 0.0084\n",
      "Epoch [172/1000], Validation Loss: 0.1120, Validation Accuracy: 97.64%\n",
      "Output Summary: Max=19.9503, Min=-13.7510, Median=-1.6665, Mean=-0.2358\n",
      "\n",
      "Epoch [173/1000], Training Loss: 0.0079\n",
      "Epoch [173/1000], Validation Loss: 0.1190, Validation Accuracy: 97.47%\n",
      "Output Summary: Max=20.2814, Min=-13.6854, Median=-1.6311, Mean=-0.2242\n",
      "\n",
      "Epoch [174/1000], Training Loss: 0.0085\n",
      "Epoch [174/1000], Validation Loss: 0.1234, Validation Accuracy: 97.35%\n",
      "Output Summary: Max=20.2411, Min=-13.6869, Median=-1.5841, Mean=-0.2035\n",
      "\n",
      "Epoch [175/1000], Training Loss: 0.0096\n",
      "Epoch [175/1000], Validation Loss: 0.1204, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=20.4162, Min=-13.7866, Median=-1.6398, Mean=-0.2231\n",
      "\n",
      "Epoch [176/1000], Training Loss: 0.0091\n",
      "Epoch [176/1000], Validation Loss: 0.1122, Validation Accuracy: 97.67%\n",
      "Output Summary: Max=20.5392, Min=-14.3650, Median=-1.7055, Mean=-0.2493\n",
      "\n",
      "Epoch [177/1000], Training Loss: 0.0094\n",
      "Epoch [177/1000], Validation Loss: 0.1190, Validation Accuracy: 97.52%\n",
      "Output Summary: Max=20.3904, Min=-14.0745, Median=-1.6344, Mean=-0.2194\n",
      "\n",
      "Epoch [178/1000], Training Loss: 0.0088\n",
      "Epoch [178/1000], Validation Loss: 0.1320, Validation Accuracy: 97.31%\n",
      "Output Summary: Max=20.8045, Min=-14.6872, Median=-1.6341, Mean=-0.2001\n",
      "\n",
      "Epoch [179/1000], Training Loss: 0.0085\n",
      "Epoch [179/1000], Validation Loss: 0.1312, Validation Accuracy: 97.23%\n",
      "Output Summary: Max=20.8234, Min=-13.9822, Median=-1.6861, Mean=-0.2315\n",
      "\n",
      "Epoch [180/1000], Training Loss: 0.0100\n",
      "Epoch [180/1000], Validation Loss: 0.1319, Validation Accuracy: 97.28%\n",
      "Output Summary: Max=20.6437, Min=-14.2896, Median=-1.6965, Mean=-0.2272\n",
      "\n",
      "Epoch [181/1000], Training Loss: 0.0091\n",
      "Epoch [181/1000], Validation Loss: 0.1227, Validation Accuracy: 97.41%\n",
      "Output Summary: Max=20.6694, Min=-14.4911, Median=-1.7160, Mean=-0.2476\n",
      "\n",
      "Epoch [182/1000], Training Loss: 0.0103\n",
      "Epoch [182/1000], Validation Loss: 0.1311, Validation Accuracy: 97.39%\n",
      "Output Summary: Max=20.8030, Min=-13.4997, Median=-1.7455, Mean=-0.2582\n",
      "\n",
      "Epoch [183/1000], Training Loss: 0.0087\n",
      "Epoch [183/1000], Validation Loss: 0.1274, Validation Accuracy: 97.27%\n",
      "Output Summary: Max=20.8982, Min=-13.1630, Median=-1.7940, Mean=-0.2470\n",
      "\n",
      "Epoch [184/1000], Training Loss: 0.0106\n",
      "Epoch [184/1000], Validation Loss: 0.1271, Validation Accuracy: 97.49%\n",
      "Output Summary: Max=20.7495, Min=-13.9766, Median=-1.6645, Mean=-0.1962\n",
      "\n",
      "Epoch [185/1000], Training Loss: 0.0125\n",
      "Epoch [185/1000], Validation Loss: 0.1077, Validation Accuracy: 97.62%\n",
      "Output Summary: Max=20.6222, Min=-13.8368, Median=-1.7066, Mean=-0.2316\n",
      "\n",
      "Epoch [186/1000], Training Loss: 0.0129\n",
      "Epoch [186/1000], Validation Loss: 0.1260, Validation Accuracy: 97.37%\n",
      "Output Summary: Max=20.5206, Min=-14.5932, Median=-1.7662, Mean=-0.2948\n",
      "\n",
      "Epoch [187/1000], Training Loss: 0.0129\n",
      "Epoch [187/1000], Validation Loss: 0.1154, Validation Accuracy: 97.55%\n",
      "Output Summary: Max=21.2405, Min=-13.7139, Median=-1.6956, Mean=-0.2343\n",
      "\n",
      "Epoch [188/1000], Training Loss: 0.0107\n",
      "Epoch [188/1000], Validation Loss: 0.1162, Validation Accuracy: 97.52%\n",
      "Output Summary: Max=20.9781, Min=-14.0627, Median=-1.7378, Mean=-0.2238\n",
      "\n",
      "Epoch [189/1000], Training Loss: 0.0099\n",
      "Epoch [189/1000], Validation Loss: 0.1288, Validation Accuracy: 97.29%\n",
      "Output Summary: Max=20.8863, Min=-13.9750, Median=-1.8915, Mean=-0.3077\n",
      "\n",
      "Epoch [190/1000], Training Loss: 0.0096\n",
      "Epoch [190/1000], Validation Loss: 0.1274, Validation Accuracy: 97.54%\n",
      "Output Summary: Max=21.0973, Min=-14.0312, Median=-1.8808, Mean=-0.2929\n",
      "\n",
      "Epoch [191/1000], Training Loss: 0.0120\n",
      "Epoch [191/1000], Validation Loss: 0.1128, Validation Accuracy: 97.74%\n",
      "Output Summary: Max=20.6931, Min=-13.8623, Median=-1.8206, Mean=-0.2901\n",
      "\n",
      "Epoch [192/1000], Training Loss: 0.0085\n",
      "Epoch [192/1000], Validation Loss: 0.1177, Validation Accuracy: 97.52%\n",
      "Output Summary: Max=20.9536, Min=-14.5553, Median=-1.8499, Mean=-0.2920\n",
      "\n",
      "Epoch [193/1000], Training Loss: 0.0082\n",
      "Epoch [193/1000], Validation Loss: 0.1159, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=21.2487, Min=-14.3066, Median=-1.7390, Mean=-0.2166\n",
      "\n",
      "Epoch [194/1000], Training Loss: 0.0064\n",
      "Epoch [194/1000], Validation Loss: 0.1242, Validation Accuracy: 97.43%\n",
      "Output Summary: Max=21.2210, Min=-13.8511, Median=-1.7963, Mean=-0.2680\n",
      "\n",
      "Epoch [195/1000], Training Loss: 0.0083\n",
      "Epoch [195/1000], Validation Loss: 0.1149, Validation Accuracy: 97.64%\n",
      "Output Summary: Max=21.2058, Min=-14.2054, Median=-1.7918, Mean=-0.2605\n",
      "\n",
      "Epoch [196/1000], Training Loss: 0.0081\n",
      "Epoch [196/1000], Validation Loss: 0.1218, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=21.4872, Min=-14.4351, Median=-1.7452, Mean=-0.2292\n",
      "\n",
      "Epoch [197/1000], Training Loss: 0.0080\n",
      "Epoch [197/1000], Validation Loss: 0.1173, Validation Accuracy: 97.65%\n",
      "Output Summary: Max=21.3535, Min=-14.5342, Median=-1.8469, Mean=-0.2695\n",
      "\n",
      "Epoch [198/1000], Training Loss: 0.0075\n",
      "Epoch [198/1000], Validation Loss: 0.1265, Validation Accuracy: 97.59%\n",
      "Output Summary: Max=21.5988, Min=-14.7623, Median=-1.8084, Mean=-0.2821\n",
      "\n",
      "Epoch [199/1000], Training Loss: 0.0082\n",
      "Epoch [199/1000], Validation Loss: 0.1266, Validation Accuracy: 97.58%\n",
      "Output Summary: Max=21.6603, Min=-14.4670, Median=-1.9492, Mean=-0.3267\n",
      "\n",
      "Epoch [200/1000], Training Loss: 0.0075\n",
      "Epoch [200/1000], Validation Loss: 0.1164, Validation Accuracy: 97.56%\n",
      "Output Summary: Max=21.4500, Min=-14.9031, Median=-1.8516, Mean=-0.3133\n",
      "\n",
      "Epoch [201/1000], Training Loss: 0.0080\n",
      "Epoch [201/1000], Validation Loss: 0.1195, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=21.5255, Min=-14.5763, Median=-1.8903, Mean=-0.3183\n",
      "\n",
      "Epoch [202/1000], Training Loss: 0.0083\n",
      "Epoch [202/1000], Validation Loss: 0.1259, Validation Accuracy: 97.52%\n",
      "Output Summary: Max=21.6669, Min=-15.2276, Median=-1.9137, Mean=-0.3267\n",
      "\n",
      "Epoch [203/1000], Training Loss: 0.0069\n",
      "Epoch [203/1000], Validation Loss: 0.1224, Validation Accuracy: 97.53%\n",
      "Output Summary: Max=21.7207, Min=-14.8028, Median=-1.8251, Mean=-0.2960\n",
      "\n",
      "Epoch [204/1000], Training Loss: 0.0095\n",
      "Epoch [204/1000], Validation Loss: 0.1246, Validation Accuracy: 97.45%\n",
      "Output Summary: Max=21.4274, Min=-15.4576, Median=-1.8199, Mean=-0.3116\n",
      "\n",
      "Epoch [205/1000], Training Loss: 0.0075\n",
      "Epoch [205/1000], Validation Loss: 0.1270, Validation Accuracy: 97.47%\n",
      "Output Summary: Max=21.7931, Min=-15.1127, Median=-1.9237, Mean=-0.3630\n",
      "\n",
      "Epoch [206/1000], Training Loss: 0.0070\n",
      "Epoch [206/1000], Validation Loss: 0.1203, Validation Accuracy: 97.53%\n",
      "Output Summary: Max=22.3211, Min=-15.0783, Median=-1.9199, Mean=-0.3525\n",
      "\n",
      "Epoch [207/1000], Training Loss: 0.0076\n",
      "Epoch [207/1000], Validation Loss: 0.1211, Validation Accuracy: 97.51%\n",
      "Output Summary: Max=22.1422, Min=-15.8772, Median=-1.9298, Mean=-0.3543\n",
      "\n",
      "Epoch [208/1000], Training Loss: 0.0066\n",
      "Epoch [208/1000], Validation Loss: 0.1245, Validation Accuracy: 97.49%\n",
      "Output Summary: Max=22.2821, Min=-15.1519, Median=-1.8189, Mean=-0.2881\n",
      "\n",
      "Epoch [209/1000], Training Loss: 0.0066\n",
      "Epoch [209/1000], Validation Loss: 0.1177, Validation Accuracy: 97.69%\n",
      "Output Summary: Max=22.1839, Min=-14.5705, Median=-1.8963, Mean=-0.3112\n",
      "\n",
      "Epoch [210/1000], Training Loss: 0.0068\n",
      "Epoch [210/1000], Validation Loss: 0.1228, Validation Accuracy: 97.48%\n",
      "Output Summary: Max=22.5700, Min=-15.3262, Median=-1.8817, Mean=-0.3058\n",
      "\n",
      "Epoch [211/1000], Training Loss: 0.0057\n",
      "Epoch [211/1000], Validation Loss: 0.1173, Validation Accuracy: 97.59%\n",
      "Output Summary: Max=22.6126, Min=-15.0731, Median=-1.8389, Mean=-0.2691\n",
      "\n",
      "Epoch [212/1000], Training Loss: 0.0061\n",
      "Epoch [212/1000], Validation Loss: 0.1217, Validation Accuracy: 97.52%\n",
      "Output Summary: Max=22.5175, Min=-15.1756, Median=-1.8529, Mean=-0.2954\n",
      "\n",
      "Epoch [213/1000], Training Loss: 0.0068\n",
      "Epoch [213/1000], Validation Loss: 0.1145, Validation Accuracy: 97.77%\n",
      "Output Summary: Max=22.4301, Min=-15.8202, Median=-1.8986, Mean=-0.3062\n",
      "\n",
      "Epoch [214/1000], Training Loss: 0.0068\n",
      "Epoch [214/1000], Validation Loss: 0.1175, Validation Accuracy: 97.65%\n",
      "Output Summary: Max=22.8159, Min=-15.3187, Median=-1.9212, Mean=-0.2883\n",
      "\n",
      "Epoch [215/1000], Training Loss: 0.0055\n",
      "Epoch [215/1000], Validation Loss: 0.1175, Validation Accuracy: 97.77%\n",
      "Output Summary: Max=23.0053, Min=-15.7189, Median=-1.9631, Mean=-0.3102\n",
      "\n",
      "Epoch [216/1000], Training Loss: 0.0067\n",
      "Epoch [216/1000], Validation Loss: 0.1173, Validation Accuracy: 97.56%\n",
      "Output Summary: Max=22.8451, Min=-15.6440, Median=-1.9158, Mean=-0.3036\n",
      "\n",
      "Epoch [217/1000], Training Loss: 0.0065\n",
      "Epoch [217/1000], Validation Loss: 0.1272, Validation Accuracy: 97.64%\n",
      "Output Summary: Max=22.7860, Min=-15.5194, Median=-1.9097, Mean=-0.2715\n",
      "\n",
      "Epoch [218/1000], Training Loss: 0.0053\n",
      "Epoch [218/1000], Validation Loss: 0.1190, Validation Accuracy: 97.65%\n",
      "Output Summary: Max=22.6602, Min=-15.6433, Median=-1.9333, Mean=-0.3083\n",
      "\n",
      "Epoch [219/1000], Training Loss: 0.0043\n",
      "Epoch [219/1000], Validation Loss: 0.1235, Validation Accuracy: 97.72%\n",
      "Output Summary: Max=23.0734, Min=-15.5423, Median=-1.8623, Mean=-0.2615\n",
      "\n",
      "Epoch [220/1000], Training Loss: 0.0036\n",
      "Epoch [220/1000], Validation Loss: 0.1213, Validation Accuracy: 97.61%\n",
      "Output Summary: Max=23.0937, Min=-15.6782, Median=-1.8636, Mean=-0.2754\n",
      "\n",
      "Epoch [221/1000], Training Loss: 0.0032\n",
      "Epoch [221/1000], Validation Loss: 0.1238, Validation Accuracy: 97.73%\n",
      "Output Summary: Max=23.2666, Min=-15.0748, Median=-1.9764, Mean=-0.3084\n",
      "\n",
      "Epoch [222/1000], Training Loss: 0.0026\n",
      "Epoch [222/1000], Validation Loss: 0.1251, Validation Accuracy: 97.68%\n",
      "Output Summary: Max=23.4227, Min=-16.0317, Median=-1.9366, Mean=-0.3141\n",
      "\n",
      "Epoch [223/1000], Training Loss: 0.0028\n",
      "Epoch [223/1000], Validation Loss: 0.1264, Validation Accuracy: 97.65%\n",
      "Output Summary: Max=23.5515, Min=-15.0378, Median=-1.9867, Mean=-0.3144\n",
      "\n",
      "Epoch [224/1000], Training Loss: 0.0026\n",
      "Epoch [224/1000], Validation Loss: 0.1278, Validation Accuracy: 97.56%\n",
      "Output Summary: Max=23.3329, Min=-15.4940, Median=-1.9148, Mean=-0.2779\n",
      "\n",
      "Epoch [225/1000], Training Loss: 0.0028\n",
      "Epoch [225/1000], Validation Loss: 0.1219, Validation Accuracy: 97.65%\n",
      "Output Summary: Max=23.4542, Min=-16.0441, Median=-1.9761, Mean=-0.3167\n",
      "\n",
      "Epoch [226/1000], Training Loss: 0.0030\n",
      "Epoch [226/1000], Validation Loss: 0.1260, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=23.6408, Min=-16.2977, Median=-1.9437, Mean=-0.2946\n",
      "\n",
      "Epoch [227/1000], Training Loss: 0.0032\n",
      "Epoch [227/1000], Validation Loss: 0.1234, Validation Accuracy: 97.70%\n",
      "Output Summary: Max=23.5062, Min=-15.9302, Median=-1.9952, Mean=-0.3458\n",
      "\n",
      "Epoch [228/1000], Training Loss: 0.0031\n",
      "Epoch [228/1000], Validation Loss: 0.1314, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=23.4547, Min=-16.0299, Median=-2.0279, Mean=-0.3677\n",
      "\n",
      "Epoch [229/1000], Training Loss: 0.0032\n",
      "Epoch [229/1000], Validation Loss: 0.1372, Validation Accuracy: 97.43%\n",
      "Output Summary: Max=23.8094, Min=-15.5832, Median=-2.0642, Mean=-0.3779\n",
      "\n",
      "Epoch [230/1000], Training Loss: 0.0038\n",
      "Epoch [230/1000], Validation Loss: 0.1319, Validation Accuracy: 97.56%\n",
      "Output Summary: Max=23.7522, Min=-15.8044, Median=-1.9957, Mean=-0.3218\n",
      "\n",
      "Epoch [231/1000], Training Loss: 0.0028\n",
      "Epoch [231/1000], Validation Loss: 0.1324, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=23.8865, Min=-16.1506, Median=-2.0953, Mean=-0.4050\n",
      "\n",
      "Epoch [232/1000], Training Loss: 0.0025\n",
      "Epoch [232/1000], Validation Loss: 0.1273, Validation Accuracy: 97.78%\n",
      "Output Summary: Max=23.6265, Min=-16.1280, Median=-2.0972, Mean=-0.3899\n",
      "\n",
      "Epoch [233/1000], Training Loss: 0.0025\n",
      "Epoch [233/1000], Validation Loss: 0.1325, Validation Accuracy: 97.54%\n",
      "Output Summary: Max=23.9287, Min=-17.0497, Median=-2.1148, Mean=-0.4051\n",
      "\n",
      "Epoch [234/1000], Training Loss: 0.0031\n",
      "Epoch [234/1000], Validation Loss: 0.1339, Validation Accuracy: 97.70%\n",
      "Output Summary: Max=23.9914, Min=-16.1812, Median=-2.0855, Mean=-0.3648\n",
      "\n",
      "Epoch [235/1000], Training Loss: 0.0039\n",
      "Epoch [235/1000], Validation Loss: 0.1439, Validation Accuracy: 97.42%\n",
      "Output Summary: Max=23.9062, Min=-16.1688, Median=-2.0901, Mean=-0.3783\n",
      "\n",
      "Epoch [236/1000], Training Loss: 0.0052\n",
      "Epoch [236/1000], Validation Loss: 0.1361, Validation Accuracy: 97.58%\n",
      "Output Summary: Max=24.3445, Min=-16.7138, Median=-2.1460, Mean=-0.4099\n",
      "\n",
      "Epoch [237/1000], Training Loss: 0.0067\n",
      "Epoch [237/1000], Validation Loss: 0.1403, Validation Accuracy: 97.63%\n",
      "Output Summary: Max=23.7154, Min=-16.5924, Median=-2.1425, Mean=-0.4444\n",
      "\n",
      "Epoch [238/1000], Training Loss: 0.0063\n",
      "Epoch [238/1000], Validation Loss: 0.1371, Validation Accuracy: 97.56%\n",
      "Output Summary: Max=23.4661, Min=-15.4975, Median=-2.0356, Mean=-0.3530\n",
      "\n",
      "Epoch [239/1000], Training Loss: 0.0038\n",
      "Epoch [239/1000], Validation Loss: 0.1250, Validation Accuracy: 97.71%\n",
      "Output Summary: Max=23.9772, Min=-16.7094, Median=-2.0219, Mean=-0.3269\n",
      "\n",
      "Epoch [240/1000], Training Loss: 0.0040\n",
      "Epoch [240/1000], Validation Loss: 0.1309, Validation Accuracy: 97.67%\n",
      "Output Summary: Max=24.0672, Min=-16.2610, Median=-2.0845, Mean=-0.3706\n",
      "\n",
      "Epoch [241/1000], Training Loss: 0.0030\n",
      "Epoch [241/1000], Validation Loss: 0.1297, Validation Accuracy: 97.68%\n",
      "Output Summary: Max=24.3130, Min=-17.3615, Median=-2.0457, Mean=-0.3359\n",
      "\n",
      "Epoch [242/1000], Training Loss: 0.0027\n",
      "Epoch [242/1000], Validation Loss: 0.1329, Validation Accuracy: 97.55%\n",
      "Output Summary: Max=24.0580, Min=-16.4418, Median=-2.0491, Mean=-0.3155\n",
      "\n",
      "Epoch [243/1000], Training Loss: 0.0027\n",
      "Epoch [243/1000], Validation Loss: 0.1284, Validation Accuracy: 97.85%\n",
      "Output Summary: Max=24.3565, Min=-15.9433, Median=-2.0545, Mean=-0.3368\n",
      "\n",
      "Epoch [244/1000], Training Loss: 0.0033\n",
      "Epoch [244/1000], Validation Loss: 0.1337, Validation Accuracy: 97.75%\n",
      "Output Summary: Max=24.3595, Min=-15.9403, Median=-2.0702, Mean=-0.3562\n",
      "\n",
      "Epoch [245/1000], Training Loss: 0.0023\n",
      "Epoch [245/1000], Validation Loss: 0.1291, Validation Accuracy: 97.72%\n",
      "Output Summary: Max=24.5533, Min=-16.0691, Median=-2.0488, Mean=-0.3115\n",
      "\n",
      "Epoch [246/1000], Training Loss: 0.0021\n",
      "Epoch [246/1000], Validation Loss: 0.1280, Validation Accuracy: 97.79%\n",
      "Output Summary: Max=24.5387, Min=-16.5084, Median=-2.1174, Mean=-0.3387\n",
      "\n",
      "Epoch [247/1000], Training Loss: 0.0018\n",
      "Epoch [247/1000], Validation Loss: 0.1255, Validation Accuracy: 97.78%\n",
      "Output Summary: Max=24.7327, Min=-16.3312, Median=-2.0750, Mean=-0.3316\n",
      "\n",
      "Epoch [248/1000], Training Loss: 0.0024\n",
      "Epoch [248/1000], Validation Loss: 0.1307, Validation Accuracy: 97.72%\n",
      "Output Summary: Max=24.6496, Min=-16.5346, Median=-2.1024, Mean=-0.3581\n",
      "\n",
      "Epoch [249/1000], Training Loss: 0.0021\n",
      "Epoch [249/1000], Validation Loss: 0.1329, Validation Accuracy: 97.73%\n",
      "Output Summary: Max=24.4722, Min=-16.8972, Median=-2.1018, Mean=-0.3336\n",
      "\n",
      "Epoch [250/1000], Training Loss: 0.0023\n",
      "Epoch [250/1000], Validation Loss: 0.1315, Validation Accuracy: 97.72%\n",
      "Output Summary: Max=24.8111, Min=-17.0114, Median=-2.1161, Mean=-0.3733\n",
      "\n",
      "Epoch [251/1000], Training Loss: 0.0024\n",
      "Epoch [251/1000], Validation Loss: 0.1312, Validation Accuracy: 97.64%\n",
      "Output Summary: Max=25.0225, Min=-16.6259, Median=-2.0812, Mean=-0.3622\n",
      "\n",
      "Epoch [252/1000], Training Loss: 0.0020\n",
      "Epoch [252/1000], Validation Loss: 0.1295, Validation Accuracy: 97.76%\n",
      "Output Summary: Max=24.9931, Min=-16.9353, Median=-2.0942, Mean=-0.3399\n",
      "\n",
      "Epoch [253/1000], Training Loss: 0.0020\n",
      "Epoch [253/1000], Validation Loss: 0.1244, Validation Accuracy: 97.77%\n",
      "Output Summary: Max=25.2666, Min=-17.0357, Median=-2.1201, Mean=-0.3737\n",
      "\n",
      "Epoch [254/1000], Training Loss: 0.0023\n",
      "Epoch [254/1000], Validation Loss: 0.1269, Validation Accuracy: 97.73%\n",
      "Output Summary: Max=25.4166, Min=-17.1042, Median=-2.0794, Mean=-0.3198\n",
      "\n",
      "Epoch [255/1000], Training Loss: 0.0022\n",
      "Epoch [255/1000], Validation Loss: 0.1315, Validation Accuracy: 97.69%\n",
      "Output Summary: Max=25.2056, Min=-16.8373, Median=-2.1796, Mean=-0.3822\n",
      "\n",
      "Epoch [256/1000], Training Loss: 0.0022\n",
      "Epoch [256/1000], Validation Loss: 0.1280, Validation Accuracy: 97.77%\n",
      "Output Summary: Max=24.9513, Min=-17.0126, Median=-2.1474, Mean=-0.3878\n",
      "\n",
      "Epoch [257/1000], Training Loss: 0.0021\n",
      "Epoch [257/1000], Validation Loss: 0.1295, Validation Accuracy: 97.71%\n",
      "Output Summary: Max=25.1131, Min=-17.2140, Median=-2.1708, Mean=-0.3780\n",
      "\n",
      "Epoch [258/1000], Training Loss: 0.0030\n",
      "Epoch [258/1000], Validation Loss: 0.1402, Validation Accuracy: 97.54%\n",
      "Output Summary: Max=25.6358, Min=-16.6285, Median=-2.0961, Mean=-0.3414\n",
      "\n",
      "Epoch [259/1000], Training Loss: 0.0026\n",
      "Epoch [259/1000], Validation Loss: 0.1439, Validation Accuracy: 97.48%\n",
      "Output Summary: Max=25.3099, Min=-16.5141, Median=-2.2051, Mean=-0.4265\n",
      "\n",
      "Epoch [260/1000], Training Loss: 0.0028\n",
      "Epoch [260/1000], Validation Loss: 0.1360, Validation Accuracy: 97.64%\n",
      "Output Summary: Max=25.6823, Min=-16.3321, Median=-2.1543, Mean=-0.3675\n",
      "\n",
      "Epoch [261/1000], Training Loss: 0.0032\n",
      "Epoch [261/1000], Validation Loss: 0.1411, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=25.4410, Min=-16.4572, Median=-2.2270, Mean=-0.4016\n",
      "\n",
      "Epoch [262/1000], Training Loss: 0.0038\n",
      "Epoch [262/1000], Validation Loss: 0.1473, Validation Accuracy: 97.57%\n",
      "Output Summary: Max=25.4695, Min=-17.7459, Median=-2.2135, Mean=-0.3978\n",
      "\n",
      "Epoch [263/1000], Training Loss: 0.0055\n",
      "Epoch [263/1000], Validation Loss: 0.1445, Validation Accuracy: 97.49%\n",
      "Output Summary: Max=24.9107, Min=-17.4165, Median=-2.2282, Mean=-0.4107\n",
      "\n",
      "Epoch [264/1000], Training Loss: 0.0066\n",
      "Epoch [264/1000], Validation Loss: 0.1456, Validation Accuracy: 97.48%\n",
      "Output Summary: Max=25.4659, Min=-17.5203, Median=-2.2252, Mean=-0.3974\n",
      "\n",
      "Epoch [265/1000], Training Loss: 0.0078\n",
      "Epoch [265/1000], Validation Loss: 0.1462, Validation Accuracy: 97.60%\n",
      "Output Summary: Max=25.3193, Min=-17.8322, Median=-2.0161, Mean=-0.2864\n",
      "\n",
      "Epoch [266/1000], Training Loss: 0.0124\n",
      "Epoch [266/1000], Validation Loss: 0.1596, Validation Accuracy: 97.20%\n",
      "Output Summary: Max=25.4576, Min=-18.1052, Median=-2.2062, Mean=-0.4490\n",
      "\n",
      "Epoch [267/1000], Training Loss: 0.0197\n",
      "Epoch [267/1000], Validation Loss: 0.1457, Validation Accuracy: 97.48%\n",
      "Output Summary: Max=25.4939, Min=-17.5113, Median=-2.1415, Mean=-0.3834\n",
      "\n",
      "Epoch [268/1000], Training Loss: 0.0161\n",
      "Epoch [268/1000], Validation Loss: 0.1274, Validation Accuracy: 97.58%\n",
      "Output Summary: Max=25.2289, Min=-17.0398, Median=-2.0672, Mean=-0.3312\n",
      "\n",
      "Epoch [269/1000], Training Loss: 0.0129\n",
      "Epoch [269/1000], Validation Loss: 0.1441, Validation Accuracy: 97.44%\n",
      "Output Summary: Max=25.0037, Min=-18.3807, Median=-1.9154, Mean=-0.1901\n",
      "\n",
      "Epoch [270/1000], Training Loss: 0.0144\n",
      "Epoch [270/1000], Validation Loss: 0.1322, Validation Accuracy: 97.53%\n",
      "Output Summary: Max=25.3181, Min=-16.7492, Median=-2.0849, Mean=-0.3525\n",
      "\n",
      "Epoch [271/1000], Training Loss: 0.0092\n",
      "Epoch [271/1000], Validation Loss: 0.1296, Validation Accuracy: 97.53%\n",
      "Output Summary: Max=25.6449, Min=-16.8849, Median=-2.0817, Mean=-0.3428\n",
      "\n",
      "Epoch [272/1000], Training Loss: 0.0079\n",
      "Epoch [272/1000], Validation Loss: 0.1287, Validation Accuracy: 97.76%\n",
      "Output Summary: Max=25.5915, Min=-17.1699, Median=-2.0562, Mean=-0.3425\n",
      "\n",
      "Epoch [273/1000], Training Loss: 0.0063\n",
      "Epoch [273/1000], Validation Loss: 0.1261, Validation Accuracy: 97.64%\n",
      "Output Summary: Max=25.8317, Min=-16.6678, Median=-1.9973, Mean=-0.3141\n",
      "\n",
      "Epoch [274/1000], Training Loss: 0.0051\n",
      "Epoch [274/1000], Validation Loss: 0.1298, Validation Accuracy: 97.78%\n",
      "Output Summary: Max=25.9860, Min=-17.1323, Median=-2.0517, Mean=-0.3448\n",
      "\n",
      "Epoch [275/1000], Training Loss: 0.0049\n",
      "Epoch [275/1000], Validation Loss: 0.1340, Validation Accuracy: 97.75%\n",
      "Output Summary: Max=26.4555, Min=-17.5129, Median=-2.0933, Mean=-0.3726\n",
      "\n",
      "Epoch [276/1000], Training Loss: 0.0045\n",
      "Epoch [276/1000], Validation Loss: 0.1277, Validation Accuracy: 97.83%\n",
      "Output Summary: Max=26.1620, Min=-17.1241, Median=-2.1948, Mean=-0.4240\n",
      "\n",
      "Epoch [277/1000], Training Loss: 0.0029\n",
      "Epoch [277/1000], Validation Loss: 0.1280, Validation Accuracy: 97.84%\n",
      "Output Summary: Max=26.3322, Min=-17.6404, Median=-2.1098, Mean=-0.3538\n",
      "\n",
      "Epoch [278/1000], Training Loss: 0.0018\n",
      "Epoch [278/1000], Validation Loss: 0.1242, Validation Accuracy: 97.93%\n",
      "Output Summary: Max=26.2181, Min=-17.8334, Median=-2.0984, Mean=-0.3587\n",
      "\n",
      "Epoch [279/1000], Training Loss: 0.0012\n",
      "Epoch [279/1000], Validation Loss: 0.1206, Validation Accuracy: 97.91%\n",
      "Output Summary: Max=26.3844, Min=-18.2278, Median=-2.1541, Mean=-0.3798\n",
      "\n",
      "Epoch [280/1000], Training Loss: 0.0008\n",
      "Epoch [280/1000], Validation Loss: 0.1247, Validation Accuracy: 97.80%\n",
      "Output Summary: Max=26.5864, Min=-18.2384, Median=-2.1481, Mean=-0.3746\n",
      "\n",
      "Epoch [281/1000], Training Loss: 0.0012\n",
      "Epoch [281/1000], Validation Loss: 0.1287, Validation Accuracy: 97.80%\n",
      "Output Summary: Max=26.4344, Min=-18.0770, Median=-2.1297, Mean=-0.3775\n",
      "\n",
      "Epoch [282/1000], Training Loss: 0.0011\n",
      "Epoch [282/1000], Validation Loss: 0.1272, Validation Accuracy: 97.77%\n",
      "Output Summary: Max=26.3182, Min=-18.2227, Median=-2.1600, Mean=-0.3772\n",
      "\n",
      "Epoch [283/1000], Training Loss: 0.0007\n",
      "Epoch [283/1000], Validation Loss: 0.1236, Validation Accuracy: 97.81%\n",
      "Output Summary: Max=26.2938, Min=-17.6014, Median=-2.2103, Mean=-0.4045\n",
      "\n",
      "Epoch [284/1000], Training Loss: 0.0004\n",
      "Epoch [284/1000], Validation Loss: 0.1245, Validation Accuracy: 97.89%\n",
      "Output Summary: Max=26.2870, Min=-18.3223, Median=-2.1964, Mean=-0.3939\n",
      "\n",
      "Epoch [285/1000], Training Loss: 0.0003\n",
      "Epoch [285/1000], Validation Loss: 0.1215, Validation Accuracy: 97.86%\n",
      "Output Summary: Max=26.2745, Min=-18.0167, Median=-2.1769, Mean=-0.3806\n",
      "\n",
      "Epoch [286/1000], Training Loss: 0.0003\n",
      "Epoch [286/1000], Validation Loss: 0.1220, Validation Accuracy: 97.90%\n",
      "Output Summary: Max=26.3142, Min=-18.1130, Median=-2.1893, Mean=-0.3868\n",
      "\n",
      "Epoch [287/1000], Training Loss: 0.0002\n",
      "Epoch [287/1000], Validation Loss: 0.1224, Validation Accuracy: 97.90%\n",
      "Output Summary: Max=26.3483, Min=-18.1744, Median=-2.1938, Mean=-0.3875\n",
      "\n",
      "Epoch [288/1000], Training Loss: 0.0002\n",
      "Epoch [288/1000], Validation Loss: 0.1227, Validation Accuracy: 97.89%\n",
      "Output Summary: Max=26.3796, Min=-18.2066, Median=-2.1962, Mean=-0.3877\n",
      "\n",
      "Epoch [289/1000], Training Loss: 0.0002\n",
      "Epoch [289/1000], Validation Loss: 0.1229, Validation Accuracy: 97.89%\n",
      "Output Summary: Max=26.4046, Min=-18.2547, Median=-2.2003, Mean=-0.3893\n",
      "\n",
      "Epoch [290/1000], Training Loss: 0.0002\n",
      "Epoch [290/1000], Validation Loss: 0.1232, Validation Accuracy: 97.90%\n",
      "Output Summary: Max=26.4280, Min=-18.2944, Median=-2.2054, Mean=-0.3904\n",
      "\n",
      "Epoch [291/1000], Training Loss: 0.0002\n",
      "Epoch [291/1000], Validation Loss: 0.1234, Validation Accuracy: 97.91%\n",
      "Output Summary: Max=26.4519, Min=-18.3297, Median=-2.2104, Mean=-0.3918\n",
      "\n",
      "Epoch [292/1000], Training Loss: 0.0002\n",
      "Epoch [292/1000], Validation Loss: 0.1236, Validation Accuracy: 97.92%\n",
      "Output Summary: Max=26.4770, Min=-18.3566, Median=-2.2153, Mean=-0.3932\n",
      "\n",
      "Epoch [293/1000], Training Loss: 0.0002\n",
      "Epoch [293/1000], Validation Loss: 0.1239, Validation Accuracy: 97.91%\n",
      "Output Summary: Max=26.4983, Min=-18.3916, Median=-2.2206, Mean=-0.3945\n",
      "\n",
      "Epoch [294/1000], Training Loss: 0.0002\n",
      "Epoch [294/1000], Validation Loss: 0.1241, Validation Accuracy: 97.90%\n",
      "Output Summary: Max=26.5190, Min=-18.4227, Median=-2.2232, Mean=-0.3954\n",
      "\n",
      "Epoch [295/1000], Training Loss: 0.0002\n",
      "Epoch [295/1000], Validation Loss: 0.1243, Validation Accuracy: 97.89%\n",
      "Output Summary: Max=26.5388, Min=-18.4575, Median=-2.2279, Mean=-0.3966\n",
      "\n",
      "Epoch [296/1000], Training Loss: 0.0002\n",
      "Epoch [296/1000], Validation Loss: 0.1245, Validation Accuracy: 97.89%\n",
      "Output Summary: Max=26.5567, Min=-18.4908, Median=-2.2292, Mean=-0.3975\n",
      "\n",
      "Epoch [297/1000], Training Loss: 0.0002\n",
      "Epoch [297/1000], Validation Loss: 0.1247, Validation Accuracy: 97.90%\n",
      "Output Summary: Max=26.5750, Min=-18.5180, Median=-2.2332, Mean=-0.3982\n",
      "\n",
      "Epoch [298/1000], Training Loss: 0.0002\n",
      "Epoch [298/1000], Validation Loss: 0.1249, Validation Accuracy: 97.89%\n",
      "Output Summary: Max=26.5933, Min=-18.5442, Median=-2.2369, Mean=-0.3993\n",
      "\n",
      "Epoch [299/1000], Training Loss: 0.0002\n",
      "Epoch [299/1000], Validation Loss: 0.1251, Validation Accuracy: 97.89%\n",
      "Output Summary: Max=26.6111, Min=-18.5740, Median=-2.2421, Mean=-0.4003\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[98]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m output = model(data)\n\u001b[32m     15\u001b[39m loss = criterion(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     19\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "patience = 10000\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5f22263",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss: 2.3023\n",
      "Epoch [1/1000], Validation Loss: 2.3016, Validation Accuracy: 15.66%\n",
      "Output Summary: Max=0.1028, Min=-0.0965, Median=0.0467, Mean=0.0335\n",
      "\n",
      "Epoch [2/1000], Training Loss: 2.2845\n",
      "Epoch [2/1000], Validation Loss: 2.1563, Validation Accuracy: 27.01%\n",
      "Output Summary: Max=0.7537, Min=-0.6424, Median=0.0407, Mean=0.0154\n",
      "\n",
      "Epoch [3/1000], Training Loss: 1.7491\n",
      "Epoch [3/1000], Validation Loss: 1.2844, Validation Accuracy: 61.41%\n",
      "Output Summary: Max=3.8563, Min=-3.6543, Median=0.1253, Mean=0.0692\n",
      "\n",
      "Epoch [4/1000], Training Loss: 1.0003\n",
      "Epoch [4/1000], Validation Loss: 0.7231, Validation Accuracy: 80.32%\n",
      "Output Summary: Max=5.1553, Min=-4.6620, Median=-0.1656, Mean=0.0501\n",
      "\n",
      "Epoch [5/1000], Training Loss: 0.6128\n",
      "Epoch [5/1000], Validation Loss: 0.4861, Validation Accuracy: 86.23%\n",
      "Output Summary: Max=6.4259, Min=-4.8845, Median=-0.1543, Mean=0.0677\n",
      "\n",
      "Epoch [6/1000], Training Loss: 0.4516\n",
      "Epoch [6/1000], Validation Loss: 0.3873, Validation Accuracy: 88.88%\n",
      "Output Summary: Max=7.0779, Min=-5.1089, Median=-0.1523, Mean=0.0762\n",
      "\n",
      "Epoch [7/1000], Training Loss: 0.3713\n",
      "Epoch [7/1000], Validation Loss: 0.3271, Validation Accuracy: 90.59%\n",
      "Output Summary: Max=7.4075, Min=-5.5463, Median=-0.1732, Mean=0.0880\n",
      "\n",
      "Epoch [8/1000], Training Loss: 0.3192\n",
      "Epoch [8/1000], Validation Loss: 0.2875, Validation Accuracy: 91.96%\n",
      "Output Summary: Max=7.6741, Min=-5.8554, Median=-0.1911, Mean=0.0949\n",
      "\n",
      "Epoch [9/1000], Training Loss: 0.2826\n",
      "Epoch [9/1000], Validation Loss: 0.2636, Validation Accuracy: 92.46%\n",
      "Output Summary: Max=7.7950, Min=-6.2427, Median=-0.2110, Mean=0.0960\n",
      "\n",
      "Epoch [10/1000], Training Loss: 0.2536\n",
      "Epoch [10/1000], Validation Loss: 0.2414, Validation Accuracy: 92.87%\n",
      "Output Summary: Max=7.9645, Min=-6.4648, Median=-0.2159, Mean=0.0977\n",
      "\n",
      "Epoch [11/1000], Training Loss: 0.2321\n",
      "Epoch [11/1000], Validation Loss: 0.2257, Validation Accuracy: 93.33%\n",
      "Output Summary: Max=8.0874, Min=-6.7161, Median=-0.2150, Mean=0.1021\n",
      "\n",
      "Epoch [12/1000], Training Loss: 0.2165\n",
      "Epoch [12/1000], Validation Loss: 0.2102, Validation Accuracy: 93.73%\n",
      "Output Summary: Max=8.2696, Min=-6.9760, Median=-0.2179, Mean=0.1050\n",
      "\n",
      "Epoch [13/1000], Training Loss: 0.2020\n",
      "Epoch [13/1000], Validation Loss: 0.1970, Validation Accuracy: 94.05%\n",
      "Output Summary: Max=8.4510, Min=-7.1552, Median=-0.2219, Mean=0.1059\n",
      "\n",
      "Epoch [14/1000], Training Loss: 0.1892\n",
      "Epoch [14/1000], Validation Loss: 0.1897, Validation Accuracy: 94.32%\n",
      "Output Summary: Max=8.6840, Min=-7.1962, Median=-0.2254, Mean=0.1089\n",
      "\n",
      "Epoch [15/1000], Training Loss: 0.1774\n",
      "Epoch [15/1000], Validation Loss: 0.1812, Validation Accuracy: 94.63%\n",
      "Output Summary: Max=8.8756, Min=-7.3150, Median=-0.2192, Mean=0.1173\n",
      "\n",
      "Epoch [16/1000], Training Loss: 0.1687\n",
      "Epoch [16/1000], Validation Loss: 0.1734, Validation Accuracy: 94.92%\n",
      "Output Summary: Max=9.0529, Min=-7.5374, Median=-0.2207, Mean=0.1235\n",
      "\n",
      "Epoch [17/1000], Training Loss: 0.1607\n",
      "Epoch [17/1000], Validation Loss: 0.1684, Validation Accuracy: 94.95%\n",
      "Output Summary: Max=9.2553, Min=-7.7577, Median=-0.2069, Mean=0.1175\n",
      "\n",
      "Epoch [18/1000], Training Loss: 0.1526\n",
      "Epoch [18/1000], Validation Loss: 0.1589, Validation Accuracy: 95.19%\n",
      "Output Summary: Max=9.4843, Min=-7.9429, Median=-0.2225, Mean=0.1233\n",
      "\n",
      "Epoch [19/1000], Training Loss: 0.1443\n",
      "Epoch [19/1000], Validation Loss: 0.1534, Validation Accuracy: 95.36%\n",
      "Output Summary: Max=9.6493, Min=-8.0218, Median=-0.2246, Mean=0.1280\n",
      "\n",
      "Epoch [20/1000], Training Loss: 0.1379\n",
      "Epoch [20/1000], Validation Loss: 0.1509, Validation Accuracy: 95.36%\n",
      "Output Summary: Max=9.8182, Min=-8.0967, Median=-0.2212, Mean=0.1313\n",
      "\n",
      "Epoch [21/1000], Training Loss: 0.1332\n",
      "Epoch [21/1000], Validation Loss: 0.1494, Validation Accuracy: 95.44%\n",
      "Output Summary: Max=9.9475, Min=-8.1967, Median=-0.2251, Mean=0.1333\n",
      "\n",
      "Epoch [22/1000], Training Loss: 0.1295\n",
      "Epoch [22/1000], Validation Loss: 0.1448, Validation Accuracy: 95.57%\n",
      "Output Summary: Max=10.1170, Min=-8.3324, Median=-0.2222, Mean=0.1348\n",
      "\n",
      "Epoch [23/1000], Training Loss: 0.1252\n",
      "Epoch [23/1000], Validation Loss: 0.1421, Validation Accuracy: 95.64%\n",
      "Output Summary: Max=10.2675, Min=-8.4682, Median=-0.2220, Mean=0.1364\n",
      "\n",
      "Epoch [24/1000], Training Loss: 0.1217\n",
      "Epoch [24/1000], Validation Loss: 0.1421, Validation Accuracy: 95.53%\n",
      "Output Summary: Max=10.3904, Min=-8.5221, Median=-0.2215, Mean=0.1396\n",
      "\n",
      "Epoch [25/1000], Training Loss: 0.1199\n",
      "Epoch [25/1000], Validation Loss: 0.1410, Validation Accuracy: 95.45%\n",
      "Output Summary: Max=10.4641, Min=-8.6580, Median=-0.2116, Mean=0.1426\n",
      "\n",
      "Epoch [26/1000], Training Loss: 0.1176\n",
      "Epoch [26/1000], Validation Loss: 0.1390, Validation Accuracy: 95.64%\n",
      "Output Summary: Max=10.6587, Min=-8.7122, Median=-0.2178, Mean=0.1439\n",
      "\n",
      "Epoch [27/1000], Training Loss: 0.1148\n",
      "Epoch [27/1000], Validation Loss: 0.1346, Validation Accuracy: 95.84%\n",
      "Output Summary: Max=10.8022, Min=-8.7617, Median=-0.2145, Mean=0.1394\n",
      "\n",
      "Epoch [28/1000], Training Loss: 0.1120\n",
      "Epoch [28/1000], Validation Loss: 0.1323, Validation Accuracy: 95.78%\n",
      "Output Summary: Max=10.9468, Min=-8.8677, Median=-0.2186, Mean=0.1444\n",
      "\n",
      "Epoch [29/1000], Training Loss: 0.1109\n",
      "Epoch [29/1000], Validation Loss: 0.1304, Validation Accuracy: 95.94%\n",
      "Output Summary: Max=11.0443, Min=-8.9359, Median=-0.2348, Mean=0.1345\n",
      "\n",
      "Epoch [30/1000], Training Loss: 0.1122\n",
      "Epoch [30/1000], Validation Loss: 0.1248, Validation Accuracy: 96.08%\n",
      "Output Summary: Max=11.0610, Min=-9.0026, Median=-0.2430, Mean=0.1321\n",
      "\n",
      "Epoch [31/1000], Training Loss: 0.1101\n",
      "Epoch [31/1000], Validation Loss: 0.1256, Validation Accuracy: 96.12%\n",
      "Output Summary: Max=11.0957, Min=-9.0159, Median=-0.2646, Mean=0.1325\n",
      "\n",
      "Epoch [32/1000], Training Loss: 0.1076\n",
      "Epoch [32/1000], Validation Loss: 0.1335, Validation Accuracy: 95.84%\n",
      "Output Summary: Max=11.1565, Min=-9.1613, Median=-0.2685, Mean=0.1348\n",
      "\n",
      "Epoch [33/1000], Training Loss: 0.1051\n",
      "Epoch [33/1000], Validation Loss: 0.1252, Validation Accuracy: 96.12%\n",
      "Output Summary: Max=11.2397, Min=-9.2372, Median=-0.2646, Mean=0.1249\n",
      "\n",
      "Epoch [34/1000], Training Loss: 0.0991\n",
      "Epoch [34/1000], Validation Loss: 0.1228, Validation Accuracy: 96.30%\n",
      "Output Summary: Max=11.3437, Min=-9.1657, Median=-0.2700, Mean=0.1271\n",
      "\n",
      "Epoch [35/1000], Training Loss: 0.0944\n",
      "Epoch [35/1000], Validation Loss: 0.1216, Validation Accuracy: 96.38%\n",
      "Output Summary: Max=11.5111, Min=-9.2358, Median=-0.2665, Mean=0.1288\n",
      "\n",
      "Epoch [36/1000], Training Loss: 0.0932\n",
      "Epoch [36/1000], Validation Loss: 0.1211, Validation Accuracy: 96.37%\n",
      "Output Summary: Max=11.6550, Min=-9.2451, Median=-0.2631, Mean=0.1233\n",
      "\n",
      "Epoch [37/1000], Training Loss: 0.0932\n",
      "Epoch [37/1000], Validation Loss: 0.1236, Validation Accuracy: 96.36%\n",
      "Output Summary: Max=11.7967, Min=-9.2165, Median=-0.2725, Mean=0.1220\n",
      "\n",
      "Epoch [38/1000], Training Loss: 0.0928\n",
      "Epoch [38/1000], Validation Loss: 0.1267, Validation Accuracy: 96.28%\n",
      "Output Summary: Max=11.8766, Min=-9.2334, Median=-0.2811, Mean=0.1198\n",
      "\n",
      "Epoch [39/1000], Training Loss: 0.0933\n",
      "Epoch [39/1000], Validation Loss: 0.1242, Validation Accuracy: 96.38%\n",
      "Output Summary: Max=11.9606, Min=-9.3880, Median=-0.2840, Mean=0.1214\n",
      "\n",
      "Epoch [40/1000], Training Loss: 0.0938\n",
      "Epoch [40/1000], Validation Loss: 0.1209, Validation Accuracy: 96.44%\n",
      "Output Summary: Max=11.9657, Min=-9.6196, Median=-0.2723, Mean=0.1332\n",
      "\n",
      "Epoch [41/1000], Training Loss: 0.0899\n",
      "Epoch [41/1000], Validation Loss: 0.1229, Validation Accuracy: 96.41%\n",
      "Output Summary: Max=12.1902, Min=-9.6193, Median=-0.2720, Mean=0.1343\n",
      "\n",
      "Epoch [42/1000], Training Loss: 0.0872\n",
      "Epoch [42/1000], Validation Loss: 0.1239, Validation Accuracy: 96.43%\n",
      "Output Summary: Max=12.2585, Min=-9.6796, Median=-0.2769, Mean=0.1340\n",
      "\n",
      "Epoch [43/1000], Training Loss: 0.0850\n",
      "Epoch [43/1000], Validation Loss: 0.1172, Validation Accuracy: 96.65%\n",
      "Output Summary: Max=12.3345, Min=-9.6183, Median=-0.2902, Mean=0.1366\n",
      "\n",
      "Epoch [44/1000], Training Loss: 0.0818\n",
      "Epoch [44/1000], Validation Loss: 0.1157, Validation Accuracy: 96.69%\n",
      "Output Summary: Max=12.3605, Min=-9.7240, Median=-0.2960, Mean=0.1350\n",
      "\n",
      "Epoch [45/1000], Training Loss: 0.0799\n",
      "Epoch [45/1000], Validation Loss: 0.1137, Validation Accuracy: 96.76%\n",
      "Output Summary: Max=12.4751, Min=-9.7705, Median=-0.3025, Mean=0.1325\n",
      "\n",
      "Epoch [46/1000], Training Loss: 0.0784\n",
      "Epoch [46/1000], Validation Loss: 0.1180, Validation Accuracy: 96.62%\n",
      "Output Summary: Max=12.5510, Min=-9.8239, Median=-0.3183, Mean=0.1270\n",
      "\n",
      "Epoch [47/1000], Training Loss: 0.0758\n",
      "Epoch [47/1000], Validation Loss: 0.1212, Validation Accuracy: 96.51%\n",
      "Output Summary: Max=12.6375, Min=-9.8817, Median=-0.3148, Mean=0.1229\n",
      "\n",
      "Epoch [48/1000], Training Loss: 0.0747\n",
      "Epoch [48/1000], Validation Loss: 0.1160, Validation Accuracy: 96.78%\n",
      "Output Summary: Max=12.7342, Min=-9.9029, Median=-0.2990, Mean=0.1254\n",
      "\n",
      "Epoch [49/1000], Training Loss: 0.0731\n",
      "Epoch [49/1000], Validation Loss: 0.1123, Validation Accuracy: 96.78%\n",
      "Output Summary: Max=12.8428, Min=-9.9868, Median=-0.2995, Mean=0.1334\n",
      "\n",
      "Epoch [50/1000], Training Loss: 0.0714\n",
      "Epoch [50/1000], Validation Loss: 0.1126, Validation Accuracy: 96.82%\n",
      "Output Summary: Max=12.9426, Min=-10.1714, Median=-0.3029, Mean=0.1401\n",
      "\n",
      "Epoch [51/1000], Training Loss: 0.0698\n",
      "Epoch [51/1000], Validation Loss: 0.1124, Validation Accuracy: 96.89%\n",
      "Output Summary: Max=13.0605, Min=-10.2806, Median=-0.3050, Mean=0.1403\n",
      "\n",
      "Epoch [52/1000], Training Loss: 0.0703\n",
      "Epoch [52/1000], Validation Loss: 0.1145, Validation Accuracy: 96.79%\n",
      "Output Summary: Max=13.1549, Min=-10.2514, Median=-0.3068, Mean=0.1410\n",
      "\n",
      "Epoch [53/1000], Training Loss: 0.0695\n",
      "Epoch [53/1000], Validation Loss: 0.1114, Validation Accuracy: 96.89%\n",
      "Output Summary: Max=13.3067, Min=-10.2270, Median=-0.3115, Mean=0.1442\n",
      "\n",
      "Epoch [54/1000], Training Loss: 0.0707\n",
      "Epoch [54/1000], Validation Loss: 0.1117, Validation Accuracy: 96.79%\n",
      "Output Summary: Max=13.4463, Min=-10.1930, Median=-0.3292, Mean=0.1443\n",
      "\n",
      "Epoch [55/1000], Training Loss: 0.0716\n",
      "Epoch [55/1000], Validation Loss: 0.1131, Validation Accuracy: 96.82%\n",
      "Output Summary: Max=13.5230, Min=-10.1536, Median=-0.3294, Mean=0.1417\n",
      "\n",
      "Epoch [56/1000], Training Loss: 0.0740\n",
      "Epoch [56/1000], Validation Loss: 0.1223, Validation Accuracy: 96.50%\n",
      "Output Summary: Max=13.5895, Min=-10.2286, Median=-0.3322, Mean=0.1433\n",
      "\n",
      "Epoch [57/1000], Training Loss: 0.0771\n",
      "Epoch [57/1000], Validation Loss: 0.1410, Validation Accuracy: 95.75%\n",
      "Output Summary: Max=13.5867, Min=-10.2697, Median=-0.3361, Mean=0.1451\n",
      "\n",
      "Epoch [58/1000], Training Loss: 0.0808\n",
      "Epoch [58/1000], Validation Loss: 0.1123, Validation Accuracy: 96.94%\n",
      "Output Summary: Max=13.7322, Min=-10.6110, Median=-0.3132, Mean=0.1331\n",
      "\n",
      "Epoch [59/1000], Training Loss: 0.0725\n",
      "Epoch [59/1000], Validation Loss: 0.1127, Validation Accuracy: 96.75%\n",
      "Output Summary: Max=13.7031, Min=-10.5097, Median=-0.2812, Mean=0.1336\n",
      "\n",
      "Epoch [60/1000], Training Loss: 0.0652\n",
      "Epoch [60/1000], Validation Loss: 0.1097, Validation Accuracy: 96.84%\n",
      "Output Summary: Max=13.8052, Min=-10.6380, Median=-0.2962, Mean=0.1355\n",
      "\n",
      "Epoch [61/1000], Training Loss: 0.0634\n",
      "Epoch [61/1000], Validation Loss: 0.1107, Validation Accuracy: 96.89%\n",
      "Output Summary: Max=13.8531, Min=-10.7483, Median=-0.3162, Mean=0.1396\n",
      "\n",
      "Epoch [62/1000], Training Loss: 0.0612\n",
      "Epoch [62/1000], Validation Loss: 0.1117, Validation Accuracy: 96.85%\n",
      "Output Summary: Max=13.9851, Min=-10.5941, Median=-0.3227, Mean=0.1410\n",
      "\n",
      "Epoch [63/1000], Training Loss: 0.0603\n",
      "Epoch [63/1000], Validation Loss: 0.1124, Validation Accuracy: 96.82%\n",
      "Output Summary: Max=14.0873, Min=-10.4972, Median=-0.3207, Mean=0.1334\n",
      "\n",
      "Epoch [64/1000], Training Loss: 0.0606\n",
      "Epoch [64/1000], Validation Loss: 0.1127, Validation Accuracy: 96.91%\n",
      "Output Summary: Max=14.2030, Min=-10.4115, Median=-0.3254, Mean=0.1314\n",
      "\n",
      "Epoch [65/1000], Training Loss: 0.0590\n",
      "Epoch [65/1000], Validation Loss: 0.1150, Validation Accuracy: 96.81%\n",
      "Output Summary: Max=14.3744, Min=-10.5401, Median=-0.3235, Mean=0.1196\n",
      "\n",
      "Epoch [66/1000], Training Loss: 0.0591\n",
      "Epoch [66/1000], Validation Loss: 0.1149, Validation Accuracy: 96.67%\n",
      "Output Summary: Max=14.4447, Min=-10.5675, Median=-0.3306, Mean=0.1261\n",
      "\n",
      "Epoch [67/1000], Training Loss: 0.0582\n",
      "Epoch [67/1000], Validation Loss: 0.1145, Validation Accuracy: 96.78%\n",
      "Output Summary: Max=14.5818, Min=-11.0542, Median=-0.3300, Mean=0.1346\n",
      "\n",
      "Epoch [68/1000], Training Loss: 0.0563\n",
      "Epoch [68/1000], Validation Loss: 0.1155, Validation Accuracy: 96.67%\n",
      "Output Summary: Max=14.6515, Min=-10.9893, Median=-0.3243, Mean=0.1372\n",
      "\n",
      "Epoch [69/1000], Training Loss: 0.0565\n",
      "Epoch [69/1000], Validation Loss: 0.1177, Validation Accuracy: 96.62%\n",
      "Output Summary: Max=14.7339, Min=-10.6384, Median=-0.3240, Mean=0.1318\n",
      "\n",
      "Epoch [70/1000], Training Loss: 0.0559\n",
      "Epoch [70/1000], Validation Loss: 0.1180, Validation Accuracy: 96.71%\n",
      "Output Summary: Max=14.8453, Min=-10.6378, Median=-0.3253, Mean=0.1298\n",
      "\n",
      "Epoch [71/1000], Training Loss: 0.0553\n",
      "Epoch [71/1000], Validation Loss: 0.1185, Validation Accuracy: 96.75%\n",
      "Output Summary: Max=15.0378, Min=-10.6938, Median=-0.3141, Mean=0.1293\n",
      "\n",
      "Epoch [72/1000], Training Loss: 0.0559\n",
      "Epoch [72/1000], Validation Loss: 0.1231, Validation Accuracy: 96.46%\n",
      "Output Summary: Max=15.1060, Min=-10.7331, Median=-0.3239, Mean=0.1313\n",
      "\n",
      "Epoch [73/1000], Training Loss: 0.0571\n",
      "Epoch [73/1000], Validation Loss: 0.1226, Validation Accuracy: 96.49%\n",
      "Output Summary: Max=15.2281, Min=-10.9896, Median=-0.3250, Mean=0.1303\n",
      "\n",
      "Epoch [74/1000], Training Loss: 0.0583\n",
      "Epoch [74/1000], Validation Loss: 0.1238, Validation Accuracy: 96.42%\n",
      "Output Summary: Max=15.2821, Min=-11.2556, Median=-0.3352, Mean=0.1385\n",
      "\n",
      "Epoch [75/1000], Training Loss: 0.0620\n",
      "Epoch [75/1000], Validation Loss: 0.1178, Validation Accuracy: 96.63%\n",
      "Output Summary: Max=15.2813, Min=-10.8372, Median=-0.3430, Mean=0.1367\n",
      "\n",
      "Epoch [76/1000], Training Loss: 0.0656\n",
      "Epoch [76/1000], Validation Loss: 0.1183, Validation Accuracy: 96.68%\n",
      "Output Summary: Max=15.2325, Min=-11.2848, Median=-0.3375, Mean=0.1384\n",
      "\n",
      "Epoch [77/1000], Training Loss: 0.0688\n",
      "Epoch [77/1000], Validation Loss: 0.1142, Validation Accuracy: 96.76%\n",
      "Output Summary: Max=15.3722, Min=-11.1066, Median=-0.3241, Mean=0.1477\n",
      "\n",
      "Epoch [78/1000], Training Loss: 0.0647\n",
      "Epoch [78/1000], Validation Loss: 0.1135, Validation Accuracy: 96.71%\n",
      "Output Summary: Max=15.5042, Min=-11.0122, Median=-0.3428, Mean=0.1440\n",
      "\n",
      "Epoch [79/1000], Training Loss: 0.0578\n",
      "Epoch [79/1000], Validation Loss: 0.1075, Validation Accuracy: 96.98%\n",
      "Output Summary: Max=15.3741, Min=-11.0930, Median=-0.3429, Mean=0.1431\n",
      "\n",
      "Epoch [80/1000], Training Loss: 0.0552\n",
      "Epoch [80/1000], Validation Loss: 0.1137, Validation Accuracy: 96.65%\n",
      "Output Summary: Max=15.2651, Min=-11.3621, Median=-0.3349, Mean=0.1387\n",
      "\n",
      "Epoch [81/1000], Training Loss: 0.0523\n",
      "Epoch [81/1000], Validation Loss: 0.1147, Validation Accuracy: 96.74%\n",
      "Output Summary: Max=15.2960, Min=-11.4168, Median=-0.3409, Mean=0.1389\n",
      "\n",
      "Epoch [82/1000], Training Loss: 0.0505\n",
      "Epoch [82/1000], Validation Loss: 0.1125, Validation Accuracy: 96.77%\n",
      "Output Summary: Max=15.4303, Min=-11.3351, Median=-0.3335, Mean=0.1434\n",
      "\n",
      "Epoch [83/1000], Training Loss: 0.0486\n",
      "Epoch [83/1000], Validation Loss: 0.1122, Validation Accuracy: 96.77%\n",
      "Output Summary: Max=15.5841, Min=-11.4372, Median=-0.3275, Mean=0.1473\n",
      "\n",
      "Epoch [84/1000], Training Loss: 0.0472\n",
      "Epoch [84/1000], Validation Loss: 0.1107, Validation Accuracy: 96.78%\n",
      "Output Summary: Max=15.6237, Min=-11.6569, Median=-0.3317, Mean=0.1460\n",
      "\n",
      "Epoch [85/1000], Training Loss: 0.0451\n",
      "Epoch [85/1000], Validation Loss: 0.1107, Validation Accuracy: 97.01%\n",
      "Output Summary: Max=15.7203, Min=-11.6927, Median=-0.3370, Mean=0.1390\n",
      "\n",
      "Epoch [86/1000], Training Loss: 0.0447\n",
      "Epoch [86/1000], Validation Loss: 0.1145, Validation Accuracy: 96.87%\n",
      "Output Summary: Max=15.7372, Min=-11.8177, Median=-0.3548, Mean=0.1388\n",
      "\n",
      "Epoch [87/1000], Training Loss: 0.0447\n",
      "Epoch [87/1000], Validation Loss: 0.1144, Validation Accuracy: 96.86%\n",
      "Output Summary: Max=15.7831, Min=-11.9530, Median=-0.3506, Mean=0.1368\n",
      "\n",
      "Epoch [88/1000], Training Loss: 0.0441\n",
      "Epoch [88/1000], Validation Loss: 0.1138, Validation Accuracy: 96.77%\n",
      "Output Summary: Max=15.8744, Min=-12.0761, Median=-0.3348, Mean=0.1368\n",
      "\n",
      "Epoch [89/1000], Training Loss: 0.0426\n",
      "Epoch [89/1000], Validation Loss: 0.1100, Validation Accuracy: 96.98%\n",
      "Output Summary: Max=16.0006, Min=-12.0394, Median=-0.3391, Mean=0.1360\n",
      "\n",
      "Epoch [90/1000], Training Loss: 0.0418\n",
      "Epoch [90/1000], Validation Loss: 0.1095, Validation Accuracy: 97.06%\n",
      "Output Summary: Max=16.1120, Min=-11.7674, Median=-0.3520, Mean=0.1451\n",
      "\n",
      "Epoch [91/1000], Training Loss: 0.0410\n",
      "Epoch [91/1000], Validation Loss: 0.1124, Validation Accuracy: 96.83%\n",
      "Output Summary: Max=16.3164, Min=-11.8579, Median=-0.3353, Mean=0.1515\n",
      "\n",
      "Epoch [92/1000], Training Loss: 0.0404\n",
      "Epoch [92/1000], Validation Loss: 0.1119, Validation Accuracy: 97.02%\n",
      "Output Summary: Max=16.4243, Min=-11.7869, Median=-0.3385, Mean=0.1419\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[89]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m output = model(data)\n\u001b[32m     15\u001b[39m loss = criterion(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     19\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "patience = 10000\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb29bce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [1/1000], Training Loss: 2.3031\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [1/1000], Validation Loss: 2.3011, Validation Accuracy: 10.28%\n",
      "Output Summary: Max=0.0767, Min=-0.0834, Median=0.0046, Mean=0.0008\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [2/1000], Training Loss: 2.2977\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [2/1000], Validation Loss: 2.2762, Validation Accuracy: 11.35%\n",
      "Output Summary: Max=0.1527, Min=-0.1679, Median=0.0052, Mean=0.0058\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [3/1000], Training Loss: 2.0019\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [3/1000], Validation Loss: 1.6313, Validation Accuracy: 51.01%\n",
      "Output Summary: Max=2.1313, Min=-1.8099, Median=0.0843, Mean=0.0537\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [4/1000], Training Loss: 1.3945\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [4/1000], Validation Loss: 1.1465, Validation Accuracy: 67.82%\n",
      "Output Summary: Max=3.1563, Min=-2.7234, Median=-0.0423, Mean=0.0473\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [5/1000], Training Loss: 1.0291\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [5/1000], Validation Loss: 0.9088, Validation Accuracy: 75.40%\n",
      "Output Summary: Max=3.9097, Min=-3.4140, Median=-0.1451, Mean=0.0575\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [6/1000], Training Loss: 0.8387\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [6/1000], Validation Loss: 0.7428, Validation Accuracy: 81.17%\n",
      "Output Summary: Max=4.4202, Min=-3.7784, Median=-0.1797, Mean=0.0656\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [7/1000], Training Loss: 0.6917\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [7/1000], Validation Loss: 0.6092, Validation Accuracy: 85.28%\n",
      "Output Summary: Max=4.8790, Min=-4.1071, Median=-0.2077, Mean=0.0763\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [8/1000], Training Loss: 0.5786\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [8/1000], Validation Loss: 0.5193, Validation Accuracy: 87.37%\n",
      "Output Summary: Max=5.2353, Min=-4.4579, Median=-0.2286, Mean=0.0732\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [9/1000], Training Loss: 0.5033\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [9/1000], Validation Loss: 0.4525, Validation Accuracy: 88.72%\n",
      "Output Summary: Max=5.6125, Min=-4.7865, Median=-0.2175, Mean=0.0761\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [10/1000], Training Loss: 0.4529\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [10/1000], Validation Loss: 0.4090, Validation Accuracy: 89.58%\n",
      "Output Summary: Max=5.9201, Min=-5.0788, Median=-0.1938, Mean=0.0795\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [11/1000], Training Loss: 0.4159\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [11/1000], Validation Loss: 0.3812, Validation Accuracy: 90.17%\n",
      "Output Summary: Max=6.1766, Min=-5.3369, Median=-0.1754, Mean=0.0799\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [12/1000], Training Loss: 0.3845\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [12/1000], Validation Loss: 0.3571, Validation Accuracy: 90.71%\n",
      "Output Summary: Max=6.3701, Min=-5.5552, Median=-0.1718, Mean=0.0773\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [13/1000], Training Loss: 0.3601\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [13/1000], Validation Loss: 0.3338, Validation Accuracy: 91.17%\n",
      "Output Summary: Max=6.5295, Min=-5.7530, Median=-0.1655, Mean=0.0786\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [14/1000], Training Loss: 0.3384\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [14/1000], Validation Loss: 0.3159, Validation Accuracy: 91.75%\n",
      "Output Summary: Max=6.6785, Min=-5.9214, Median=-0.1648, Mean=0.0792\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [15/1000], Training Loss: 0.3209\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [15/1000], Validation Loss: 0.3024, Validation Accuracy: 92.07%\n",
      "Output Summary: Max=6.7953, Min=-6.0790, Median=-0.1615, Mean=0.0789\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [16/1000], Training Loss: 0.3066\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [16/1000], Validation Loss: 0.2915, Validation Accuracy: 92.30%\n",
      "Output Summary: Max=6.8990, Min=-6.2172, Median=-0.1603, Mean=0.0781\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [17/1000], Training Loss: 0.2949\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [17/1000], Validation Loss: 0.2830, Validation Accuracy: 92.47%\n",
      "Output Summary: Max=6.9847, Min=-6.3353, Median=-0.1547, Mean=0.0777\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [18/1000], Training Loss: 0.2838\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [18/1000], Validation Loss: 0.2744, Validation Accuracy: 92.52%\n",
      "Output Summary: Max=7.0719, Min=-6.4409, Median=-0.1475, Mean=0.0794\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [19/1000], Training Loss: 0.2726\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [19/1000], Validation Loss: 0.2634, Validation Accuracy: 92.86%\n",
      "Output Summary: Max=7.1932, Min=-6.5429, Median=-0.1360, Mean=0.0829\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [20/1000], Training Loss: 0.2621\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [20/1000], Validation Loss: 0.2543, Validation Accuracy: 92.97%\n",
      "Output Summary: Max=7.3111, Min=-6.6464, Median=-0.1325, Mean=0.0853\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [21/1000], Training Loss: 0.2535\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [21/1000], Validation Loss: 0.2478, Validation Accuracy: 93.14%\n",
      "Output Summary: Max=7.4241, Min=-6.7660, Median=-0.1309, Mean=0.0876\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [22/1000], Training Loss: 0.2469\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [22/1000], Validation Loss: 0.2420, Validation Accuracy: 93.20%\n",
      "Output Summary: Max=7.5304, Min=-6.8890, Median=-0.1304, Mean=0.0895\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [23/1000], Training Loss: 0.2412\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [23/1000], Validation Loss: 0.2366, Validation Accuracy: 93.30%\n",
      "Output Summary: Max=7.6238, Min=-6.9997, Median=-0.1296, Mean=0.0911\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [24/1000], Training Loss: 0.2360\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [24/1000], Validation Loss: 0.2320, Validation Accuracy: 93.37%\n",
      "Output Summary: Max=7.7082, Min=-7.0984, Median=-0.1285, Mean=0.0926\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [25/1000], Training Loss: 0.2315\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [25/1000], Validation Loss: 0.2283, Validation Accuracy: 93.51%\n",
      "Output Summary: Max=7.7861, Min=-7.1879, Median=-0.1257, Mean=0.0943\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [26/1000], Training Loss: 0.2272\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [26/1000], Validation Loss: 0.2258, Validation Accuracy: 93.54%\n",
      "Output Summary: Max=7.8593, Min=-7.2652, Median=-0.1231, Mean=0.0960\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [27/1000], Training Loss: 0.2228\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [27/1000], Validation Loss: 0.2237, Validation Accuracy: 93.64%\n",
      "Output Summary: Max=7.9273, Min=-7.3290, Median=-0.1170, Mean=0.0981\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [28/1000], Training Loss: 0.2185\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [28/1000], Validation Loss: 0.2213, Validation Accuracy: 93.71%\n",
      "Output Summary: Max=7.9935, Min=-7.3902, Median=-0.1129, Mean=0.1000\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [29/1000], Training Loss: 0.2145\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [29/1000], Validation Loss: 0.2185, Validation Accuracy: 93.77%\n",
      "Output Summary: Max=8.0612, Min=-7.4547, Median=-0.1112, Mean=0.1011\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [30/1000], Training Loss: 0.2108\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [30/1000], Validation Loss: 0.2155, Validation Accuracy: 93.98%\n",
      "Output Summary: Max=8.1400, Min=-7.5196, Median=-0.1118, Mean=0.1009\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [31/1000], Training Loss: 0.2073\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [31/1000], Validation Loss: 0.2128, Validation Accuracy: 94.09%\n",
      "Output Summary: Max=8.2158, Min=-7.5821, Median=-0.1164, Mean=0.1002\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [32/1000], Training Loss: 0.2039\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [32/1000], Validation Loss: 0.2104, Validation Accuracy: 94.17%\n",
      "Output Summary: Max=8.2844, Min=-7.6416, Median=-0.1212, Mean=0.0998\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [33/1000], Training Loss: 0.2007\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [33/1000], Validation Loss: 0.2080, Validation Accuracy: 94.38%\n",
      "Output Summary: Max=8.3441, Min=-7.6997, Median=-0.1263, Mean=0.0996\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [34/1000], Training Loss: 0.1976\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [34/1000], Validation Loss: 0.2059, Validation Accuracy: 94.35%\n",
      "Output Summary: Max=8.3958, Min=-7.7567, Median=-0.1315, Mean=0.0996\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [35/1000], Training Loss: 0.1948\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [35/1000], Validation Loss: 0.2038, Validation Accuracy: 94.39%\n",
      "Output Summary: Max=8.4618, Min=-7.8136, Median=-0.1374, Mean=0.0996\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [36/1000], Training Loss: 0.1924\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [36/1000], Validation Loss: 0.2018, Validation Accuracy: 94.41%\n",
      "Output Summary: Max=8.5238, Min=-7.8719, Median=-0.1429, Mean=0.0994\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [37/1000], Training Loss: 0.1902\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [37/1000], Validation Loss: 0.1998, Validation Accuracy: 94.44%\n",
      "Output Summary: Max=8.5791, Min=-7.9319, Median=-0.1481, Mean=0.0989\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [38/1000], Training Loss: 0.1884\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [38/1000], Validation Loss: 0.1979, Validation Accuracy: 94.50%\n",
      "Output Summary: Max=8.6242, Min=-7.9931, Median=-0.1567, Mean=0.0978\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [39/1000], Training Loss: 0.1868\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [39/1000], Validation Loss: 0.1972, Validation Accuracy: 94.54%\n",
      "Output Summary: Max=8.6531, Min=-8.0534, Median=-0.1601, Mean=0.0963\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [40/1000], Training Loss: 0.1849\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [40/1000], Validation Loss: 0.1985, Validation Accuracy: 94.37%\n",
      "Output Summary: Max=8.6742, Min=-8.1019, Median=-0.1654, Mean=0.0946\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [41/1000], Training Loss: 0.1823\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [41/1000], Validation Loss: 0.1982, Validation Accuracy: 94.32%\n",
      "Output Summary: Max=8.7225, Min=-8.1250, Median=-0.1672, Mean=0.0945\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [42/1000], Training Loss: 0.1800\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [42/1000], Validation Loss: 0.1966, Validation Accuracy: 94.45%\n",
      "Output Summary: Max=8.7843, Min=-8.1390, Median=-0.1671, Mean=0.0953\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [43/1000], Training Loss: 0.1782\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [43/1000], Validation Loss: 0.1953, Validation Accuracy: 94.49%\n",
      "Output Summary: Max=8.8418, Min=-8.1577, Median=-0.1693, Mean=0.0957\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [44/1000], Training Loss: 0.1765\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [44/1000], Validation Loss: 0.1943, Validation Accuracy: 94.52%\n",
      "Output Summary: Max=8.8881, Min=-8.1798, Median=-0.1703, Mean=0.0961\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [45/1000], Training Loss: 0.1750\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [45/1000], Validation Loss: 0.1933, Validation Accuracy: 94.53%\n",
      "Output Summary: Max=8.9290, Min=-8.2038, Median=-0.1697, Mean=0.0968\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [46/1000], Training Loss: 0.1735\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [46/1000], Validation Loss: 0.1923, Validation Accuracy: 94.53%\n",
      "Output Summary: Max=8.9760, Min=-8.2296, Median=-0.1702, Mean=0.0977\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [47/1000], Training Loss: 0.1721\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [47/1000], Validation Loss: 0.1915, Validation Accuracy: 94.57%\n",
      "Output Summary: Max=9.0222, Min=-8.2567, Median=-0.1713, Mean=0.0988\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [48/1000], Training Loss: 0.1706\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [48/1000], Validation Loss: 0.1906, Validation Accuracy: 94.55%\n",
      "Output Summary: Max=9.0662, Min=-8.2848, Median=-0.1708, Mean=0.0998\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [49/1000], Training Loss: 0.1693\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [49/1000], Validation Loss: 0.1891, Validation Accuracy: 94.61%\n",
      "Output Summary: Max=9.1077, Min=-8.3155, Median=-0.1709, Mean=0.1004\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [50/1000], Training Loss: 0.1683\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [50/1000], Validation Loss: 0.1862, Validation Accuracy: 94.68%\n",
      "Output Summary: Max=9.1458, Min=-8.3496, Median=-0.1680, Mean=0.1002\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [51/1000], Training Loss: 0.1676\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [51/1000], Validation Loss: 0.1828, Validation Accuracy: 94.76%\n",
      "Output Summary: Max=9.1813, Min=-8.3846, Median=-0.1669, Mean=0.0992\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [52/1000], Training Loss: 0.1669\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [52/1000], Validation Loss: 0.1801, Validation Accuracy: 94.75%\n",
      "Output Summary: Max=9.2219, Min=-8.4197, Median=-0.1715, Mean=0.0981\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [53/1000], Training Loss: 0.1656\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [53/1000], Validation Loss: 0.1794, Validation Accuracy: 94.70%\n",
      "Output Summary: Max=9.2775, Min=-8.4609, Median=-0.1761, Mean=0.0967\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [54/1000], Training Loss: 0.1638\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [54/1000], Validation Loss: 0.1793, Validation Accuracy: 94.67%\n",
      "Output Summary: Max=9.3146, Min=-8.4938, Median=-0.1754, Mean=0.0957\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [55/1000], Training Loss: 0.1612\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [55/1000], Validation Loss: 0.1772, Validation Accuracy: 94.72%\n",
      "Output Summary: Max=9.3505, Min=-8.5080, Median=-0.1717, Mean=0.0960\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [56/1000], Training Loss: 0.1585\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [56/1000], Validation Loss: 0.1747, Validation Accuracy: 94.81%\n",
      "Output Summary: Max=9.3958, Min=-8.5205, Median=-0.1695, Mean=0.0970\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [57/1000], Training Loss: 0.1561\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [57/1000], Validation Loss: 0.1729, Validation Accuracy: 94.84%\n",
      "Output Summary: Max=9.4372, Min=-8.5427, Median=-0.1674, Mean=0.0977\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [58/1000], Training Loss: 0.1541\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [58/1000], Validation Loss: 0.1716, Validation Accuracy: 94.81%\n",
      "Output Summary: Max=9.4741, Min=-8.5705, Median=-0.1672, Mean=0.0980\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [59/1000], Training Loss: 0.1523\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [59/1000], Validation Loss: 0.1705, Validation Accuracy: 94.91%\n",
      "Output Summary: Max=9.5098, Min=-8.6002, Median=-0.1650, Mean=0.0981\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [60/1000], Training Loss: 0.1507\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [60/1000], Validation Loss: 0.1696, Validation Accuracy: 94.95%\n",
      "Output Summary: Max=9.5553, Min=-8.6378, Median=-0.1645, Mean=0.0982\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [61/1000], Training Loss: 0.1492\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [61/1000], Validation Loss: 0.1688, Validation Accuracy: 94.98%\n",
      "Output Summary: Max=9.6013, Min=-8.6822, Median=-0.1637, Mean=0.0981\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [62/1000], Training Loss: 0.1477\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [62/1000], Validation Loss: 0.1680, Validation Accuracy: 95.02%\n",
      "Output Summary: Max=9.6454, Min=-8.7275, Median=-0.1628, Mean=0.0981\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [63/1000], Training Loss: 0.1463\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [63/1000], Validation Loss: 0.1671, Validation Accuracy: 95.05%\n",
      "Output Summary: Max=9.6879, Min=-8.7737, Median=-0.1599, Mean=0.0980\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [64/1000], Training Loss: 0.1449\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [64/1000], Validation Loss: 0.1663, Validation Accuracy: 95.06%\n",
      "Output Summary: Max=9.7294, Min=-8.8206, Median=-0.1566, Mean=0.0979\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [65/1000], Training Loss: 0.1436\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [65/1000], Validation Loss: 0.1655, Validation Accuracy: 95.09%\n",
      "Output Summary: Max=9.7706, Min=-8.8676, Median=-0.1542, Mean=0.0979\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [66/1000], Training Loss: 0.1423\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [66/1000], Validation Loss: 0.1647, Validation Accuracy: 95.10%\n",
      "Output Summary: Max=9.8123, Min=-8.9133, Median=-0.1531, Mean=0.0979\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [67/1000], Training Loss: 0.1411\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [67/1000], Validation Loss: 0.1638, Validation Accuracy: 95.12%\n",
      "Output Summary: Max=9.8547, Min=-8.9576, Median=-0.1509, Mean=0.0980\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [68/1000], Training Loss: 0.1399\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [68/1000], Validation Loss: 0.1629, Validation Accuracy: 95.13%\n",
      "Output Summary: Max=9.8970, Min=-9.0018, Median=-0.1498, Mean=0.0981\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [69/1000], Training Loss: 0.1387\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [69/1000], Validation Loss: 0.1621, Validation Accuracy: 95.16%\n",
      "Output Summary: Max=9.9395, Min=-9.0503, Median=-0.1472, Mean=0.0982\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [70/1000], Training Loss: 0.1375\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [70/1000], Validation Loss: 0.1612, Validation Accuracy: 95.16%\n",
      "Output Summary: Max=9.9823, Min=-9.1070, Median=-0.1462, Mean=0.0984\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [71/1000], Training Loss: 0.1364\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [71/1000], Validation Loss: 0.1603, Validation Accuracy: 95.19%\n",
      "Output Summary: Max=10.0255, Min=-9.1629, Median=-0.1451, Mean=0.0986\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [72/1000], Training Loss: 0.1353\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [72/1000], Validation Loss: 0.1595, Validation Accuracy: 95.24%\n",
      "Output Summary: Max=10.0691, Min=-9.2178, Median=-0.1465, Mean=0.0988\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [73/1000], Training Loss: 0.1342\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [73/1000], Validation Loss: 0.1587, Validation Accuracy: 95.23%\n",
      "Output Summary: Max=10.1131, Min=-9.2715, Median=-0.1461, Mean=0.0991\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [74/1000], Training Loss: 0.1331\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [74/1000], Validation Loss: 0.1579, Validation Accuracy: 95.28%\n",
      "Output Summary: Max=10.1575, Min=-9.3238, Median=-0.1446, Mean=0.0994\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [75/1000], Training Loss: 0.1321\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [75/1000], Validation Loss: 0.1572, Validation Accuracy: 95.31%\n",
      "Output Summary: Max=10.2022, Min=-9.3745, Median=-0.1446, Mean=0.0997\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [76/1000], Training Loss: 0.1311\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [76/1000], Validation Loss: 0.1566, Validation Accuracy: 95.30%\n",
      "Output Summary: Max=10.2474, Min=-9.4237, Median=-0.1420, Mean=0.1000\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [77/1000], Training Loss: 0.1301\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [77/1000], Validation Loss: 0.1559, Validation Accuracy: 95.29%\n",
      "Output Summary: Max=10.2932, Min=-9.4714, Median=-0.1397, Mean=0.1003\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [78/1000], Training Loss: 0.1291\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [78/1000], Validation Loss: 0.1554, Validation Accuracy: 95.29%\n",
      "Output Summary: Max=10.3398, Min=-9.5176, Median=-0.1353, Mean=0.1005\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [79/1000], Training Loss: 0.1282\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [79/1000], Validation Loss: 0.1549, Validation Accuracy: 95.36%\n",
      "Output Summary: Max=10.3873, Min=-9.5625, Median=-0.1330, Mean=0.1008\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [80/1000], Training Loss: 0.1273\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [80/1000], Validation Loss: 0.1544, Validation Accuracy: 95.34%\n",
      "Output Summary: Max=10.4357, Min=-9.6061, Median=-0.1294, Mean=0.1009\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [81/1000], Training Loss: 0.1264\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [81/1000], Validation Loss: 0.1540, Validation Accuracy: 95.38%\n",
      "Output Summary: Max=10.4851, Min=-9.6485, Median=-0.1273, Mean=0.1009\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [82/1000], Training Loss: 0.1256\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [82/1000], Validation Loss: 0.1537, Validation Accuracy: 95.40%\n",
      "Output Summary: Max=10.5353, Min=-9.6894, Median=-0.1253, Mean=0.1009\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [83/1000], Training Loss: 0.1248\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [83/1000], Validation Loss: 0.1534, Validation Accuracy: 95.41%\n",
      "Output Summary: Max=10.5862, Min=-9.7290, Median=-0.1246, Mean=0.1008\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [84/1000], Training Loss: 0.1241\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [84/1000], Validation Loss: 0.1533, Validation Accuracy: 95.43%\n",
      "Output Summary: Max=10.6374, Min=-9.7670, Median=-0.1208, Mean=0.1005\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [85/1000], Training Loss: 0.1234\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [85/1000], Validation Loss: 0.1532, Validation Accuracy: 95.45%\n",
      "Output Summary: Max=10.6888, Min=-9.8035, Median=-0.1198, Mean=0.1002\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [86/1000], Training Loss: 0.1229\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [86/1000], Validation Loss: 0.1533, Validation Accuracy: 95.44%\n",
      "Output Summary: Max=10.7401, Min=-9.8384, Median=-0.1163, Mean=0.0998\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [87/1000], Training Loss: 0.1224\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [87/1000], Validation Loss: 0.1535, Validation Accuracy: 95.44%\n",
      "Output Summary: Max=10.7907, Min=-9.8713, Median=-0.1133, Mean=0.0994\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [88/1000], Training Loss: 0.1220\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "Epoch [88/1000], Validation Loss: 0.1540, Validation Accuracy: 95.41%\n",
      "Output Summary: Max=10.8404, Min=-9.9018, Median=-0.1111, Mean=0.0990\n",
      "\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n",
      "torch.Size([2500, 32, 5, 5])\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[81]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m output = model(data)\n\u001b[32m     15\u001b[39m loss = criterion(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     19\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "patience = 10000\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bece12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
