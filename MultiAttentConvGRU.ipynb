{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6832cb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class AttentionGRUConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, patch_size=2, stride=1, heads=1):\n",
    "        super().__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.patch_size = patch_size\n",
    "        self.stride = stride\n",
    "        self.heads = heads\n",
    "        self.hidden_size = out_channels\n",
    "\n",
    "        self.input_dim = patch_size * patch_size * in_channels\n",
    "        self.attn_input_dim = in_channels\n",
    "\n",
    "        # Positional encoding for 2x2 grid\n",
    "        self.pos_embed = nn.Parameter(torch.zeros(4, in_channels))  # 4 corners of the 2x2 patch\n",
    "\n",
    "        # Multi-head attention for 2x2 pixels\n",
    "        self.attn = nn.MultiheadAttention(embed_dim=in_channels, num_heads=heads, batch_first=True)\n",
    "\n",
    "        # GRU cell to generate output feature vector\n",
    "        self.gru = nn.GRU(input_size=self.input_dim, hidden_size=self.hidden_size, batch_first=True, num_layers=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "\n",
    "        # Use unfold to get 2x2 patches\n",
    "        patches = F.unfold(x, kernel_size=self.patch_size, stride=self.stride)  # (B, C*K*K, L)\n",
    "        L = patches.shape[-1]  # Number of patches\n",
    "        patches = patches.transpose(1, 2)  # (B, L, C*K*K)\n",
    "\n",
    "        # Get 4 corners for attention: reshape to (B*L, 4, C)\n",
    "        corners = patches.view(B, L, self.patch_size * self.patch_size, C)\n",
    "        corners = corners[:, :, [0, 1, 2, 3]]  # 2x2 order; assumed flattened row-wise\n",
    "        corners = corners.reshape(B * L, 4, C)\n",
    "\n",
    "        # Add positional encoding\n",
    "        corners_pe = corners + self.pos_embed.unsqueeze(0)  # (B*L, 4, C)\n",
    "\n",
    "        # Apply MHA: output will be (B*L, 4, C)\n",
    "        attn_output, _ = self.attn(corners_pe, corners_pe, corners_pe)  # Self-attn\n",
    "\n",
    "        # Aggregate attention outputs into a vector to use as GRU hidden state\n",
    "        init_hidden = attn_output.mean(dim=1).unsqueeze(0)  # (1, B*L, C)\n",
    "\n",
    "        # Flatten patch for input to GRU\n",
    "        patch_inputs = patches.reshape(B * L, 1, -1)  # (B*L, 1, C*4)\n",
    "\n",
    "        # Run GRU\n",
    "        _, h_n = self.gru(patch_inputs, init_hidden)  # h_n: (1, B*L, hidden_size)\n",
    "\n",
    "        # Reshape to (B, out_channels, H_out, W_out)\n",
    "        output = h_n.squeeze(0).view(B, L, self.out_channels).transpose(1, 2)  # (B, out_channels, L)\n",
    "        H_out = (H - self.patch_size) // self.stride + 1\n",
    "        W_out = (W - self.patch_size) // self.stride + 1\n",
    "        output = output.view(B, self.out_channels, H_out, W_out)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f0a886df",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f94be421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5fa4979a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "afcd05cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train_dataset.data.to(device).float() / 255.0\n",
    "train_targets = train_dataset.targets.to(device)\n",
    "\n",
    "test_data = test_dataset.data.to(device).float() / 255.0\n",
    "test_targets = test_dataset.targets.to(device)\n",
    "\n",
    "train_data = train_data.unsqueeze(1)\n",
    "test_data = test_data.unsqueeze(1)\n",
    "\n",
    "def get_batches(data, targets, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size], targets[i:i + batch_size]\n",
    "\n",
    "batch_size = 2500\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a85092",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MNISTAttentionGRUCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=2, stride=2, padding=1)\n",
    "        self.attn_gru_conv = AttentionGRUConv2d(in_channels=32, out_channels=32, patch_size=2, stride=1, heads=2)\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, stride=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=2, stride=2, padding=1)\n",
    "\n",
    "        self.fc1 = nn.Linear(32, 10)\n",
    "\n",
    "    def forward(self, x): # (B, 1, 28, 28)\n",
    "        x = self.conv1(x) # (B, 16, 15, 15)\n",
    "        x = self.attn_gru_conv(x)  # (B, 16, 14, 14)\n",
    "        x = self.conv2(x) # (B, 16, 8, 8)\n",
    "        x = self.conv3(x) # (B, 16, 5, 5)\n",
    "        x = self.attn_gru_conv(x) # (B, 16, 4, 4)\n",
    "        x = self.attn_gru_conv(x) # (B, 16, 4, 4)\n",
    "        x = self.attn_gru_conv(x) # (B, 16, 2, 2)\n",
    "        x = self.attn_gru_conv(x) # (B, 16, 1, 1)\n",
    "        \n",
    "        x = x.reshape(x.size(0), -1)  # Flatten\n",
    "        x = self.fc1(x)\n",
    "        print(\"here\")\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "d812474e",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 * 1\n",
    "epochs = 1000\n",
    "\n",
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "model = MNISTAttentionGRUCNN().to(device)\n",
    "# model = torch.compile(MNIST2DLSTMClassifier()).to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d7ebaf5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight: 128 params, requires_grad=True\n",
      "conv1.bias: 32 params, requires_grad=True\n",
      "attn_gru_conv.pos_embed: 128 params, requires_grad=True\n",
      "attn_gru_conv.attn.in_proj_weight: 3072 params, requires_grad=True\n",
      "attn_gru_conv.attn.in_proj_bias: 96 params, requires_grad=True\n",
      "attn_gru_conv.attn.out_proj.weight: 1024 params, requires_grad=True\n",
      "attn_gru_conv.attn.out_proj.bias: 32 params, requires_grad=True\n",
      "attn_gru_conv.gru.weight_ih_l0: 12288 params, requires_grad=True\n",
      "attn_gru_conv.gru.weight_hh_l0: 3072 params, requires_grad=True\n",
      "attn_gru_conv.gru.bias_ih_l0: 96 params, requires_grad=True\n",
      "attn_gru_conv.gru.bias_hh_l0: 96 params, requires_grad=True\n",
      "conv2.weight: 4096 params, requires_grad=True\n",
      "conv2.bias: 32 params, requires_grad=True\n",
      "conv3.weight: 4096 params, requires_grad=True\n",
      "conv3.bias: 32 params, requires_grad=True\n",
      "fc1.weight: 320 params, requires_grad=True\n",
      "fc1.bias: 10 params, requires_grad=True\n",
      "\n",
      "28650\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} params, requires_grad={param.requires_grad}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print()\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "17fea1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [1/1000], Training Loss: 2.2595\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [1/1000], Validation Loss: 2.0938, Validation Accuracy: 51.24%\n",
      "Output Summary: Max=0.6251, Min=-0.5494, Median=-0.0035, Mean=0.0065\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [2/1000], Training Loss: 1.7153\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [2/1000], Validation Loss: 1.2773, Validation Accuracy: 69.98%\n",
      "Output Summary: Max=3.0340, Min=-2.4188, Median=-0.0510, Mean=-0.0024\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [3/1000], Training Loss: 1.0272\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [3/1000], Validation Loss: 0.7672, Validation Accuracy: 84.94%\n",
      "Output Summary: Max=4.1335, Min=-2.9024, Median=-0.0315, Mean=0.0875\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [4/1000], Training Loss: 0.6450\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [4/1000], Validation Loss: 0.5025, Validation Accuracy: 89.87%\n",
      "Output Summary: Max=4.8591, Min=-3.3602, Median=-0.0790, Mean=0.1228\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [5/1000], Training Loss: 0.4398\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [5/1000], Validation Loss: 0.3598, Validation Accuracy: 91.95%\n",
      "Output Summary: Max=5.4270, Min=-3.7083, Median=-0.1128, Mean=0.1370\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [6/1000], Training Loss: 0.3277\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [6/1000], Validation Loss: 0.2823, Validation Accuracy: 93.13%\n",
      "Output Summary: Max=6.0651, Min=-3.9983, Median=-0.1512, Mean=0.1400\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [7/1000], Training Loss: 0.2623\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [7/1000], Validation Loss: 0.2361, Validation Accuracy: 94.14%\n",
      "Output Summary: Max=6.8451, Min=-4.0468, Median=-0.1877, Mean=0.1375\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [8/1000], Training Loss: 0.2206\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [8/1000], Validation Loss: 0.2047, Validation Accuracy: 94.67%\n",
      "Output Summary: Max=7.6252, Min=-4.1549, Median=-0.2098, Mean=0.1378\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [9/1000], Training Loss: 0.1940\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [9/1000], Validation Loss: 0.1850, Validation Accuracy: 95.13%\n",
      "Output Summary: Max=8.1954, Min=-4.3893, Median=-0.2283, Mean=0.1358\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [10/1000], Training Loss: 0.1762\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [10/1000], Validation Loss: 0.1683, Validation Accuracy: 95.49%\n",
      "Output Summary: Max=8.7264, Min=-4.3177, Median=-0.2522, Mean=0.1408\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [11/1000], Training Loss: 0.1594\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [11/1000], Validation Loss: 0.1618, Validation Accuracy: 95.59%\n",
      "Output Summary: Max=8.5930, Min=-4.5400, Median=-0.2399, Mean=0.1569\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [12/1000], Training Loss: 0.1477\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [12/1000], Validation Loss: 0.1515, Validation Accuracy: 95.78%\n",
      "Output Summary: Max=9.2334, Min=-4.3839, Median=-0.2625, Mean=0.1588\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [13/1000], Training Loss: 0.1340\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [13/1000], Validation Loss: 0.1474, Validation Accuracy: 95.85%\n",
      "Output Summary: Max=9.8230, Min=-4.4487, Median=-0.2964, Mean=0.1526\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [14/1000], Training Loss: 0.1243\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [14/1000], Validation Loss: 0.1379, Validation Accuracy: 95.99%\n",
      "Output Summary: Max=9.7874, Min=-4.5236, Median=-0.2812, Mean=0.1579\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [15/1000], Training Loss: 0.1158\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [15/1000], Validation Loss: 0.1358, Validation Accuracy: 96.03%\n",
      "Output Summary: Max=10.2797, Min=-5.0073, Median=-0.2871, Mean=0.1631\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [16/1000], Training Loss: 0.1090\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [16/1000], Validation Loss: 0.1352, Validation Accuracy: 96.00%\n",
      "Output Summary: Max=10.7585, Min=-5.3890, Median=-0.2911, Mean=0.1671\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [17/1000], Training Loss: 0.1044\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [17/1000], Validation Loss: 0.1348, Validation Accuracy: 96.10%\n",
      "Output Summary: Max=11.0497, Min=-5.6642, Median=-0.2834, Mean=0.1784\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [18/1000], Training Loss: 0.1002\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [18/1000], Validation Loss: 0.1316, Validation Accuracy: 96.13%\n",
      "Output Summary: Max=11.3984, Min=-5.8418, Median=-0.2805, Mean=0.1846\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [19/1000], Training Loss: 0.0987\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [19/1000], Validation Loss: 0.1211, Validation Accuracy: 96.34%\n",
      "Output Summary: Max=11.6611, Min=-5.8562, Median=-0.2768, Mean=0.1795\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [20/1000], Training Loss: 0.0957\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [20/1000], Validation Loss: 0.1135, Validation Accuracy: 96.54%\n",
      "Output Summary: Max=11.9707, Min=-6.0594, Median=-0.2589, Mean=0.1708\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [21/1000], Training Loss: 0.0903\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [21/1000], Validation Loss: 0.1073, Validation Accuracy: 96.76%\n",
      "Output Summary: Max=11.9077, Min=-6.1856, Median=-0.2750, Mean=0.1669\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [22/1000], Training Loss: 0.0845\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [22/1000], Validation Loss: 0.1043, Validation Accuracy: 96.93%\n",
      "Output Summary: Max=11.9827, Min=-6.3576, Median=-0.2956, Mean=0.1688\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [23/1000], Training Loss: 0.0799\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [23/1000], Validation Loss: 0.1029, Validation Accuracy: 97.02%\n",
      "Output Summary: Max=11.6644, Min=-6.3238, Median=-0.2958, Mean=0.1747\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [24/1000], Training Loss: 0.0774\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [24/1000], Validation Loss: 0.1011, Validation Accuracy: 97.04%\n",
      "Output Summary: Max=11.2007, Min=-6.3099, Median=-0.2826, Mean=0.1785\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [25/1000], Training Loss: 0.0742\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [25/1000], Validation Loss: 0.1023, Validation Accuracy: 96.95%\n",
      "Output Summary: Max=11.0358, Min=-5.9788, Median=-0.2699, Mean=0.1863\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [26/1000], Training Loss: 0.0721\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [26/1000], Validation Loss: 0.1026, Validation Accuracy: 97.03%\n",
      "Output Summary: Max=11.1012, Min=-6.1093, Median=-0.2677, Mean=0.1887\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [27/1000], Training Loss: 0.0678\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [27/1000], Validation Loss: 0.0976, Validation Accuracy: 97.09%\n",
      "Output Summary: Max=12.1423, Min=-6.9361, Median=-0.2755, Mean=0.1887\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [28/1000], Training Loss: 0.0620\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [28/1000], Validation Loss: 0.0967, Validation Accuracy: 97.06%\n",
      "Output Summary: Max=11.7823, Min=-6.5029, Median=-0.2698, Mean=0.2088\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [29/1000], Training Loss: 0.0575\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [29/1000], Validation Loss: 0.0948, Validation Accuracy: 97.16%\n",
      "Output Summary: Max=11.7374, Min=-6.7216, Median=-0.2737, Mean=0.2145\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [30/1000], Training Loss: 0.0545\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [30/1000], Validation Loss: 0.0911, Validation Accuracy: 97.31%\n",
      "Output Summary: Max=12.4818, Min=-7.0952, Median=-0.2920, Mean=0.2040\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [31/1000], Training Loss: 0.0517\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [31/1000], Validation Loss: 0.0905, Validation Accuracy: 97.30%\n",
      "Output Summary: Max=12.4361, Min=-6.9527, Median=-0.2939, Mean=0.1959\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [32/1000], Training Loss: 0.0498\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [32/1000], Validation Loss: 0.0882, Validation Accuracy: 97.32%\n",
      "Output Summary: Max=12.4556, Min=-6.8432, Median=-0.2980, Mean=0.1975\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [33/1000], Training Loss: 0.0485\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [33/1000], Validation Loss: 0.0885, Validation Accuracy: 97.33%\n",
      "Output Summary: Max=12.6661, Min=-7.0400, Median=-0.3011, Mean=0.2057\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [34/1000], Training Loss: 0.0471\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [34/1000], Validation Loss: 0.0886, Validation Accuracy: 97.32%\n",
      "Output Summary: Max=13.1807, Min=-7.7106, Median=-0.3212, Mean=0.2049\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [35/1000], Training Loss: 0.0467\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [35/1000], Validation Loss: 0.0917, Validation Accuracy: 97.22%\n",
      "Output Summary: Max=13.4896, Min=-8.2060, Median=-0.3385, Mean=0.2037\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [36/1000], Training Loss: 0.0450\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [36/1000], Validation Loss: 0.0904, Validation Accuracy: 97.24%\n",
      "Output Summary: Max=13.5402, Min=-8.1243, Median=-0.3534, Mean=0.2033\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [37/1000], Training Loss: 0.0440\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [37/1000], Validation Loss: 0.0885, Validation Accuracy: 97.24%\n",
      "Output Summary: Max=12.8698, Min=-7.7272, Median=-0.3422, Mean=0.2146\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [38/1000], Training Loss: 0.0417\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [38/1000], Validation Loss: 0.0906, Validation Accuracy: 97.25%\n",
      "Output Summary: Max=13.0865, Min=-7.6258, Median=-0.3349, Mean=0.2260\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [39/1000], Training Loss: 0.0414\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [39/1000], Validation Loss: 0.0919, Validation Accuracy: 97.25%\n",
      "Output Summary: Max=13.4927, Min=-8.0564, Median=-0.3639, Mean=0.2257\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [40/1000], Training Loss: 0.0385\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [40/1000], Validation Loss: 0.0908, Validation Accuracy: 97.24%\n",
      "Output Summary: Max=13.4603, Min=-7.8966, Median=-0.3770, Mean=0.2191\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [41/1000], Training Loss: 0.0362\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [41/1000], Validation Loss: 0.0856, Validation Accuracy: 97.38%\n",
      "Output Summary: Max=13.7489, Min=-8.4908, Median=-0.3890, Mean=0.2124\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [42/1000], Training Loss: 0.0357\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [42/1000], Validation Loss: 0.0831, Validation Accuracy: 97.47%\n",
      "Output Summary: Max=13.3686, Min=-8.0140, Median=-0.3725, Mean=0.2210\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [43/1000], Training Loss: 0.0349\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [43/1000], Validation Loss: 0.0833, Validation Accuracy: 97.45%\n",
      "Output Summary: Max=13.5099, Min=-8.1970, Median=-0.3835, Mean=0.2186\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [44/1000], Training Loss: 0.0337\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [44/1000], Validation Loss: 0.0910, Validation Accuracy: 97.31%\n",
      "Output Summary: Max=14.3711, Min=-8.9754, Median=-0.4116, Mean=0.2088\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [45/1000], Training Loss: 0.0334\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [45/1000], Validation Loss: 0.0838, Validation Accuracy: 97.50%\n",
      "Output Summary: Max=13.8587, Min=-8.3466, Median=-0.3748, Mean=0.2189\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [46/1000], Training Loss: 0.0330\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [46/1000], Validation Loss: 0.0841, Validation Accuracy: 97.40%\n",
      "Output Summary: Max=13.5374, Min=-8.2396, Median=-0.3716, Mean=0.2234\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [47/1000], Training Loss: 0.0316\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [47/1000], Validation Loss: 0.0926, Validation Accuracy: 97.26%\n",
      "Output Summary: Max=14.0838, Min=-8.9372, Median=-0.4089, Mean=0.2079\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [48/1000], Training Loss: 0.0308\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "Epoch [48/1000], Validation Loss: 0.0878, Validation Accuracy: 97.32%\n",
      "Output Summary: Max=14.2894, Min=-8.8723, Median=-0.4002, Mean=0.2226\n",
      "\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n",
      "here\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 16\u001b[39m\n\u001b[32m     14\u001b[39m output = model(data)\n\u001b[32m     15\u001b[39m loss = criterion(output, target)\n\u001b[32m---> \u001b[39m\u001b[32m16\u001b[39m \u001b[43mloss\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     18\u001b[39m optimizer.step()\n\u001b[32m     19\u001b[39m running_loss += loss.item()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/_tensor.py:626\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    616\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    617\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    618\u001b[39m         Tensor.backward,\n\u001b[32m    619\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    624\u001b[39m         inputs=inputs,\n\u001b[32m    625\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m626\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    627\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    628\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/__init__.py:347\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    342\u001b[39m     retain_graph = create_graph\n\u001b[32m    344\u001b[39m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[32m    345\u001b[39m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[32m    346\u001b[39m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    348\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    349\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    350\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    351\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    352\u001b[39m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    353\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    354\u001b[39m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    355\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/graph.py:823\u001b[39m, in \u001b[36m_engine_run_backward\u001b[39m\u001b[34m(t_outputs, *args, **kwargs)\u001b[39m\n\u001b[32m    821\u001b[39m     unregister_hooks = _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[32m    822\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m823\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_execution_engine\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[32m    824\u001b[39m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\n\u001b[32m    825\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[32m    826\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    827\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "patience = 10000\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(10000):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04bece12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
