{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":18858,"sourceType":"datasetVersion","datasetId":13996}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport keras\nimport tensorflow as tf\nfrom keras import layers\nfrom keras import models\nfrom keras.datasets import california_housing\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchinfo import summary\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import StandardScaler\n\nimport sys\nimport math\n\nimport numpy as np\nimport math\n\nimport numpy as np\nimport keras\nimport tensorflow as tf\nfrom keras import layers\nfrom keras import models\nfrom keras.datasets import mnist\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchinfo import summary\nfrom torch.optim.lr_scheduler import StepLR\n\nimport pandas as pd\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.special import logit\nfrom sklearn.preprocessing import StandardScaler, PowerTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import log_loss, accuracy_score\nfrom sklearn.model_selection import LeaveOneOut, cross_val_predict, StratifiedKFold\nfrom scipy.stats import norm","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:46.586926Z","iopub.execute_input":"2024-09-26T03:12:46.587367Z","iopub.status.idle":"2024-09-26T03:12:46.598562Z","shell.execute_reply.started":"2024-09-26T03:12:46.587327Z","shell.execute_reply":"2024-09-26T03:12:46.597391Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"def calculate_metrics(model, loader):\n    model.eval()\n    all_preds = []\n    all_labels = []\n    with torch.no_grad():\n        for inputs, labels in loader:\n            inputs, labels = inputs.to(device), labels.to(device)\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    return accuracy, f1","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-09-26T03:12:46.921087Z","iopub.execute_input":"2024-09-26T03:12:46.921538Z","iopub.status.idle":"2024-09-26T03:12:46.928473Z","shell.execute_reply.started":"2024-09-26T03:12:46.921495Z","shell.execute_reply":"2024-09-26T03:12:46.927417Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class CustomDataLoader:\n    def __init__(self, features, labels, batch_size=1, validation_size=0.0, shuffle=False):\n\n        if validation_size > 0:\n            train_data, val_data, train_labels, val_labels = train_test_split(features, labels, test_size=validation_size, stratify=labels, random_state=42)\n            train_data_tensor = torch.tensor(train_data).float().to(device)\n            train_labels_tensor = torch.tensor(train_labels).long().to(device)\n            val_data_tensor = torch.tensor(val_data).float().to(device)\n            val_labels_tensor = torch.tensor(val_labels).long().to(device)\n    \n            train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n            val_dataset = TensorDataset(val_data_tensor, val_labels_tensor)\n\n            self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n            self.val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n        else:\n            features_tensor = torch.tensor(features).float().to(device)\n            labels_tensor = torch.tensor(labels).long().to(device)\n\n            dataset = TensorDataset(features_tensor, labels_tensor)\n\n            self.train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n            self.val_loader = None\n\n    def get_train_loader(self):\n        return self.train_loader\n    \n    def get_val_loader(self):\n        return self.val_loader","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:47.394990Z","iopub.execute_input":"2024-09-26T03:12:47.395440Z","iopub.status.idle":"2024-09-26T03:12:47.405572Z","shell.execute_reply.started":"2024-09-26T03:12:47.395396Z","shell.execute_reply":"2024-09-26T03:12:47.404315Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, custom_train_loader, criterion, optimizer):\n    num_epochs = 10000\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for inputs, labels in custom_train_loader.get_train_loader():        \n            optimizer.zero_grad()\n            outputs = model(inputs.view(-1, 40))\n\n            loss = criterion(outputs, labels, model)\n            loss.backward()\n            optimizer.step()\n            \n            running_loss += loss.item()\n            \n        unreg_criterion = nn.CrossEntropyLoss()\n        if (epoch + 1) % 1 == 0:\n            print(f'Epoch {epoch+1}, Loss: {running_loss / (len(custom_train_loader.get_train_loader()))}')\n\n            model.eval()\n            running_val_loss = 0.0\n            with torch.no_grad():\n                for inputs, labels in custom_train_loader.get_val_loader():\n                    inputs, labels = inputs.to(device), labels.to(device)\n                    outputs = model(inputs.view(-1, 40))\n                    val_loss = unreg_criterion(outputs, labels)\n                    running_val_loss += val_loss.item()\n\n                avg_val_loss = running_val_loss / (len(custom_train_loader.get_val_loader()))\n                print(f'Validation Loss: {avg_val_loss}')\n            \n            val_accuracy, val_f1 = calculate_metrics(model, custom_train_loader.get_val_loader())\n            print(f'Val Accuracy: {val_accuracy:.4f}, Val F1-score: {val_f1:.4f}')\n            print()\n\n    model.eval()\n    running_val_loss = 0.0\n    with torch.no_grad():\n        for inputs, labels in custom_train_loader.get_val_loader():\n            outputs = model(inputs.view(-1, 40))\n            val_loss = criterion(outputs, labels)\n            running_val_loss += val_loss.item()\n\n    avg_val_loss = running_val_loss / len(custom_train_loader.get_val_loader())\n    print(f'Validation Loss: {avg_val_loss}')","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:48.080017Z","iopub.execute_input":"2024-09-26T03:12:48.080460Z","iopub.status.idle":"2024-09-26T03:12:48.091439Z","shell.execute_reply.started":"2024-09-26T03:12:48.080419Z","shell.execute_reply":"2024-09-26T03:12:48.090334Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:50.563840Z","iopub.execute_input":"2024-09-26T03:12:50.565132Z","iopub.status.idle":"2024-09-26T03:12:50.569686Z","shell.execute_reply.started":"2024-09-26T03:12:50.565082Z","shell.execute_reply":"2024-09-26T03:12:50.568629Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/telco-customer-churn/WA_Fn-UseC_-Telco-Customer-Churn.csv')\ndata = data.drop(columns=[\"customerID\"])\ndata['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce')\ndata = data.dropna()\n\ncategorical_cols = data.select_dtypes(include=['object']).columns\nfor col in categorical_cols:\n    if data[col].nunique() == 2:\n        data[col], _ = pd.factorize(data[col])\n\ncategorical_cols = data.select_dtypes(include=['object']).columns\ndata = pd.get_dummies(data, columns=['MultipleLines', 'InternetService', 'OnlineSecurity', 'OnlineBackup',\n       'DeviceProtection', 'TechSupport', 'StreamingTV', 'StreamingMovies',\n       'Contract', 'PaymentMethod'])","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:50.832011Z","iopub.execute_input":"2024-09-26T03:12:50.832430Z","iopub.status.idle":"2024-09-26T03:12:50.924130Z","shell.execute_reply.started":"2024-09-26T03:12:50.832385Z","shell.execute_reply":"2024-09-26T03:12:50.923048Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"X = data.drop(\n    [\n        \"Churn\",\n    ],\n    axis=1,\n)\ny = data[\"Churn\"]","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:52.194845Z","iopub.execute_input":"2024-09-26T03:12:52.195284Z","iopub.status.idle":"2024-09-26T03:12:52.202642Z","shell.execute_reply.started":"2024-09-26T03:12:52.195221Z","shell.execute_reply":"2024-09-26T03:12:52.201550Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"x_scaler = StandardScaler()\nx_scaled = x_scaler.fit_transform(X)\n\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:52.462337Z","iopub.execute_input":"2024-09-26T03:12:52.462734Z","iopub.status.idle":"2024-09-26T03:12:52.489629Z","shell.execute_reply.started":"2024-09-26T03:12:52.462698Z","shell.execute_reply":"2024-09-26T03:12:52.488717Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"custom_train_loader = CustomDataLoader(x_scaled, y_encoded, batch_size=16, validation_size=0.2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:53.563121Z","iopub.execute_input":"2024-09-26T03:12:53.563556Z","iopub.status.idle":"2024-09-26T03:12:53.576420Z","shell.execute_reply.started":"2024-09-26T03:12:53.563517Z","shell.execute_reply":"2024-09-26T03:12:53.575280Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"class CustomLinearLayer(nn.Module):\n    def __init__(self, input_size, output_size, mode=\"\"):\n        super(CustomLinearLayer, self).__init__()\n        self.linear = nn.Linear(input_size, output_size, bias=True)    \n        \n        nn.init.zeros_(self.linear.bias)\n        if mode == \"init_zero\":\n            nn.init.zeros_(self.linear.weight)\n        elif mode == \"split_inputs\":\n            self.split_inputs()\n        else:\n            self.custom_weight_init()\n\n    def custom_weight_init(self):\n        with torch.no_grad():\n            rows, cols = self.linear.weight.size()\n            weight = torch.zeros(rows, cols)\n            for i in range(min(rows, cols) // 2):\n                weight[2 * i, 2 * i] = 1\n                weight[2 * i, 2 * i + 1] = -1\n                if 2 * i + 1 < rows and 2 * i + 1 < cols:\n                    weight[2 * i + 1, 2 * i] = -1\n                    weight[2 * i + 1, 2 * i + 1] = 1\n            self.linear.weight.copy_(weight)\n            nn.init.zeros_(self.linear.bias)\n            \n    def split_inputs(self):\n        weight = torch.zeros((self.linear.out_features, self.linear.in_features))\n        \n        for i in range(self.linear.out_features):\n            if i % 2 == 0:\n                weight[i, (i // 2) % self.linear.in_features] = 1\n            else:\n                weight[i, (i - 1) // 2 % self.linear.in_features] = -1\n        \n        self.linear.weight = nn.Parameter(weight)\n\n    def forward(self, x):\n        return self.linear(x)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T03:12:54.629363Z","iopub.execute_input":"2024-09-26T03:12:54.629754Z","iopub.status.idle":"2024-09-26T03:12:54.641678Z","shell.execute_reply.started":"2024-09-26T03:12:54.629719Z","shell.execute_reply":"2024-09-26T03:12:54.640289Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"class PairwiseCustomActivationNetwork(nn.Module):\n    def __init__(self, input_size, num_layers, output_size):\n        super(PairwiseCustomActivationNetwork, self).__init__()\n        \n        self.activation = nn.Softplus()\n        \n        layer_size = input_size * 2\n        self.res_layer = CustomLinearLayer(input_size, layer_size, mode=\"split_inputs\")\n        self.layers = nn.ModuleList()\n\n        for i in range(num_layers):\n            self.layers.append(CustomLinearLayer(layer_size, layer_size))\n            layer_size *= 2\n            \n        self.last_layer = CustomLinearLayer(layer_size, output_size, mode=\"init_zero\")\n\n    def forward(self, x):\n        outputs = [self.activation(self.res_layer(x))]\n        \n        for layer in self.layers:\n            concatenated_outputs = torch.cat(outputs, dim=1)\n            outputs.append(self.activation(layer(concatenated_outputs)))\n\n        concatenated_outputs = torch.cat(outputs, dim=1)\n        return self.last_layer(concatenated_outputs)\n    \nmodel = PairwiseCustomActivationNetwork(40, 6, 2).to(device)\ncriterion = nn.CrossEntropyLoss()\nprint(summary(model, input_size=(1, 40)))\n\n# remember to add original input features to every layer have the neuron be like [1, 0, 0], [-1, 0, 0], [0, 1, 0], [0, -1, 0]\n# look at NN vs tree notebook\n# or may be not","metadata":{"execution":{"iopub.status.busy":"2024-09-26T04:01:26.737644Z","iopub.execute_input":"2024-09-26T04:01:26.738070Z","iopub.status.idle":"2024-09-26T04:01:26.955676Z","shell.execute_reply.started":"2024-09-26T04:01:26.738031Z","shell.execute_reply":"2024-09-26T04:01:26.954527Z"},"trusted":true},"execution_count":72,"outputs":[{"name":"stdout","text":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nPairwiseCustomActivationNetwork          [1, 2]                    --\n├─CustomLinearLayer: 1-1                 [1, 80]                   --\n│    └─Linear: 2-1                       [1, 80]                   3,280\n├─Softplus: 1-2                          [1, 80]                   --\n├─ModuleList: 1-13                       --                        (recursive)\n│    └─CustomLinearLayer: 2-2            [1, 80]                   --\n│    │    └─Linear: 3-1                  [1, 80]                   6,480\n├─Softplus: 1-4                          [1, 80]                   --\n├─ModuleList: 1-13                       --                        (recursive)\n│    └─CustomLinearLayer: 2-3            [1, 160]                  --\n│    │    └─Linear: 3-2                  [1, 160]                  25,760\n├─Softplus: 1-6                          [1, 160]                  --\n├─ModuleList: 1-13                       --                        (recursive)\n│    └─CustomLinearLayer: 2-4            [1, 320]                  --\n│    │    └─Linear: 3-3                  [1, 320]                  102,720\n├─Softplus: 1-8                          [1, 320]                  --\n├─ModuleList: 1-13                       --                        (recursive)\n│    └─CustomLinearLayer: 2-5            [1, 640]                  --\n│    │    └─Linear: 3-4                  [1, 640]                  410,240\n├─Softplus: 1-10                         [1, 640]                  --\n├─ModuleList: 1-13                       --                        (recursive)\n│    └─CustomLinearLayer: 2-6            [1, 1280]                 --\n│    │    └─Linear: 3-5                  [1, 1280]                 1,639,680\n├─Softplus: 1-12                         [1, 1280]                 --\n├─ModuleList: 1-13                       --                        (recursive)\n│    └─CustomLinearLayer: 2-7            [1, 2560]                 --\n│    │    └─Linear: 3-6                  [1, 2560]                 6,556,160\n├─Softplus: 1-14                         [1, 2560]                 --\n├─CustomLinearLayer: 1-15                [1, 2]                    --\n│    └─Linear: 2-8                       [1, 2]                    10,242\n==========================================================================================\nTotal params: 8,754,562\nTrainable params: 8,754,562\nNon-trainable params: 0\nTotal mult-adds (M): 8.75\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.04\nParams size (MB): 35.02\nEstimated Total Size (MB): 35.06\n==========================================================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomLoss(nn.Module):\n    def __init__(self, l1_lambda):\n        super(CustomLoss, self).__init__()\n        self.l1_lambda = l1_lambda\n        self.cross_entropy_loss = nn.CrossEntropyLoss()\n\n    def forward(self, outputs, labels, model):\n        loss = self.cross_entropy_loss(outputs, labels)\n\n        return loss\n    \ncriterion = CustomLoss(0.001 * 0.1 * 10.0)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T04:01:29.215575Z","iopub.execute_input":"2024-09-26T04:01:29.215985Z","iopub.status.idle":"2024-09-26T04:01:29.224163Z","shell.execute_reply.started":"2024-09-26T04:01:29.215947Z","shell.execute_reply":"2024-09-26T04:01:29.222843Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.0001)\noptimizer = optim.SGD(model.parameters(), lr=0.0001)\nevaluate_model(model, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-09-26T04:01:30.598981Z","iopub.execute_input":"2024-09-26T04:01:30.599536Z","iopub.status.idle":"2024-09-26T04:03:07.026703Z","shell.execute_reply.started":"2024-09-26T04:01:30.599477Z","shell.execute_reply":"2024-09-26T04:03:07.024994Z"},"trusted":true},"execution_count":74,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 0.4695108407177031\nValidation Loss: 0.4457737561315298\nVal Accuracy: 0.7889, Val F1-score: 0.7801\n\nEpoch 2, Loss: 0.428804059301249\nValidation Loss: 0.43925589831037953\nVal Accuracy: 0.7925, Val F1-score: 0.7881\n\nEpoch 3, Loss: 0.42304384972984815\nValidation Loss: 0.43732415817000647\nVal Accuracy: 0.7974, Val F1-score: 0.7946\n\nEpoch 4, Loss: 0.42068568543023005\nValidation Loss: 0.43623795749788935\nVal Accuracy: 0.7982, Val F1-score: 0.7954\n\nEpoch 5, Loss: 0.4193577145183967\nValidation Loss: 0.43543119728565216\nVal Accuracy: 0.8017, Val F1-score: 0.7989\n\nEpoch 6, Loss: 0.4184817880053412\nValidation Loss: 0.4347681672396985\nVal Accuracy: 0.7996, Val F1-score: 0.7970\n\nEpoch 7, Loss: 0.41784746445376764\nValidation Loss: 0.4342036848379807\nVal Accuracy: 0.8010, Val F1-score: 0.7983\n\nEpoch 8, Loss: 0.41735779178667476\nValidation Loss: 0.43371597067876294\nVal Accuracy: 0.8017, Val F1-score: 0.7991\n\nEpoch 9, Loss: 0.41696095919575205\nValidation Loss: 0.4332908940586177\nVal Accuracy: 0.8017, Val F1-score: 0.7993\n\nEpoch 10, Loss: 0.4166266572746364\nValidation Loss: 0.4329178441654552\nVal Accuracy: 0.8024, Val F1-score: 0.8001\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[74], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0001\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[13], line 10\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m      7\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m40\u001b[39m))\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels, model)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     13\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    if 'weight' in name:\n        print(f\"Layer: {name} | Weights: {param.data}\")","metadata":{"execution":{"iopub.status.busy":"2024-09-26T04:03:09.436019Z","iopub.execute_input":"2024-09-26T04:03:09.436454Z","iopub.status.idle":"2024-09-26T04:03:09.453978Z","shell.execute_reply.started":"2024-09-26T04:03:09.436413Z","shell.execute_reply":"2024-09-26T04:03:09.452832Z"},"trusted":true},"execution_count":75,"outputs":[{"name":"stdout","text":"Layer: res_layer.linear.weight | Weights: tensor([[ 9.9999e-01, -7.0296e-06,  7.8543e-06,  ...,  2.7559e-05,\n         -2.5271e-05,  4.4993e-06],\n        [-1.0000e+00,  4.3546e-06, -3.3533e-06,  ..., -9.4785e-06,\n          5.5113e-06,  3.9543e-06],\n        [-8.6647e-06,  1.0000e+00,  2.8408e-05,  ...,  2.3260e-05,\n         -8.1537e-06,  4.5484e-05],\n        ...,\n        [ 6.7579e-05, -1.0137e-04, -4.8738e-05,  ...,  1.5827e-05,\n         -1.0000e+00, -2.7119e-05],\n        [ 1.6327e-05, -2.8739e-05, -2.4351e-05,  ...,  5.5670e-06,\n         -6.5580e-07,  9.9998e-01],\n        [-6.3283e-06,  7.8899e-06,  9.2957e-06,  ..., -4.6058e-06,\n          6.4861e-06, -9.9999e-01]])\nLayer: layers.0.linear.weight | Weights: tensor([[ 9.9999e-01, -1.0000e+00, -3.2534e-06,  ...,  4.5872e-06,\n          6.6648e-07, -1.5862e-06],\n        [-1.0000e+00,  1.0000e+00, -5.1788e-07,  ..., -3.1119e-06,\n         -7.1759e-07, -2.6909e-06],\n        [-3.0179e-06,  1.2876e-06,  1.0000e+00,  ...,  8.4481e-07,\n          1.3716e-05, -9.0122e-06],\n        ...,\n        [ 2.8979e-05, -4.8385e-06, -2.3087e-05,  ...,  1.0000e+00,\n          3.3597e-06,  1.6897e-05],\n        [ 3.0131e-06, -5.1606e-06, -1.1002e-05,  ..., -8.3976e-07,\n          9.9999e-01, -1.0000e+00],\n        [-3.5045e-06, -3.5116e-07,  7.8973e-07,  ..., -3.2330e-06,\n         -1.0000e+00,  1.0000e+00]])\nLayer: layers.1.linear.weight | Weights: tensor([[ 1.0000e+00, -1.0000e+00, -1.7143e-06,  ...,  2.3043e-06,\n          2.9823e-07, -8.3049e-07],\n        [-1.0000e+00,  1.0000e+00, -3.5332e-07,  ..., -1.5543e-06,\n         -4.0233e-07, -1.3883e-06],\n        [-1.5382e-06,  5.8553e-07,  1.0000e+00,  ...,  3.9933e-07,\n          6.8105e-06, -4.5472e-06],\n        ...,\n        [ 1.4463e-05, -2.4653e-06, -1.1605e-05,  ...,  1.0000e+00,\n          1.6501e-06,  8.4095e-06],\n        [ 1.4690e-06, -2.6280e-06, -5.5751e-06,  ..., -3.9800e-07,\n          9.9999e-01, -1.0000e+00],\n        [-1.7834e-06, -2.1705e-07,  3.2889e-07,  ..., -1.5874e-06,\n         -1.0000e+00,  1.0000e+00]])\nLayer: layers.2.linear.weight | Weights: tensor([[ 1.0000e+00, -1.0000e+00, -9.4561e-07,  ...,  1.1616e-06,\n          1.1320e-07, -4.5350e-07],\n        [-1.0000e+00,  1.0000e+00, -2.6849e-07,  ..., -7.7188e-07,\n         -2.4124e-07, -7.3501e-07],\n        [-7.9797e-07,  2.3532e-07,  1.0000e+00,  ...,  1.7726e-07,\n          3.3604e-06, -2.3153e-06],\n        ...,\n        [ 7.2038e-06, -1.2782e-06, -5.8635e-06,  ...,  1.0000e+00,\n          7.9378e-07,  4.1659e-06],\n        [ 6.9964e-07, -1.3588e-06, -2.8579e-06,  ..., -1.7315e-07,\n          9.9999e-01, -1.0000e+00],\n        [-9.2338e-07, -1.5030e-07,  9.8138e-08,  ..., -7.6448e-07,\n         -1.0000e+00,  1.0000e+00]])\nLayer: layers.3.linear.weight | Weights: tensor([[ 1.0000e+00, -1.0000e+00, -5.6168e-07,  ...,  5.8978e-07,\n          2.0333e-08, -2.6536e-07],\n        [-1.0000e+00,  1.0000e+00, -2.2478e-07,  ..., -3.7905e-07,\n         -1.5893e-07, -4.0741e-07],\n        [-4.2757e-07,  6.0690e-08,  1.0000e+00,  ...,  6.6857e-08,\n          1.6367e-06, -1.1995e-06],\n        ...,\n        [ 3.5735e-06, -6.8445e-07, -2.9927e-06,  ...,  1.0000e+00,\n          3.6479e-07,  2.0441e-06],\n        [ 3.1636e-07, -7.2280e-07, -1.4974e-06,  ..., -5.9071e-08,\n          1.0000e+00, -1.0000e+00],\n        [-4.9358e-07, -1.1704e-07, -1.7378e-08,  ..., -3.5310e-07,\n         -1.0000e+00,  1.0000e+00]])\nLayer: layers.4.linear.weight | Weights: tensor([[ 1.0000e+00, -1.0000e+00, -3.6988e-07,  ...,  3.0366e-07,\n         -2.6230e-08, -1.7145e-07],\n        [-1.0000e+00,  1.0000e+00, -2.0225e-07,  ..., -1.8176e-07,\n         -1.1686e-07, -2.4310e-07],\n        [-2.4223e-07, -2.6363e-08,  1.0000e+00,  ...,  1.1983e-08,\n          7.7563e-07, -6.4162e-07],\n        ...,\n        [ 1.7581e-06, -3.8743e-07, -1.5572e-06,  ...,  9.9999e-01,\n          1.4992e-07,  9.8326e-07],\n        [ 1.2544e-07, -4.0405e-07, -8.1614e-07,  ..., -1.1746e-09,\n          1.0000e+00, -1.0000e+00],\n        [-2.7877e-07, -1.0044e-07, -7.5178e-08,  ..., -1.4741e-07,\n         -1.0000e+00,  1.0000e+00]])\nLayer: layers.5.linear.weight | Weights: tensor([[ 1.0000e+00, -1.0000e+00, -2.7404e-07,  ...,  1.6053e-07,\n         -4.9532e-08, -1.2456e-07],\n        [-1.0000e+00,  1.0000e+00, -1.9062e-07,  ..., -8.2659e-08,\n         -9.5327e-08, -1.6067e-07],\n        [-1.4946e-07, -6.9727e-08,  1.0000e+00,  ..., -1.5265e-08,\n          3.4549e-07, -3.6271e-07],\n        ...,\n        [ 8.5033e-07, -2.3882e-07, -8.3937e-07,  ...,  1.0000e+00,\n          4.2353e-08,  4.5289e-07],\n        [ 3.0359e-08, -2.4427e-07, -4.7502e-07,  ...,  2.8236e-08,\n          1.0000e+00, -1.0000e+00],\n        [-1.7139e-07, -9.2127e-08, -1.0407e-07,  ..., -4.4528e-08,\n         -1.0000e+00,  1.0000e+00]])\nLayer: last_layer.linear.weight | Weights: tensor([[ 0.0003,  0.0001, -0.0006,  ...,  0.0010,  0.0003,  0.0002],\n        [-0.0003, -0.0001,  0.0006,  ..., -0.0010, -0.0003, -0.0002]])\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}