{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"},{"sourceId":408,"sourceType":"datasetVersion","datasetId":180},{"sourceId":668,"sourceType":"datasetVersion","datasetId":308},{"sourceId":7949759,"sourceType":"datasetVersion","datasetId":4675026},{"sourceId":9738619,"sourceType":"datasetVersion","datasetId":5960716}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nimport time\nimport math\nimport itertools\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nfrom scipy.special import logit\nfrom scipy.stats import norm\n\nimport tensorflow as tf\nfrom keras import layers, models, datasets\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torch.optim.lr_scheduler import StepLR, LambdaLR\nimport torch.autograd.profiler as profiler\n\nfrom sklearn.model_selection import train_test_split, LeaveOneOut, StratifiedKFold, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, PowerTransformer\nfrom sklearn.metrics import f1_score, log_loss, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:22:00.627456Z","iopub.execute_input":"2025-01-23T18:22:00.627815Z","iopub.status.idle":"2025-01-23T18:22:17.926944Z","shell.execute_reply.started":"2025-01-23T18:22:00.627768Z","shell.execute_reply":"2025-01-23T18:22:17.925711Z"}},"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"def calculate_metrics(model, data_tensor, labels_tensor, batch_size=1024, num_features=22):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for start_idx in range(0, len(data_tensor), batch_size):\n            end_idx = min(start_idx + batch_size, len(data_tensor))\n            inputs = data_tensor[start_idx:end_idx].view(-1, num_features)\n            labels = labels_tensor[start_idx:end_idx]\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    return accuracy, f1","metadata":{"execution":{"iopub.status.busy":"2025-01-23T18:22:17.928773Z","iopub.execute_input":"2025-01-23T18:22:17.929334Z","iopub.status.idle":"2025-01-23T18:22:17.936763Z","shell.execute_reply.started":"2025-01-23T18:22:17.929301Z","shell.execute_reply":"2025-01-23T18:22:17.935713Z"},"trusted":true},"outputs":[],"execution_count":2},{"cell_type":"code","source":"class CustomDataLoader:\n    def __init__(self, features, labels, validation_size=0.2, random_state=42, classification=True):        \n        if validation_size > 0.0:\n            stratify = labels if classification else None\n            train_data, val_data, train_labels, val_labels = train_test_split(\n                features, labels, test_size=validation_size, stratify=stratify, random_state=random_state\n            )\n            \n            self.val_data_tensor = torch.tensor(val_data).float().to(device)\n            \n            if classification:\n                self.val_labels_tensor = torch.tensor(val_labels).long().to(device)\n\n            else:\n                self.val_labels_tensor =torch.tensor(val_labels).float().to(device)\n        else:\n            train_data, train_labels = features, labels\n            self.val_data_tensor, self.val_labels_tensor = None, None\n        \n        self.train_data_tensor = torch.tensor(train_data).float().to(device)\n\n        if classification:\n            self.train_labels_tensor = torch.tensor(train_labels).long().to(device)\n        else:\n            self.train_labels_tensor = torch.tensor(train_labels).float().to(device)\n\n        torch.manual_seed(random_state)\n        indices = torch.randperm(len(self.train_data_tensor))\n\n        self.train_data_tensor = self.train_data_tensor[indices]\n        self.train_labels_tensor = self.train_labels_tensor[indices]","metadata":{"execution":{"iopub.status.busy":"2025-01-23T18:22:22.142740Z","iopub.execute_input":"2025-01-23T18:22:22.143121Z","iopub.status.idle":"2025-01-23T18:22:22.151843Z","shell.execute_reply.started":"2025-01-23T18:22:22.143087Z","shell.execute_reply":"2025-01-23T18:22:22.150796Z"},"trusted":true},"outputs":[],"execution_count":3},{"cell_type":"code","source":"def evaluate_model(model, custom_train_loader, criterion, optimizer, num_epochs, scheduler, batch_size=1024, num_features=22, early_stopping_patience=10):\n    best_val_loss = float('inf')\n    best_epoch = 0\n    patience_counter = 0\n    \n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        model.train()\n        i = 0\n        total_loss = 0\n        num_items = 0\n\n        for start_idx in range(0, len(custom_train_loader.train_data_tensor), batch_size):\n            end_idx = min(start_idx + batch_size, len(custom_train_loader.train_data_tensor))\n            inputs = custom_train_loader.train_data_tensor[start_idx:end_idx].view(-1, num_features)\n            labels = custom_train_loader.train_labels_tensor[start_idx:end_idx]\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels, model)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            running_loss += loss.item() * len(labels)\n            total_loss += loss.item() * len(labels)\n            num_items += len(labels)\n\n            i += 1\n\n        if epoch % 10 == 0:\n            model.eval()\n            for param_group in optimizer.param_groups:\n                print(\"Learning Rate:\", param_group['lr'])\n\n            train_reg_loss = 0.0\n            val_loss = 0.0\n            with torch.no_grad():\n                for start_idx in range(0, len(custom_train_loader.train_data_tensor), batch_size):\n                    end_idx = min(start_idx + batch_size, len(custom_train_loader.train_data_tensor))\n                    inputs = custom_train_loader.train_data_tensor[start_idx:end_idx].view(-1, num_features)\n                    labels = custom_train_loader.train_labels_tensor[start_idx:end_idx]\n        \n                    outputs = model(inputs)\n                    train_reg_loss += criterion.regular_loss(outputs, labels).item() * len(labels)\n\n                for start_idx in range(0, len(custom_train_loader.val_data_tensor), batch_size):\n                    end_idx = min(start_idx + batch_size, len(custom_train_loader.val_data_tensor))\n                    val_inputs = custom_train_loader.val_data_tensor[start_idx:end_idx].view(-1, num_features)\n                    val_labels = custom_train_loader.val_labels_tensor[start_idx:end_idx]\n    \n                    val_outputs = model(val_inputs)\n                    val_loss += criterion.regular_loss(val_outputs, val_labels).item() * len(val_labels)\n    \n            avg_train_loss = running_loss / len(custom_train_loader.train_data_tensor)\n            avg_val_loss = val_loss / len(custom_train_loader.val_data_tensor)\n    \n            train_accuracy, train_f1 = calculate_metrics(model, custom_train_loader.train_data_tensor, custom_train_loader.train_labels_tensor, batch_size, num_features)\n            val_accuracy, val_f1 = calculate_metrics(model, custom_train_loader.val_data_tensor, custom_train_loader.val_labels_tensor, batch_size, num_features)\n    \n            print(f'Epoch {epoch + 1}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}')\n            print(f'Epoch {epoch + 1}, Training Loss: {train_reg_loss / len(custom_train_loader.train_data_tensor)}, Validation Loss: {avg_val_loss}')\n            print(f'Training Accuracy: {train_accuracy}, Training F1 Score: {train_f1}')\n            print(f'Validation Accuracy: {val_accuracy}, Validation F1 Score: {val_f1}')\n            print()\n            \n            if avg_val_loss < best_val_loss:\n                best_val_loss = avg_val_loss\n                best_epoch = epoch + 1\n                patience_counter = 0\n            else:\n                patience_counter += 10\n                if patience_counter >= early_stopping_patience:\n                    print(f'Early stopping triggered after {epoch + 1} epochs.')\n                    print(f'Best Validation Loss: {best_val_loss} from Epoch {best_epoch}')\n                    break\n\n    if patience_counter < early_stopping_patience:\n        print(f'Best Validation Loss after {num_epochs} epochs: {best_val_loss} from Epoch {best_epoch}')","metadata":{"execution":{"iopub.status.busy":"2025-01-23T18:22:23.200208Z","iopub.execute_input":"2025-01-23T18:22:23.200577Z","iopub.status.idle":"2025-01-23T18:22:23.215011Z","shell.execute_reply.started":"2025-01-23T18:22:23.200546Z","shell.execute_reply":"2025-01-23T18:22:23.213835Z"},"trusted":true},"outputs":[],"execution_count":4},{"cell_type":"code","source":"data_dl = pd.read_csv('/kaggle/input/playground-series-s4e10/train.csv')\ndata_og = pd.read_csv('/kaggle/input/loan-approval-prediction/credit_risk_dataset.csv')\n\ndata_dl = data_dl.drop([\"id\"], axis=1)\n\nmedian_emp_length = data_og['person_emp_length'].median()\nmedian_int_rate = data_og['loan_int_rate'].median()\n\ndata_dl['source'] = 0\ndata_og['source'] = 1\n\ndata = pd.concat([data_dl, data_og], ignore_index=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:05.152335Z","iopub.execute_input":"2025-01-23T18:34:05.152733Z","iopub.status.idle":"2025-01-23T18:34:05.290131Z","shell.execute_reply.started":"2025-01-23T18:34:05.152688Z","shell.execute_reply":"2025-01-23T18:34:05.289036Z"}},"outputs":[],"execution_count":35},{"cell_type":"code","source":"data = data_dl\n\ndata['person_emp_length_missing'] = data['person_emp_length'].isna().astype(int)\ndata['loan_int_rate_missing'] = data['loan_int_rate'].isna().astype(int)\n\ndata['person_emp_length'] = data['person_emp_length'].fillna(median_emp_length)\ndata['loan_int_rate'] = data['loan_int_rate'].fillna(median_int_rate)\n\n# grade_mapping = {'A': 7, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1}\n# data['loan_grade'] = data['loan_grade'].map(grade_mapping)\n\n# purpose_mapping = {\n#     'DEBTCONSOLIDATION': 1,\n#     'HOMEIMPROVEMENT': 2,\n#     'MEDICAL': 3,\n#     'PERSONAL': 4,\n#     'EDUCATION': 5,\n#     'VENTURE': 6\n# }\n# data['loan_intent'] = data['loan_intent'].map(purpose_mapping)\n\n# home_ownership_mapping = {\n#     'OWN': 1,\n#     'MORTGAGE': 2,\n#     'OTHER': 3,\n#     'RENT': 4\n# }\n# data['person_home_ownership'] = data['person_home_ownership'].map(home_ownership_mapping)\n\nX = data.drop([\"loan_status\"], axis=1)\nX = pd.get_dummies(X, drop_first=True)\ny = data[\"loan_status\"]\n\ncolumn_to_log = [\n    'person_age',\n    'person_income',\n]\n\ncolumn_to_sqrt = [\n    'person_emp_length',\n    'loan_percent_income',\n]\n\nfor col in column_to_log:\n    if (X[col] <= 0).any():\n        print(f\"Column '{col}' contains non-positive values. Adding 1 to avoid log of non-positive numbers.\")\n        X[col] = np.log(X[col] + 1)\n    else:\n        X[col] = np.log(X[col])\n\nfor col in column_to_sqrt:\n    if (X[col] < 0).any():\n        print(f\"Column '{col}' contains negative values. Setting negative values to NaN before applying sqrt.\")\n        X[col] = np.sqrt(X[col].clip(lower=0))\n    else:\n        X[col] = np.sqrt(X[col])\n\nprint(data.isnull().sum())\nprint(X.columns)\nprint(X.shape, y.shape)\nprint(X.columns.get_loc('source'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:31.917303Z","iopub.execute_input":"2025-01-23T18:34:31.918184Z","iopub.status.idle":"2025-01-23T18:34:31.980169Z","shell.execute_reply.started":"2025-01-23T18:34:31.918134Z","shell.execute_reply":"2025-01-23T18:34:31.979069Z"}},"outputs":[{"name":"stdout","text":"person_age                    0\nperson_income                 0\nperson_home_ownership         0\nperson_emp_length             0\nloan_intent                   0\nloan_grade                    0\nloan_amnt                     0\nloan_int_rate                 0\nloan_percent_income           0\ncb_person_default_on_file     0\ncb_person_cred_hist_length    0\nloan_status                   0\nsource                        0\nperson_emp_length_missing     0\nloan_int_rate_missing         0\ndtype: int64\nIndex(['person_age', 'person_income', 'person_emp_length', 'loan_amnt',\n       'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n       'source', 'person_emp_length_missing', 'loan_int_rate_missing',\n       'person_home_ownership_OTHER', 'person_home_ownership_OWN',\n       'person_home_ownership_RENT', 'loan_intent_EDUCATION',\n       'loan_intent_HOMEIMPROVEMENT', 'loan_intent_MEDICAL',\n       'loan_intent_PERSONAL', 'loan_intent_VENTURE', 'loan_grade_B',\n       'loan_grade_C', 'loan_grade_D', 'loan_grade_E', 'loan_grade_F',\n       'loan_grade_G', 'cb_person_default_on_file_Y'],\n      dtype='object')\n(58645, 25) (58645,)\n7\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"x_scaler = StandardScaler()\nx_scaled = x_scaler.fit_transform(X)\n\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nprint(x_scaled.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:17.360971Z","iopub.execute_input":"2025-01-23T18:34:17.361849Z","iopub.status.idle":"2025-01-23T18:34:17.401610Z","shell.execute_reply.started":"2025-01-23T18:34:17.361812Z","shell.execute_reply":"2025-01-23T18:34:17.400732Z"}},"outputs":[{"name":"stdout","text":"(32581, 25)\n","output_type":"stream"}],"execution_count":38},{"cell_type":"code","source":"x_scaled = x_scaler.transform(X)\n\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nprint(x_scaled)\nprint(x_scaled.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:36.941650Z","iopub.execute_input":"2025-01-23T18:34:36.942032Z","iopub.status.idle":"2025-01-23T18:34:37.002764Z","shell.execute_reply.started":"2025-01-23T18:34:36.941998Z","shell.execute_reply":"2025-01-23T18:34:37.001613Z"}},"outputs":[{"name":"stdout","text":"[[ 1.56429348 -0.81624065 -1.86421602 ... -0.08632538 -0.04436441\n  -0.46268575]\n [-1.06299707  0.01394005  0.50889981 ... -0.08632538 -0.04436441\n  -0.46268575]\n [ 0.33310246 -1.16062639  0.8760221  ... -0.08632538 -0.04436441\n  -0.46268575]\n ...\n [-0.83835155 -0.41203131  0.69904203 ... -0.08632538 -0.04436441\n  -0.46268575]\n [-1.06299707 -1.08852135 -0.49409696 ... -0.08632538 -0.04436441\n  -0.46268575]\n [ 0.67014014  0.52994887 -0.49409696 ... -0.08632538 -0.04436441\n  -0.46268575]]\n(58645, 25)\n","output_type":"stream"}],"execution_count":41},{"cell_type":"code","source":"feature_means = x_scaled.mean(axis=0)\nfeature_variances = x_scaled.var(axis=0)\nfeature_mins = x_scaled.min(axis=0)\nfeature_maxs = x_scaled.max(axis=0)\n\nfeature_stats_scaled_full = pd.DataFrame({\n    'Mean': feature_means,\n    'Variance': feature_variances,\n    'Min': feature_mins,\n    'Max': feature_maxs\n})\n\nprint(\"Mean, Variance, Min, and Max of Scaled Features:\")\nprint(feature_stats_scaled_full)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:39.691092Z","iopub.execute_input":"2025-01-23T18:34:39.692126Z","iopub.status.idle":"2025-01-23T18:34:39.714006Z","shell.execute_reply.started":"2025-01-23T18:34:39.692073Z","shell.execute_reply":"2025-01-23T18:34:39.712962Z"}},"outputs":[{"name":"stdout","text":"Mean, Variance, Min, and Max of Scaled Features:\n        Mean  Variance       Min        Max\n0  -0.027383  0.948764 -1.544665   7.635124\n1   0.056332  0.651183 -4.561322   6.238936\n2  -0.014743  0.991884 -1.864216   8.880523\n3  -0.058813  0.774514 -1.437739   4.019404\n4  -0.107655  0.969797 -1.813891   3.962397\n5  -0.077807  0.797797 -3.079228   4.070171\n6   0.002305  0.987326 -0.938167   5.966992\n7  -1.000000  0.000000 -1.000000  -1.000000\n8  -0.168065  0.000000 -0.168065  -0.168065\n9  -0.325196  0.000000 -0.325196  -0.325196\n10 -0.030876  0.462923 -0.057402  17.421117\n11 -0.095483  0.693581 -0.293499   3.407161\n12  0.033819  0.998211 -1.009591   0.990500\n13  0.028057  1.041726 -0.496967   2.012205\n14 -0.011356  0.971681 -0.352723   2.835088\n15  0.000278  1.000448 -0.478548   2.089656\n16  0.003561  1.006262 -0.451695   2.213885\n17 -0.012688  0.978196 -0.461414   2.167251\n18  0.058028  1.041196 -0.687208   1.455163\n19 -0.025161  0.961272 -0.497207   2.011234\n20 -0.080934  0.793382 -0.353877   2.825842\n21 -0.073076  0.588917 -0.174614   5.726929\n22 -0.056674  0.345161 -0.086325  11.584078\n23 -0.031656  0.286865 -0.044364  22.540588\n24 -0.073328  0.870067 -0.462686   2.161294\n","output_type":"stream"}],"execution_count":42},{"cell_type":"code","source":"class CustomLoss(nn.Module):\n    def __init__(self, criterion, f1_lambda, f2_lambda, l1_lambda, l2_lambda, wa_lambda):\n        super(CustomLoss, self).__init__()\n        self.criterion = criterion\n        self.f1_lambda = f1_lambda\n        self.f2_lambda = f2_lambda\n        self.l1_lambda = l1_lambda\n        self.l2_lambda = l2_lambda\n        self.wa_lambda = wa_lambda\n        self.i = 0\n\n    def forward(self, outputs, labels, model): \n        f1_loss = 0.0\n        f2_loss = 0.0\n        l1_loss = 0.0\n        l2_loss = 0.0\n\n        for name, module in model.named_modules():\n            if isinstance(module, CustomActivation):\n                f1_loss += (module.a ** 2).sum() + (module.b ** 2).sum()\n                f2_loss += ((module.a - module.b) ** 2).sum()\n\n            if isinstance(module, nn.Linear):\n                l1_loss += torch.norm(module.weight, 1)\n                l2_loss += torch.norm(module.weight, 2) ** 2\n\n        total_loss = (self.criterion(outputs, labels)\n                      + self.f1_lambda * f1_loss\n                      + self.f2_lambda * f2_loss\n                      + self.l1_lambda * l1_loss\n                      + self.l2_lambda * l2_loss)\n        self.i += 1\n\n        return total_loss\n\n    def compute_gradient_magnitude(self, model):\n        total_abs_sum = 0.0\n        for param in model.parameters():\n            if param.grad is not None:\n                total_abs_sum += param.grad.abs().sum().item()\n        self.grad_magnitude = total_abs_sum\n\n    def regular_loss(self, outputs, labels):\n        return self.criterion(outputs, labels)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:46.778296Z","iopub.execute_input":"2025-01-23T18:34:46.778709Z","iopub.status.idle":"2025-01-23T18:34:46.788479Z","shell.execute_reply.started":"2025-01-23T18:34:46.778649Z","shell.execute_reply":"2025-01-23T18:34:46.787458Z"}},"outputs":[],"execution_count":43},{"cell_type":"code","source":"class CustomActivation1d(nn.Module):\n    def __init__(self, num_features):\n        super(CustomActivation1d, self).__init__()\n        self.a = nn.Parameter(torch.zeros(num_features))\n        self.b = nn.Parameter(torch.zeros(num_features))\n        \n        self.local_bias = nn.Parameter(torch.zeros(num_features))\n        self.global_bias = nn.Parameter(torch.tensor(0.0))\n\n    def forward(self, x):\n        x = x + self.local_bias\n        x = torch.where(x < 0, self.a * x, self.b * x)\n        return x.sum(dim=-1) + self.global_bias","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:48.279291Z","iopub.execute_input":"2025-01-23T18:34:48.280320Z","iopub.status.idle":"2025-01-23T18:34:48.286117Z","shell.execute_reply.started":"2025-01-23T18:34:48.280268Z","shell.execute_reply":"2025-01-23T18:34:48.285075Z"}},"outputs":[],"execution_count":44},{"cell_type":"code","source":"class CustomActivation(nn.Module):\n    def __init__(self, num_features):\n        super(CustomActivation, self).__init__()\n        self.a = nn.Parameter(torch.zeros(num_features, num_features))\n        self.b = nn.Parameter(torch.zeros(num_features, num_features))\n        \n        self.local_bias = nn.Parameter(torch.zeros(num_features, num_features))\n        self.global_bias = nn.Parameter(torch.zeros(num_features))\n\n        with torch.no_grad():\n            self.a.fill_diagonal_(1)\n            self.b.fill_diagonal_(1)\n            \n    def forward(self, x):\n        batch_size, num_features = x.shape\n        x = x.unsqueeze(-1).expand(-1, -1, num_features)\n        x = x + self.local_bias\n        x = torch.where(x < 0, self.a * x, self.b * x)\n        return x.sum(dim=1) + self.global_bias","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:48.507397Z","iopub.execute_input":"2025-01-23T18:34:48.508313Z","iopub.status.idle":"2025-01-23T18:34:48.515294Z","shell.execute_reply.started":"2025-01-23T18:34:48.508275Z","shell.execute_reply":"2025-01-23T18:34:48.514292Z"}},"outputs":[],"execution_count":45},{"cell_type":"code","source":"class CustomLinear(nn.Module):\n    def __init__(self, num_features, num_outputs, init_identity=False):\n        super(CustomLinear, self).__init__()\n        \n        if init_identity and num_features != num_outputs:\n            raise ValueError(\"For identity initialization, num_features must equal num_outputs.\")\n\n        self.linear = nn.Linear(num_features, num_outputs, bias=True)\n        \n        with torch.no_grad():\n            self.linear.bias.zero_()\n\n            if init_identity:\n                self.linear.weight.copy_(torch.eye(num_features, num_outputs))\n            else:\n                self.linear.weight.zero_()\n\n    def forward(self, x):\n        return self.linear(x)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T06:10:51.267925Z","iopub.execute_input":"2025-01-22T06:10:51.268266Z","iopub.status.idle":"2025-01-22T06:10:51.274970Z","shell.execute_reply.started":"2025-01-22T06:10:51.268234Z","shell.execute_reply":"2025-01-22T06:10:51.273879Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"\"\"\"\nclass TabularDenseNet(nn.Module):\n    def __init__(self, input_size, output_size, num_control_points, num_layers, window_size):\n        super(TabularDenseNet, self).__init__()\n        self.layers = nn.ModuleList()\n        \n        if num_layers % 2 == 1:\n            self.layers.append(CustomLinear(input_size, input_size, init_identity=True))\n            # self.layers.append(CustomActivation(input_size, window_size, num_control_points, init_identity=True))\n            num_layers -= 1\n            input_size *= 2\n            \n        for i in range(num_layers):\n            if i % 2 == 0:\n                self.layers.append(CustomLinear(input_size, input_size, init_identity=True))\n            else:\n                # self.layers.append(CustomActivation(input_size, window_size, num_control_points, init_identity=True))\n                self.layers.append(CustomLinear(input_size, input_size, init_identity=True))\n\n            input_size *= 2\n\n        self.final = CustomLinear(input_size, output_size, init_identity=False)\n        self.final_act = CustomActivation(output_size, window_size, num_control_points, init_identity=True)\n        \n    def forward(self, x):\n        outputs = [x]\n\n        for layer in self.layers:\n            concatenated_outputs = torch.cat(outputs, dim=-1)\n            outputs.append(F.relu(layer(concatenated_outputs)))\n\n        concatenated_outputs = torch.cat(outputs, dim=-1)\n        x = self.final(concatenated_outputs)\n        x = self.final_act(x)\n        return x\n\"\"\"\nprint(\"\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T05:50:03.734906Z","iopub.execute_input":"2025-01-22T05:50:03.735246Z","iopub.status.idle":"2025-01-22T05:50:03.740190Z","shell.execute_reply.started":"2025-01-22T05:50:03.735218Z","shell.execute_reply":"2025-01-22T05:50:03.739349Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"class TabularDenseNet(nn.Module):\n    def __init__(self, input_size, output_size, num_control_points, num_layers):\n        super(TabularDenseNet, self).__init__()\n        self.layers = nn.ModuleList()\n        for i in range(num_layers):\n            self.layers.append(CustomActivation(input_size))\n            input_size *= 2\n\n        self.final_layer = CustomActivation1d(input_size)\n\n    def forward(self, x):\n        outputs = [x]\n\n        for layer in self.layers:\n            concatenated_outputs = torch.cat(outputs, dim=-1)\n            outputs.append(layer(concatenated_outputs))\n\n        final_out = self.final_layer(torch.cat(outputs, dim=-1))\n        return torch.stack([final_out, -final_out], dim=-1)\n\n    # def forward(self, x):\n    #     outputs = [x]\n    #     summed_total = torch.zeros(x.size(0), device=x.device)\n    #     summed_total += self.bias\n\n    #     for layer, layer_norm in zip(self.layers, self.layer_norms):\n    #         concatenated_outputs = torch.cat(outputs, dim=-1)\n    #         inter_features = layer_norm(layer(concatenated_outputs))\n    #         summed_feature = inter_features.sum(dim=-1)\n\n    #         outputs.append(inter_features)\n    #         outputs.append(summed_feature.unsqueeze(-1))\n    #         summed_total += summed_feature\n\n    #     print(torch.cat(outputs, dim=-1).shape)\n    #     return torch.stack([summed_total, -summed_total], dim=-1)\n\n    # def forward(self, x):\n    #     batch_size = x.size(0)\n    #     device = x.device\n    #     L = self.num_layers\n    #     D = self.input_dim\n\n    #     total_features = 6656\n    #     concatenated_features = torch.zeros(batch_size, total_features, device=device)\n\n    #     concatenated_features[:, :D] = x\n\n    #     current_pos = D\n    #     summed_total = self.bias.expand(batch_size)\n\n    #     for i, (layer, layer_norm) in enumerate(zip(self.layers, self.layer_norms)):\n    #         current_features = concatenated_features[:, :current_pos]\n    #         inter_features = (layer(current_features))\n    #         summed_feature = inter_features.sum(dim=-1, keepdim=True)\n\n    #         concatenated_features[:, current_pos:current_pos + current_pos] = inter_features\n    #         concatenated_features[:, current_pos + current_pos + 1] = summed_feature.squeeze(-1)\n\n    #         current_pos += current_pos + 1\n    #         summed_total = summed_total + summed_feature.squeeze(-1)\n\n    #     return torch.stack([summed_total, -summed_total], dim=-1)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:34:59.836029Z","iopub.execute_input":"2025-01-23T18:34:59.836711Z","iopub.status.idle":"2025-01-23T18:34:59.844278Z","shell.execute_reply.started":"2025-01-23T18:34:59.836665Z","shell.execute_reply":"2025-01-23T18:34:59.843293Z"}},"outputs":[],"execution_count":46},{"cell_type":"code","source":"custom_train_loader = CustomDataLoader(x_scaled, y_encoded, validation_size=0.1, random_state=0, classification=True)\nprint(custom_train_loader.train_data_tensor.shape)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:35:07.570026Z","iopub.execute_input":"2025-01-23T18:35:07.570670Z","iopub.status.idle":"2025-01-23T18:35:07.619289Z","shell.execute_reply.started":"2025-01-23T18:35:07.570634Z","shell.execute_reply":"2025-01-23T18:35:07.618347Z"}},"outputs":[{"name":"stdout","text":"torch.Size([52780, 25])\n","output_type":"stream"}],"execution_count":47},{"cell_type":"code","source":"num_features = 25\nnum_classes = 2\nnum_control_points = 21\nnum_epochs = 10000\nbatch_size = 730 * 1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:35:08.551406Z","iopub.execute_input":"2025-01-23T18:35:08.551764Z","iopub.status.idle":"2025-01-23T18:35:08.556624Z","shell.execute_reply.started":"2025-01-23T18:35:08.551734Z","shell.execute_reply":"2025-01-23T18:35:08.555521Z"}},"outputs":[],"execution_count":48},{"cell_type":"code","source":"torch.cuda.empty_cache()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:35:09.738738Z","iopub.execute_input":"2025-01-23T18:35:09.739119Z","iopub.status.idle":"2025-01-23T18:35:09.743692Z","shell.execute_reply.started":"2025-01-23T18:35:09.739085Z","shell.execute_reply":"2025-01-23T18:35:09.742796Z"}},"outputs":[],"execution_count":49},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99999 ** (step - num_step_threshold)\n\nstart_time = time.time()\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 1.0)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 500, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:35:24.754923Z","iopub.execute_input":"2025-01-23T18:35:24.755414Z","iopub.status.idle":"2025-01-23T18:36:10.376525Z","shell.execute_reply.started":"2025-01-23T18:35:24.755364Z","shell.execute_reply":"2025-01-23T18:36:10.375079Z"}},"outputs":[{"name":"stdout","text":"Learning Rate: 0.00073\nEpoch 1, Training Loss: 0.1929988909700505, Validation Loss: 0.18885775679327033\nEpoch 1, Training Loss: 0.1882823111348958, Validation Loss: 0.18885775679327033\nTraining Accuracy: 0.9486737400530504, Training F1 Score: 0.9457383289777652\nValidation Accuracy: 0.947996589940324, Validation F1 Score: 0.9453974942513467\n\nhere\nLearning Rate: 0.0009929946177428413\nEpoch 11, Training Loss: 0.17267540987692534, Validation Loss: 0.1793293354386513\nEpoch 11, Training Loss: 0.17210056624569736, Validation Loss: 0.1793293354386513\nTraining Accuracy: 0.9502463054187192, Training F1 Score: 0.9475322487788732\nValidation Accuracy: 0.9493606138107417, Validation F1 Score: 0.9469281521237626\n\nLearning Rate: 0.0009857721151293795\nEpoch 21, Training Loss: 0.1690200964873286, Validation Loss: 0.17698571255203505\nEpoch 21, Training Loss: 0.16873886605619526, Validation Loss: 0.17698571255203505\nTraining Accuracy: 0.9504736642667677, Training F1 Score: 0.9478049175727021\nValidation Accuracy: 0.950383631713555, Validation F1 Score: 0.9480322676938525\n\nLearning Rate: 0.0009786021450705453\nEpoch 31, Training Loss: 0.16732859851205922, Validation Loss: 0.1764040370674237\nEpoch 31, Training Loss: 0.16726234720122773, Validation Loss: 0.1764040370674237\nTraining Accuracy: 0.9506820765441455, Training F1 Score: 0.9480445351285598\nValidation Accuracy: 0.948849104859335, Validation F1 Score: 0.9465395220562344\n\nLearning Rate: 0.0009714843254731166\nEpoch 41, Training Loss: 0.16624716198119127, Validation Loss: 0.1761858930743005\nEpoch 41, Training Loss: 0.166281803290516, Validation Loss: 0.1761858930743005\nTraining Accuracy: 0.9507578628268284, Training F1 Score: 0.9481207511197175\nValidation Accuracy: 0.9495311167945439, Validation F1 Score: 0.947155566417676\n\nLearning Rate: 0.0009644182770230093\nEpoch 51, Training Loss: 0.16541091916364853, Validation Loss: 0.17618296903265102\nEpoch 51, Training Loss: 0.16548381222947703, Validation Loss: 0.17618296903265102\nTraining Accuracy: 0.9509283819628647, Training F1 Score: 0.9483130346026309\nValidation Accuracy: 0.9502131287297527, Validation F1 Score: 0.9478055465970653\n\nLearning Rate: 0.0009574036231650638\nEpoch 61, Training Loss: 0.16473558769985192, Validation Loss: 0.17628240670757933\nEpoch 61, Training Loss: 0.1648230915843266, Validation Loss: 0.17628240670757933\nTraining Accuracy: 0.9509852216748769, Training F1 Score: 0.9483458467730019\nValidation Accuracy: 0.9500426257459506, Validation F1 Score: 0.9475782690865546\n\nLearning Rate: 0.0009504399900829778\nEpoch 71, Training Loss: 0.16413531114755592, Validation Loss: 0.17622946411726928\nEpoch 71, Training Loss: 0.16426173645004985, Validation Loss: 0.17622946411726928\nTraining Accuracy: 0.9513830996589617, Training F1 Score: 0.9487705229872218\nValidation Accuracy: 0.9505541346973572, Validation F1 Score: 0.9480989494363249\n\nLearning Rate: 0.0009435270066793853\nEpoch 81, Training Loss: 0.16357496342268482, Validation Loss: 0.17627513931725947\nEpoch 81, Training Loss: 0.16369108017357564, Validation Loss: 0.17627513931725947\nTraining Accuracy: 0.951496779082986, Training F1 Score: 0.9489081594348614\nValidation Accuracy: 0.9505541346973572, Validation F1 Score: 0.9480989494363249\n\nLearning Rate: 0.000936664304556081\nEpoch 91, Training Loss: 0.16304370021506123, Validation Loss: 0.1763099936382545\nEpoch 91, Training Loss: 0.16313514783103253, Validation Loss: 0.1763099936382545\nTraining Accuracy: 0.9516294050776809, Training F1 Score: 0.9490745044887788\nValidation Accuracy: 0.9507246376811594, Validation F1 Score: 0.9482939241160897\n\nLearning Rate: 0.0009298515179943872\nEpoch 101, Training Loss: 0.16257897822462325, Validation Loss: 0.17641450426932695\nEpoch 101, Training Loss: 0.16270592885516094, Validation Loss: 0.17641450426932695\nTraining Accuracy: 0.9517999242137173, Training F1 Score: 0.9492451890793561\nValidation Accuracy: 0.9508951406649616, Validation F1 Score: 0.9484887631256642\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[50], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m LambdaLR(optimizer, lr_lambda\u001b[38;5;241m=\u001b[39mcustom_lr_lambda)\n\u001b[1;32m     15\u001b[0m criterion \u001b[38;5;241m=\u001b[39m CustomLoss(nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 16\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer, num_epochs, scheduler, batch_size, num_features, early_stopping_patience)\u001b[0m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels, model)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":50},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99999 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 1).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 1.0)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 200, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:28:57.806323Z","iopub.execute_input":"2025-01-23T18:28:57.806686Z","iopub.status.idle":"2025-01-23T18:29:50.985301Z","shell.execute_reply.started":"2025-01-23T18:28:57.806652Z","shell.execute_reply":"2025-01-23T18:29:50.984317Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Learning Rate: 0.00041\nEpoch 1, Training Loss: 0.655168993688851, Validation Loss: 0.576732883079537\nEpoch 1, Training Loss: 0.5773437749671949, Validation Loss: 0.576732883079537\nTraining Accuracy: 0.7837800968556033, Training F1 Score: 0.6907128531495372\nValidation Accuracy: 0.783369131635471, Validation F1 Score: 0.6903129502633537\n\nhere\nLearning Rate: 0.0009964961353604535\nEpoch 11, Training Loss: 0.29465572077807134, Validation Loss: 0.30033097432851424\nEpoch 11, Training Loss: 0.29160624468898183, Validation Loss: 0.30033097432851424\nTraining Accuracy: 0.8927085464838688, Training F1 Score: 0.887580517860501\nValidation Accuracy: 0.8895366676894753, Validation F1 Score: 0.8841371518181538\n\nLearning Rate: 0.0009924188449759277\nEpoch 21, Training Loss: 0.26235879765884845, Validation Loss: 0.2718926128542983\nEpoch 21, Training Loss: 0.2607936156150971, Validation Loss: 0.2718926128542983\nTraining Accuracy: 0.9114657936020736, Training F1 Score: 0.9070734432749952\nValidation Accuracy: 0.9091745934335685, Validation F1 Score: 0.9052433020945196\n\nLearning Rate: 0.000988358237342383\nEpoch 31, Training Loss: 0.24800488618660832, Validation Loss: 0.25818376777617613\nEpoch 31, Training Loss: 0.24688826693465477, Validation Loss: 0.25818376777617613\nTraining Accuracy: 0.9155923879680786, Training F1 Score: 0.9114348954477681\nValidation Accuracy: 0.9146977600490949, Validation F1 Score: 0.9110055337239068\n\nLearning Rate: 0.000984314244200227\nEpoch 41, Training Loss: 0.23953903173288002, Validation Loss: 0.25045919591168314\nEpoch 41, Training Loss: 0.2386027360824761, Validation Loss: 0.25045919591168314\nTraining Accuracy: 0.9176045290225769, Training F1 Score: 0.9135624574107629\nValidation Accuracy: 0.9171525007671065, Validation F1 Score: 0.9134520627654718\n\nLearning Rate: 0.0009802867975691593\nEpoch 51, Training Loss: 0.23348884594594138, Validation Loss: 0.24450820373058613\nEpoch 51, Training Loss: 0.23264766378439625, Validation Loss: 0.24450820373058613\nTraining Accuracy: 0.9199918150194393, Training F1 Score: 0.9159906539908581\nValidation Accuracy: 0.9180730285363609, Validation F1 Score: 0.9142133264828061\n\nLearning Rate: 0.0009762758297470308\nEpoch 61, Training Loss: 0.22859270168874526, Validation Loss: 0.2398572599789086\nEpoch 61, Training Loss: 0.22773584499970423, Validation Loss: 0.2398572599789086\nTraining Accuracy: 0.9218675397312598, Training F1 Score: 0.9178759652997734\nValidation Accuracy: 0.9202209266646211, Validation F1 Score: 0.9164904660302676\n\nLearning Rate: 0.0009722812733087035\nEpoch 71, Training Loss: 0.22449144467139226, Validation Loss: 0.23644238525682082\nEpoch 71, Training Loss: 0.22360739857822312, Validation Loss: 0.23644238525682082\nTraining Accuracy: 0.9231634949866994, Training F1 Score: 0.9192319717578782\nValidation Accuracy: 0.9220619822031298, Validation F1 Score: 0.9183076500556034\n\nLearning Rate: 0.0009683030611049181\nEpoch 81, Training Loss: 0.22121676961190623, Validation Loss: 0.23466664659223443\nEpoch 81, Training Loss: 0.2204391012782249, Validation Loss: 0.23466664659223443\nTraining Accuracy: 0.9242889298137917, Training F1 Score: 0.9204119583549888\nValidation Accuracy: 0.9239030377416385, Validation F1 Score: 0.9202373906054713\n\nLearning Rate: 0.000964341126261165\nEpoch 91, Training Loss: 0.21842305058834863, Validation Loss: 0.23348918396678942\nEpoch 91, Training Loss: 0.21773302296516914, Validation Loss: 0.23348918396678942\nTraining Accuracy: 0.9250051156128504, Training F1 Score: 0.9211256881377673\nValidation Accuracy: 0.924823565510893, Validation F1 Score: 0.921228860026586\n\nLearning Rate: 0.0009603954021765601\nEpoch 101, Training Loss: 0.2160679014504716, Validation Loss: 0.2327618615992708\nEpoch 101, Training Loss: 0.21536895097111072, Validation Loss: 0.2327618615992708\nTraining Accuracy: 0.9254825728122229, Training F1 Score: 0.9216098589546652\nValidation Accuracy: 0.9257440932801473, Validation F1 Score: 0.9220083281874781\n\nLearning Rate: 0.0009564658225227256\nEpoch 111, Training Loss: 0.21407336723238554, Validation Loss: 0.23285891319590502\nEpoch 111, Training Loss: 0.21336475313400946, Validation Loss: 0.23285891319590502\nTraining Accuracy: 0.9266080076393152, Training F1 Score: 0.9227612444932844\nValidation Accuracy: 0.924823565510893, Validation F1 Score: 0.9210144967163238\n\nLearning Rate: 0.0009525523212426743\nEpoch 121, Training Loss: 0.21244008440200876, Validation Loss: 0.23280616659681355\nEpoch 121, Training Loss: 0.21162255114861314, Validation Loss: 0.23280616659681355\nTraining Accuracy: 0.9273241934383739, Training F1 Score: 0.9234650088741093\nValidation Accuracy: 0.9263577784596502, Validation F1 Score: 0.9226528874586558\n\nLearning Rate: 0.0009486548325496996\nEpoch 131, Training Loss: 0.21083915117439717, Validation Loss: 0.23283969652308903\nEpoch 131, Training Loss: 0.21000820760975414, Validation Loss: 0.23283969652308903\nTraining Accuracy: 0.9276311302093991, Training F1 Score: 0.9237853118680782\nValidation Accuracy: 0.9260509358698987, Validation F1 Score: 0.9223571040342652\n\nLearning Rate: 0.0009447732909262696\nEpoch 141, Training Loss: 0.20933787267911516, Validation Loss: 0.23261604606007902\nEpoch 141, Training Loss: 0.20846835477039422, Validation Loss: 0.23261604606007902\nTraining Accuracy: 0.9282450037514495, Training F1 Score: 0.9244376224564897\nValidation Accuracy: 0.9254372506903958, Validation F1 Score: 0.9217660289858235\n\nLearning Rate: 0.0009409076311229258\nEpoch 151, Training Loss: 0.2079092325554661, Validation Loss: 0.23200357498000393\nEpoch 151, Training Loss: 0.20700725180948587, Validation Loss: 0.23200357498000393\nTraining Accuracy: 0.9283814200941273, Training F1 Score: 0.9245464149130072\nValidation Accuracy: 0.9260509358698987, Validation F1 Score: 0.9223571040342652\n\nLearning Rate: 0.000937057788157186\nEpoch 161, Training Loss: 0.20664975840091934, Validation Loss: 0.23180981785122987\nEpoch 161, Training Loss: 0.20568100251214225, Validation Loss: 0.23180981785122987\nTraining Accuracy: 0.9289270854648387, Training F1 Score: 0.925109745594781\nValidation Accuracy: 0.9263577784596502, Validation F1 Score: 0.9226528874586558\n\nLearning Rate: 0.0009332236973124521\nEpoch 171, Training Loss: 0.20556730115005487, Validation Loss: 0.23183932611915956\nEpoch 171, Training Loss: 0.20465617840345443, Validation Loss: 0.23183932611915956\nTraining Accuracy: 0.9292681263215333, Training F1 Score: 0.9254691038212934\nValidation Accuracy: 0.9263577784596502, Validation F1 Score: 0.9226528874586558\n\nLearning Rate: 0.0009294052941369222\nEpoch 181, Training Loss: 0.2046358948007473, Validation Loss: 0.23187196075495636\nEpoch 181, Training Loss: 0.20369941313789092, Validation Loss: 0.23187196075495636\nTraining Accuracy: 0.929540959006889, Training F1 Score: 0.925768044385844\nValidation Accuracy: 0.9263577784596502, Validation F1 Score: 0.9226528874586558\n\nLearning Rate: 0.0009256025144425073\nEpoch 191, Training Loss: 0.20369507571945702, Validation Loss: 0.23222060741621792\nEpoch 191, Training Loss: 0.2028031911581285, Validation Loss: 0.23222060741621792\nTraining Accuracy: 0.9299161039492532, Training F1 Score: 0.9261319210709978\nValidation Accuracy: 0.9269714636391531, Validation F1 Score: 0.9232449489439609\n\nBest Validation Loss after 200 epochs: 0.23180981785122987 from Epoch 161\nExecution time: 53.172295 seconds\n","output_type":"stream"}],"execution_count":19},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99999 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 1).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 1.0)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 10000, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:23:36.779037Z","iopub.execute_input":"2025-01-23T18:23:36.779431Z","iopub.status.idle":"2025-01-23T18:24:48.201534Z","shell.execute_reply.started":"2025-01-23T18:23:36.779398Z","shell.execute_reply":"2025-01-23T18:24:48.200092Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"Learning Rate: 0.00041\nEpoch 1, Training Loss: 0.655168993688851, Validation Loss: 0.576732883079537\nEpoch 1, Training Loss: 0.5773437749671949, Validation Loss: 0.576732883079537\nTraining Accuracy: 0.7837800968556033, Training F1 Score: 0.6907128531495372\nValidation Accuracy: 0.783369131635471, Validation F1 Score: 0.6903129502633537\n\nhere\nLearning Rate: 0.0009964961353604535\nEpoch 11, Training Loss: 0.29465572077807134, Validation Loss: 0.30033097432851424\nEpoch 11, Training Loss: 0.29160624468898183, Validation Loss: 0.30033097432851424\nTraining Accuracy: 0.8927085464838688, Training F1 Score: 0.887580517860501\nValidation Accuracy: 0.8895366676894753, Validation F1 Score: 0.8841371518181538\n\nLearning Rate: 0.0009924188449759277\nEpoch 21, Training Loss: 0.26235879765884845, Validation Loss: 0.2718926128542983\nEpoch 21, Training Loss: 0.2607936156150971, Validation Loss: 0.2718926128542983\nTraining Accuracy: 0.9114657936020736, Training F1 Score: 0.9070734432749952\nValidation Accuracy: 0.9091745934335685, Validation F1 Score: 0.9052433020945196\n\nLearning Rate: 0.000988358237342383\nEpoch 31, Training Loss: 0.24800488618660832, Validation Loss: 0.25818376777617613\nEpoch 31, Training Loss: 0.24688826693465477, Validation Loss: 0.25818376777617613\nTraining Accuracy: 0.9155923879680786, Training F1 Score: 0.9114348954477681\nValidation Accuracy: 0.9146977600490949, Validation F1 Score: 0.9110055337239068\n\nLearning Rate: 0.000984314244200227\nEpoch 41, Training Loss: 0.23953903173288002, Validation Loss: 0.25045919591168314\nEpoch 41, Training Loss: 0.2386027360824761, Validation Loss: 0.25045919591168314\nTraining Accuracy: 0.9176045290225769, Training F1 Score: 0.9135624574107629\nValidation Accuracy: 0.9171525007671065, Validation F1 Score: 0.9134520627654718\n\nLearning Rate: 0.0009802867975691593\nEpoch 51, Training Loss: 0.23348884594594138, Validation Loss: 0.24450820373058613\nEpoch 51, Training Loss: 0.23264766378439625, Validation Loss: 0.24450820373058613\nTraining Accuracy: 0.9199918150194393, Training F1 Score: 0.9159906539908581\nValidation Accuracy: 0.9180730285363609, Validation F1 Score: 0.9142133264828061\n\nLearning Rate: 0.0009762758297470308\nEpoch 61, Training Loss: 0.22859270168874526, Validation Loss: 0.2398572599789086\nEpoch 61, Training Loss: 0.22773584499970423, Validation Loss: 0.2398572599789086\nTraining Accuracy: 0.9218675397312598, Training F1 Score: 0.9178759652997734\nValidation Accuracy: 0.9202209266646211, Validation F1 Score: 0.9164904660302676\n\nLearning Rate: 0.0009722812733087035\nEpoch 71, Training Loss: 0.22449144467139226, Validation Loss: 0.23644238525682082\nEpoch 71, Training Loss: 0.22360739857822312, Validation Loss: 0.23644238525682082\nTraining Accuracy: 0.9231634949866994, Training F1 Score: 0.9192319717578782\nValidation Accuracy: 0.9220619822031298, Validation F1 Score: 0.9183076500556034\n\nLearning Rate: 0.0009683030611049181\nEpoch 81, Training Loss: 0.22121676961190623, Validation Loss: 0.23466664659223443\nEpoch 81, Training Loss: 0.2204391012782249, Validation Loss: 0.23466664659223443\nTraining Accuracy: 0.9242889298137917, Training F1 Score: 0.9204119583549888\nValidation Accuracy: 0.9239030377416385, Validation F1 Score: 0.9202373906054713\n\nLearning Rate: 0.000964341126261165\nEpoch 91, Training Loss: 0.21842305058834863, Validation Loss: 0.23348918396678942\nEpoch 91, Training Loss: 0.21773302296516914, Validation Loss: 0.23348918396678942\nTraining Accuracy: 0.9250051156128504, Training F1 Score: 0.9211256881377673\nValidation Accuracy: 0.924823565510893, Validation F1 Score: 0.921228860026586\n\nLearning Rate: 0.0009603954021765601\nEpoch 101, Training Loss: 0.2160679014504716, Validation Loss: 0.2327618615992708\nEpoch 101, Training Loss: 0.21536895097111072, Validation Loss: 0.2327618615992708\nTraining Accuracy: 0.9254825728122229, Training F1 Score: 0.9216098589546652\nValidation Accuracy: 0.9257440932801473, Validation F1 Score: 0.9220083281874781\n\nLearning Rate: 0.0009564658225227256\nEpoch 111, Training Loss: 0.21407336723238554, Validation Loss: 0.23285891319590502\nEpoch 111, Training Loss: 0.21336475313400946, Validation Loss: 0.23285891319590502\nTraining Accuracy: 0.9266080076393152, Training F1 Score: 0.9227612444932844\nValidation Accuracy: 0.924823565510893, Validation F1 Score: 0.9210144967163238\n\nLearning Rate: 0.0009525523212426743\nEpoch 121, Training Loss: 0.21244008440200876, Validation Loss: 0.23280616659681355\nEpoch 121, Training Loss: 0.21162255114861314, Validation Loss: 0.23280616659681355\nTraining Accuracy: 0.9273241934383739, Training F1 Score: 0.9234650088741093\nValidation Accuracy: 0.9263577784596502, Validation F1 Score: 0.9226528874586558\n\nLearning Rate: 0.0009486548325496996\nEpoch 131, Training Loss: 0.21083915117439717, Validation Loss: 0.23283969652308903\nEpoch 131, Training Loss: 0.21000820760975414, Validation Loss: 0.23283969652308903\nTraining Accuracy: 0.9276311302093991, Training F1 Score: 0.9237853118680782\nValidation Accuracy: 0.9260509358698987, Validation F1 Score: 0.9223571040342652\n\nLearning Rate: 0.0009447732909262696\nEpoch 141, Training Loss: 0.20933787267911516, Validation Loss: 0.23261604606007902\nEpoch 141, Training Loss: 0.20846835477039422, Validation Loss: 0.23261604606007902\nTraining Accuracy: 0.9282450037514495, Training F1 Score: 0.9244376224564897\nValidation Accuracy: 0.9254372506903958, Validation F1 Score: 0.9217660289858235\n\nLearning Rate: 0.0009409076311229258\nEpoch 151, Training Loss: 0.2079092325554661, Validation Loss: 0.23200357498000393\nEpoch 151, Training Loss: 0.20700725180948587, Validation Loss: 0.23200357498000393\nTraining Accuracy: 0.9283814200941273, Training F1 Score: 0.9245464149130072\nValidation Accuracy: 0.9260509358698987, Validation F1 Score: 0.9223571040342652\n\nLearning Rate: 0.000937057788157186\nEpoch 161, Training Loss: 0.20664975840091934, Validation Loss: 0.23180981785122987\nEpoch 161, Training Loss: 0.20568100251214225, Validation Loss: 0.23180981785122987\nTraining Accuracy: 0.9289270854648387, Training F1 Score: 0.925109745594781\nValidation Accuracy: 0.9263577784596502, Validation F1 Score: 0.9226528874586558\n\nLearning Rate: 0.0009332236973124521\nEpoch 171, Training Loss: 0.20556730115005487, Validation Loss: 0.23183932611915956\nEpoch 171, Training Loss: 0.20465617840345443, Validation Loss: 0.23183932611915956\nTraining Accuracy: 0.9292681263215333, Training F1 Score: 0.9254691038212934\nValidation Accuracy: 0.9263577784596502, Validation F1 Score: 0.9226528874586558\n\nLearning Rate: 0.0009294052941369222\nEpoch 181, Training Loss: 0.2046358948007473, Validation Loss: 0.23187196075495636\nEpoch 181, Training Loss: 0.20369941313789092, Validation Loss: 0.23187196075495636\nTraining Accuracy: 0.929540959006889, Training F1 Score: 0.925768044385844\nValidation Accuracy: 0.9263577784596502, Validation F1 Score: 0.9226528874586558\n\nLearning Rate: 0.0009256025144425073\nEpoch 191, Training Loss: 0.20369507571945702, Validation Loss: 0.23222060741621792\nEpoch 191, Training Loss: 0.2028031911581285, Validation Loss: 0.23222060741621792\nTraining Accuracy: 0.9299161039492532, Training F1 Score: 0.9261319210709978\nValidation Accuracy: 0.9269714636391531, Validation F1 Score: 0.9232449489439609\n\nLearning Rate: 0.0009218152943037517\nEpoch 201, Training Loss: 0.20296765134032252, Validation Loss: 0.23250822227730567\nEpoch 201, Training Loss: 0.20208357186056355, Validation Loss: 0.23250822227730567\nTraining Accuracy: 0.9300184162062615, Training F1 Score: 0.9262426074268291\nValidation Accuracy: 0.9266646210494016, Validation F1 Score: 0.923001443419873\n\nLearning Rate: 0.0009180435700567591\nEpoch 211, Training Loss: 0.20227163455108366, Validation Loss: 0.23270105889930648\nEpoch 211, Training Loss: 0.2013528627841439, Validation Loss: 0.23270105889930648\nTraining Accuracy: 0.9304276652342951, Training F1 Score: 0.9266739372079588\nValidation Accuracy: 0.9272783062289046, Validation F1 Score: 0.9236457828054806\n\nLearning Rate: 0.0009142872782981222\nEpoch 221, Training Loss: 0.2016091181695701, Validation Loss: 0.232881889213591\nEpoch 221, Training Loss: 0.20071270371063143, Validation Loss: 0.232881889213591\nTraining Accuracy: 0.9307346020053202, Training F1 Score: 0.9270284174794406\nValidation Accuracy: 0.9269714636391531, Validation F1 Score: 0.9232974467298338\n\nLearning Rate: 0.0009105463558838564\nEpoch 231, Training Loss: 0.20098814724387873, Validation Loss: 0.2329285350011221\nEpoch 231, Training Loss: 0.20005908532614566, Validation Loss: 0.2329285350011221\nTraining Accuracy: 0.930939226519337, Training F1 Score: 0.9272608072749273\nValidation Accuracy: 0.9266646210494016, Validation F1 Score: 0.923001443419873\n\nLearning Rate: 0.0009068207399283392\nEpoch 241, Training Loss: 0.20036280988106078, Validation Loss: 0.23317086305234944\nEpoch 241, Training Loss: 0.19946463908228979, Validation Loss: 0.23317086305234944\nTraining Accuracy: 0.9311438510333538, Training F1 Score: 0.9275042230028514\nValidation Accuracy: 0.9272783062289046, Validation F1 Score: 0.9236457828054806\n\nLearning Rate: 0.0009031103678032523\nEpoch 251, Training Loss: 0.1998194392464852, Validation Loss: 0.2331673979859807\nEpoch 251, Training Loss: 0.19895414655231436, Validation Loss: 0.2331673979859807\nTraining Accuracy: 0.9311779551190232, Training F1 Score: 0.9275261987249032\nValidation Accuracy: 0.9275851488186561, Validation F1 Score: 0.9239938446145245\n\nLearning Rate: 0.0008994151771365291\nEpoch 261, Training Loss: 0.1993327260060083, Validation Loss: 0.23323119042859045\nEpoch 261, Training Loss: 0.19837439199709467, Validation Loss: 0.23323119042859045\nTraining Accuracy: 0.9312802673760316, Training F1 Score: 0.9276478500994283\nValidation Accuracy: 0.9275851488186561, Validation F1 Score: 0.9239938446145245\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m LambdaLR(optimizer, lr_lambda\u001b[38;5;241m=\u001b[39mcustom_lr_lambda)\n\u001b[1;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m CustomLoss(nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[4], line 21\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer, num_epochs, scheduler, batch_size, num_features, early_stopping_patience)\u001b[0m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels, model)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":16},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99999 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 1).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 1.0)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 10000, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:09:58.475191Z","iopub.execute_input":"2025-01-23T04:09:58.475984Z","iopub.status.idle":"2025-01-23T04:23:19.679874Z","shell.execute_reply.started":"2025-01-23T04:09:58.475948Z","shell.execute_reply":"2025-01-23T04:23:19.678735Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"here\nLearning Rate: 0.0009998700077997146\nEpoch 1, Training Loss: 0.49528662510020316, Validation Loss: 0.3185676628562242\nEpoch 1, Training Loss: 0.3205098198033491, Validation Loss: 0.3185676628562242\nTraining Accuracy: 0.8678732811224925, Training F1 Score: 0.8451023475456597\nValidation Accuracy: 0.8712046475939932, Validation F1 Score: 0.8501742789721651\n\nLearning Rate: 0.0009886350177801951\nEpoch 11, Training Loss: 0.21353975831286232, Validation Loss: 0.22155042180500964\nEpoch 11, Training Loss: 0.2119047555450359, Validation Loss: 0.22155042180500964\nTraining Accuracy: 0.9322436451773991, Training F1 Score: 0.928668983024037\nValidation Accuracy: 0.9266688589279842, Validation F1 Score: 0.9228546861033203\n\nLearning Rate: 0.0009775262691718131\nEpoch 21, Training Loss: 0.2003762004482626, Validation Loss: 0.21076466172368435\nEpoch 21, Training Loss: 0.19941092322888726, Validation Loss: 0.21076466172368435\nTraining Accuracy: 0.937079034870833, Training F1 Score: 0.9336873602605845\nValidation Accuracy: 0.9310533815630824, Validation F1 Score: 0.927371145352716\n\nLearning Rate: 0.0009665423434691799\nEpoch 31, Training Loss: 0.19495804004420442, Validation Loss: 0.20617141354525675\nEpoch 31, Training Loss: 0.19412409196729402, Validation Loss: 0.20617141354525675\nTraining Accuracy: 0.93893036795245, Training F1 Score: 0.9355955786963049\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9290347571409071\n\nLearning Rate: 0.0009556818381058724\nEpoch 41, Training Loss: 0.19143393492805533, Validation Loss: 0.20397245847191006\nEpoch 41, Training Loss: 0.19068591458637624, Validation Loss: 0.20397245847191006\nTraining Accuracy: 0.9405624642217703, Training F1 Score: 0.9372842139157587\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9307541511572971\n\nLearning Rate: 0.000944943366275336\nEpoch 51, Training Loss: 0.18928241735907106, Validation Loss: 0.20284442476839215\nEpoch 51, Training Loss: 0.18864933516367716, Validation Loss: 0.20284442476839215\nTraining Accuracy: 0.9411470957212282, Training F1 Score: 0.9379126233515123\nValidation Accuracy: 0.9344513866052834, Validation F1 Score: 0.9310078152390956\n\nLearning Rate: 0.0009343255567537995\nEpoch 61, Training Loss: 0.187710839862134, Validation Loss: 0.20182757040237265\nEpoch 61, Training Loss: 0.18715554124812162, Validation Loss: 0.20182757040237265\nTraining Accuracy: 0.9417195473977809, Training F1 Score: 0.9384833851648094\nValidation Accuracy: 0.9345609996711608, Validation F1 Score: 0.9311345748510945\n\nLearning Rate: 0.0009238270537251801\nEpoch 71, Training Loss: 0.1862949488539499, Validation Loss: 0.2008947752866125\nEpoch 71, Training Loss: 0.18576179006047489, Validation Loss: 0.2008947752866125\nTraining Accuracy: 0.9422189201369012, Training F1 Score: 0.9389889022388009\nValidation Accuracy: 0.9352186780664256, Validation F1 Score: 0.9318041324719937\n\nLearning Rate: 0.0009134465166079558\nEpoch 81, Training Loss: 0.18518130535201152, Validation Loss: 0.20006853340586248\nEpoch 81, Training Loss: 0.18471487876376608, Validation Loss: 0.20006853340586248\nTraining Accuracy: 0.942633034115684, Training F1 Score: 0.9394397048961306\nValidation Accuracy: 0.9358763564616902, Validation F1 Score: 0.9324964763047653\n\nLearning Rate: 0.0009031826198839819\nEpoch 91, Training Loss: 0.18412119488810474, Validation Loss: 0.19928088854942408\nEpoch 91, Training Loss: 0.18368176932518018, Validation Loss: 0.19928088854942408\nTraining Accuracy: 0.9431324068548044, Training F1 Score: 0.9399746970396019\nValidation Accuracy: 0.936534034856955, Validation F1 Score: 0.9331666817985076\n\nLearning Rate: 0.0008930340529292337\nEpoch 101, Training Loss: 0.1830827351968756, Validation Loss: 0.19870521379715386\nEpoch 101, Training Loss: 0.18271208331913594, Validation Loss: 0.19870521379715386\nTraining Accuracy: 0.9436317795939247, Training F1 Score: 0.9405537172330475\nValidation Accuracy: 0.9370821001863422, Validation F1 Score: 0.933798621329924\n\nLearning Rate: 0.0008829995198464485\nEpoch 111, Training Loss: 0.18219987560421733, Validation Loss: 0.1982806163076297\nEpoch 111, Training Loss: 0.18180412767893991, Validation Loss: 0.1982806163076297\nTraining Accuracy: 0.9438753760520322, Training F1 Score: 0.9408193907951604\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9329580388599463\n\nLearning Rate: 0.0008730777392996492\nEpoch 121, Training Loss: 0.18143463348692018, Validation Loss: 0.19825638341469864\nEpoch 121, Training Loss: 0.1810973637041862, Validation Loss: 0.19825638341469864\nTraining Accuracy: 0.9439484549894644, Training F1 Score: 0.9409205136576794\nValidation Accuracy: 0.9367532609887098, Validation F1 Score: 0.9333532984389721\n\nLearning Rate: 0.0008632674443505271\nEpoch 131, Training Loss: 0.18076013722852477, Validation Loss: 0.19798092147008534\nEpoch 131, Training Loss: 0.1804183819630523, Validation Loss: 0.19798092147008534\nTraining Accuracy: 0.9442164110933827, Training F1 Score: 0.9411789951913706\nValidation Accuracy: 0.9368628740545873, Validation F1 Score: 0.9334577384085085\n\nLearning Rate: 0.0008535673822966636\nEpoch 141, Training Loss: 0.18023406770436737, Validation Loss: 0.19774044751728964\nEpoch 141, Training Loss: 0.17986865006608202, Validation Loss: 0.19774044751728964\nTraining Accuracy: 0.9443625689682472, Training F1 Score: 0.9413222365161295\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9330179143497537\n\nLearning Rate: 0.0008439763145115688\nEpoch 151, Training Loss: 0.179728210785291, Validation Loss: 0.1975166601193496\nEpoch 151, Training Loss: 0.1793013391191744, Validation Loss: 0.1975166601193496\nTraining Accuracy: 0.9444112882598688, Training F1 Score: 0.9413801385733526\nValidation Accuracy: 0.936534034856955, Validation F1 Score: 0.9331222873417068\n\nLearning Rate: 0.0008344930162865182\nEpoch 161, Training Loss: 0.17928797965074253, Validation Loss: 0.19737566260931902\nEpoch 161, Training Loss: 0.17891032862773326, Validation Loss: 0.19737566260931902\nTraining Accuracy: 0.9444965470202064, Training F1 Score: 0.9414928027262236\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9330623461187203\n\nLearning Rate: 0.0008251162766741667\nEpoch 171, Training Loss: 0.17889026111091907, Validation Loss: 0.19721422180374973\nEpoch 171, Training Loss: 0.17849897540708368, Validation Loss: 0.19721422180374973\nTraining Accuracy: 0.9445209066660171, Training F1 Score: 0.9415119864992342\nValidation Accuracy: 0.936534034856955, Validation F1 Score: 0.933188820137537\n\nLearning Rate: 0.0008158448983339194\nEpoch 181, Training Loss: 0.17855374025750123, Validation Loss: 0.19714798628434557\nEpoch 181, Training Loss: 0.17817495749127207, Validation Loss: 0.19714798628434557\nTraining Accuracy: 0.9445330864889224, Training F1 Score: 0.9415259092881745\nValidation Accuracy: 0.9369724871204648, Validation F1 Score: 0.9336283972955819\n\nLearning Rate: 0.0008066776973790393\nEpoch 191, Training Loss: 0.17832457708122276, Validation Loss: 0.19711585909660664\nEpoch 191, Training Loss: 0.17788677887073098, Validation Loss: 0.19711585909660664\nTraining Accuracy: 0.9446670645408816, Training F1 Score: 0.9416595903849281\nValidation Accuracy: 0.9367532609887098, Validation F1 Score: 0.9333975395470449\n\nLearning Rate: 0.000797613503225475\nEpoch 201, Training Loss: 0.17811441783806123, Validation Loss: 0.1970446003635868\nEpoch 201, Training Loss: 0.17763077893182425, Validation Loss: 0.1970446003635868\nTraining Accuracy: 0.9447279636554085, Training F1 Score: 0.9417140816927856\nValidation Accuracy: 0.9370821001863422, Validation F1 Score: 0.9337108324771701\n\nLearning Rate: 0.0007886511584423848\nEpoch 211, Training Loss: 0.17790902101313177, Validation Loss: 0.19699984793468067\nEpoch 211, Training Loss: 0.17747685557351706, Validation Loss: 0.19699984793468067\nTraining Accuracy: 0.9448375820615569, Training F1 Score: 0.9418242855916917\nValidation Accuracy: 0.9368628740545873, Validation F1 Score: 0.9335239851110052\n\nLearning Rate: 0.0007797895186043415\nEpoch 221, Training Loss: 0.17775333991673228, Validation Loss: 0.19689032870871476\nEpoch 221, Training Loss: 0.17731440307752003, Validation Loss: 0.19689032870871476\nTraining Accuracy: 0.9449472004677052, Training F1 Score: 0.9419409684298562\nValidation Accuracy: 0.9370821001863422, Validation F1 Score: 0.9337548046071475\n\nLearning Rate: 0.0007710274521451978\nEpoch 231, Training Loss: 0.17758682543639195, Validation Loss: 0.19688834791269452\nEpoch 231, Training Loss: 0.1771140643714742, Validation Loss: 0.19688834791269452\nTraining Accuracy: 0.9449715601135159, Training F1 Score: 0.9419645062565396\nValidation Accuracy: 0.9367532609887098, Validation F1 Score: 0.9334416242698181\n\nLearning Rate: 0.0007623638402135935\nEpoch 241, Training Loss: 0.17745345345694474, Validation Loss: 0.19691009410350427\nEpoch 241, Training Loss: 0.17691327106322086, Validation Loss: 0.19691009410350427\nTraining Accuracy: 0.9450811785196643, Training F1 Score: 0.9420682947620372\nValidation Accuracy: 0.9371917132522196, Validation F1 Score: 0.9338592550441189\n\nLearning Rate: 0.0007537975765300869\nEpoch 251, Training Loss: 0.17731942159869532, Validation Loss: 0.19694778184827766\nEpoch 251, Training Loss: 0.17678582952541422, Validation Loss: 0.19694778184827766\nTraining Accuracy: 0.9450811785196643, Training F1 Score: 0.942079040789376\nValidation Accuracy: 0.9371917132522196, Validation F1 Score: 0.9338811639703086\n\nLearning Rate: 0.00074532756724589\nEpoch 261, Training Loss: 0.1771708555565771, Validation Loss: 0.19680502872567396\nEpoch 261, Training Loss: 0.17661047616330963, Validation Loss: 0.19680502872567396\nTraining Accuracy: 0.9450202794051374, Training F1 Score: 0.9420072831771262\nValidation Accuracy: 0.937520552449852, Validation F1 Score: 0.9342164435994322\n\nLearning Rate: 0.0007369527308031936\nEpoch 271, Training Loss: 0.17704977233407007, Validation Loss: 0.19670570824447595\nEpoch 271, Training Loss: 0.17645003477995627, Validation Loss: 0.19670570824447595\nTraining Accuracy: 0.9451177179883804, Training F1 Score: 0.9421014654018864\nValidation Accuracy: 0.9379590047133618, Validation F1 Score: 0.9346564221485527\n\nLearning Rate: 0.0007286719977970586\nEpoch 281, Training Loss: 0.17690822333520337, Validation Loss: 0.1967633639307225\nEpoch 281, Training Loss: 0.1763354231063648, Validation Loss: 0.1967633639307225\nTraining Accuracy: 0.9450811785196643, Training F1 Score: 0.9420682947620372\nValidation Accuracy: 0.9379590047133618, Validation F1 Score: 0.9346780825917167\n\nLearning Rate: 0.0007204843108388624\nEpoch 291, Training Loss: 0.17680412162539832, Validation Loss: 0.19677639626612545\nEpoch 291, Training Loss: 0.17625325761913574, Validation Loss: 0.19677639626612545\nTraining Accuracy: 0.9451542574570966, Training F1 Score: 0.9421496768197787\nValidation Accuracy: 0.9380686177792393, Validation F1 Score: 0.9347826860382674\n\nLearning Rate: 0.0007123886244212772\nEpoch 301, Training Loss: 0.1766640778200424, Validation Loss: 0.1966183511710776\nEpoch 301, Training Loss: 0.17611171775538162, Validation Loss: 0.1966183511710776\nTraining Accuracy: 0.9451177179883804, Training F1 Score: 0.9421079131748226\nValidation Accuracy: 0.9379590047133618, Validation F1 Score: 0.934634723313725\n\nLearning Rate: 0.0007043839047847668\nEpoch 311, Training Loss: 0.17656356697646428, Validation Loss: 0.19645045159659624\nEpoch 311, Training Loss: 0.17596416191826908, Validation Loss: 0.19645045159659624\nTraining Accuracy: 0.9451664372800019, Training F1 Score: 0.9421528622368602\nValidation Accuracy: 0.9381782308451168, Validation F1 Score: 0.934865696022864\n\nLearning Rate: 0.0006964691297855829\nEpoch 321, Training Loss: 0.17647489387846782, Validation Loss: 0.19632990209762038\nEpoch 321, Training Loss: 0.17584959290962615, Validation Loss: 0.19632990209762038\nTraining Accuracy: 0.9452516960403395, Training F1 Score: 0.9422481669894338\nValidation Accuracy: 0.9380686177792393, Validation F1 Score: 0.9347610447126941\n\nLearning Rate: 0.0006886432887652451\nEpoch 331, Training Loss: 0.17636984524735666, Validation Loss: 0.19634131491216902\nEpoch 331, Training Loss: 0.1757699038564361, Validation Loss: 0.19634131491216902\nTraining Accuracy: 0.9452760556861504, Training F1 Score: 0.9422652891040737\nValidation Accuracy: 0.9381782308451168, Validation F1 Score: 0.9348873181833636\n\nLearning Rate: 0.0006809053824214873\nEpoch 341, Training Loss: 0.17627208898895463, Validation Loss: 0.1961308398585067\nEpoch 341, Training Loss: 0.17563638908878923, Validation Loss: 0.1961308398585067\nTraining Accuracy: 0.9452760556861504, Training F1 Score: 0.942269576908068\nValidation Accuracy: 0.9381782308451168, Validation F1 Score: 0.9349089020878593\n\nLearning Rate: 0.0006732544226806538\nEpoch 351, Training Loss: 0.1761542692784669, Validation Loss: 0.1960742825771468\nEpoch 351, Training Loss: 0.17554668156566042, Validation Loss: 0.1960742825771468\nTraining Accuracy: 0.9452760556861504, Training F1 Score: 0.9422760054452914\nValidation Accuracy: 0.9381782308451168, Validation F1 Score: 0.9348873181833636\n\nLearning Rate: 0.0006656894325715299\nEpoch 361, Training Loss: 0.17605873211337497, Validation Loss: 0.1960489114759314\nEpoch 361, Training Loss: 0.17543538503372694, Validation Loss: 0.1960489114759314\nTraining Accuracy: 0.9453247749777718, Training F1 Score: 0.9423273956029184\nValidation Accuracy: 0.9385070700427491, Validation F1 Score: 0.9352229134226927\n\nLearning Rate: 0.0006582094461005897\nEpoch 371, Training Loss: 0.17595360748657765, Validation Loss: 0.1957856535202681\nEpoch 371, Training Loss: 0.1753096630299929, Validation Loss: 0.1957856535202681\nTraining Accuracy: 0.9455196521442578, Training F1 Score: 0.9425244221636725\nValidation Accuracy: 0.9385070700427491, Validation F1 Score: 0.9352229134226927\n\nLearning Rate: 0.000650813508128646\nEpoch 381, Training Loss: 0.1758700401749188, Validation Loss: 0.19572493091109655\nEpoch 381, Training Loss: 0.1752302336678726, Validation Loss: 0.19572493091109655\nTraining Accuracy: 0.9455683714358794, Training F1 Score: 0.9425694207107114\nValidation Accuracy: 0.9386166831086266, Validation F1 Score: 0.9353276414411414\n\nLearning Rate: 0.000643500674248886\nEpoch 391, Training Loss: 0.17578226382217124, Validation Loss: 0.19565460133563004\nEpoch 391, Training Loss: 0.17512856746405084, Validation Loss: 0.19565460133563004\nTraining Accuracy: 0.9455805512587847, Training F1 Score: 0.9425812049202893\nValidation Accuracy: 0.938726296174504, Validation F1 Score: 0.9354538477776919\n\nLearning Rate: 0.000636270010666277\nEpoch 401, Training Loss: 0.1757003437500959, Validation Loss: 0.19561129753054932\nEpoch 401, Training Loss: 0.17502596947239585, Validation Loss: 0.19561129753054932\nTraining Accuracy: 0.9455805512587847, Training F1 Score: 0.9425769371899655\nValidation Accuracy: 0.9385070700427491, Validation F1 Score: 0.9352229134226927\n\nLearning Rate: 0.0006291205940783288\nEpoch 411, Training Loss: 0.1756124349568193, Validation Loss: 0.1956615493470844\nEpoch 411, Training Loss: 0.17496243337794284, Validation Loss: 0.1956615493470844\nTraining Accuracy: 0.9455805512587847, Training F1 Score: 0.9425769371899655\nValidation Accuracy: 0.9388359092403814, Validation F1 Score: 0.9355800062877957\n\nLearning Rate: 0.0006220515115571937\nEpoch 421, Training Loss: 0.17553644676254263, Validation Loss: 0.19555014766982207\nEpoch 421, Training Loss: 0.17486681270097426, Validation Loss: 0.19555014766982207\nTraining Accuracy: 0.945653630196217, Training F1 Score: 0.942654049628833\nValidation Accuracy: 0.938726296174504, Validation F1 Score: 0.9354323983143593\n\nLearning Rate: 0.0006150618604330928\nEpoch 431, Training Loss: 0.17545402793125314, Validation Loss: 0.19548598262617675\nEpoch 431, Training Loss: 0.17474472618019685, Validation Loss: 0.19548598262617675\nTraining Accuracy: 0.9457145293107438, Training F1 Score: 0.942712986103885\nValidation Accuracy: 0.9386166831086266, Validation F1 Score: 0.9353061345638277\n\nLearning Rate: 0.0006081507481790516\nEpoch 441, Training Loss: 0.17536126473538804, Validation Loss: 0.19541311627461122\nEpoch 441, Training Loss: 0.17467562826739294, Validation Loss: 0.19541311627461122\nTraining Accuracy: 0.9456779898420277, Training F1 Score: 0.9426669634233112\nValidation Accuracy: 0.938726296174504, Validation F1 Score: 0.9353893851929795\n\nLearning Rate: 0.000601317292296931\nEpoch 451, Training Loss: 0.17529113119705372, Validation Loss: 0.19532035265551134\nEpoch 451, Training Loss: 0.1745957919391208, Validation Loss: 0.19532035265551134\nTraining Accuracy: 0.945653630196217, Training F1 Score: 0.9426497859485007\nValidation Accuracy: 0.9388359092403814, Validation F1 Score: 0.9355157160059491\n\nLearning Rate: 0.0005945606202047386\nEpoch 461, Training Loss: 0.17522834694143924, Validation Loss: 0.19533274031601414\nEpoch 461, Training Loss: 0.17453457258384272, Validation Loss: 0.19533274031601414\nTraining Accuracy: 0.9455805512587847, Training F1 Score: 0.9425726677763117\nValidation Accuracy: 0.9386166831086266, Validation F1 Score: 0.9353061345638277\n\nLearning Rate: 0.0005878798691252067\nEpoch 471, Training Loss: 0.17513596012371824, Validation Loss: 0.19531259861749528\nEpoch 471, Training Loss: 0.1744516667769864, Validation Loss: 0.19531259861749528\nTraining Accuracy: 0.9455318319671632, Training F1 Score: 0.9425298004484185\nValidation Accuracy: 0.9385070700427491, Validation F1 Score: 0.9351798228374972\n\nLearning Rate: 0.0005812741859756216\nEpoch 481, Training Loss: 0.17503304170038084, Validation Loss: 0.1952625819609822\nEpoch 481, Training Loss: 0.1743375231116201, Validation Loss: 0.1952625819609822\nTraining Accuracy: 0.9455683714358794, Training F1 Score: 0.9425651524460121\nValidation Accuracy: 0.9385070700427491, Validation F1 Score: 0.9352013872170942\n\nLearning Rate: 0.0005747427272588915\nEpoch 491, Training Loss: 0.1749499524829042, Validation Loss: 0.19517180458189795\nEpoch 491, Training Loss: 0.17424547526187606, Validation Loss: 0.19517180458189795\nTraining Accuracy: 0.9456292705504062, Training F1 Score: 0.9426219464644519\nValidation Accuracy: 0.9386166831086266, Validation F1 Score: 0.9353061345638277\n\nLearning Rate: 0.0005682846589558382\nEpoch 501, Training Loss: 0.17485916510718186, Validation Loss: 0.19507246747634188\nEpoch 501, Training Loss: 0.17417042724987014, Validation Loss: 0.19507246747634188\nTraining Accuracy: 0.9457145293107438, Training F1 Score: 0.9427236312614992\nValidation Accuracy: 0.9388359092403814, Validation F1 Score: 0.9355371840832427\n\nLearning Rate: 0.0005618991564186986\nEpoch 511, Training Loss: 0.1747878628800839, Validation Loss: 0.19501367625562452\nEpoch 511, Training Loss: 0.17409478960703037, Validation Loss: 0.19501367625562452\nTraining Accuracy: 0.9457023494878385, Training F1 Score: 0.9427075872205842\nValidation Accuracy: 0.9388359092403814, Validation F1 Score: 0.9355371840832427\n\nLearning Rate: 0.0005555854042658238\nEpoch 521, Training Loss: 0.17470342485787493, Validation Loss: 0.19500789058374415\nEpoch 521, Training Loss: 0.17401064743738295, Validation Loss: 0.19500789058374415\nTraining Accuracy: 0.9457023494878385, Training F1 Score: 0.9427075872205842\nValidation Accuracy: 0.9389455223062589, Validation F1 Score: 0.9356634094116246\n\nLearning Rate: 0.0005493425962775601\nEpoch 531, Training Loss: 0.17458945877646148, Validation Loss: 0.19484093077223538\nEpoch 531, Training Loss: 0.17390580614082138, Validation Loss: 0.19484093077223538\nTraining Accuracy: 0.9457510687794599, Training F1 Score: 0.9427653732524249\nValidation Accuracy: 0.9389455223062589, Validation F1 Score: 0.9356634094116246\n\nLearning Rate: 0.0005431699352933019\nEpoch 541, Training Loss: 0.17449137724812322, Validation Loss: 0.19466287397794735\nEpoch 541, Training Loss: 0.17380029421977167, Validation Loss: 0.19466287397794735\nTraining Accuracy: 0.9457632486023653, Training F1 Score: 0.9427792860851191\nValidation Accuracy: 0.9391647484380138, Validation F1 Score: 0.9358944205088898\n\nLearning Rate: 0.0005370666331096988\nEpoch 551, Training Loss: 0.17438747703059182, Validation Loss: 0.1945792750744238\nEpoch 551, Training Loss: 0.17369620248430512, Validation Loss: 0.1945792750744238\nTraining Accuracy: 0.9458363275397975, Training F1 Score: 0.9428563856322759\nValidation Accuracy: 0.9391647484380138, Validation F1 Score: 0.9358730867643688\n\nLearning Rate: 0.0005310319103800086\nEpoch 561, Training Loss: 0.1742858246500413, Validation Loss: 0.19444516523128982\nEpoch 561, Training Loss: 0.17359447833523367, Validation Loss: 0.19444516523128982\nTraining Accuracy: 0.9457632486023653, Training F1 Score: 0.9427814111099561\nValidation Accuracy: 0.9394935876356462, Validation F1 Score: 0.9362303326414876\n\nLearning Rate: 0.0005250649965145806\nEpoch 571, Training Loss: 0.17418731732160725, Validation Loss: 0.19431771343049414\nEpoch 571, Training Loss: 0.17348729686941175, Validation Loss: 0.19431771343049414\nTraining Accuracy: 0.9457388889565546, Training F1 Score: 0.942753586236067\nValidation Accuracy: 0.9396032007015236, Validation F1 Score: 0.9363564427034204\n\nLearning Rate: 0.0005191651295824565\nEpoch 581, Training Loss: 0.17408576807238121, Validation Loss: 0.19415491834245308\nEpoch 581, Training Loss: 0.1733931563941169, Validation Loss: 0.19415491834245308\nTraining Accuracy: 0.9457876082481761, Training F1 Score: 0.9428007365368932\nValidation Accuracy: 0.9396032007015236, Validation F1 Score: 0.9363564427034204\n\nLearning Rate: 0.0005133315562140772\nEpoch 591, Training Loss: 0.17398061758983777, Validation Loss: 0.19399824423753653\nEpoch 591, Training Loss: 0.1732985868331493, Validation Loss: 0.19399824423753653\nTraining Accuracy: 0.9458363275397975, Training F1 Score: 0.9428606295370974\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9365663506912405\n\nLearning Rate: 0.0005075635315050845\nEpoch 601, Training Loss: 0.17388659971667203, Validation Loss: 0.19389087062197977\nEpoch 601, Training Loss: 0.17320289451978707, Validation Loss: 0.19389087062197977\nTraining Accuracy: 0.9458728670085137, Training F1 Score: 0.9429065942488148\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9365663506912405\n\nLearning Rate: 0.0005018603189212003\nEpoch 611, Training Loss: 0.17379312716741988, Validation Loss: 0.19379332647255137\nEpoch 611, Training Loss: 0.17312712330317284, Validation Loss: 0.19379332647255137\nTraining Accuracy: 0.9459703055917567, Training F1 Score: 0.94300091001393\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9367763751351696\n\nLearning Rate: 0.0004962211902041782\nEpoch 621, Training Loss: 0.17371045244862002, Validation Loss: 0.19370419605806916\nEpoch 621, Training Loss: 0.17304211274591064, Validation Loss: 0.19370419605806916\nTraining Accuracy: 0.9460433845291889, Training F1 Score: 0.9430716624942306\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368814311312466\n\nLearning Rate: 0.0004906454252788093\nEpoch 631, Training Loss: 0.17364490210731207, Validation Loss: 0.19360884950896123\nEpoch 631, Training Loss: 0.17294697193214145, Validation Loss: 0.19360884950896123\nTraining Accuracy: 0.9459824854146621, Training F1 Score: 0.9430105847265898\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9369865163651531\n\nLearning Rate: 0.00048513231216097436\nEpoch 641, Training Loss: 0.17355942881511843, Validation Loss: 0.19359174756402445\nEpoch 641, Training Loss: 0.1728689849838398, Validation Loss: 0.19359174756402445\nTraining Accuracy: 0.9460312047062835, Training F1 Score: 0.9430619844246941\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9369654552819082\n\nLearning Rate: 0.0004796811468667287\nEpoch 651, Training Loss: 0.1734915049629229, Validation Loss: 0.19355358257538574\nEpoch 651, Training Loss: 0.17280350844613943, Validation Loss: 0.19355358257538574\nTraining Accuracy: 0.9459946652375675, Training F1 Score: 0.9430244926821624\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368603501094473\n\nLearning Rate: 0.0004742912333224084\nEpoch 661, Training Loss: 0.1734399775094243, Validation Loss: 0.1934934567885089\nEpoch 661, Training Loss: 0.17274576417330711, Validation Loss: 0.1934934567885089\nTraining Accuracy: 0.9460799239979051, Training F1 Score: 0.9431070437712683\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368392316564237\n\nLearning Rate: 0.0004689618832757469\nEpoch 671, Training Loss: 0.17336535133133663, Validation Loss: 0.1934479189003349\nEpoch 671, Training Loss: 0.17267530171429474, Validation Loss: 0.1934479189003349\nTraining Accuracy: 0.9460921038208104, Training F1 Score: 0.9431251778211117\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368392316564237\n\nLearning Rate: 0.00046369241620799036\nEpoch 681, Training Loss: 0.17330321577270955, Validation Loss: 0.19338767429617534\nEpoch 681, Training Loss: 0.17260991988897964, Validation Loss: 0.19338767429617534\nTraining Accuracy: 0.9460799239979051, Training F1 Score: 0.9431133841227987\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9367341358517499\n\nLearning Rate: 0.0004584821592470003\nEpoch 691, Training Loss: 0.17323255250347608, Validation Loss: 0.19331312681660898\nEpoch 691, Training Loss: 0.17255239947731396, Validation Loss: 0.19331312681660898\nTraining Accuracy: 0.9461164634666211, Training F1 Score: 0.9431466541108684\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368603501094473\n\nLearning Rate: 0.00045333044708133294\nEpoch 701, Training Loss: 0.17318400658915098, Validation Loss: 0.19332919636898288\nEpoch 701, Training Loss: 0.17252220301800575, Validation Loss: 0.19332919636898288\nTraining Accuracy: 0.9460799239979051, Training F1 Score: 0.9431133841227987\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368814311312466\n\nLearning Rate: 0.0004482366218752834\nEpoch 711, Training Loss: 0.17312865667227972, Validation Loss: 0.19330138705689617\nEpoch 711, Training Loss: 0.1724582181685215, Validation Loss: 0.19330138705689617\nTraining Accuracy: 0.9460921038208104, Training F1 Score: 0.9431272901694296\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368814311312466\n\nLearning Rate: 0.0004432000331848857\nEpoch 721, Training Loss: 0.17308085410852342, Validation Loss: 0.19326273452931167\nEpoch 721, Training Loss: 0.1724085499132475, Validation Loss: 0.19326273452931167\nTraining Accuracy: 0.9460555643520944, Training F1 Score: 0.9430876842737463\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9367763751351696\n\nLearning Rate: 0.000438220037874855\nEpoch 731, Training Loss: 0.17302874758330156, Validation Loss: 0.19319770324521585\nEpoch 731, Training Loss: 0.1723491691583147, Validation Loss: 0.19319770324521585\nTraining Accuracy: 0.9460677441749997, Training F1 Score: 0.9430952496389977\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9367763751351696\n\nLearning Rate: 0.00043329600003646476\nEpoch 741, Training Loss: 0.17296566168366778, Validation Loss: 0.1931337880487833\nEpoch 741, Training Loss: 0.17228597414260813, Validation Loss: 0.1931337880487833\nTraining Accuracy: 0.9461895424040534, Training F1 Score: 0.9432237608186748\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9369865163651531\n\nLearning Rate: 0.00042842729090634496\nEpoch 751, Training Loss: 0.1729083462386059, Validation Loss: 0.19309188908036048\nEpoch 751, Training Loss: 0.17222777996534622, Validation Loss: 0.19309188908036048\nTraining Accuracy: 0.9462260818727696, Training F1 Score: 0.9432591514990253\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9369865163651531\n\nLearning Rate: 0.00042361328878619465\nEpoch 761, Training Loss: 0.1728660234864495, Validation Loss: 0.19308158732272027\nEpoch 761, Training Loss: 0.17218668082932911, Validation Loss: 0.19308158732272027\nTraining Accuracy: 0.9461651827582427, Training F1 Score: 0.943195947849929\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368603501094473\n\nLearning Rate: 0.0004188533789633949\nEpoch 771, Training Loss: 0.1728200414363033, Validation Loss: 0.19303627391401434\nEpoch 771, Training Loss: 0.17213660261071953, Validation Loss: 0.19303627391401434\nTraining Accuracy: 0.9462260818727696, Training F1 Score: 0.9432591514990253\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.936755274223374\n\nLearning Rate: 0.0004141469536325149\nEpoch 781, Training Loss: 0.1727798605458001, Validation Loss: 0.19300088233642249\nEpoch 781, Training Loss: 0.1720989342801744, Validation Loss: 0.19300088233642249\nTraining Accuracy: 0.9461286432895266, Training F1 Score: 0.9431605611553985\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.936755274223374\n\nLearning Rate: 0.0004094934118176996\nEpoch 791, Training Loss: 0.17271905420639685, Validation Loss: 0.1929435774881589\nEpoch 791, Training Loss: 0.17203690050128967, Validation Loss: 0.1929435774881589\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431862629138633\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.936755274223374\n\nLearning Rate: 0.00040489215929592943\nEpoch 801, Training Loss: 0.17266660513850193, Validation Loss: 0.19287785284354292\nEpoch 801, Training Loss: 0.17200297804313236, Validation Loss: 0.19287785284354292\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.9432204007025933\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9370075401255346\n\nLearning Rate: 0.0004003426085211425\nEpoch 811, Training Loss: 0.17262069256080237, Validation Loss: 0.192912909359795\nEpoch 811, Training Loss: 0.17196704540774893, Validation Loss: 0.192912909359795\nTraining Accuracy: 0.9462382616956749, Training F1 Score: 0.9432835926062865\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9372387051158997\n\nLearning Rate: 0.0003958441785492091\nEpoch 821, Training Loss: 0.1725850550572698, Validation Loss: 0.19287807610288962\nEpoch 821, Training Loss: 0.17192279224131324, Validation Loss: 0.19287807610288962\nTraining Accuracy: 0.9462139020498642, Training F1 Score: 0.9432578941887992\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9372177585069322\n\nLearning Rate: 0.00039139629496375\nEpoch 831, Training Loss: 0.1725487943471495, Validation Loss: 0.1928861864392177\nEpoch 831, Training Loss: 0.17188950605074219, Validation Loss: 0.1928861864392177\nTraining Accuracy: 0.9462626213414856, Training F1 Score: 0.9433092910237733\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9368814311312466\n\nLearning Rate: 0.00038699838980278683\nEpoch 841, Training Loss: 0.17251234435745347, Validation Loss: 0.19283289569394835\nEpoch 841, Training Loss: 0.1718346128003855, Validation Loss: 0.19283289569394835\nTraining Accuracy: 0.9462748011643911, Training F1 Score: 0.9433126654788941\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9372177585069322\n\nLearning Rate: 0.00038264990148621824\nEpoch 851, Training Loss: 0.17246936880764543, Validation Loss: 0.1928262091559772\nEpoch 851, Training Loss: 0.1717880260991845, Validation Loss: 0.1928262091559772\nTraining Accuracy: 0.9463235204560125, Training F1 Score: 0.94336827912559\nValidation Accuracy: 0.9406993313602982, Validation F1 Score: 0.9374280941422243\n\nLearning Rate: 0.0003783502747441099\nEpoch 861, Training Loss: 0.1724290580253265, Validation Loss: 0.19286695922086156\nEpoch 861, Training Loss: 0.1717470976643421, Validation Loss: 0.19286695922086156\nTraining Accuracy: 0.9463722397476341, Training F1 Score: 0.9434175787400452\nValidation Accuracy: 0.9406993313602982, Validation F1 Score: 0.9374490006487117\n\nLearning Rate: 0.00037409896054579065\nEpoch 871, Training Loss: 0.17238873440161614, Validation Loss: 0.19283657418352645\nEpoch 871, Training Loss: 0.17171166732638865, Validation Loss: 0.19283657418352645\nTraining Accuracy: 0.9463722397476341, Training F1 Score: 0.9434217823114258\nValidation Accuracy: 0.9408089444261756, Validation F1 Score: 0.9375541924159372\n\nLearning Rate: 0.0003698954160297454\nEpoch 881, Training Loss: 0.1723505603058446, Validation Loss: 0.1927399171521812\nEpoch 881, Training Loss: 0.17165811693249625, Validation Loss: 0.1927399171521812\nTraining Accuracy: 0.9463722397476341, Training F1 Score: 0.943411270274244\nValidation Accuracy: 0.9406993313602982, Validation F1 Score: 0.9374280941422243\n\nLearning Rate: 0.00036573910443429586\nEpoch 891, Training Loss: 0.1723067565864749, Validation Loss: 0.1926596537877577\nEpoch 891, Training Loss: 0.17161779453894888, Validation Loss: 0.1926596537877577\nTraining Accuracy: 0.9464087792163502, Training F1 Score: 0.9434466737277908\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376385473635118\n\nLearning Rate: 0.00036162949502905966\nEpoch 901, Training Loss: 0.1722685257589193, Validation Loss: 0.19265806647516795\nEpoch 901, Training Loss: 0.17157951113726236, Validation Loss: 0.19265806647516795\nTraining Accuracy: 0.9464209590392556, Training F1 Score: 0.9434584756273255\nValidation Accuracy: 0.941137783623808, Validation F1 Score: 0.9378491185038331\n\nLearning Rate: 0.0003575660630471803\nEpoch 911, Training Loss: 0.17222886868317147, Validation Loss: 0.1926687294900071\nEpoch 911, Training Loss: 0.1715481783794288, Validation Loss: 0.1926687294900071\nTraining Accuracy: 0.9465062177995932, Training F1 Score: 0.9435473989408316\nValidation Accuracy: 0.941137783623808, Validation F1 Score: 0.9378491185038331\n\nLearning Rate: 0.00035354828961831807\nEpoch 921, Training Loss: 0.172183522202769, Validation Loss: 0.19266941062317963\nEpoch 921, Training Loss: 0.17151535362157325, Validation Loss: 0.19266941062317963\nTraining Accuracy: 0.9464574985079717, Training F1 Score: 0.943495984914366\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376176440848532\n\nLearning Rate: 0.0003495756617023944\nEpoch 931, Training Loss: 0.17214998922477187, Validation Loss: 0.1926783822998723\nEpoch 931, Training Loss: 0.17148241033611777, Validation Loss: 0.1926783822998723\nTraining Accuracy: 0.9464574985079717, Training F1 Score: 0.943495984914366\nValidation Accuracy: 0.941137783623808, Validation F1 Score: 0.937869944219306\n\nLearning Rate: 0.0003456476720240801\nEpoch 941, Training Loss: 0.1721195411713636, Validation Loss: 0.1926815191666233\nEpoch 941, Training Loss: 0.17145489819241957, Validation Loss: 0.1926815191666233\nTraining Accuracy: 0.9464453186850663, Training F1 Score: 0.943482080549273\nValidation Accuracy: 0.9412473966896854, Validation F1 Score: 0.9379752537931164\n\nLearning Rate: 0.0003417638190080203\nEpoch 951, Training Loss: 0.17208902954096225, Validation Loss: 0.1926718515323649\nEpoch 951, Training Loss: 0.17141937604488797, Validation Loss: 0.1926718515323649\nTraining Accuracy: 0.9464087792163502, Training F1 Score: 0.9434424676332873\nValidation Accuracy: 0.9410281705579305, Validation F1 Score: 0.9377438181729418\n\nLearning Rate: 0.00033792360671478677\nEpoch 961, Training Loss: 0.17204764670754807, Validation Loss: 0.1926549390231153\nEpoch 961, Training Loss: 0.17137951194784834, Validation Loss: 0.1926549390231153\nTraining Accuracy: 0.9464453186850663, Training F1 Score: 0.9434778760790203\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376385473635118\n\nLearning Rate: 0.0003341265447775503\nEpoch 971, Training Loss: 0.172008495862013, Validation Loss: 0.1926621458995738\nEpoch 971, Training Loss: 0.1713593917686974, Validation Loss: 0.1926621458995738\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434660728893243\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376385473635118\n\nLearning Rate: 0.00033037214833946425\nEpoch 981, Training Loss: 0.1719606876489084, Validation Loss: 0.19262684316870599\nEpoch 981, Training Loss: 0.17131957404960046, Validation Loss: 0.19262684316870599\nTraining Accuracy: 0.9464453186850663, Training F1 Score: 0.9434799785214402\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376385473635118\n\nLearning Rate: 0.0003266599379917521\nEpoch 991, Training Loss: 0.17194121066041343, Validation Loss: 0.19263668913342352\nEpoch 991, Training Loss: 0.17129259916950781, Validation Loss: 0.19263668913342352\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434660728893243\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376385473635118\n\nLearning Rate: 0.0003229894397124905\nEpoch 1001, Training Loss: 0.1719027530206068, Validation Loss: 0.1926368081695767\nEpoch 1001, Training Loss: 0.17126390413154938, Validation Loss: 0.1926368081695767\nTraining Accuracy: 0.9464574985079717, Training F1 Score: 0.9434917818147951\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376385473635118\n\nLearning Rate: 0.0003193601848060798\nEpoch 1011, Training Loss: 0.17186715619103904, Validation Loss: 0.1926252971965075\nEpoch 1011, Training Loss: 0.17124058721637675, Validation Loss: 0.1926252971965075\nTraining Accuracy: 0.9464940379766879, Training F1 Score: 0.9435292948863171\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376385473635118\n\nLearning Rate: 0.00031577170984339555\nEpoch 1021, Training Loss: 0.17184019620012903, Validation Loss: 0.1926242562206275\nEpoch 1021, Training Loss: 0.17121174635528427, Validation Loss: 0.1926242562206275\nTraining Accuracy: 0.9465183976224986, Training F1 Score: 0.9435508039005143\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9376385473635118\n\nLearning Rate: 0.0003122235566026117\nEpoch 1031, Training Loss: 0.17181276754072047, Validation Loss: 0.19268572957032504\nEpoch 1031, Training Loss: 0.1711870906772334, Validation Loss: 0.19268572957032504\nTraining Accuracy: 0.9465183976224986, Training F1 Score: 0.9435550042899655\nValidation Accuracy: 0.9410281705579305, Validation F1 Score: 0.9377438181729418\n\nLearning Rate: 0.0003087152720106892\nEpoch 1041, Training Loss: 0.1717865895949759, Validation Loss: 0.19269150896192863\nEpoch 1041, Training Loss: 0.17115673248216665, Validation Loss: 0.19269150896192863\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434576578881503\nValidation Accuracy: 0.9410281705579305, Validation F1 Score: 0.9377438181729418\n\nLearning Rate: 0.00030524640808552166\nEpoch 1051, Training Loss: 0.1717554595225543, Validation Loss: 0.19270013857015872\nEpoch 1051, Training Loss: 0.1711289705406096, Validation Loss: 0.19270013857015872\nTraining Accuracy: 0.9464087792163502, Training F1 Score: 0.9434277332304968\nValidation Accuracy: 0.9412473966896854, Validation F1 Score: 0.9379336060210325\n\nLearning Rate: 0.0003018165218787319\nEpoch 1061, Training Loss: 0.1717278619841658, Validation Loss: 0.19267912510552584\nEpoch 1061, Training Loss: 0.17110839182501647, Validation Loss: 0.19267912510552584\nTraining Accuracy: 0.9464209590392556, Training F1 Score: 0.9434395375672017\nValidation Accuracy: 0.9412473966896854, Validation F1 Score: 0.9379336060210325\n\nLearning Rate: 0.0002984251754191101\nEpoch 1071, Training Loss: 0.17169828976142096, Validation Loss: 0.192669157816315\nEpoch 1071, Training Loss: 0.17107612689512794, Validation Loss: 0.192669157816315\nTraining Accuracy: 0.9463965993934448, Training F1 Score: 0.9434117151592003\nValidation Accuracy: 0.9412473966896854, Validation F1 Score: 0.9379336060210325\n\nLearning Rate: 0.0002950719356566883\nEpoch 1081, Training Loss: 0.17166812098949133, Validation Loss: 0.19264944696438152\nEpoch 1081, Training Loss: 0.17105124900169355, Validation Loss: 0.19264944696438152\nTraining Accuracy: 0.9463844195705394, Training F1 Score: 0.9433999110303113\nValidation Accuracy: 0.941137783623808, Validation F1 Score: 0.9378073559600795\n\nLearning Rate: 0.00029175637440744315\nEpoch 1091, Training Loss: 0.17163525663265705, Validation Loss: 0.1926482020534602\nEpoch 1091, Training Loss: 0.1710295138272766, Validation Loss: 0.1926482020534602\nTraining Accuracy: 0.9463844195705394, Training F1 Score: 0.9433978030810414\nValidation Accuracy: 0.941137783623808, Validation F1 Score: 0.9378073559600795\n\nLearning Rate: 0.00028847806829862\nEpoch 1101, Training Loss: 0.17161439575637233, Validation Loss: 0.19264074303654874\nEpoch 1101, Training Loss: 0.171002261518754, Validation Loss: 0.19264074303654874\nTraining Accuracy: 0.9463965993934448, Training F1 Score: 0.9434074993867546\nValidation Accuracy: 0.9410281705579305, Validation F1 Score: 0.937702014998723\n\nLearning Rate: 0.0002852365987146714\nEpoch 1111, Training Loss: 0.1715903395560854, Validation Loss: 0.19267230870384508\nEpoch 1111, Training Loss: 0.17098815862407055, Validation Loss: 0.19267230870384508\nTraining Accuracy: 0.9464087792163502, Training F1 Score: 0.9434171961937323\nValidation Accuracy: 0.9410281705579305, Validation F1 Score: 0.937702014998723\n\nLearning Rate: 0.00028203155174380263\nEpoch 1121, Training Loss: 0.17156616556542512, Validation Loss: 0.1926899209665936\nEpoch 1121, Training Loss: 0.17095604814043544, Validation Loss: 0.1926899209665936\nTraining Accuracy: 0.9464087792163502, Training F1 Score: 0.9434129784676907\nValidation Accuracy: 0.940918557492053, Validation F1 Score: 0.9375967036571468\n\nLearning Rate: 0.00027886251812511855\nEpoch 1131, Training Loss: 0.17153593456826602, Validation Loss: 0.19269423103314226\nEpoch 1131, Training Loss: 0.17093799687597944, Validation Loss: 0.19269423103314226\nTraining Accuracy: 0.9464209590392556, Training F1 Score: 0.9434247847024999\nValidation Accuracy: 0.9408089444261756, Validation F1 Score: 0.9374704239764133\n\nLearning Rate: 0.0002757290931963639\nEpoch 1141, Training Loss: 0.1715077539594894, Validation Loss: 0.19268615181072624\nEpoch 1141, Training Loss: 0.17090999703491472, Validation Loss: 0.19268615181072624\nTraining Accuracy: 0.9464453186850663, Training F1 Score: 0.9434547218214917\nValidation Accuracy: 0.9408089444261756, Validation F1 Score: 0.9374704239764133\n\nLearning Rate: 0.0002726308768422507\nEpoch 1151, Training Loss: 0.17148747950323695, Validation Loss: 0.19268936571989434\nEpoch 1151, Training Loss: 0.17089248101331558, Validation Loss: 0.19268936571989434\nTraining Accuracy: 0.9463844195705394, Training F1 Score: 0.9433851466481354\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9372388329541037\n\nLearning Rate: 0.000269567473443367\nEpoch 1161, Training Loss: 0.1714565822018611, Validation Loss: 0.19269186929301135\nEpoch 1161, Training Loss: 0.1708699098006861, Validation Loss: 0.19269186929301135\nTraining Accuracy: 0.9464087792163502, Training F1 Score: 0.9434129784676907\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9372388329541037\n\nLearning Rate: 0.00026653849182565857\nEpoch 1171, Training Loss: 0.17142790615828687, Validation Loss: 0.19269118337245492\nEpoch 1171, Training Loss: 0.1708493523143882, Validation Loss: 0.19269118337245492\nTraining Accuracy: 0.9463722397476341, Training F1 Score: 0.9433712298630015\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9372388329541037\n\nLearning Rate: 0.0002635435452104793\nEpoch 1181, Training Loss: 0.1714068450997486, Validation Loss: 0.19269652397933398\nEpoch 1181, Training Loss: 0.17082675472385575, Validation Loss: 0.19269652397933398\nTraining Accuracy: 0.9463478801018234, Training F1 Score: 0.9433412816150676\nValidation Accuracy: 0.9406993313602982, Validation F1 Score: 0.9373440960417186\n\nLearning Rate: 0.00026058225116520217\nEpoch 1191, Training Loss: 0.17137745834176754, Validation Loss: 0.19272496688232654\nEpoch 1191, Training Loss: 0.1708135072253005, Validation Loss: 0.19272496688232654\nTraining Accuracy: 0.9463844195705394, Training F1 Score: 0.9433809245063053\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9371124660825385\n\nLearning Rate: 0.0002576542315543855\nEpoch 1201, Training Loss: 0.17135494493536366, Validation Loss: 0.19275495714750857\nEpoch 1201, Training Loss: 0.17079795827150138, Validation Loss: 0.19275495714750857\nTraining Accuracy: 0.9463235204560125, Training F1 Score: 0.9433155568848135\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9371124660825385\n\nLearning Rate: 0.000254759112491488\nEpoch 1211, Training Loss: 0.17133178433092724, Validation Loss: 0.1927619943421595\nEpoch 1211, Training Loss: 0.17077670673153736, Validation Loss: 0.1927619943421595\nTraining Accuracy: 0.9463478801018234, Training F1 Score: 0.9433391682715095\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 0.0002518965242911258\nEpoch 1221, Training Loss: 0.1713094244959781, Validation Loss: 0.19277915684399108\nEpoch 1221, Training Loss: 0.17076096806620794, Validation Loss: 0.19277915684399108\nTraining Accuracy: 0.9463600599247287, Training F1 Score: 0.9433509745281196\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 0.0002490661014218668\nEpoch 1231, Training Loss: 0.17128437445504732, Validation Loss: 0.1927815904046809\nEpoch 1231, Training Loss: 0.17073747034611722, Validation Loss: 0.1927815904046809\nTraining Accuracy: 0.9463235204560125, Training F1 Score: 0.9433134425817352\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 0.0002462674824595549\nEpoch 1241, Training Loss: 0.17126151762246003, Validation Loss: 0.19277694236124135\nEpoch 1241, Training Loss: 0.17071921139265483, Validation Loss: 0.19277694236124135\nTraining Accuracy: 0.9463357002789179, Training F1 Score: 0.9433231339093368\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368595872260256\n\nLearning Rate: 0.00024350031004115837\nEpoch 1251, Training Loss: 0.17124026486521907, Validation Loss: 0.1927673294429754\nEpoch 1251, Training Loss: 0.17069986469653176, Validation Loss: 0.1927673294429754\nTraining Accuracy: 0.9463357002789179, Training F1 Score: 0.9433231339093368\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.0002407642308191378\nEpoch 1261, Training Loss: 0.17122216701011003, Validation Loss: 0.19276038433073853\nEpoch 1261, Training Loss: 0.17068168492051813, Validation Loss: 0.19276038433073853\nTraining Accuracy: 0.9463235204560125, Training F1 Score: 0.9433113278613473\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.000238058895416326\nEpoch 1271, Training Loss: 0.1712008632737031, Validation Loss: 0.19276998987764196\nEpoch 1271, Training Loss: 0.17066958474621866, Validation Loss: 0.19276998987764196\nTraining Accuracy: 0.9463113406331072, Training F1 Score: 0.9432974067799264\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00023538395838131496\nEpoch 1281, Training Loss: 0.17117441762866936, Validation Loss: 0.19276742461407692\nEpoch 1281, Training Loss: 0.17065407817333073, Validation Loss: 0.19276742461407692\nTraining Accuracy: 0.9463357002789179, Training F1 Score: 0.9433189037587926\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00023273907814434438\nEpoch 1291, Training Loss: 0.17116012363511923, Validation Loss: 0.1927573710098531\nEpoch 1291, Training Loss: 0.17063468180116506, Validation Loss: 0.1927573710098531\nTraining Accuracy: 0.9463357002789179, Training F1 Score: 0.9433189037587926\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00023012391697368586\nEpoch 1301, Training Loss: 0.17113305306765822, Validation Loss: 0.19276598662507125\nEpoch 1301, Training Loss: 0.17061401779977778, Validation Loss: 0.19276598662507125\nTraining Accuracy: 0.9463478801018234, Training F1 Score: 0.9433285952949373\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00022753814093251674\nEpoch 1311, Training Loss: 0.17111461417772414, Validation Loss: 0.19275196093772307\nEpoch 1311, Training Loss: 0.17060101185855034, Validation Loss: 0.19275196093772307\nTraining Accuracy: 0.9463235204560125, Training F1 Score: 0.9433028648047194\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368595872260256\n\nLearning Rate: 0.0002249814198362791\nEpoch 1321, Training Loss: 0.17108898555782492, Validation Loss: 0.19278047602551424\nEpoch 1321, Training Loss: 0.17058250221174012, Validation Loss: 0.19278047602551424\nTraining Accuracy: 0.9462991608102018, Training F1 Score: 0.9432792516655861\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367330751169637\n\nLearning Rate: 0.00022245342721051746\nEpoch 1331, Training Loss: 0.17106517677402058, Validation Loss: 0.19278292489243903\nEpoch 1331, Training Loss: 0.17056620588692809, Validation Loss: 0.19278292489243903\nTraining Accuracy: 0.9463113406331072, Training F1 Score: 0.9432889409674786\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368595872260256\n\nLearning Rate: 0.00021995384024919046\nEpoch 1341, Training Loss: 0.17103959055862672, Validation Loss: 0.19279180283702205\nEpoch 1341, Training Loss: 0.17054812338290262, Validation Loss: 0.19279180283702205\nTraining Accuracy: 0.9462991608102018, Training F1 Score: 0.9432771343145016\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368595872260256\n\nLearning Rate: 0.000217482339773451\nEpoch 1351, Training Loss: 0.17102035206983845, Validation Loss: 0.19279584005698816\nEpoch 1351, Training Loss: 0.17052850624857194, Validation Loss: 0.19279584005698816\nTraining Accuracy: 0.9463113406331072, Training F1 Score: 0.9432868234697401\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367330751169637\n\nLearning Rate: 0.0002150386101908892\nEpoch 1361, Training Loss: 0.17099819462845978, Validation Loss: 0.19279136746602402\nEpoch 1361, Training Loss: 0.17050655732834735, Validation Loss: 0.19279136746602402\nTraining Accuracy: 0.9462869809872965, Training F1 Score: 0.943263209996956\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367330751169637\n\nLearning Rate: 0.0002126223394552338\nEpoch 1371, Training Loss: 0.17097477649072984, Validation Loss: 0.19279051545052286\nEpoch 1371, Training Loss: 0.17048406589409162, Validation Loss: 0.19279051545052286\nTraining Accuracy: 0.9463600599247287, Training F1 Score: 0.9433382873322903\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367330751169637\n\nLearning Rate: 0.0002102332190265061\nEpoch 1381, Training Loss: 0.1709506071933101, Validation Loss: 0.19280112761227064\nEpoch 1381, Training Loss: 0.1704698378859534, Validation Loss: 0.19280112761227064\nTraining Accuracy: 0.9463722397476341, Training F1 Score: 0.9433522108980475\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00020787094383162158\nEpoch 1391, Training Loss: 0.17093066221709874, Validation Loss: 0.1928252956198977\nEpoch 1391, Training Loss: 0.17045340935873182, Validation Loss: 0.1928252956198977\nTraining Accuracy: 0.9463600599247287, Training F1 Score: 0.9433382873322903\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00020553521222543448\nEpoch 1401, Training Loss: 0.17091045443466307, Validation Loss: 0.19282021339454763\nEpoch 1401, Training Loss: 0.1704342872798773, Validation Loss: 0.19282021339454763\nTraining Accuracy: 0.9463600599247287, Training F1 Score: 0.9433382873322903\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00020322572595221972\nEpoch 1411, Training Loss: 0.17089498050029653, Validation Loss: 0.19280506551566254\nEpoch 1411, Training Loss: 0.17041546180206357, Validation Loss: 0.19280506551566254\nTraining Accuracy: 0.9463844195705394, Training F1 Score: 0.9433619042306033\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365013281393699\n\nLearning Rate: 0.00020094219010758805\nEpoch 1421, Training Loss: 0.1708708575873532, Validation Loss: 0.19281430889231768\nEpoch 1421, Training Loss: 0.1704033234796444, Validation Loss: 0.19281430889231768\nTraining Accuracy: 0.9464087792163502, Training F1 Score: 0.9433855226334098\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00019868431310082884\nEpoch 1431, Training Loss: 0.1708543432316719, Validation Loss: 0.192811824697407\nEpoch 1431, Training Loss: 0.1703875301642614, Validation Loss: 0.192811824697407\nTraining Accuracy: 0.9463722397476341, Training F1 Score: 0.9433458637311747\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00019645180661767605\nEpoch 1441, Training Loss: 0.17082656687063744, Validation Loss: 0.1928096063746233\nEpoch 1441, Training Loss: 0.17036897053414007, Validation Loss: 0.1928096063746233\nTraining Accuracy: 0.9464209590392556, Training F1 Score: 0.9433973323991454\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00019424438558349273\nEpoch 1451, Training Loss: 0.17080997990103844, Validation Loss: 0.1928012843317177\nEpoch 1451, Training Loss: 0.1703480876281738, Validation Loss: 0.1928012843317177\nTraining Accuracy: 0.9464209590392556, Training F1 Score: 0.9433952177641727\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.0001920617681268689\nEpoch 1461, Training Loss: 0.1707873424882902, Validation Loss: 0.19279978448076102\nEpoch 1461, Training Loss: 0.17032397741814234, Validation Loss: 0.19279978448076102\nTraining Accuracy: 0.9464453186850663, Training F1 Score: 0.9434209530595743\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365013281393699\n\nLearning Rate: 0.00018990367554362899\nEpoch 1471, Training Loss: 0.17076002003797294, Validation Loss: 0.19281195170926665\nEpoch 1471, Training Loss: 0.17030762988058218, Validation Loss: 0.19281195170926665\nTraining Accuracy: 0.9464818581537825, Training F1 Score: 0.9434648357994709\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365013281393699\n\nLearning Rate: 0.0001877698322612429\nEpoch 1481, Training Loss: 0.170736307611611, Validation Loss: 0.19281882269463754\nEpoch 1481, Training Loss: 0.17028616214973002, Validation Loss: 0.19281882269463754\nTraining Accuracy: 0.9464818581537825, Training F1 Score: 0.9434669469886658\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365013281393699\n\nLearning Rate: 0.00018565996580363788\nEpoch 1491, Training Loss: 0.1707152502001847, Validation Loss: 0.1928239682976985\nEpoch 1491, Training Loss: 0.1702682451734069, Validation Loss: 0.1928239682976985\nTraining Accuracy: 0.9464574985079717, Training F1 Score: 0.9434412150573906\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9363961713524552\n\nLearning Rate: 0.00018357380675640495\nEpoch 1501, Training Loss: 0.1706924301238434, Validation Loss: 0.19283881173588055\nEpoch 1501, Training Loss: 0.17025078541497565, Validation Loss: 0.19283881173588055\nTraining Accuracy: 0.9464574985079717, Training F1 Score: 0.943443326790616\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9363961713524552\n\nLearning Rate: 0.00018151108873239706\nEpoch 1511, Training Loss: 0.1706739879022331, Validation Loss: 0.1928305786328006\nEpoch 1511, Training Loss: 0.17023279763386212, Validation Loss: 0.1928305786328006\nTraining Accuracy: 0.946469678330877, Training F1 Score: 0.9434551367015487\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.000179471548337713\nEpoch 1521, Training Loss: 0.17065220245230048, Validation Loss: 0.19279484849520764\nEpoch 1521, Training Loss: 0.17021691536034536, Validation Loss: 0.19279484849520764\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434175958200933\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.0001774549251380642\nEpoch 1531, Training Loss: 0.1706337519117539, Validation Loss: 0.19280112001060407\nEpoch 1531, Training Loss: 0.17020176608428195, Validation Loss: 0.19280112001060407\nTraining Accuracy: 0.946469678330877, Training F1 Score: 0.9434530252403034\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.0001754609616255192\nEpoch 1541, Training Loss: 0.1706099407235236, Validation Loss: 0.19279294073823433\nEpoch 1541, Training Loss: 0.17018447819003574, Validation Loss: 0.19279294073823433\nTraining Accuracy: 0.9464453186850663, Training F1 Score: 0.9434294052506735\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9363961713524552\n\nLearning Rate: 0.0001734894031856216\nEpoch 1551, Training Loss: 0.1705996681717533, Validation Loss: 0.19278787513560897\nEpoch 1551, Training Loss: 0.17017002184110824, Validation Loss: 0.19278787513560897\nTraining Accuracy: 0.9464087792163502, Training F1 Score: 0.9433939780871089\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.00017153999806487788\nEpoch 1561, Training Loss: 0.17057631261171324, Validation Loss: 0.1927745593841382\nEpoch 1561, Training Loss: 0.17015472310242152, Validation Loss: 0.1927745593841382\nTraining Accuracy: 0.9464209590392556, Training F1 Score: 0.9434057867655913\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.00016961249733861013\nEpoch 1571, Training Loss: 0.17056216053882386, Validation Loss: 0.19276603917849242\nEpoch 1571, Training Loss: 0.17013638973789277, Validation Loss: 0.19276603917849242\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434197080970693\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9363961713524552\n\nLearning Rate: 0.00016770665487917037\nEpoch 1581, Training Loss: 0.17054019049003297, Validation Loss: 0.19276070981894383\nEpoch 1581, Training Loss: 0.17012388545759757, Validation Loss: 0.19276070981894383\nTraining Accuracy: 0.9464574985079717, Training F1 Score: 0.943443326790616\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.0001658222273245118\nEpoch 1591, Training Loss: 0.17052400468696088, Validation Loss: 0.19275332481129628\nEpoch 1591, Training Loss: 0.17010532835404735, Validation Loss: 0.19275332481129628\nTraining Accuracy: 0.9464574985079717, Training F1 Score: 0.943443326790616\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9363961713524552\n\nLearning Rate: 0.0001639589740471132\nEpoch 1601, Training Loss: 0.17050354715276575, Validation Loss: 0.19276588985000828\nEpoch 1601, Training Loss: 0.17009143647423874, Validation Loss: 0.19276588985000828\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434175958200933\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9363961713524552\n\nLearning Rate: 0.00016211665712325267\nEpoch 1611, Training Loss: 0.17048524926313885, Validation Loss: 0.1927648970191055\nEpoch 1611, Training Loss: 0.17007696816452633, Validation Loss: 0.1927648970191055\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434175958200933\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9363961713524552\n\nLearning Rate: 0.0001602950413026265\nEpoch 1621, Training Loss: 0.17046792924780924, Validation Loss: 0.19274740372554233\nEpoch 1621, Training Loss: 0.1700607658529866, Validation Loss: 0.19274740372554233\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434154831261155\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.00015849389397830927\nEpoch 1631, Training Loss: 0.1704526575650852, Validation Loss: 0.1927583031956595\nEpoch 1631, Training Loss: 0.17004554158725552, Validation Loss: 0.1927583031956595\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434154831261155\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.000156712985157052\nEpoch 1641, Training Loss: 0.1704369055710543, Validation Loss: 0.192739079111725\nEpoch 1641, Training Loss: 0.17003422852396818, Validation Loss: 0.192739079111725\nTraining Accuracy: 0.9464209590392556, Training F1 Score: 0.9434015604168591\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.0001549520874299134\nEpoch 1651, Training Loss: 0.17041977029723687, Validation Loss: 0.1927448176709129\nEpoch 1651, Training Loss: 0.17001946554956918, Validation Loss: 0.1927448176709129\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434154831261155\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.00015321097594322153\nEpoch 1661, Training Loss: 0.1704039369968384, Validation Loss: 0.19274663988872015\nEpoch 1661, Training Loss: 0.1700073474464339, Validation Loss: 0.19274663988872015\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434154831261155\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.9365227129991971\n\nLearning Rate: 0.00015148942836986162\nEpoch 1671, Training Loss: 0.17038686082020993, Validation Loss: 0.19272462983318528\nEpoch 1671, Training Loss: 0.16999227689154456, Validation Loss: 0.19272462983318528\nTraining Accuracy: 0.946433138862161, Training F1 Score: 0.9434133700150371\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 0.00014978722488088667\nEpoch 1681, Training Loss: 0.17037048324801568, Validation Loss: 0.19271472446635982\nEpoch 1681, Training Loss: 0.16997798337895223, Validation Loss: 0.19271472446635982\nTraining Accuracy: 0.9464574985079717, Training F1 Score: 0.9434391029072537\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00014810414811744667\nEpoch 1691, Training Loss: 0.17035628519810278, Validation Loss: 0.1927107682399134\nEpoch 1691, Training Loss: 0.16996737521284194, Validation Loss: 0.1927107682399134\nTraining Accuracy: 0.9464453186850663, Training F1 Score: 0.9434230667331308\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00014643998316303368\nEpoch 1701, Training Loss: 0.1703409387914176, Validation Loss: 0.19270594285419868\nEpoch 1701, Training Loss: 0.16995405035322494, Validation Loss: 0.19270594285419868\nTraining Accuracy: 0.9464940379766879, Training F1 Score: 0.9434766467349514\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00014479451751603842\nEpoch 1711, Training Loss: 0.17032534937218968, Validation Loss: 0.1926989007316947\nEpoch 1711, Training Loss: 0.1699411295839952, Validation Loss: 0.1926989007316947\nTraining Accuracy: 0.9464940379766879, Training F1 Score: 0.9434766467349514\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00014316754106261562\nEpoch 1721, Training Loss: 0.1703101378309682, Validation Loss: 0.19270960900862724\nEpoch 1721, Training Loss: 0.16992956058727965, Validation Loss: 0.19270960900862724\nTraining Accuracy: 0.9464818581537825, Training F1 Score: 0.9434627241934553\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.0001415588460498537\nEpoch 1731, Training Loss: 0.1702972102138071, Validation Loss: 0.1927055622743277\nEpoch 1731, Training Loss: 0.16991663644426716, Validation Loss: 0.1927055622743277\nTraining Accuracy: 0.9464940379766879, Training F1 Score: 0.9434745354011017\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00013996822705924649\nEpoch 1741, Training Loss: 0.17028131348197328, Validation Loss: 0.19273537607761665\nEpoch 1741, Training Loss: 0.16990691929456328, Validation Loss: 0.19273537607761665\nTraining Accuracy: 0.9465427572683093, Training F1 Score: 0.9435238942411808\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00013839548098046277\nEpoch 1751, Training Loss: 0.17026940812806476, Validation Loss: 0.1927363460414519\nEpoch 1751, Training Loss: 0.16989139762613462, Validation Loss: 0.1927363460414519\nTraining Accuracy: 0.9464818581537825, Training F1 Score: 0.9434606121705199\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00013684040698541043\nEpoch 1761, Training Loss: 0.17025624916385593, Validation Loss: 0.19272903259792545\nEpoch 1761, Training Loss: 0.16988275051984483, Validation Loss: 0.19272903259792545\nTraining Accuracy: 0.9464818581537825, Training F1 Score: 0.9434542735992049\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00013530280650259245\nEpoch 1771, Training Loss: 0.1702394721342591, Validation Loss: 0.19274189308894957\nEpoch 1771, Training Loss: 0.16987312562201878, Validation Loss: 0.19274189308894957\nTraining Accuracy: 0.9464940379766879, Training F1 Score: 0.9434660858959676\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00013378248319175051\nEpoch 1781, Training Loss: 0.1702252809444377, Validation Loss: 0.1927425541121696\nEpoch 1781, Training Loss: 0.16986144209691262, Validation Loss: 0.1927425541121696\nTraining Accuracy: 0.9464940379766879, Training F1 Score: 0.9434660858959676\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00013227924291879403\nEpoch 1791, Training Loss: 0.1702118094440584, Validation Loss: 0.1927241209853993\nEpoch 1791, Training Loss: 0.16984922743723654, Validation Loss: 0.1927241209853993\nTraining Accuracy: 0.9464818581537825, Training F1 Score: 0.9434542735992049\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00013079289373101047\nEpoch 1801, Training Loss: 0.17019947745264308, Validation Loss: 0.19272730964605816\nEpoch 1801, Training Loss: 0.16984135745437134, Validation Loss: 0.19272730964605816\nTraining Accuracy: 0.9464818581537825, Training F1 Score: 0.9434542735992049\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00012932324583255454\nEpoch 1811, Training Loss: 0.1701883054482853, Validation Loss: 0.1927262305442432\nEpoch 1811, Training Loss: 0.1698286621031595, Validation Loss: 0.1927262305442432\nTraining Accuracy: 0.9464940379766879, Training F1 Score: 0.9434681988979098\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00012787011156021255\nEpoch 1821, Training Loss: 0.17017512356126538, Validation Loss: 0.192733082319644\nEpoch 1821, Training Loss: 0.16981912362491752, Validation Loss: 0.192733082319644\nTraining Accuracy: 0.9465062177995932, Training F1 Score: 0.9434778985694527\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.0001264333053594393\nEpoch 1831, Training Loss: 0.17016303327110216, Validation Loss: 0.19273584551074507\nEpoch 1831, Training Loss: 0.16981228067005394, Validation Loss: 0.19273584551074507\nTraining Accuracy: 0.9465062177995932, Training F1 Score: 0.9434757854227023\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00012501264376066408\nEpoch 1841, Training Loss: 0.17015231939918204, Validation Loss: 0.19273026610634691\nEpoch 1841, Training Loss: 0.16980078924856248, Validation Loss: 0.19273026610634691\nTraining Accuracy: 0.9464818581537825, Training F1 Score: 0.9434521599075993\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.0001236079453558629\nEpoch 1851, Training Loss: 0.17014151595205027, Validation Loss: 0.19272016947120216\nEpoch 1851, Training Loss: 0.16979230761806788, Validation Loss: 0.19272016947120216\nTraining Accuracy: 0.9465427572683093, Training F1 Score: 0.943515450762685\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00012221903077539413\nEpoch 1861, Training Loss: 0.17012745870316465, Validation Loss: 0.1927098485460593\nEpoch 1861, Training Loss: 0.16978267188961696, Validation Loss: 0.1927098485460593\nTraining Accuracy: 0.9465305774454039, Training F1 Score: 0.9435057489987503\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00012084572266509432\nEpoch 1871, Training Loss: 0.17011513676213363, Validation Loss: 0.19270882241580617\nEpoch 1871, Training Loss: 0.1697744828409895, Validation Loss: 0.19270882241580617\nTraining Accuracy: 0.9465427572683093, Training F1 Score: 0.9435175622575466\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00011948784566363123\nEpoch 1881, Training Loss: 0.1701054241154651, Validation Loss: 0.19270941636991726\nEpoch 1881, Training Loss: 0.16976667067487655, Validation Loss: 0.19270941636991726\nTraining Accuracy: 0.9465671169141201, Training F1 Score: 0.9435433004383359\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00011814522638011164\nEpoch 1891, Training Loss: 0.17009477782355878, Validation Loss: 0.19270153126603715\nEpoch 1891, Training Loss: 0.16975803032177858, Validation Loss: 0.19270153126603715\nTraining Accuracy: 0.9465792967370255, Training F1 Score: 0.9435572243982961\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 0.00011681769337194054\nEpoch 1901, Training Loss: 0.1700837751651637, Validation Loss: 0.19271116531837357\nEpoch 1901, Training Loss: 0.16975129914023418, Validation Loss: 0.19271116531837357\nTraining Accuracy: 0.9465671169141201, Training F1 Score: 0.9435454105543204\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.00011550507712292916\nEpoch 1911, Training Loss: 0.17007465203462513, Validation Loss: 0.19272024116272546\nEpoch 1911, Training Loss: 0.16974258639318865, Validation Loss: 0.19272024116272546\nTraining Accuracy: 0.9465792967370255, Training F1 Score: 0.9435572243982961\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.00011420721002164905\nEpoch 1921, Training Loss: 0.17006501198299892, Validation Loss: 0.19272490609186096\nEpoch 1921, Training Loss: 0.1697343423170011, Validation Loss: 0.19272490609186096\nTraining Accuracy: 0.9465914765599308, Training F1 Score: 0.943571147773124\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.0001129239263400293\nEpoch 1931, Training Loss: 0.1700566941894132, Validation Loss: 0.19271950700572352\nEpoch 1931, Training Loss: 0.1697270622769571, Validation Loss: 0.19271950700572352\nTraining Accuracy: 0.9466036563828362, Training F1 Score: 0.9435829620980689\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.00011165506221219427\nEpoch 1941, Training Loss: 0.17004355497677945, Validation Loss: 0.19273104198594684\nEpoch 1941, Training Loss: 0.16971906491414626, Validation Loss: 0.19273104198594684\nTraining Accuracy: 0.9465914765599308, Training F1 Score: 0.943571147773124\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.0001104004556135392\nEpoch 1951, Training Loss: 0.17003501104101673, Validation Loss: 0.19271292596006817\nEpoch 1951, Training Loss: 0.16971208343037258, Validation Loss: 0.19271292596006817\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.9435989927677182\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.00010915994634004076\nEpoch 1961, Training Loss: 0.17002580940274042, Validation Loss: 0.1927080804758345\nEpoch 1961, Training Loss: 0.1697055683251939, Validation Loss: 0.1927080804758345\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.9435989927677182\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.00010793337598780022\nEpoch 1971, Training Loss: 0.17001613642256622, Validation Loss: 0.192713066311595\nEpoch 1971, Training Loss: 0.16969813851870647, Validation Loss: 0.192713066311595\nTraining Accuracy: 0.9465914765599308, Training F1 Score: 0.9435753648319837\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.0001067205879328165\nEpoch 1981, Training Loss: 0.1700079678923239, Validation Loss: 0.19270809075621467\nEpoch 1981, Training Loss: 0.16969143536284453, Validation Loss: 0.19270809075621467\nTraining Accuracy: 0.9466036563828362, Training F1 Score: 0.9435892862438691\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.936544059887175\n\nLearning Rate: 0.00010552142731098633\nEpoch 1991, Training Loss: 0.16999877313355885, Validation Loss: 0.19270190837501394\nEpoch 1991, Training Loss: 0.16968434217707862, Validation Loss: 0.19270190837501394\nTraining Accuracy: 0.9466036563828362, Training F1 Score: 0.9435892862438691\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.936544059887175\n\nLearning Rate: 0.00010433574099832932\nEpoch 2001, Training Loss: 0.16998767573845835, Validation Loss: 0.19270701521839553\nEpoch 2001, Training Loss: 0.16967847435505293, Validation Loss: 0.19270701521839553\nTraining Accuracy: 0.9466036563828362, Training F1 Score: 0.9435913934601976\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 0.00010316337759143513\nEpoch 2011, Training Loss: 0.16997875854878075, Validation Loss: 0.1926958940651259\nEpoch 2011, Training Loss: 0.16967096348394728, Validation Loss: 0.1926958940651259\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.9436074197106371\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.936544059887175\n\nLearning Rate: 0.00010200418738813036\nEpoch 2021, Training Loss: 0.16996829514043763, Validation Loss: 0.1926888123646282\nEpoch 2021, Training Loss: 0.1696640948818736, Validation Loss: 0.1926888123646282\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943605313598746\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.936544059887175\n\nLearning Rate: 0.00010085802236836271\nEpoch 2031, Training Loss: 0.16995841933854983, Validation Loss: 0.19268441701698472\nEpoch 2031, Training Loss: 0.16965728352412165, Validation Loss: 0.19268441701698472\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943605313598746\nValidation Accuracy: 0.939932039899156, Validation F1 Score: 0.936544059887175\n\nLearning Rate: 9.97247361752999e-05\nEpoch 2041, Training Loss: 0.16995189978333192, Validation Loss: 0.19268289253002951\nEpoch 2041, Training Loss: 0.16965071541158708, Validation Loss: 0.19268289253002951\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943605313598746\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 9.860418409664096e-05\nEpoch 2051, Training Loss: 0.16994121684825006, Validation Loss: 0.19268446593780889\nEpoch 2051, Training Loss: 0.16964453090644585, Validation Loss: 0.19268446593780889\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436171273135461\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366492061641779\n\nLearning Rate: 9.749622304613755e-05\nEpoch 2061, Training Loss: 0.16993239445099637, Validation Loss: 0.19267272567338722\nEpoch 2061, Training Loss: 0.16963726462887282, Validation Loss: 0.19267272567338722\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436289414050137\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 9.640071154532292e-05\nEpoch 2071, Training Loss: 0.16992379382319664, Validation Loss: 0.19267042285352243\nEpoch 2071, Training Loss: 0.16963338211038848, Validation Loss: 0.19267042285352243\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436289414050137\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 9.531750970544613e-05\nEpoch 2081, Training Loss: 0.1699161545880876, Validation Loss: 0.1926709670243942\nEpoch 2081, Training Loss: 0.1696289971371193, Validation Loss: 0.1926709670243942\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.943631046971505\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 9.424647920960926e-05\nEpoch 2091, Training Loss: 0.16990700159242986, Validation Loss: 0.19266542931319355\nEpoch 2091, Training Loss: 0.16962154370525942, Validation Loss: 0.19266542931319355\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436428611668943\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 9.318748329510543e-05\nEpoch 2101, Training Loss: 0.16989876134012896, Validation Loss: 0.19265505287987772\nEpoch 2101, Training Loss: 0.16961594355402843, Validation Loss: 0.19265505287987772\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436289414050137\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 9.214038673595515e-05\nEpoch 2111, Training Loss: 0.16989169121728712, Validation Loss: 0.1926482492167869\nEpoch 2111, Training Loss: 0.16960992845220182, Validation Loss: 0.1926482492167869\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436171273135461\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 9.110505582563898e-05\nEpoch 2121, Training Loss: 0.1698822995064899, Validation Loss: 0.19264072980141675\nEpoch 2121, Training Loss: 0.1696048523600165, Validation Loss: 0.19264072980141675\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436289414050137\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 9.008135836002418e-05\nEpoch 2131, Training Loss: 0.16987483199127856, Validation Loss: 0.19264110677155777\nEpoch 2131, Training Loss: 0.16959920582576102, Validation Loss: 0.19264110677155777\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436289414050137\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.906916362048325e-05\nEpoch 2141, Training Loss: 0.16986648111759772, Validation Loss: 0.19263406189357216\nEpoch 2141, Training Loss: 0.16959398351206337, Validation Loss: 0.19263406189357216\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436171273135461\nValidation Accuracy: 0.9400416529650334, Validation F1 Score: 0.9366278792892403\n\nLearning Rate: 8.806834235720207e-05\nEpoch 2151, Training Loss: 0.1698600408008104, Validation Loss: 0.19263679210709517\nEpoch 2151, Training Loss: 0.16958750058568303, Validation Loss: 0.19263679210709517\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436171273135461\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.707876677267569e-05\nEpoch 2161, Training Loss: 0.1698507391781255, Validation Loss: 0.19264061235779148\nEpoch 2161, Training Loss: 0.16958255167071506, Validation Loss: 0.19264061235779148\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943605313598746\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.610031050538955e-05\nEpoch 2171, Training Loss: 0.1698439764617217, Validation Loss: 0.19264274222585803\nEpoch 2171, Training Loss: 0.16957763053350944, Validation Loss: 0.19264274222585803\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436171273135461\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.513284861368397e-05\nEpoch 2181, Training Loss: 0.16983564607484616, Validation Loss: 0.1926374661808773\nEpoch 2181, Training Loss: 0.16957315965573475, Validation Loss: 0.1926374661808773\nTraining Accuracy: 0.9465914765599308, Training F1 Score: 0.9435774727370433\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.417625755980011e-05\nEpoch 2191, Training Loss: 0.16982984331388598, Validation Loss: 0.1926405165268117\nEpoch 2191, Training Loss: 0.16956771984439575, Validation Loss: 0.1926405165268117\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.9436032070710285\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.323041519410501e-05\nEpoch 2201, Training Loss: 0.1698221893654615, Validation Loss: 0.19264899280318745\nEpoch 2201, Training Loss: 0.16956303197752448, Validation Loss: 0.19264899280318745\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943605313598746\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.229520073949409e-05\nEpoch 2211, Training Loss: 0.16981381213783486, Validation Loss: 0.19263725290627226\nEpoch 2211, Training Loss: 0.16955605725765072, Validation Loss: 0.19263725290627226\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943605313598746\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.13704947759687e-05\nEpoch 2221, Training Loss: 0.1698076311460449, Validation Loss: 0.19264392124205765\nEpoch 2221, Training Loss: 0.16955167195950815, Validation Loss: 0.19264392124205765\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943605313598746\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 8.045617922538717e-05\nEpoch 2231, Training Loss: 0.16980057733819867, Validation Loss: 0.19264287695861967\nEpoch 2231, Training Loss: 0.16954738500961025, Validation Loss: 0.19264287695861967\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436192331527723\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 7.955213733638697e-05\nEpoch 2241, Training Loss: 0.16979234861363918, Validation Loss: 0.19263893350506384\nEpoch 2241, Training Loss: 0.1695427046643743, Validation Loss: 0.19263893350506384\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436331521223594\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 7.865825366947657e-05\nEpoch 2251, Training Loss: 0.16978562492069826, Validation Loss: 0.19264676055272628\nEpoch 2251, Training Loss: 0.16953693567391048, Validation Loss: 0.19264676055272628\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436352568576759\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367756509094846\n\nLearning Rate: 7.777441408229454e-05\nEpoch 2261, Training Loss: 0.16977892490503693, Validation Loss: 0.19263572937646717\nEpoch 2261, Training Loss: 0.16953285135352456, Validation Loss: 0.19263572937646717\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436352568576759\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367756509094846\n\nLearning Rate: 7.690050571503448e-05\nEpoch 2271, Training Loss: 0.1697715659801117, Validation Loss: 0.19263889964383696\nEpoch 2271, Training Loss: 0.16952810923370748, Validation Loss: 0.19263889964383696\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436352568576759\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367756509094846\n\nLearning Rate: 7.603641697603363e-05\nEpoch 2281, Training Loss: 0.16976433388230286, Validation Loss: 0.19264683167093954\nEpoch 2281, Training Loss: 0.16952404303907784, Validation Loss: 0.19264683167093954\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436352568576759\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367756509094846\n\nLearning Rate: 7.518203752752347e-05\nEpoch 2291, Training Loss: 0.16975876378748517, Validation Loss: 0.192643382080707\nEpoch 2291, Training Loss: 0.16951860423956513, Validation Loss: 0.192643382080707\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436213385763161\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367756509094846\n\nLearning Rate: 7.433725827154037e-05\nEpoch 2301, Training Loss: 0.1697526098598251, Validation Loss: 0.19263934877100944\nEpoch 2301, Training Loss: 0.16951478122354474, Validation Loss: 0.19263934877100944\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436331521223594\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367756509094846\n\nLearning Rate: 7.350197133599456e-05\nEpoch 2311, Training Loss: 0.16974585968516695, Validation Loss: 0.19264211712026758\nEpoch 2311, Training Loss: 0.16951046450399326, Validation Loss: 0.19264211712026758\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436331521223594\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367756509094846\n\nLearning Rate: 7.267607006089569e-05\nEpoch 2321, Training Loss: 0.16973896003971828, Validation Loss: 0.19264456747191838\nEpoch 2321, Training Loss: 0.16950614860715185, Validation Loss: 0.19264456747191838\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.9436095254068005\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 7.185944898473313e-05\nEpoch 2331, Training Loss: 0.16973268703108457, Validation Loss: 0.19264583737654448\nEpoch 2331, Training Loss: 0.1695017681118719, Validation Loss: 0.19264583737654448\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436213385763161\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 7.105200383100935e-05\nEpoch 2341, Training Loss: 0.16972653648537445, Validation Loss: 0.19265361119620728\nEpoch 2341, Training Loss: 0.16949749169585698, Validation Loss: 0.19265361119620728\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436213385763161\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 7.025363149492449e-05\nEpoch 2351, Training Loss: 0.16971906392555117, Validation Loss: 0.19266460140774833\nEpoch 2351, Training Loss: 0.1694934705295843, Validation Loss: 0.19266460140774833\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436213385763161\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.946423003021071e-05\nEpoch 2361, Training Loss: 0.16971290188494995, Validation Loss: 0.1926597851998945\nEpoch 2361, Training Loss: 0.1694894694174364, Validation Loss: 0.1926597851998945\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436213385763161\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.868369863611437e-05\nEpoch 2371, Training Loss: 0.16970646648808851, Validation Loss: 0.19266505328386901\nEpoch 2371, Training Loss: 0.1694862832013227, Validation Loss: 0.19266505328386901\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436352568576759\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.791193764452457e-05\nEpoch 2381, Training Loss: 0.16970264601497362, Validation Loss: 0.19266795948397678\nEpoch 2381, Training Loss: 0.16948249018908246, Validation Loss: 0.19266795948397678\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436213385763161\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.714884850724613e-05\nEpoch 2391, Training Loss: 0.16969554527581102, Validation Loss: 0.19266793667571033\nEpoch 2391, Training Loss: 0.16947876241286747, Validation Loss: 0.19266793667571033\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436352568576759\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.63943337834159e-05\nEpoch 2401, Training Loss: 0.1696899904458675, Validation Loss: 0.19266745705366997\nEpoch 2401, Training Loss: 0.16947483057461227, Validation Loss: 0.19266745705366997\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943611630687335\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.564829712706012e-05\nEpoch 2411, Training Loss: 0.16968288790066302, Validation Loss: 0.19266507625547166\nEpoch 2411, Training Loss: 0.1694699309059103, Validation Loss: 0.19266507625547166\nTraining Accuracy: 0.9466158362057415, Training F1 Score: 0.943611630687335\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.491064327479185e-05\nEpoch 2421, Training Loss: 0.16967657449048626, Validation Loss: 0.1926594858748811\nEpoch 2421, Training Loss: 0.16946444138223002, Validation Loss: 0.1926594858748811\nTraining Accuracy: 0.9466036563828362, Training F1 Score: 0.943599818166792\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.418127803364647e-05\nEpoch 2431, Training Loss: 0.16966995414248767, Validation Loss: 0.19266735351648845\nEpoch 2431, Training Loss: 0.1694607834483454, Validation Loss: 0.19266735351648845\nTraining Accuracy: 0.946628016028647, Training F1 Score: 0.9436276523538423\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.346010826905397e-05\nEpoch 2441, Training Loss: 0.16966399283696923, Validation Loss: 0.19267044573692355\nEpoch 2441, Training Loss: 0.1694564886711771, Validation Loss: 0.19267044573692355\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.943655484205049\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.274704189294635e-05\nEpoch 2451, Training Loss: 0.16965806236247838, Validation Loss: 0.19266999791970735\nEpoch 2451, Training Loss: 0.16945298341942908, Validation Loss: 0.19266999791970735\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436693992549194\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.204198785199862e-05\nEpoch 2461, Training Loss: 0.1696516783950683, Validation Loss: 0.19268187547963556\nEpoch 2461, Training Loss: 0.16945056486239818, Validation Loss: 0.19268187547963556\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436715009541277\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.134485611600201e-05\nEpoch 2471, Training Loss: 0.16964646361280664, Validation Loss: 0.1926805210730283\nEpoch 2471, Training Loss: 0.16944632610483348, Validation Loss: 0.1926805210730283\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436457743046431\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 6.065555766636775e-05\nEpoch 2481, Training Loss: 0.1696401914319648, Validation Loss: 0.19268734878247393\nEpoch 2481, Training Loss: 0.16944353564274744, Validation Loss: 0.19268734878247393\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.943643671645536\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.9974004484760035e-05\nEpoch 2491, Training Loss: 0.16963437630113332, Validation Loss: 0.19269863128577175\nEpoch 2491, Training Loss: 0.16943842797287023, Validation Loss: 0.19269863128577175\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.930010954185675e-05\nEpoch 2501, Training Loss: 0.16962836599654305, Validation Loss: 0.19270696156898848\nEpoch 2501, Training Loss: 0.1694337491104362, Validation Loss: 0.19270696156898848\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436715009541277\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 5.863378678623648e-05\nEpoch 2511, Training Loss: 0.1696230576683548, Validation Loss: 0.19271735043708893\nEpoch 2511, Training Loss: 0.16943121943092185, Validation Loss: 0.19271735043708893\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.797495113339034e-05\nEpoch 2521, Training Loss: 0.16961765777542318, Validation Loss: 0.19271797455776213\nEpoch 2521, Training Loss: 0.16942725725094557, Validation Loss: 0.19271797455776213\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 5.7323518454857354e-05\nEpoch 2531, Training Loss: 0.16961131268972957, Validation Loss: 0.19272503394326868\nEpoch 2531, Training Loss: 0.16942362464629443, Validation Loss: 0.19272503394326868\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436715009541277\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9367543819298567\n\nLearning Rate: 5.667940556748183e-05\nEpoch 2541, Training Loss: 0.1696056493597022, Validation Loss: 0.19273172250497528\nEpoch 2541, Training Loss: 0.1694205660555056, Validation Loss: 0.19273172250497528\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.604253022279151e-05\nEpoch 2551, Training Loss: 0.1696004380174684, Validation Loss: 0.19273522400181767\nEpoch 2551, Training Loss: 0.16941646018893677, Validation Loss: 0.19273522400181767\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436715009541277\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.541281109649504e-05\nEpoch 2561, Training Loss: 0.16959512426171694, Validation Loss: 0.19273097697977407\nEpoch 2561, Training Loss: 0.16941278060088066, Validation Loss: 0.19273097697977407\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.479016777809745e-05\nEpoch 2571, Training Loss: 0.1695892951426366, Validation Loss: 0.1927370018411804\nEpoch 2571, Training Loss: 0.16940939195852772, Validation Loss: 0.1927370018411804\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.417452076063233e-05\nEpoch 2581, Training Loss: 0.16958420935506824, Validation Loss: 0.19273626883406525\nEpoch 2581, Training Loss: 0.16940544965481258, Validation Loss: 0.19273626883406525\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.356579143050937e-05\nEpoch 2591, Training Loss: 0.1695791273089885, Validation Loss: 0.192739047677674\nEpoch 2591, Training Loss: 0.1694023804882157, Validation Loss: 0.192739047677674\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.943643671645536\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.296390205747601e-05\nEpoch 2601, Training Loss: 0.16957220307879273, Validation Loss: 0.19273695805891294\nEpoch 2601, Training Loss: 0.16939717064493676, Validation Loss: 0.19273695805891294\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.236877578469182e-05\nEpoch 2611, Training Loss: 0.16956620749078474, Validation Loss: 0.19274570716227094\nEpoch 2611, Training Loss: 0.16939312804119583, Validation Loss: 0.19274570716227094\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436693992549194\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.178033661891446e-05\nEpoch 2621, Training Loss: 0.16956044211821245, Validation Loss: 0.19274639018524325\nEpoch 2621, Training Loss: 0.169388735331766, Validation Loss: 0.19274639018524325\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.943643671645536\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.119850942079593e-05\nEpoch 2631, Training Loss: 0.16955469714841395, Validation Loss: 0.19275628130098557\nEpoch 2631, Training Loss: 0.1693852638512403, Validation Loss: 0.19275628130098557\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.943655484205049\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 5.0623219895287796e-05\nEpoch 2641, Training Loss: 0.16954902442065292, Validation Loss: 0.19275857319365883\nEpoch 2641, Training Loss: 0.16938124018090173, Validation Loss: 0.19275857319365883\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.943655484205049\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 5.0054394582154255e-05\nEpoch 2651, Training Loss: 0.16954421459776942, Validation Loss: 0.19276808269234533\nEpoch 2651, Training Loss: 0.16937765480394582, Validation Loss: 0.19276808269234533\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436693992549194\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9368808361233583\n\nLearning Rate: 4.949196084659187e-05\nEpoch 2661, Training Loss: 0.16953835250440472, Validation Loss: 0.19277744682018372\nEpoch 2661, Training Loss: 0.16937411509547448, Validation Loss: 0.19277744682018372\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.943655484205049\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.893584686995453e-05\nEpoch 2671, Training Loss: 0.16953281681041033, Validation Loss: 0.1927874987175443\nEpoch 2671, Training Loss: 0.16936986945386115, Validation Loss: 0.1927874987175443\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436533814034297\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.838598164058283e-05\nEpoch 2681, Training Loss: 0.1695268560971052, Validation Loss: 0.1927964804884139\nEpoch 2681, Training Loss: 0.16936502657974004, Validation Loss: 0.1927964804884139\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.9436415685713845\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.784229494473637e-05\nEpoch 2691, Training Loss: 0.16952081042469422, Validation Loss: 0.19279729054447958\nEpoch 2691, Training Loss: 0.16936200192206574, Validation Loss: 0.19279729054447958\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.943643671645536\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.730471735762798e-05\nEpoch 2701, Training Loss: 0.16951567044516186, Validation Loss: 0.1928000576834165\nEpoch 2701, Training Loss: 0.16935828228329353, Validation Loss: 0.1928000576834165\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.943643671645536\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.677318023455868e-05\nEpoch 2711, Training Loss: 0.16951028117940087, Validation Loss: 0.19280806902004258\nEpoch 2711, Training Loss: 0.1693549647776826, Validation Loss: 0.19280806902004258\nTraining Accuracy: 0.9466401958515523, Training F1 Score: 0.943643671645536\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.6247615702152266e-05\nEpoch 2721, Training Loss: 0.1695054803413533, Validation Loss: 0.1928097817421639\nEpoch 2721, Training Loss: 0.16935173178125518, Validation Loss: 0.1928097817421639\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.5727956649688385e-05\nEpoch 2731, Training Loss: 0.16950112511595844, Validation Loss: 0.19280285939572608\nEpoch 2731, Training Loss: 0.1693480260167539, Validation Loss: 0.19280285939572608\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436715009541277\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.5214136720532984e-05\nEpoch 2741, Training Loss: 0.16949584530457412, Validation Loss: 0.19280853259103492\nEpoch 2741, Training Loss: 0.16934454710533964, Validation Loss: 0.19280853259103492\nTraining Accuracy: 0.9466645554973631, Training F1 Score: 0.9436715009541277\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.4706090303665026e-05\nEpoch 2751, Training Loss: 0.16949138297351005, Validation Loss: 0.1928085197299428\nEpoch 2751, Training Loss: 0.1693413738188232, Validation Loss: 0.1928085197299428\nTraining Accuracy: 0.9466889151431738, Training F1 Score: 0.943697227603612\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.420375252529852e-05\nEpoch 2761, Training Loss: 0.16948690611497988, Validation Loss: 0.1928090569100254\nEpoch 2761, Training Loss: 0.16933909136123038, Validation Loss: 0.1928090569100254\nTraining Accuracy: 0.9466767353202684, Training F1 Score: 0.9436854147329946\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.3707059240598545e-05\nEpoch 2771, Training Loss: 0.16948237357950588, Validation Loss: 0.19280735030811136\nEpoch 2771, Training Loss: 0.16933632497189824, Validation Loss: 0.19280735030811136\nTraining Accuracy: 0.9466523756744577, Training F1 Score: 0.9436575865916691\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.321594702549044e-05\nEpoch 2781, Training Loss: 0.16947863290599946, Validation Loss: 0.19280666585104725\nEpoch 2781, Training Loss: 0.16933313006115672, Validation Loss: 0.19280666585104725\nTraining Accuracy: 0.9466889151431738, Training F1 Score: 0.9436993279283535\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.2730353168561066e-05\nEpoch 2791, Training Loss: 0.16947408116070847, Validation Loss: 0.19280689551807295\nEpoch 2791, Training Loss: 0.1693307374624158, Validation Loss: 0.19280689551807295\nTraining Accuracy: 0.9467010949660792, Training F1 Score: 0.9437111409026002\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.225021566305096e-05\nEpoch 2801, Training Loss: 0.16946929283119325, Validation Loss: 0.19280079794592545\nEpoch 2801, Training Loss: 0.16932868864358916, Validation Loss: 0.19280079794592545\nTraining Accuracy: 0.9466889151431738, Training F1 Score: 0.9436993279283535\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.1775473198936556e-05\nEpoch 2811, Training Loss: 0.16946615205270435, Validation Loss: 0.19280270796183835\nEpoch 2811, Training Loss: 0.1693261833261294, Validation Loss: 0.19280270796183835\nTraining Accuracy: 0.9467010949660792, Training F1 Score: 0.9437132405402879\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.130606515510135e-05\nEpoch 2821, Training Loss: 0.16946224524911865, Validation Loss: 0.19279929153865386\nEpoch 2821, Training Loss: 0.16932358558673236, Validation Loss: 0.19279929153865386\nTraining Accuracy: 0.9466889151431738, Training F1 Score: 0.9436993279283535\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.084193159159502e-05\nEpoch 2831, Training Loss: 0.16945876110306876, Validation Loss: 0.19279807857955925\nEpoch 2831, Training Loss: 0.1693211054413327, Validation Loss: 0.19279807857955925\nTraining Accuracy: 0.9466767353202684, Training F1 Score: 0.9436854147329946\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 4.038301324197954e-05\nEpoch 2841, Training Loss: 0.16945468942316091, Validation Loss: 0.19280090736321004\nEpoch 2841, Training Loss: 0.16931900345126152, Validation Loss: 0.19280090736321004\nTraining Accuracy: 0.9467010949660792, Training F1 Score: 0.9437090408504896\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 3.992925150576128e-05\nEpoch 2851, Training Loss: 0.1694508885344656, Validation Loss: 0.19280190384957688\nEpoch 2851, Training Loss: 0.16931677588002683, Validation Loss: 0.19280190384957688\nTraining Accuracy: 0.9466767353202684, Training F1 Score: 0.9436854147329946\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 3.9480588440908184e-05\nEpoch 2861, Training Loss: 0.16944749322876013, Validation Loss: 0.19280266117255154\nEpoch 2861, Training Loss: 0.1693144593731636, Validation Loss: 0.19280266117255154\nTraining Accuracy: 0.9466889151431738, Training F1 Score: 0.9436951268643029\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 3.9036966756450965e-05\nEpoch 2871, Training Loss: 0.16944345205591396, Validation Loss: 0.1928045253546944\nEpoch 2871, Training Loss: 0.1693117237869091, Validation Loss: 0.1928045253546944\nTraining Accuracy: 0.9466889151431738, Training F1 Score: 0.9436951268643029\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\nLearning Rate: 3.85983298051675e-05\nEpoch 2881, Training Loss: 0.16944009077897013, Validation Loss: 0.19281193484970446\nEpoch 2881, Training Loss: 0.16930954358275666, Validation Loss: 0.19281193484970446\nTraining Accuracy: 0.9466889151431738, Training F1 Score: 0.9436951268643029\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9369860508605166\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[135], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m LambdaLR(optimizer, lr_lambda\u001b[38;5;241m=\u001b[39mcustom_lr_lambda)\n\u001b[1;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m CustomLoss(nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer, num_epochs, scheduler, batch_size, num_features, early_stopping_patience)\u001b[0m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels, model)\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 22\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:130\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    129\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:92\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 92\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprev_grad\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ret\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py:187\u001b[0m, in \u001b[0;36mset_grad_enabled.__init__\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    185\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n\u001b[1;32m    186\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n\u001b[0;32m--> 187\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":135},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    print(name)\n    print(param)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T04:23:22.753071Z","iopub.execute_input":"2025-01-23T04:23:22.753725Z","iopub.status.idle":"2025-01-23T04:23:22.799527Z","shell.execute_reply.started":"2025-01-23T04:23:22.753689Z","shell.execute_reply":"2025-01-23T04:23:22.798693Z"},"collapsed":true,"jupyter":{"outputs_hidden":true,"source_hidden":true}},"outputs":[{"name":"stdout","text":"layers.0.a\nParameter containing:\ntensor([[ 4.4564e+00,  4.3177e-01,  5.1845e-02,  1.4698e-01, -1.4075e+00,\n          1.4098e-01,  5.7946e-01, -1.2160e-01, -7.6425e-01,  9.1887e-02,\n         -1.4741e-01, -4.8555e-01,  1.1405e-01, -5.2058e-01,  2.6454e+00,\n         -8.5377e-01,  6.9552e-02, -2.0482e-01, -5.8601e-02,  2.7055e-01,\n         -9.0596e-01, -1.8602e+00,  1.9821e-01, -7.3506e-02,  2.9277e-02],\n        [ 7.1102e-02,  7.7473e-01, -3.9996e-02, -1.4458e-01, -5.5886e-01,\n         -2.6232e-01, -5.2604e-01,  6.6752e-01, -4.2569e-02, -2.9622e-01,\n         -6.3417e-01,  6.3476e-01, -2.3447e+00, -4.2899e-01, -2.8613e-01,\n          4.3231e-02, -3.8118e-01,  4.4963e-02, -6.1407e-01, -2.4469e-01,\n         -6.8058e-02,  3.5061e-02, -6.1081e-01, -3.4325e-01,  7.0763e-01],\n        [-3.7448e-02,  6.8192e-02,  5.0094e+00,  3.1936e-02, -9.1801e-01,\n         -9.2670e-02,  1.3304e-01,  2.8113e-02,  1.8417e-01, -8.7350e-02,\n         -8.1643e-02, -3.9441e-01, -2.6840e-01,  7.7351e-02,  3.4614e-01,\n         -2.7835e-02,  5.0947e-01, -3.9961e-01,  1.2164e-01,  2.1237e-01,\n         -4.1672e-02, -3.3710e-01, -1.2811e-01,  1.1230e-04,  2.5954e-01],\n        [-8.6786e-02,  2.7667e+00,  1.6761e-01,  3.8974e-01,  1.3881e-01,\n         -4.0404e+00, -4.6495e-02,  1.4246e-01,  2.6503e-01,  4.2203e-01,\n         -2.0153e-01,  9.6065e-01,  5.6831e-03, -3.4021e-01, -5.3450e-01,\n         -1.1182e+00, -3.8837e-01,  6.3096e-01, -1.1343e-01, -1.9251e-01,\n          1.1739e+00,  4.5416e-02,  2.9761e-01,  3.4669e-01,  6.0378e-01],\n        [ 1.4139e-01, -1.4581e-01,  2.2426e-01,  2.7057e-01,  7.9813e-01,\n         -1.5233e-01,  1.2880e-01,  8.3171e-02,  4.3042e-01,  9.2388e-02,\n          2.7481e-01,  2.2447e-01, -5.6681e-02,  5.0656e-01,  1.0992e-01,\n          1.7684e-01,  5.2188e-01,  2.8580e-02, -4.4010e-01,  1.8943e-01,\n          1.7903e-01, -9.4244e-02, -3.0694e-01, -5.9094e-02, -5.5185e-01],\n        [ 5.0952e-03, -1.3462e+00,  7.4812e-02, -1.8060e-02,  2.6206e-01,\n          7.2967e-01,  2.8821e-01,  2.7172e-01, -5.7272e-01, -4.2340e-01,\n         -3.3579e-01, -5.1984e-01, -1.1176e-01, -1.6511e-01, -4.8542e-01,\n          6.1135e-01,  3.6397e-02, -1.4717e-01, -3.2893e-01, -9.9524e-02,\n         -6.2208e-01,  3.3763e-01,  7.4143e-02, -3.0846e-01, -2.1949e-01],\n        [ 8.1573e-02, -3.5274e-01,  9.1950e-02, -1.3413e-01, -2.4960e-02,\n         -1.1812e-01,  8.5471e-01, -1.5827e-01,  1.5194e-01, -1.3668e-01,\n          3.1930e-01,  2.9363e-01, -3.0580e-01,  4.5530e-01, -4.6929e-01,\n          1.6803e-01,  1.6008e+00,  2.3314e-01,  5.2355e-01,  8.6368e-01,\n         -2.4978e-01, -3.2918e-01, -5.1913e-01,  7.0566e-02,  2.6930e-01],\n        [-7.2807e-02,  7.9219e-02, -1.6397e-02, -1.0355e-01, -2.6887e-01,\n          3.5683e-01,  8.0507e-02,  1.0498e+00, -9.9816e-02,  1.0922e-01,\n          3.4868e-02,  1.1734e-01, -2.5548e-01, -6.3846e-02,  1.0411e-01,\n         -2.7133e-02,  2.7153e-01,  3.4875e-01,  2.2500e-01,  1.0908e-01,\n          2.0322e-02, -2.4499e-01,  1.3046e-01,  1.4198e-02, -9.4821e-02],\n        [-7.1519e-04,  6.0175e-03, -4.4683e-03,  7.3141e-04,  3.2043e-03,\n          2.8322e-01, -5.1926e-03, -3.7431e-04,  9.0435e-01, -1.2272e-03,\n          4.7388e-03, -2.9285e-03,  7.9081e-05, -2.4945e-04, -4.7619e-04,\n          4.0968e-03,  1.0686e-03,  2.6747e-04, -2.8542e-04, -2.8771e-03,\n         -1.9203e-03,  4.8471e-03, -2.9022e-04, -2.8550e-03, -1.7946e-05],\n        [-2.4666e-03,  1.8518e-03,  2.3749e-04, -1.0144e-03,  2.3454e-04,\n          3.1127e-01, -1.2150e-02, -2.4153e-03,  5.4763e-03,  9.5491e-01,\n          1.2165e-03,  2.6973e-03, -2.8627e-04,  2.0713e-03, -2.3865e-03,\n          4.4984e-03,  5.0902e-03,  8.8839e-02,  1.8710e-03,  7.4472e-02,\n         -9.2356e-03, -1.2536e-01,  5.2353e-02,  6.3789e-03,  3.1742e-02],\n        [ 2.5846e-03,  3.6723e-03,  1.6108e-04,  1.0631e-03,  1.0240e-04,\n          2.6667e-01, -8.3601e-04, -7.6957e-05,  2.7373e-04, -2.0940e-04,\n          8.6668e-01, -6.6577e-04, -1.4027e-04, -3.0706e-04,  6.1781e-05,\n          9.0684e-04, -1.3482e-03,  1.0712e-04,  2.0995e-03, -3.0418e-04,\n          5.0268e-04, -2.6487e-03,  1.3759e-06, -3.2027e-04, -3.4774e-03],\n        [ 3.0612e-03,  1.1312e-03, -1.2077e-04,  2.2168e-02,  1.0911e-02,\n          2.6705e-01,  1.7132e-02, -1.9408e-03,  3.1588e-03, -1.3093e-03,\n         -4.9029e-04,  1.1000e+00,  5.5797e-04,  8.2643e-02, -6.9858e-03,\n         -4.5791e-03,  9.5861e-02,  3.3779e-02, -9.8412e-03,  8.5165e-02,\n          6.8431e-03, -1.1122e-01, -4.1225e-03,  1.7287e-04,  7.3132e-03],\n        [ 8.3261e-03, -7.9549e-01,  9.8793e-01, -5.7679e-01,  2.9018e-01,\n          3.8803e-01,  2.6560e-01,  6.9001e-01,  5.2268e-01, -4.9706e-02,\n         -2.5794e-01,  5.7076e-01,  1.8539e+00, -6.4361e-02,  4.6787e-01,\n          7.2444e-01,  4.4739e-02, -5.0687e-02,  4.5294e-01,  2.6546e-01,\n          8.6255e-01, -2.9177e-01,  1.1421e-01, -3.1945e-01,  2.9731e-01],\n        [-3.9262e-02, -5.8256e-02, -1.3670e-04,  5.6057e-02, -2.7706e-01,\n          3.4507e-01,  2.3773e-01,  2.7952e-02, -2.7995e-02,  7.5332e-02,\n          1.5624e-02,  1.3872e-01, -6.0104e-02,  1.2857e+00,  1.0712e-01,\n          1.2105e-01,  3.7911e-01,  6.8120e-01,  1.2531e-01,  2.4256e-01,\n         -1.4709e-01, -2.0985e-01,  2.2126e-01,  3.9210e-02,  1.7711e-01],\n        [-7.5390e-02, -1.1444e-01,  1.7113e-03,  7.2588e-02, -3.3380e-03,\n          3.7217e-01, -1.2325e-02,  1.0060e-02, -3.1501e-03,  3.9768e-03,\n          3.0252e-02,  2.7174e-01,  1.7465e-03,  8.8316e-02,  1.0036e+00,\n          2.0143e-03,  2.0540e-01,  2.8156e-01,  3.0708e-03, -1.0150e-02,\n          9.7150e-03, -4.7743e-02,  1.2869e-01,  4.8545e-02,  2.5985e-01],\n        [-1.2571e-02, -6.9133e-02, -1.7103e-02,  9.9894e-02, -3.1132e-02,\n          3.3004e-01,  1.5702e-01,  3.3395e-02, -5.6991e-03,  3.0644e-03,\n          5.3049e-02,  3.8657e-02, -1.9855e-01,  3.4337e-01,  1.4160e-01,\n          1.0744e+00,  2.1216e-01,  9.9374e-03,  3.2360e-01,  2.3300e-01,\n          6.5616e-02, -2.4645e-01,  2.7067e-01,  5.2424e-02,  1.4887e-02],\n        [-4.3073e-02, -1.2942e-03, -2.4048e-02,  6.1601e-02, -2.7261e-01,\n          3.6417e-01,  1.8780e-01, -6.7206e-02, -2.0570e-02,  8.9227e-02,\n          9.0234e-02,  2.4330e-01, -2.5366e-02,  3.2321e-01,  1.2482e-01,\n          6.4062e-02,  1.0933e+00,  5.4428e-01, -7.6589e-02,  6.6281e-02,\n         -5.2156e-02, -3.1201e-01,  2.7440e-01,  5.6573e-02,  2.4380e-01],\n        [ 5.3808e-03, -3.3240e-02, -1.5765e-03,  4.9511e-02,  3.7730e-02,\n          3.8227e-01,  8.3734e-02, -1.3415e-02,  3.2004e-02,  1.3218e-03,\n         -2.2892e-03,  1.6473e-01,  5.8047e-03,  2.7293e-01,  9.3307e-02,\n          2.7331e-02,  1.0781e-01,  1.2937e+00,  1.1161e-01,  2.9352e-01,\n         -5.5372e-02, -2.3680e-01,  1.7920e-01,  8.4092e-02,  1.7548e-01],\n        [-3.7929e-02, -3.1859e-02, -1.0223e-01,  1.0985e-02, -1.3177e-01,\n          3.0955e-01, -5.7426e-02, -3.0821e-02, -2.9375e-02,  6.0395e-02,\n         -1.2924e-01,  1.9003e-01,  7.5765e-02, -2.3136e-02,  2.6718e-02,\n         -1.2220e-01,  1.0927e-01,  1.9011e-01,  1.2193e+00,  4.0399e-01,\n          1.5509e-01, -1.6333e-01,  2.5973e-01,  1.2231e-01,  1.4129e-01],\n        [-4.9688e-02, -3.6725e-02, -1.0005e-01, -7.3257e-03, -5.3030e-02,\n          3.8584e-01,  1.5591e-01, -7.6133e-03,  1.5497e-02,  6.7917e-02,\n         -3.9268e-02,  1.8385e-01,  1.7108e-02,  5.0888e-02,  1.5765e-02,\n         -6.1680e-03,  2.4933e-01,  3.6513e-02,  2.1558e-01,  1.1689e+00,\n          3.5039e-03, -4.3430e-01,  2.4771e-01,  1.1548e-01,  3.0679e-01],\n        [ 3.4712e-04,  6.3711e-04,  1.4298e-01,  9.4817e-03,  2.6646e-02,\n          3.1046e-01,  4.7251e-02, -9.1924e-03,  9.2849e-04, -2.3252e-02,\n         -7.7323e-02,  2.2757e-01,  1.4374e-02,  6.2695e-01,  3.5771e-01,\n          1.7730e-02,  2.0839e-01,  4.6905e-01,  4.1939e-02,  1.7719e-01,\n          1.0450e+00,  3.6211e-02,  2.1213e-01,  7.2172e-02,  1.9052e-01],\n        [-4.7011e-03, -4.7740e-03,  1.4287e-02,  1.2076e-02, -1.0541e-02,\n          2.7132e-01, -4.0885e-04, -2.1320e-02, -9.8020e-04,  3.4363e-07,\n          3.1491e-03,  4.2490e-03, -2.3684e-03,  8.7949e-03, -1.5548e-02,\n          4.2564e-03, -8.5011e-02,  4.9812e-02, -8.8965e-03,  2.8822e-02,\n          1.1260e-02, -2.4591e-02, -1.2135e-03, -3.2484e-03, -6.3283e-03],\n        [ 1.7048e-03,  2.1420e-03,  1.5841e-04,  1.0534e-03,  2.2888e-03,\n          2.7832e-01,  1.6841e-04,  3.6663e-03, -8.2766e-04, -1.6908e-04,\n         -7.5859e-05,  8.6428e-04,  4.4722e-04, -3.0931e-03, -2.0059e-03,\n          3.8066e-04,  1.1530e-04, -8.0641e-03,  9.5583e-06, -3.9431e-03,\n         -4.2085e-03,  1.7615e-03,  1.0380e+00, -1.6886e-04,  1.0142e-03],\n        [ 1.6128e-05,  2.0322e-04, -3.7300e-05, -9.3726e-05, -2.4683e-05,\n          2.5638e-01, -4.9750e-04,  1.2024e-03,  9.1398e-05, -1.8612e-04,\n          2.3090e-05,  1.4012e-05, -9.8732e-05,  2.7626e-04, -4.8742e-04,\n          3.2785e-04,  1.8586e-03, -2.3376e-03, -2.2909e-04, -3.6002e-04,\n          3.8335e-05, -6.5007e-04, -9.1476e-05,  8.5799e-01, -3.8765e-04],\n        [ 1.1690e-02, -1.2117e-02, -6.7276e-02,  1.8254e-02,  9.0424e-04,\n          2.7348e-01, -2.2510e-02,  5.3902e-02,  2.6200e-02,  1.4984e-02,\n         -3.7325e-03,  4.0370e-02,  1.4403e-02,  3.5789e-03, -4.4303e-03,\n          9.2170e-02, -4.6347e-02,  4.4290e-02,  4.0646e-01, -4.8283e-02,\n          5.8082e-03, -2.8959e-01,  2.2971e-01, -1.9854e-04,  9.9966e-01]],\n       device='cuda:0', requires_grad=True)\nlayers.0.b\nParameter containing:\ntensor([[ 1.4805e-01, -1.7539e-01, -3.1364e-02, -2.4946e-01, -4.0705e-02,\n          6.6856e-02,  2.9143e-01,  4.8763e-01,  6.9359e-02,  1.3721e-02,\n          1.3766e-02,  8.7022e-02, -1.5821e-01, -1.0886e-01, -1.6989e-01,\n          1.0177e-01, -2.8067e-01,  2.4954e-01,  8.2926e-02, -1.1277e-01,\n          1.7357e-01,  1.8476e-01, -1.4363e-01,  1.3397e-02,  7.1285e-01],\n        [-1.3141e-01,  1.4180e-01,  4.1944e-02,  3.0718e-01,  3.7490e-01,\n          1.1730e-01,  3.4502e-01, -7.3807e-02, -8.4824e-01, -5.6548e-01,\n         -1.4947e-01, -4.4498e-01, -2.0290e-02, -6.7643e-02, -5.7581e-01,\n          5.2358e-01,  1.5325e-01, -6.1281e-01, -1.3203e-01,  3.6549e-01,\n         -6.6571e-01, -7.0750e-01,  3.3119e-02, -3.6044e-01,  2.9018e-01],\n        [ 4.6742e-02, -6.8108e-02,  1.8690e-01,  1.4715e-01,  3.5243e-01,\n         -4.2543e-04, -2.1996e-01, -1.6963e-01, -9.4619e-02,  1.0132e-01,\n          4.5161e-02,  9.3952e-02, -1.8598e-01, -1.2780e-01,  1.7018e-01,\n         -1.1727e-01, -5.3746e-01,  2.2090e-01, -6.3302e-02,  4.5596e-01,\n          2.5255e-01,  2.3699e-01,  2.2108e-01, -6.7640e-02, -9.1352e-01],\n        [-7.0435e-02,  3.6702e-01, -1.2052e-01,  3.8616e-01,  1.1719e-01,\n          4.7288e-02,  3.4344e-01,  5.7887e-02,  1.6775e-01,  3.0922e-01,\n          3.3867e-01,  1.8695e-01,  4.3451e-01,  1.9761e-02,  8.3934e-02,\n         -2.3677e-01,  2.6974e-01, -9.7043e-02,  1.4228e-01, -6.4647e-01,\n          4.6816e-01,  2.5073e-01,  2.6309e-01,  2.1947e-01, -5.0894e-02],\n        [-7.0085e-02, -6.2335e-02, -8.4423e-02, -6.0561e-02,  2.6765e-01,\n          7.3723e-03, -2.6523e-02,  5.8931e-01, -8.4430e-02,  8.8959e-02,\n         -5.5380e-02, -1.0795e-01, -3.6848e-01,  4.6512e-02,  9.0500e-02,\n         -2.2604e-01,  2.3320e-01, -3.7198e-02,  2.4469e-01,  6.4132e-01,\n         -4.6663e-01,  2.8662e-01,  8.8173e-01,  8.0366e-02,  3.2510e-01],\n        [ 8.1950e-02, -3.1399e-01, -5.0637e-01,  5.4533e+00,  1.0081e+00,\n          2.0289e+00,  2.8772e-01,  5.2218e-01,  3.2690e+00,  6.3668e+00,\n          9.3617e+00,  8.7466e-01, -4.2440e-01, -8.7595e-01,  1.0108e+00,\n          5.5991e-01, -7.4818e-01,  1.6600e-01,  6.6071e-01,  2.4134e-01,\n          4.0963e-01,  3.6127e-01,  1.8606e+00,  8.4468e+00,  2.4322e-03],\n        [ 5.8005e-03,  2.3541e-01,  4.6382e-02,  6.9714e-02,  1.5623e-01,\n         -6.5997e-02,  1.2028e+00, -4.7256e-02, -1.1279e-01, -1.5876e-02,\n         -2.3346e-02, -9.9660e-02, -2.7505e-03,  7.6103e-03,  1.0520e-01,\n         -1.4159e-01, -1.0055e-01, -2.3952e-01, -1.1376e-01, -1.2461e-01,\n          1.5791e-01,  9.9681e-02,  1.2708e-01, -1.5557e-02, -2.8960e-01],\n        [ 5.1314e-03,  1.6490e-01,  1.0828e-03, -1.8048e-01, -1.2734e-01,\n         -9.6281e-02,  3.3533e-02,  1.6662e+00, -1.7425e-01,  4.8828e-02,\n         -1.2530e-02, -4.1558e-02, -3.1307e-01, -2.3992e-01,  2.6115e-02,\n         -1.6585e-01,  1.5268e-01,  1.7047e-01,  5.6130e-02, -7.1147e-02,\n          6.7154e-02,  6.3135e-02, -1.0479e-01, -8.3447e-02, -2.6532e-01],\n        [ 5.9405e-03,  6.3190e-02, -4.3391e-01, -2.9340e-03,  5.6070e-02,\n          1.8988e-02,  5.4247e-02,  2.6697e-01,  1.4470e-01,  2.7114e-02,\n         -8.6939e-02, -1.6911e-02, -4.3472e-02, -2.5947e-03,  1.4021e-02,\n          1.7070e-02, -1.5686e-01,  5.4257e-02, -1.6473e-02, -6.9615e-02,\n          7.1883e-02,  9.7330e-02,  1.1490e-01, -6.1694e-03, -2.8568e-02],\n        [ 4.2322e-02,  2.3511e-02, -4.0375e-04,  3.3808e-03,  1.0205e-02,\n         -3.8986e-02, -1.7430e-01,  4.2634e-01, -2.4615e-02,  3.7950e-01,\n          2.5919e-02, -1.1887e-02, -3.1278e-02,  2.6541e-02, -4.0674e-02,\n         -2.0195e-02,  2.8597e-02,  6.1355e-02, -1.0712e-01, -9.2978e-02,\n         -1.1087e-01,  6.8136e-02,  7.6029e-03, -3.2003e-02,  1.5898e-01],\n        [ 3.3589e-03, -2.8563e-01,  2.7696e-02, -3.6640e-02, -1.3885e-02,\n          6.5254e-02, -1.7508e-01,  8.1323e-02,  6.5919e-02,  6.1852e-03,\n          5.3542e-01,  7.5287e-02,  9.4232e-02, -2.9633e-02,  5.8713e-02,\n          1.0851e-01,  1.1291e-03,  7.3322e-02, -1.6811e-01,  8.5035e-02,\n          1.1598e-01, -1.5671e-01, -3.2598e-02, -7.4321e-02,  2.6310e-01],\n        [-5.7543e-02, -3.0120e-01,  9.7973e-02,  4.9625e-01,  3.7916e-01,\n         -9.3778e-03,  3.0644e-01,  2.9277e-02,  4.0608e-01,  3.5620e-02,\n         -1.9963e-02,  1.2980e+00, -2.4942e-02,  2.1287e-01, -2.2550e-01,\n         -1.8378e-01,  3.3773e-01, -3.3402e-01,  5.4159e-01, -8.3861e-02,\n         -5.9126e-01,  8.0928e-02, -9.2057e-01, -1.6774e-01, -5.1343e-01],\n        [ 6.0763e-02, -3.6290e-01,  5.7273e-01, -5.4270e-01,  4.3434e-01,\n          4.3069e-01,  1.7768e-01,  5.6420e-01,  4.2355e-01, -7.3074e-02,\n         -1.7527e-01,  3.1748e-01,  1.6375e+00, -1.8671e-01,  2.2294e-01,\n          6.6600e-01, -4.0967e-02, -2.8812e-01,  2.8022e-01,  1.3833e-01,\n          5.6330e-01,  1.1674e-01, -8.1480e-02, -2.5799e-01,  1.3290e-01],\n        [-1.8071e-01, -2.2197e-02,  3.7710e-02,  6.0633e-02, -3.5275e-01,\n         -1.1836e-01,  3.1578e-01,  7.0484e-02, -1.7151e-01,  2.6239e-02,\n         -4.9811e-02, -2.0768e-02, -3.0135e-01,  1.3230e+00, -1.3916e-01,\n          1.5185e-01,  3.7263e-01,  7.3258e-01, -1.7687e-01, -2.3765e-01,\n         -5.8729e-01, -4.5694e-02,  4.0863e-02, -4.2034e-02,  1.2214e-01],\n        [ 4.2427e-01, -3.5246e-01,  2.5257e-02,  4.0073e-01,  3.3585e-02,\n          1.1033e-01,  6.3458e-01,  7.5561e-02,  1.0488e-01, -4.9573e-02,\n         -5.0637e-03,  6.6161e-01, -1.4702e-01,  4.1839e-04,  8.2045e-01,\n         -1.9507e-02,  4.5980e-01,  5.0537e-01, -1.8174e-01, -2.6550e-01,\n          7.1924e-02,  6.4066e-01, -2.9059e-02,  4.3392e-02,  5.1840e-01],\n        [-4.5450e-03, -8.3526e-03,  2.9779e-02,  1.4201e-01, -6.0933e-02,\n         -7.2998e-02,  2.6583e-01,  1.3444e-01, -1.1378e-01, -3.4643e-02,\n         -7.6171e-02, -2.7372e-01, -4.1258e-01,  4.4971e-01,  9.8456e-02,\n          1.3212e+00,  2.8027e-01, -3.5038e-01,  3.1976e-01,  2.8499e-01,\n          2.4447e-01, -1.6849e-01,  1.9797e-01, -8.8307e-02, -1.8323e-01],\n        [-4.8927e-02,  9.2932e-02,  6.9607e-02,  8.9129e-02, -4.1610e-01,\n         -7.2457e-02,  1.9684e-01, -1.9816e-01, -1.3680e-01, -5.1906e-02,\n          3.1811e-02,  2.8228e-01, -1.7996e-01,  2.7803e-01,  1.3806e-02,\n         -3.5051e-02,  1.1655e+00,  7.5013e-01, -4.0567e-01, -8.6415e-02,\n         -4.4959e-01, -3.2612e-01,  2.2591e-01, -3.3258e-02,  3.1790e-01],\n        [-8.2408e-02,  3.8232e-01,  5.6345e-02,  1.1526e-01, -8.8550e-01,\n          3.6071e-03,  1.3080e-01, -1.0039e-01,  3.6387e-02, -4.6853e-02,\n          4.4112e-03,  9.3291e-02, -1.6660e-01,  3.5503e-01, -2.5610e-02,\n         -5.4856e-01,  6.9217e-02,  1.2558e+00,  1.2810e-02,  7.3734e-02,\n         -3.2116e-01, -2.2398e-01,  4.1955e-02,  3.9655e-02,  2.2792e-01],\n        [-1.2964e-02,  5.7988e-02, -1.1729e-01, -5.8321e-02, -8.1320e-02,\n         -9.7390e-02, -2.0731e-01, -5.5372e-02, -1.5554e-01, -5.8552e-02,\n         -3.1820e-01,  8.9474e-02,  1.3138e-01, -2.3374e-01, -1.1414e-01,\n         -2.3663e-01,  6.2921e-02,  3.5768e-02,  1.0960e+00,  2.5827e-01,\n          2.4045e-01,  8.4103e-02,  5.6901e-02,  1.3628e-02,  6.4798e-02],\n        [-9.0066e-02,  1.4835e-01, -1.7422e-01, -8.7879e-02,  5.2454e-01,\n         -3.8547e-02,  1.7680e-01, -2.8882e-02, -8.3946e-02, -2.0779e-02,\n         -1.7814e-01,  4.2278e-02,  1.9903e-01, -8.1888e-02, -1.4392e-01,\n         -1.8752e-01,  2.8571e-01, -5.8503e-01,  1.0787e-01,  1.2421e+00,\n          2.6254e-02, -2.3762e-01, -5.1845e-03,  2.3420e-02,  3.0040e-01],\n        [ 4.6806e-02,  2.8488e-02,  4.2206e-01,  8.1900e-02,  1.1281e-01,\n         -8.1363e-04,  8.3093e-02,  4.2411e-01, -2.6910e-02, -5.8044e-02,\n         -1.4453e-01,  5.1480e-01, -2.0387e-01,  1.0058e+00,  5.9944e-01,\n         -7.2703e-02,  4.1882e-01,  4.6226e-01, -1.3554e-01,  1.7211e-01,\n          1.2269e+00,  4.2507e-01,  3.4561e-01,  5.5461e-01,  3.0298e-01],\n        [ 4.0785e-02,  2.7985e-02,  2.2433e-01,  9.4620e-02,  1.8479e-01,\n         -6.2420e-04, -8.1193e-02, -1.9403e-01, -2.2520e-02, -3.2296e-02,\n         -9.8163e-02,  1.9961e-01, -1.3768e-01,  3.2115e-01,  2.1797e-01,\n         -5.3470e-02,  3.6886e-01,  2.8487e-01, -6.0161e-01, -1.6564e-02,\n          2.5607e-01,  1.0469e+00,  6.8761e-01,  1.0454e-01,  1.0096e-01],\n        [ 1.0307e-02, -1.0592e-01,  1.0938e-01, -1.2244e-02,  7.4798e-02,\n          1.6684e-02,  1.8065e-01, -1.6770e-01,  8.4089e-02, -7.8509e-03,\n          3.1562e-02,  1.3154e-01, -2.2463e-01,  8.7857e-02,  5.6452e-02,\n         -2.3495e-02,  1.0997e-01,  2.7176e-01,  6.7197e-02,  1.1349e-01,\n          1.1316e-01,  9.4803e-02,  1.8149e-01,  1.1413e-01, -5.7388e-02],\n        [ 6.8134e-03, -5.3411e-02, -2.0417e-02,  1.7703e-02,  1.8401e-01,\n          1.5190e-02,  1.3511e-01, -1.6689e-01,  1.9650e-02,  8.0709e-04,\n          3.5353e-02, -1.1080e-02,  1.3644e-01, -5.3900e-02,  5.1629e-02,\n         -2.1216e-02,  9.0790e-02,  1.1669e-01,  5.5303e-02,  1.0148e-01,\n          6.3879e-02,  2.8378e-01,  4.5047e-02,  6.6396e-01, -1.9099e-02],\n        [ 4.1909e-02,  3.3447e-02, -4.6668e-02, -8.3316e-02,  2.6156e-01,\n         -1.4863e-01, -1.5053e-01,  1.2291e-01,  1.3757e-02,  2.8588e-02,\n         -4.1002e-02, -1.0109e-02, -1.2705e-01, -1.0855e-01, -1.2253e-01,\n          8.4841e-02, -1.3689e-01, -1.5206e-01,  4.2464e-01, -2.2796e-01,\n          1.7609e-01, -8.3014e-02,  1.6670e-01, -6.9973e-03,  7.4941e-01]],\n       device='cuda:0', requires_grad=True)\nlayers.0.local_bias\nParameter containing:\ntensor([[ 5.9359e-01,  2.0409e-01,  1.0429e-02, -3.5828e-01,  6.1593e-01,\n          7.8759e-01, -1.2334e-01,  9.5645e-03,  6.1594e-01, -3.5655e-01,\n          8.3427e-01,  2.3044e-01, -6.9954e-01,  3.9426e-01,  6.1589e-01,\n          7.5221e-01, -8.6265e-01,  5.3190e-01,  2.9047e-01,  2.5780e-01,\n          7.0585e-01,  6.1589e-01, -1.7604e-01,  1.0658e-02, -3.5704e-01],\n        [-4.2204e-01,  9.8046e-02,  9.7954e-02,  4.6348e-01,  2.5231e-01,\n          5.0880e-01,  2.5240e-01,  9.8165e-02,  9.8335e-02,  9.8259e-02,\n          2.5244e-01,  9.8147e-02,  1.1546e+00,  3.3706e-01,  2.5244e-01,\n         -1.1302e-01,  9.8231e-02, -1.0782e+00, -7.2601e-02,  2.5233e-01,\n          9.8242e-02,  9.8248e-02,  2.5246e-01,  3.4241e-01,  2.5253e-01],\n        [-8.6858e-02, -8.3082e-02,  1.8003e-01, -3.1711e-01,  4.0391e-01,\n          4.8602e-01, -2.7896e-01,  6.7947e-01, -5.7362e-01,  1.7684e-01,\n          4.5669e-01, -1.8587e-01, -2.5764e-01, -8.3227e-02, -1.1735e-01,\n         -8.3051e-02,  1.7308e-01,  7.3141e-01, -8.1704e-01, -3.1225e-01,\n         -1.1372e-01, -3.1260e-01, -3.1273e-01, -8.3155e-02, -8.8786e-01],\n        [-4.9091e-01,  6.0833e-01, -4.5143e-01,  3.9267e-02, -5.9459e-02,\n          4.2981e-01,  4.7031e-01, -6.2241e-02, -1.0025e-01, -3.5510e-01,\n         -1.6716e-01, -4.3648e-01, -3.8461e-02,  4.0186e-01, -5.5492e-02,\n         -2.3099e-01, -2.5317e-01,  4.6066e-01, -4.5288e-01, -9.6605e-01,\n          3.7485e-01, -4.5325e-01, -1.0088e-01, -1.0178e-01,  7.0939e-01],\n        [ 1.4697e-01, -1.1416e-01, -2.2694e-01,  6.7426e-02,  2.7452e-01,\n          3.7491e-01, -1.0934e-02,  4.7863e-02, -2.1831e-01, -1.5752e-01,\n         -3.0053e-01,  2.6066e-01, -3.5789e-01, -2.1830e-01, -5.0209e-02,\n         -3.5813e-01, -1.0271e-01, -1.0245e+00, -2.2711e-01, -6.3326e-02,\n         -1.9042e-01,  1.5122e-02, -8.8150e-01, -5.3163e-01, -1.5835e-01],\n        [-8.1920e-01, -4.6427e-01, -8.4583e-01, -1.3546e+00, -5.1449e-01,\n          3.2945e-01, -5.1624e-01,  2.1407e-01, -1.3593e+00, -1.3595e+00,\n         -1.3594e+00, -1.3849e+00,  1.1594e-01, -1.2001e+00, -3.5739e-01,\n         -2.8188e-01, -3.0608e-01, -5.8203e-01, -7.7555e-01,  3.8571e-01,\n         -6.0726e-01, -4.0020e-01, -1.3594e+00, -1.3595e+00, -4.1941e-01],\n        [-2.9426e-01, -5.4181e-01,  2.0061e-01, -7.9861e-02,  3.0663e-01,\n         -5.2805e-02,  7.3792e-02,  1.9594e-01, -2.9565e-01, -2.9438e-01,\n          3.7567e-01,  6.9652e-01, -2.9471e-01,  3.2486e-02,  7.5959e-02,\n          2.0053e-01,  4.3567e-01, -1.3378e-01, -4.7017e-02,  1.9610e-01,\n          5.0541e-01, -4.9006e-01, -1.1206e-01,  5.4948e-01,  8.1536e-01],\n        [-1.4587e-01,  3.9939e-02,  2.7951e-01,  4.0610e-02, -2.1423e-01,\n         -3.2711e-01, -3.9290e-01,  7.0436e-02, -1.0634e-03, -1.9505e-01,\n         -2.5393e-02, -1.9552e-01,  4.0083e-02,  2.4721e-01, -1.7897e-01,\n          1.4929e-01, -2.2635e-01, -4.1757e-01, -2.2055e-01, -4.2057e-02,\n         -8.4048e-02, -2.4364e-01, -1.1520e-01, -1.6636e-03,  1.8252e-01],\n        [ 9.9948e-02,  9.8985e-02,  9.7990e-02,  2.7448e-01,  1.0268e-01,\n         -2.7224e-01,  9.9424e-02,  1.1715e-01, -2.6634e-02,  9.9824e-02,\n          9.9429e-02,  2.0386e-01,  9.9714e-02,  9.9451e-02,  1.0035e-01,\n          5.2538e-01,  1.5293e-01,  9.9412e-02,  1.0025e-01,  1.0868e-01,\n          9.7216e-02,  1.3603e-01,  1.0122e-01,  1.5641e-01,  1.3738e-01],\n        [ 1.8865e-01,  2.8932e-01,  1.9377e-01,  7.7196e-01,  1.8837e-01,\n         -3.1309e-01,  1.8744e-01,  1.9754e-01,  1.8467e-01, -4.9305e-02,\n          2.3057e-01,  1.8784e-01,  1.8733e-01,  1.4564e-01,  2.1446e-01,\n          3.2659e-01,  1.9984e-01,  3.8404e-02,  1.8803e-01,  9.5748e-03,\n          1.8945e-01, -7.9387e-02,  6.2986e-02,  1.8713e-01,  1.1944e-01],\n        [ 4.9644e-01,  1.4382e-01,  1.2681e-01,  4.6380e-02,  4.7288e-02,\n         -2.6138e-01,  1.1576e-01,  9.4529e-02,  6.4886e-02,  4.6485e-02,\n         -3.9248e-02,  4.7479e-02,  8.6214e-02,  6.0967e-01,  6.7149e-02,\n          1.8139e-01,  5.4304e-01,  3.3452e-01,  1.0095e-01,  7.2350e-02,\n          7.0169e-02,  4.6233e-02,  9.3748e-02,  1.0223e-01,  4.6908e-02],\n        [ 2.5841e-01,  1.8310e-01,  2.5844e-01,  2.0062e-01,  3.2963e-01,\n         -1.6094e-01,  2.5836e-01,  2.6050e-01,  2.9345e-01,  2.5946e-01,\n          3.4913e-01, -1.0640e-01,  2.5811e-01,  3.7423e-02,  2.8970e-01,\n          2.5274e-01,  1.0301e-01,  3.2440e-01,  2.7753e-01, -1.0183e-02,\n          2.5823e-01,  2.7592e-02,  4.0460e-01,  2.7081e-01,  3.1637e-01],\n        [-2.3302e-01, -5.1657e-01, -4.3210e-01,  2.5497e-01, -4.4323e-02,\n         -1.1789e+00, -1.4699e-01, -2.5647e-01, -3.0003e-01, -2.1590e-01,\n         -1.6992e-01, -3.7332e-01,  4.3788e-02, -8.4130e-02, -4.5178e-01,\n         -2.3386e-01, -2.0912e-01,  1.2028e-01, -1.1211e-01, -3.3749e-01,\n         -2.7482e-01, -2.9825e-01, -3.9319e-01, -1.4510e-01, -2.9004e-01],\n        [ 2.8338e-01,  1.3000e-01,  5.0800e-01,  1.1269e-01, -5.5484e-02,\n         -2.8838e-01,  9.3094e-02,  3.1948e-01,  2.4303e-01,  1.4165e-01,\n          2.2965e-01, -1.4784e-01,  2.3223e-01, -1.0412e-01, -3.6451e-02,\n          5.1565e-02, -1.8876e-01, -1.4103e-01,  1.7817e-01,  2.2789e-01,\n          3.7397e-01,  1.3155e-03, -1.4045e-01,  1.6157e-01, -8.7176e-02],\n        [ 5.8570e-02, -1.9396e-02,  3.4872e-01,  6.4148e-02,  3.4945e-01,\n         -3.5317e-01,  3.4841e-01,  3.4586e-01,  3.4841e-01,  3.4894e-01,\n          1.2490e-01,  1.4732e-01,  2.7569e-01,  2.7327e-02, -8.4106e-02,\n          3.4844e-01,  8.3001e-03,  9.0800e-02,  3.4850e-01,  2.8296e-01,\n          3.4821e-01,  3.9400e-01, -4.6969e-02,  1.1895e-01,  8.3248e-02],\n        [-3.0587e-02,  9.2264e-02,  2.7352e-01, -1.4796e-02,  3.0629e-01,\n         -2.9106e-01,  5.4155e-02,  2.4996e-01,  2.6685e-01,  4.4626e-01,\n         -7.3272e-02,  3.6037e-01,  2.2410e-01, -4.0565e-02, -1.3202e-01,\n         -3.2899e-02, -7.6294e-02,  4.7833e-01, -3.2776e-02, -1.8407e-01,\n          1.7532e-01, -1.3799e-01, -1.6518e-01,  1.7384e-01,  8.3080e-02],\n        [ 3.6436e-02,  4.3315e-01,  1.1200e-01, -5.0781e-02, -1.4957e-01,\n         -3.7494e-01, -1.1047e-01,  9.4801e-02,  7.1428e-02, -2.0599e-01,\n         -7.2058e-02, -9.9357e-02,  2.1023e-01, -1.5921e-01, -1.1131e-01,\n         -9.6195e-02, -1.0309e-01, -5.3939e-02,  5.6258e-01,  3.5823e-02,\n          3.3841e-01, -7.3199e-02, -1.7318e-01,  7.7098e-02, -1.1441e-01],\n        [ 4.5588e-01,  4.5596e-01,  4.5620e-01,  6.6014e-02,  4.3513e-01,\n         -3.7551e-01,  2.2853e-01,  3.0171e-01,  2.1763e-01,  4.5675e-01,\n          4.8235e-01, -8.5542e-02,  3.0847e-01, -8.2032e-02, -3.6012e-03,\n          4.5607e-01, -5.9928e-03, -1.7873e-01,  9.2460e-02, -5.6900e-02,\n          2.6285e-01,  3.9003e-02, -2.6911e-03,  1.0555e-01, -8.3349e-03],\n        [ 1.4927e-02,  8.8654e-02,  5.8512e-02,  1.2161e-01, -1.7175e-01,\n         -1.8269e-01,  2.1644e-01,  9.2693e-02,  2.7947e-01,  1.4401e-01,\n          1.9281e-01, -4.7305e-02, -5.8207e-02,  3.8744e-01,  2.4771e-01,\n          9.2246e-02,  1.0490e-01, -2.1176e-02, -1.3944e-01, -2.6902e-01,\n          3.6383e-02, -4.6640e-02, -2.0451e-01, -1.2533e-01,  1.2228e-02],\n        [ 7.6281e-02,  2.5657e-01,  2.0194e-02,  3.9179e-03,  4.0101e-01,\n         -3.1062e-01,  2.5511e-02,  3.6979e-01,  8.1043e-03,  7.1502e-02,\n          1.3557e-01, -1.3416e-01,  1.7178e-01,  1.4924e-01,  2.0225e-01,\n          1.7815e-01, -1.4811e-01,  4.9247e-01, -6.0456e-02, -1.1728e-01,\n          4.8410e-01, -3.8980e-01, -2.2856e-01, -5.8166e-02, -1.1328e-01],\n        [ 2.2235e-01,  3.2370e-01,  1.4217e-01,  2.5887e-01,  2.2599e-01,\n         -2.9833e-01,  7.7520e-02,  3.3093e-01,  2.3588e-01,  3.2313e-01,\n          3.0355e-01,  1.4978e-01,  2.1991e-01,  2.1598e-01,  1.0176e-01,\n          2.7335e-01,  1.2438e-01, -8.1071e-03,  1.2807e-01, -1.3003e-01,\n          3.2645e-02,  3.2651e-01,  8.7858e-03,  1.8025e-01,  4.0677e-02],\n        [ 1.4851e-01,  1.4879e-01,  1.4917e-01,  1.4831e-01,  1.5190e-01,\n         -2.5061e-01,  1.9306e-01,  1.4827e-01,  1.4843e-01,  1.4848e-01,\n          1.4860e-01,  1.4815e-01,  1.6857e-01,  1.1154e-01,  1.4858e-01,\n          1.4841e-01,  1.4633e-01,  1.1792e-01,  2.9959e-01,  6.5152e-02,\n          1.4974e-01,  1.2216e-01,  1.4775e-01,  1.5469e-01,  1.4864e-01],\n        [ 4.3664e-01,  9.3955e-02,  7.0237e-02,  6.5113e-02,  2.1636e-01,\n         -2.7422e-01,  6.5515e-02,  6.6110e-02,  9.9352e-02,  1.2802e-01,\n          7.3007e-02,  6.6317e-02,  1.2402e-01,  1.2107e-01,  6.7751e-02,\n          6.5460e-02,  7.1096e-02,  6.2796e-02,  9.1116e-02,  6.5474e-02,\n          6.6623e-02,  1.3676e-01, -1.5865e-01,  6.4711e-02,  1.6723e-01],\n        [ 3.2593e-02,  4.8427e-02,  7.3874e-02,  3.2893e-02,  6.4526e-02,\n         -2.4883e-01,  3.2601e-02,  4.9618e-02,  7.3638e-02,  3.9330e-02,\n          5.4655e-02,  3.5543e-02,  5.5120e-02,  6.8698e-02,  3.5357e-02,\n          3.3415e-02,  7.4326e-02,  3.5141e-02,  4.5322e-02,  3.1950e-02,\n          3.5940e-02,  9.7238e-02,  3.4565e-02, -6.7840e-02,  1.4165e-01],\n        [ 1.0498e-01,  4.3384e-01, -8.8172e-02,  4.3357e-01,  3.0575e-01,\n         -1.7593e-01,  1.8245e-01,  1.3248e-01,  4.3079e-02,  3.5271e-01,\n          1.3360e-01,  2.1947e-01,  4.3352e-01, -3.7208e-02,  1.4962e-01,\n          4.9545e-02,  2.3773e-01, -1.7176e-02, -1.2740e-01,  2.0940e-01,\n          2.2329e-01, -2.9022e-01, -5.9820e-02,  4.3377e-01, -9.9587e-02]],\n       device='cuda:0', requires_grad=True)\nlayers.0.global_bias\nParameter containing:\ntensor([ 0.0307,  0.0604,  0.0123, -0.0270,  0.0883, -0.3455, -0.0489,  0.0341,\n        -0.0540, -0.0769, -0.0591, -0.1250,  0.0263, -0.1086, -0.0980, -0.0598,\n        -0.0959, -0.1882, -0.1301, -0.1292,  0.0246,  0.2102, -0.1796, -0.0912,\n        -0.1097], device='cuda:0', requires_grad=True)\nfinal_layer.a\nParameter containing:\ntensor([ 1.5148e-01,  5.6302e-01,  9.7009e-02,  8.9609e-01,  3.9128e-01,\n         2.1599e-01,  3.0677e-01,  2.2480e-01, -1.9380e-03,  1.6705e-01,\n        -1.3956e-04,  1.8602e-01, -3.9613e-02,  3.3054e-01,  2.9326e-02,\n         2.3389e-01,  1.8678e-01,  1.7995e-01,  1.2494e-01,  3.0462e-01,\n         1.7110e-01,  1.4905e-01,  1.8688e-03,  6.9472e-04,  3.2705e-01,\n        -6.1251e-01,  6.6153e-01, -1.3116e-01, -5.4924e-01, -8.5632e-01,\n         2.5203e-01, -3.7971e-01, -4.8579e-01, -8.0663e-01, -1.1924e+00,\n        -1.2729e+00, -5.2327e-01, -6.4667e-02, -3.3197e-01,  2.6129e-01,\n        -4.8827e-01,  5.9906e-02, -1.2320e-02, -4.3592e-02, -2.8008e-01,\n         1.0391e-01,  1.2135e+00, -6.7124e-01, -1.7970e+00, -4.8117e-02],\n       device='cuda:0', requires_grad=True)\nfinal_layer.b\nParameter containing:\ntensor([ 0.1262, -0.3067,  0.1303,  0.0092,  0.0110, -0.4172, -0.0102, -0.2286,\n         0.0874, -0.1289,  0.0684, -0.0614, -0.4610,  0.0540, -0.4791, -0.0979,\n        -0.1938, -0.2211, -0.3251, -0.0766, -0.1717, -0.0614, -0.0748, -0.2872,\n         0.0284,  1.0791, -0.1803,  1.4300,  0.5472, -0.1937, -1.7900, -0.0043,\n        -0.0538, -0.2442,  0.2943, -0.1920,  0.1327,  0.7442,  0.3268,  0.7183,\n         0.3123,  0.4135,  0.5760,  0.4505,  0.1525, -0.6147, -0.3272, -0.0892,\n         0.2346,  0.3720], device='cuda:0', requires_grad=True)\nfinal_layer.local_bias\nParameter containing:\ntensor([ 0.0322, -0.1132, -0.0984,  0.4704, -0.0633,  0.0361,  0.2007,  0.1180,\n         0.1855, -0.0995,  0.0467, -0.0447,  0.3377, -0.2424,  0.4153, -0.1512,\n        -0.0950,  0.0665,  0.1165, -0.2106,  0.0249, -0.0445,  0.2645,  0.2483,\n        -0.3026,  0.0307,  0.0604,  0.0123, -0.0270,  0.0883, -0.3455, -0.0489,\n         0.0341, -0.0540, -0.0769, -0.0591, -0.1250,  0.0263, -0.1086, -0.0980,\n        -0.0598, -0.0959, -0.1882, -0.1301, -0.1292,  0.0246,  0.2102, -0.1796,\n        -0.0912, -0.1097], device='cuda:0', requires_grad=True)\nfinal_layer.global_bias\nParameter containing:\ntensor(-0.2769, device='cuda:0', requires_grad=True)\n","output_type":"stream"}],"execution_count":136},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99999 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 0.1)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 10000, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T02:49:09.942269Z","iopub.execute_input":"2025-01-23T02:49:09.943062Z","iopub.status.idle":"2025-01-23T03:44:53.305969Z","shell.execute_reply.started":"2025-01-23T02:49:09.943029Z","shell.execute_reply":"2025-01-23T03:44:53.304783Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"here\nLearning Rate: 9.998700077997147e-05\nEpoch 1, Training Loss: 0.3454318817470744, Validation Loss: 0.26897857872054437\nEpoch 1, Training Loss: 0.26728401439349014, Validation Loss: 0.26897857872054437\nTraining Accuracy: 0.8973240929076891, Training F1 Score: 0.8914668805126142\nValidation Accuracy: 0.898059848733969, Validation F1 Score: 0.8924544424941138\n\nLearning Rate: 9.886350177801952e-05\nEpoch 11, Training Loss: 0.21274061212868917, Validation Loss: 0.22232411616101777\nEpoch 11, Training Loss: 0.21116409075468082, Validation Loss: 0.22232411616101777\nTraining Accuracy: 0.9329378950830055, Training F1 Score: 0.9291547017317171\nValidation Accuracy: 0.9285322810479009, Validation F1 Score: 0.9245266797676718\n\nLearning Rate: 9.775262691718132e-05\nEpoch 21, Training Loss: 0.20356943747247294, Validation Loss: 0.215115248020132\nEpoch 21, Training Loss: 0.20241574494068862, Validation Loss: 0.215115248020132\nTraining Accuracy: 0.9360802893925922, Training F1 Score: 0.9325798659201071\nValidation Accuracy: 0.930505316233695, Validation F1 Score: 0.9267816512030065\n\nLearning Rate: 9.6654234346918e-05\nEpoch 31, Training Loss: 0.19877382778904915, Validation Loss: 0.212234446798698\nEpoch 31, Training Loss: 0.1982624829410759, Validation Loss: 0.212234446798698\nTraining Accuracy: 0.9376393067244803, Training F1 Score: 0.9343577591324073\nValidation Accuracy: 0.931711059958347, Validation F1 Score: 0.9281354106067534\n\nLearning Rate: 9.556818381058724e-05\nEpoch 41, Training Loss: 0.19560729140225697, Validation Loss: 0.2109821711838487\nEpoch 41, Training Loss: 0.1947436356971948, Validation Loss: 0.2109821711838487\nTraining Accuracy: 0.9389547275982607, Training F1 Score: 0.9357234794240812\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9292086577948201\n\nLearning Rate: 9.44943366275336e-05\nEpoch 51, Training Loss: 0.19300043968825897, Validation Loss: 0.2099956267580813\nEpoch 51, Training Loss: 0.19239263590199066, Validation Loss: 0.2099956267580813\nTraining Accuracy: 0.939709876618394, Training F1 Score: 0.9365209374322278\nValidation Accuracy: 0.9321495122218568, Validation F1 Score: 0.9285731945857261\n\nLearning Rate: 9.343255567537995e-05\nEpoch 61, Training Loss: 0.19101748054116677, Validation Loss: 0.20909676635740984\nEpoch 61, Training Loss: 0.19043613800692163, Validation Loss: 0.20909676635740984\nTraining Accuracy: 0.9405259247530541, Training F1 Score: 0.9374158310205436\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9294159516618704\n\nLearning Rate: 9.238270537251802e-05\nEpoch 71, Training Loss: 0.18946439969447154, Validation Loss: 0.20842522596706622\nEpoch 71, Training Loss: 0.18895503034303812, Validation Loss: 0.20842522596706622\nTraining Accuracy: 0.9410131176692691, Training F1 Score: 0.9379216596353741\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9307189211695799\n\nLearning Rate: 9.134465166079558e-05\nEpoch 81, Training Loss: 0.18811895859139413, Validation Loss: 0.2081510578623652\nEpoch 81, Training Loss: 0.1877685078029727, Validation Loss: 0.2081510578623652\nTraining Accuracy: 0.9414515912938626, Training F1 Score: 0.9383966900431339\nValidation Accuracy: 0.9347802258029158, Validation F1 Score: 0.9314557186935016\n\nLearning Rate: 9.031826198839819e-05\nEpoch 91, Training Loss: 0.1870775562189323, Validation Loss: 0.20805109802449362\nEpoch 91, Training Loss: 0.18682084537105767, Validation Loss: 0.20805109802449362\nTraining Accuracy: 0.9417195473977809, Training F1 Score: 0.9386853787006743\nValidation Accuracy: 0.9354379041981804, Validation F1 Score: 0.9321245991192478\n\nLearning Rate: 8.930340529292338e-05\nEpoch 101, Training Loss: 0.1860135438219995, Validation Loss: 0.2078105535284281\nEpoch 101, Training Loss: 0.18588464450567863, Validation Loss: 0.2078105535284281\nTraining Accuracy: 0.9418291658039292, Training F1 Score: 0.9387995811808238\nValidation Accuracy: 0.9356571303299354, Validation F1 Score: 0.9323550758624763\n\nLearning Rate: 8.829995198464486e-05\nEpoch 111, Training Loss: 0.18511557065504655, Validation Loss: 0.20800546539315892\nEpoch 111, Training Loss: 0.18511778976977292, Validation Loss: 0.20800546539315892\nTraining Accuracy: 0.9420605824391314, Training F1 Score: 0.9390598140424031\nValidation Accuracy: 0.9352186780664256, Validation F1 Score: 0.9319388792539643\n\nLearning Rate: 8.730777392996492e-05\nEpoch 121, Training Loss: 0.18425561217830172, Validation Loss: 0.20790448139976883\nEpoch 121, Training Loss: 0.18432863247427522, Validation Loss: 0.20790448139976883\nTraining Accuracy: 0.942340718365955, Training F1 Score: 0.9393600140980269\nValidation Accuracy: 0.9358763564616902, Validation F1 Score: 0.9326077234213417\n\nLearning Rate: 8.63267444350527e-05\nEpoch 131, Training Loss: 0.1833810093502234, Validation Loss: 0.2078288945482839\nEpoch 131, Training Loss: 0.18356379108882806, Validation Loss: 0.2078288945482839\nTraining Accuracy: 0.9425721350011571, Training F1 Score: 0.9396221863318535\nValidation Accuracy: 0.9356571303299354, Validation F1 Score: 0.9323995298173894\n\nLearning Rate: 8.535673822966635e-05\nEpoch 141, Training Loss: 0.18265515895591442, Validation Loss: 0.2077694428384559\nEpoch 141, Training Loss: 0.182869217196989, Validation Loss: 0.2077694428384559\nTraining Accuracy: 0.9428279112821699, Training F1 Score: 0.9398987958454329\nValidation Accuracy: 0.935109065000548, Validation F1 Score: 0.931812523308028\n\nLearning Rate: 8.439763145115688e-05\nEpoch 151, Training Loss: 0.18197773764674682, Validation Loss: 0.2076665143341816\nEpoch 151, Training Loss: 0.1822478065775319, Validation Loss: 0.2076665143341816\nTraining Accuracy: 0.9430471480944667, Training F1 Score: 0.9401445791627736\nValidation Accuracy: 0.9352186780664256, Validation F1 Score: 0.9318941223760194\n\nLearning Rate: 8.344930162865182e-05\nEpoch 161, Training Loss: 0.1813113878210336, Validation Loss: 0.2075898441423074\nEpoch 161, Training Loss: 0.1816270670112506, Validation Loss: 0.2075898441423074\nTraining Accuracy: 0.9431933059693312, Training F1 Score: 0.9403069050250977\nValidation Accuracy: 0.9354379041981804, Validation F1 Score: 0.9321245991192478\n\nLearning Rate: 8.251162766741668e-05\nEpoch 171, Training Loss: 0.18069175749677047, Validation Loss: 0.20751865837483321\nEpoch 171, Training Loss: 0.1810487207783161, Validation Loss: 0.20751865837483321\nTraining Accuracy: 0.9434247226045334, Training F1 Score: 0.9405620090000006\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9319981657645077\n\nLearning Rate: 8.158448983339194e-05\nEpoch 181, Training Loss: 0.1800932332120328, Validation Loss: 0.20734627670485448\nEpoch 181, Training Loss: 0.18044908210658234, Validation Loss: 0.20734627670485448\nTraining Accuracy: 0.9435952401252086, Training F1 Score: 0.9407562725737022\nValidation Accuracy: 0.9355475172640578, Validation F1 Score: 0.9322509846694447\n\nLearning Rate: 8.066776973790393e-05\nEpoch 191, Training Loss: 0.1795372716018858, Validation Loss: 0.20731508680064467\nEpoch 191, Training Loss: 0.17990761066413646, Validation Loss: 0.20731508680064467\nTraining Accuracy: 0.9435952401252086, Training F1 Score: 0.9407692142165509\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9320651875374031\n\nLearning Rate: 7.97613503225475e-05\nEpoch 201, Training Loss: 0.17902419487791862, Validation Loss: 0.20732200001168902\nEpoch 201, Training Loss: 0.17945871182070006, Validation Loss: 0.20732200001168902\nTraining Accuracy: 0.943546520833587, Training F1 Score: 0.9407331463297822\nValidation Accuracy: 0.935109065000548, Validation F1 Score: 0.93183490003753\n\nLearning Rate: 7.886511584423848e-05\nEpoch 211, Training Loss: 0.17852430949133818, Validation Loss: 0.2072547542268765\nEpoch 211, Training Loss: 0.1789781241910637, Validation Loss: 0.2072547542268765\nTraining Accuracy: 0.9436317795939247, Training F1 Score: 0.9408151217822168\nValidation Accuracy: 0.9349994519346706, Validation F1 Score: 0.9317309487160237\n\nLearning Rate: 7.797895186043415e-05\nEpoch 221, Training Loss: 0.17814658834903946, Validation Loss: 0.20732607611056994\nEpoch 221, Training Loss: 0.17844237954601622, Validation Loss: 0.20732607611056994\nTraining Accuracy: 0.9437901172916946, Training F1 Score: 0.9409802980129383\nValidation Accuracy: 0.9355475172640578, Validation F1 Score: 0.9322732495018926\n\nLearning Rate: 7.710274521451978e-05\nEpoch 231, Training Loss: 0.1775199719078365, Validation Loss: 0.20755439654856703\nEpoch 231, Training Loss: 0.17793319315618816, Validation Loss: 0.20755439654856703\nTraining Accuracy: 0.9438144769375053, Training F1 Score: 0.9410037291088572\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9320651875374031\n\nLearning Rate: 7.623638402135936e-05\nEpoch 241, Training Loss: 0.17703600725542432, Validation Loss: 0.20737098104321589\nEpoch 241, Training Loss: 0.17743705222289785, Validation Loss: 0.20737098104321589\nTraining Accuracy: 0.944033713749802, Training F1 Score: 0.9412317952198207\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9320205458417897\n\nLearning Rate: 7.537975765300869e-05\nEpoch 251, Training Loss: 0.17657110202667906, Validation Loss: 0.20727587425367724\nEpoch 251, Training Loss: 0.17698727272923806, Validation Loss: 0.20727587425367724\nTraining Accuracy: 0.9442042312704774, Training F1 Score: 0.9414300204798803\nValidation Accuracy: 0.935109065000548, Validation F1 Score: 0.9318572372860632\n\nLearning Rate: 7.453275672458901e-05\nEpoch 261, Training Loss: 0.17614543845918862, Validation Loss: 0.20719664485147749\nEpoch 261, Training Loss: 0.17656696899924434, Validation Loss: 0.20719664485147749\nTraining Accuracy: 0.9443138496766257, Training F1 Score: 0.9415482747896871\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9320651875374031\n\nLearning Rate: 7.369527308031936e-05\nEpoch 271, Training Loss: 0.17572183101454944, Validation Loss: 0.20709501975534989\nEpoch 271, Training Loss: 0.1761629953155558, Validation Loss: 0.20709501975534989\nTraining Accuracy: 0.9444478277285848, Training F1 Score: 0.9417005510670488\nValidation Accuracy: 0.935109065000548, Validation F1 Score: 0.93183490003753\n\nLearning Rate: 7.286719977970586e-05\nEpoch 281, Training Loss: 0.17532004749519536, Validation Loss: 0.20710427409839724\nEpoch 281, Training Loss: 0.17579734364738578, Validation Loss: 0.20710427409839724\nTraining Accuracy: 0.9444112882598688, Training F1 Score: 0.9416759589945629\nValidation Accuracy: 0.935109065000548, Validation F1 Score: 0.9318572372860632\n\nLearning Rate: 7.204843108388625e-05\nEpoch 291, Training Loss: 0.17491655422953184, Validation Loss: 0.2070164290956796\nEpoch 291, Training Loss: 0.17541418541360973, Validation Loss: 0.2070164290956796\nTraining Accuracy: 0.9444478277285848, Training F1 Score: 0.9417301347523717\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9321096718424263\n\nLearning Rate: 7.123886244212772e-05\nEpoch 301, Training Loss: 0.1745070767774638, Validation Loss: 0.20694544728938052\nEpoch 301, Training Loss: 0.17504490400003725, Validation Loss: 0.20694544728938052\nTraining Accuracy: 0.9445574461347332, Training F1 Score: 0.9418482744743829\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9321096718424263\n\nLearning Rate: 7.043839047847668e-05\nEpoch 311, Training Loss: 0.1741171690530786, Validation Loss: 0.20691694797333246\nEpoch 311, Training Loss: 0.1746637590228876, Validation Loss: 0.20691694797333246\nTraining Accuracy: 0.9446305250721655, Training F1 Score: 0.9419207182224614\nValidation Accuracy: 0.935109065000548, Validation F1 Score: 0.9319017936726983\n\nLearning Rate: 6.964691297855829e-05\nEpoch 321, Training Loss: 0.17372264897800246, Validation Loss: 0.2069626566311331\nEpoch 321, Training Loss: 0.1743388011658286, Validation Loss: 0.2069626566311331\nTraining Accuracy: 0.9447157838325031, Training F1 Score: 0.9420300834031253\nValidation Accuracy: 0.9349994519346706, Validation F1 Score: 0.9317978962440735\n\nLearning Rate: 6.886432887652451e-05\nEpoch 331, Training Loss: 0.17332915346424974, Validation Loss: 0.2070086820500861\nEpoch 331, Training Loss: 0.1739984834477894, Validation Loss: 0.2070086820500861\nTraining Accuracy: 0.9447645031241245, Training F1 Score: 0.9420979123313095\nValidation Accuracy: 0.9348898388687932, Validation F1 Score: 0.9317162816207669\n\nLearning Rate: 6.809053824214872e-05\nEpoch 341, Training Loss: 0.17295073002503142, Validation Loss: 0.20704210892680652\nEpoch 341, Training Loss: 0.17365993308536481, Validation Loss: 0.20704210892680652\nTraining Accuracy: 0.9446792443637869, Training F1 Score: 0.9420200508088162\nValidation Accuracy: 0.9345609996711608, Validation F1 Score: 0.9314048917414651\n\nLearning Rate: 6.732544226806539e-05\nEpoch 351, Training Loss: 0.17257889575649452, Validation Loss: 0.20680072775250868\nEpoch 351, Training Loss: 0.17323002783663083, Validation Loss: 0.20680072775250868\nTraining Accuracy: 0.9448863013531783, Training F1 Score: 0.9422339337451445\nValidation Accuracy: 0.9344513866052834, Validation F1 Score: 0.9313234370103659\n\nLearning Rate: 6.6568943257153e-05\nEpoch 361, Training Loss: 0.17220172612758236, Validation Loss: 0.20665466994664575\nEpoch 361, Training Loss: 0.1728864454147045, Validation Loss: 0.20665466994664575\nTraining Accuracy: 0.945068998696759, Training F1 Score: 0.9424389222805973\nValidation Accuracy: 0.9346706127370382, Validation F1 Score: 0.931575297700321\n\nLearning Rate: 6.582094461005897e-05\nEpoch 371, Training Loss: 0.17246072450071145, Validation Loss: 0.20901392791291595\nEpoch 371, Training Loss: 0.17344209096153626, Validation Loss: 0.20901392791291595\nTraining Accuracy: 0.9447888627699353, Training F1 Score: 0.9421088058750484\nValidation Accuracy: 0.9344513866052834, Validation F1 Score: 0.9312340536484901\n\nLearning Rate: 6.508135081286461e-05\nEpoch 381, Training Loss: 0.17149154407114034, Validation Loss: 0.20639897651327657\nEpoch 381, Training Loss: 0.17227395994668204, Validation Loss: 0.20639897651327657\nTraining Accuracy: 0.9450202794051374, Training F1 Score: 0.942421054511647\nValidation Accuracy: 0.9348898388687932, Validation F1 Score: 0.9318049107952864\n\nLearning Rate: 6.43500674248886e-05\nEpoch 391, Training Loss: 0.17115990403360518, Validation Loss: 0.20634040574415674\nEpoch 391, Training Loss: 0.17203437980697422, Validation Loss: 0.20634040574415674\nTraining Accuracy: 0.9451664372800019, Training F1 Score: 0.9425865064586961\nValidation Accuracy: 0.9347802258029158, Validation F1 Score: 0.9317011576336981\n\nLearning Rate: 6.36270010666277e-05\nEpoch 401, Training Loss: 0.17084720579797108, Validation Loss: 0.20628938564315485\nEpoch 401, Training Loss: 0.17176897710231942, Validation Loss: 0.20628938564315485\nTraining Accuracy: 0.9451907969258126, Training F1 Score: 0.942632611315236\nValidation Accuracy: 0.9346706127370382, Validation F1 Score: 0.9315531245120033\n\nLearning Rate: 6.291205940783288e-05\nEpoch 411, Training Loss: 0.17054123404828145, Validation Loss: 0.20635235213559147\nEpoch 411, Training Loss: 0.1715411561380218, Validation Loss: 0.20635235213559147\nTraining Accuracy: 0.9452516960403395, Training F1 Score: 0.942709705829161\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311383542475123\n\nLearning Rate: 6.220515115571938e-05\nEpoch 421, Training Loss: 0.17023431371099387, Validation Loss: 0.20635306055244224\nEpoch 421, Training Loss: 0.17133577263562302, Validation Loss: 0.20635306055244224\nTraining Accuracy: 0.9453369548006771, Training F1 Score: 0.9428122384440784\nValidation Accuracy: 0.934341773539406, Validation F1 Score: 0.9313085666965548\n\nLearning Rate: 6.150618604330927e-05\nEpoch 431, Training Loss: 0.1699533936099045, Validation Loss: 0.20644052375353417\nEpoch 431, Training Loss: 0.17113552214667294, Validation Loss: 0.20644052375353417\nTraining Accuracy: 0.945361314446488, Training F1 Score: 0.9428540806926448\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9311013958623583\n\nLearning Rate: 6.081507481790516e-05\nEpoch 441, Training Loss: 0.16966051896925946, Validation Loss: 0.2064659476107076\nEpoch 441, Training Loss: 0.17096384295359143, Validation Loss: 0.2064659476107076\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9428979216154444\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.931227094189489\n\nLearning Rate: 6.01317292296931e-05\nEpoch 451, Training Loss: 0.16937824613700728, Validation Loss: 0.2065709835308549\nEpoch 451, Training Loss: 0.17074126510232854, Validation Loss: 0.2065709835308549\nTraining Accuracy: 0.9454222135610149, Training F1 Score: 0.9429473242496654\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309978511701207\n\nLearning Rate: 5.945606202047387e-05\nEpoch 461, Training Loss: 0.16911947912798628, Validation Loss: 0.20676231201340803\nEpoch 461, Training Loss: 0.1705575546235296, Validation Loss: 0.20676231201340803\nTraining Accuracy: 0.9454831126755417, Training F1 Score: 0.9430302783354282\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9309165121614874\n\nLearning Rate: 5.878798691252068e-05\nEpoch 471, Training Loss: 0.16886023119439184, Validation Loss: 0.20689360898347012\nEpoch 471, Training Loss: 0.17040317413081754, Validation Loss: 0.20689360898347012\nTraining Accuracy: 0.945653630196217, Training F1 Score: 0.943230693198122\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9307317667313504\n\nLearning Rate: 5.8127418597562165e-05\nEpoch 481, Training Loss: 0.16860620012987143, Validation Loss: 0.20680607029328832\nEpoch 481, Training Loss: 0.1701516417507138, Validation Loss: 0.20680607029328832\nTraining Accuracy: 0.9456779898420277, Training F1 Score: 0.943264205396643\nValidation Accuracy: 0.9335744820782638, Validation F1 Score: 0.9306283645502896\n\nLearning Rate: 5.747427272588915e-05\nEpoch 491, Training Loss: 0.16835058030460806, Validation Loss: 0.20684844145522127\nEpoch 491, Training Loss: 0.16996484413673507, Validation Loss: 0.20684844145522127\nTraining Accuracy: 0.9457754284252707, Training F1 Score: 0.9433800496194468\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9304216407221051\n\nLearning Rate: 5.682846589558383e-05\nEpoch 501, Training Loss: 0.16809602288442319, Validation Loss: 0.20682840893388277\nEpoch 501, Training Loss: 0.16975311203873983, Validation Loss: 0.20682840893388277\nTraining Accuracy: 0.9459946652375675, Training F1 Score: 0.9436169735600436\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9300085141385989\n\nLearning Rate: 5.618991564186986e-05\nEpoch 511, Training Loss: 0.16783630946717823, Validation Loss: 0.2069270173492994\nEpoch 511, Training Loss: 0.16950040370160205, Validation Loss: 0.2069270173492994\nTraining Accuracy: 0.9460921038208104, Training F1 Score: 0.9437187020696329\nValidation Accuracy: 0.933136029814754, Validation F1 Score: 0.930237244484551\n\nLearning Rate: 5.555854042658237e-05\nEpoch 521, Training Loss: 0.16759259695559023, Validation Loss: 0.2070589241219837\nEpoch 521, Training Loss: 0.16923840320067635, Validation Loss: 0.2070589241219837\nTraining Accuracy: 0.9462017222269589, Training F1 Score: 0.9438361344004704\nValidation Accuracy: 0.9332456428806314, Validation F1 Score: 0.9303626870957629\n\nLearning Rate: 5.4934259627756014e-05\nEpoch 531, Training Loss: 0.16736183634553875, Validation Loss: 0.20697586223030645\nEpoch 531, Training Loss: 0.16901337926961857, Validation Loss: 0.20697586223030645\nTraining Accuracy: 0.9463113406331072, Training F1 Score: 0.9439436142996362\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9305101537179645\n\nLearning Rate: 5.43169935293302e-05\nEpoch 541, Training Loss: 0.16712673747229384, Validation Loss: 0.20706701532510974\nEpoch 541, Training Loss: 0.1687668402861813, Validation Loss: 0.20706701532510974\nTraining Accuracy: 0.9465062177995932, Training F1 Score: 0.9441470857540839\nValidation Accuracy: 0.9334648690123862, Validation F1 Score: 0.9306354486463266\n\nLearning Rate: 5.370666331096988e-05\nEpoch 551, Training Loss: 0.16690055973112844, Validation Loss: 0.207281265141971\nEpoch 551, Training Loss: 0.1685060996572633, Validation Loss: 0.207281265141971\nTraining Accuracy: 0.9465427572683093, Training F1 Score: 0.9441901861288777\nValidation Accuracy: 0.933136029814754, Validation F1 Score: 0.9303257378227563\n\nLearning Rate: 5.3103191038000865e-05\nEpoch 561, Training Loss: 0.16667943086973833, Validation Loss: 0.20721641337905525\nEpoch 561, Training Loss: 0.16825700625620252, Validation Loss: 0.20721641337905525\nTraining Accuracy: 0.9465183976224986, Training F1 Score: 0.9441766287666807\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9302225539074442\n\nLearning Rate: 5.250649965145806e-05\nEpoch 571, Training Loss: 0.16646914937763402, Validation Loss: 0.20729168600273226\nEpoch 571, Training Loss: 0.16796206341667294, Validation Loss: 0.20729168600273226\nTraining Accuracy: 0.9466036563828362, Training F1 Score: 0.9442626581583637\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9299941498285815\n\nLearning Rate: 5.1916512958245645e-05\nEpoch 581, Training Loss: 0.16627114297147166, Validation Loss: 0.20718720150558387\nEpoch 581, Training Loss: 0.16770745860272626, Validation Loss: 0.20718720150558387\nTraining Accuracy: 0.9466767353202684, Training F1 Score: 0.9443428854797885\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9299131607145898\n\nLearning Rate: 5.1333155621407726e-05\nEpoch 591, Training Loss: 0.166067769661, Validation Loss: 0.20717503912326315\nEpoch 591, Training Loss: 0.1674424945270356, Validation Loss: 0.20717503912326315\nTraining Accuracy: 0.9467376344347953, Training F1 Score: 0.9444054651780219\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9301193964425819\n\nLearning Rate: 5.075635315050845e-05\nEpoch 601, Training Loss: 0.16586719392607083, Validation Loss: 0.20704651814495983\nEpoch 601, Training Loss: 0.16718307216620487, Validation Loss: 0.20704651814495983\nTraining Accuracy: 0.9468350730180383, Training F1 Score: 0.9445071702497293\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9305321851546525\n\nLearning Rate: 5.018603189212003e-05\nEpoch 611, Training Loss: 0.1656741669472014, Validation Loss: 0.20697678338765288\nEpoch 611, Training Loss: 0.16691715476121696, Validation Loss: 0.20697678338765288\nTraining Accuracy: 0.9469081519554706, Training F1 Score: 0.944581485381239\nValidation Accuracy: 0.9332456428806314, Validation F1 Score: 0.9303848128607657\n\nLearning Rate: 4.962211902041782e-05\nEpoch 621, Training Loss: 0.1654880235202071, Validation Loss: 0.2069597788482568\nEpoch 621, Training Loss: 0.16667919473961082, Validation Loss: 0.2069597788482568\nTraining Accuracy: 0.9468472528409437, Training F1 Score: 0.9445149678531836\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9304659748305034\n\nLearning Rate: 4.906454252788093e-05\nEpoch 631, Training Loss: 0.16530908434755867, Validation Loss: 0.20690784074719715\nEpoch 631, Training Loss: 0.16642217370409168, Validation Loss: 0.20690784074719715\nTraining Accuracy: 0.9469690510699974, Training F1 Score: 0.9446362221802781\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.930133993128918\n\nLearning Rate: 4.851323121609744e-05\nEpoch 641, Training Loss: 0.1651267517320541, Validation Loss: 0.20687884376045906\nEpoch 641, Training Loss: 0.16619168361809425, Validation Loss: 0.20687884376045906\nTraining Accuracy: 0.9470786694761458, Training F1 Score: 0.9447536011769402\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9300307683973988\n\nLearning Rate: 4.796811468667287e-05\nEpoch 651, Training Loss: 0.16494175149126367, Validation Loss: 0.20686151331798375\nEpoch 651, Training Loss: 0.16593809747528077, Validation Loss: 0.20686151331798375\nTraining Accuracy: 0.9471639282364834, Training F1 Score: 0.9448396719839333\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9299498023397005\n\nLearning Rate: 4.742912333224084e-05\nEpoch 661, Training Loss: 0.16475986406026863, Validation Loss: 0.20689136985818846\nEpoch 661, Training Loss: 0.16569085563519792, Validation Loss: 0.20689136985818846\nTraining Accuracy: 0.9471517484135781, Training F1 Score: 0.9448318466017276\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9298466475081525\n\nLearning Rate: 4.689618832757469e-05\nEpoch 671, Training Loss: 0.1650814638586266, Validation Loss: 0.2075053321420787\nEpoch 671, Training Loss: 0.1653131815040727, Validation Loss: 0.2075053321420787\nTraining Accuracy: 0.947212647528105, Training F1 Score: 0.9448670551993388\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9297212535708249\n\nLearning Rate: 4.6369241620799035e-05\nEpoch 681, Training Loss: 0.1644215459285836, Validation Loss: 0.20753754691231946\nEpoch 681, Training Loss: 0.1652917844683889, Validation Loss: 0.20753754691231946\nTraining Accuracy: 0.9471882878822941, Training F1 Score: 0.9448690128794709\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9298688574150364\n\nLearning Rate: 4.5848215924700034e-05\nEpoch 691, Training Loss: 0.16426063790020273, Validation Loss: 0.20750017780379795\nEpoch 691, Training Loss: 0.16509150648408036, Validation Loss: 0.20750017780379795\nTraining Accuracy: 0.9473466255800641, Training F1 Score: 0.9450352783727284\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9297435191444686\n\nLearning Rate: 4.5333044708133294e-05\nEpoch 701, Training Loss: 0.16410672360658862, Validation Loss: 0.20745661909298246\nEpoch 701, Training Loss: 0.16492525493773572, Validation Loss: 0.20745661909298246\nTraining Accuracy: 0.9473588054029695, Training F1 Score: 0.9450528615554755\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9298910284571001\n\nLearning Rate: 4.482366218752834e-05\nEpoch 711, Training Loss: 0.16395124843743808, Validation Loss: 0.20748846938830123\nEpoch 711, Training Loss: 0.16478608587408217, Validation Loss: 0.20748846938830123\nTraining Accuracy: 0.9473831650487802, Training F1 Score: 0.9450763419808694\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9302004718654803\n\nLearning Rate: 4.432000331848857e-05\nEpoch 721, Training Loss: 0.16380278246775282, Validation Loss: 0.20758003301556716\nEpoch 721, Training Loss: 0.16466209488987418, Validation Loss: 0.20758003301556716\nTraining Accuracy: 0.9473466255800641, Training F1 Score: 0.945048907899764\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9302004718654803\n\nLearning Rate: 4.3822003787485504e-05\nEpoch 731, Training Loss: 0.16365930275986137, Validation Loss: 0.20765577103796856\nEpoch 731, Training Loss: 0.16456704511270234, Validation Loss: 0.20765577103796856\nTraining Accuracy: 0.9473953448716855, Training F1 Score: 0.9451094682302618\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9299131607145898\n\nLearning Rate: 4.3329600003646476e-05\nEpoch 741, Training Loss: 0.16351810182215923, Validation Loss: 0.2077391428078108\nEpoch 741, Training Loss: 0.16448194671603236, Validation Loss: 0.2077391428078108\nTraining Accuracy: 0.9474440641633071, Training F1 Score: 0.9451661236268966\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9299352542675223\n\nLearning Rate: 4.28427290906345e-05\nEpoch 751, Training Loss: 0.16337864466061708, Validation Loss: 0.20783903132166553\nEpoch 751, Training Loss: 0.1644051758653201, Validation Loss: 0.20783903132166553\nTraining Accuracy: 0.947504963277834, Training F1 Score: 0.9452441782443551\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9298542640931837\n\nLearning Rate: 4.2361328878619464e-05\nEpoch 761, Training Loss: 0.16324868842576634, Validation Loss: 0.20799276791982557\nEpoch 761, Training Loss: 0.16436321159332587, Validation Loss: 0.20799276791982557\nTraining Accuracy: 0.9474684238091178, Training F1 Score: 0.9452263659854288\nValidation Accuracy: 0.9322591252877342, Validation F1 Score: 0.9295673683877447\n\nLearning Rate: 4.188533789633949e-05\nEpoch 771, Training Loss: 0.16312094860628906, Validation Loss: 0.20819100786572575\nEpoch 771, Training Loss: 0.1643298218783154, Validation Loss: 0.20819100786572575\nTraining Accuracy: 0.9475171431007393, Training F1 Score: 0.945292589775343\nValidation Accuracy: 0.9321495122218568, Validation F1 Score: 0.929464444336259\n\nLearning Rate: 4.141469536325149e-05\nEpoch 781, Training Loss: 0.16298421590145679, Validation Loss: 0.2084119977507298\nEpoch 781, Training Loss: 0.1643029267016397, Validation Loss: 0.2084119977507298\nTraining Accuracy: 0.9475780422152662, Training F1 Score: 0.9453647262153544\nValidation Accuracy: 0.9320398991559794, Validation F1 Score: 0.9293394310686109\n\nLearning Rate: 4.094934118176996e-05\nEpoch 791, Training Loss: 0.16286432461213096, Validation Loss: 0.20872106420507716\nEpoch 791, Training Loss: 0.16433509584143455, Validation Loss: 0.20872106420507716\nTraining Accuracy: 0.9474562439862124, Training F1 Score: 0.9452628073112326\nValidation Accuracy: 0.9320398991559794, Validation F1 Score: 0.9293394310686109\n\nLearning Rate: 4.048921592959294e-05\nEpoch 801, Training Loss: 0.16274299048955504, Validation Loss: 0.20901408864553334\nEpoch 801, Training Loss: 0.16436539903870614, Validation Loss: 0.20901408864553334\nTraining Accuracy: 0.9474927834549286, Training F1 Score: 0.9453152689809236\nValidation Accuracy: 0.9320398991559794, Validation F1 Score: 0.9293836229475276\n\nLearning Rate: 4.0034260852114245e-05\nEpoch 811, Training Loss: 0.1629482835659006, Validation Loss: 0.2089264353064086\nEpoch 811, Training Loss: 0.16426553166038366, Validation Loss: 0.2089264353064086\nTraining Accuracy: 0.9475171431007393, Training F1 Score: 0.9453540507496917\nValidation Accuracy: 0.9318206730242244, Validation F1 Score: 0.9291779373879652\n\nLearning Rate: 3.958441785492091e-05\nEpoch 821, Training Loss: 0.16253056794562157, Validation Loss: 0.20988526589989623\nEpoch 821, Training Loss: 0.1645530426156882, Validation Loss: 0.20988526589989623\nTraining Accuracy: 0.947504963277834, Training F1 Score: 0.9453824582354634\nValidation Accuracy: 0.9313822207607146, Validation F1 Score: 0.9287668764424181\n\nLearning Rate: 3.9139629496375e-05\nEpoch 831, Training Loss: 0.16243674688963833, Validation Loss: 0.21017456810280744\nEpoch 831, Training Loss: 0.16468279387667534, Validation Loss: 0.21017456810280744\nTraining Accuracy: 0.9473466255800641, Training F1 Score: 0.9452435087554542\nValidation Accuracy: 0.9308341554313274, Validation F1 Score: 0.9282313751536888\n\nLearning Rate: 3.8699838980278686e-05\nEpoch 841, Training Loss: 0.16234975312054742, Validation Loss: 0.21048774390475186\nEpoch 841, Training Loss: 0.16481649501637205, Validation Loss: 0.21048774390475186\nTraining Accuracy: 0.9474318843404017, Training F1 Score: 0.9453483503561072\nValidation Accuracy: 0.9310533815630824, Validation F1 Score: 0.9284810341231718\n\nLearning Rate: 3.8264990148621824e-05\nEpoch 851, Training Loss: 0.1622640400743455, Validation Loss: 0.21081723887434553\nEpoch 851, Training Loss: 0.16497829792025567, Validation Loss: 0.21081723887434553\nTraining Accuracy: 0.9472979062884426, Training F1 Score: 0.9452423691793478\nValidation Accuracy: 0.9309437684972048, Validation F1 Score: 0.9283784261574953\n\nLearning Rate: 3.783502747441099e-05\nEpoch 861, Training Loss: 0.16219396776774522, Validation Loss: 0.21115698849705375\nEpoch 861, Training Loss: 0.16515931382851715, Validation Loss: 0.21115698849705375\nTraining Accuracy: 0.9472735466426319, Training F1 Score: 0.9452379471419137\nValidation Accuracy: 0.9306149292995725, Validation F1 Score: 0.9280707553508614\n\nLearning Rate: 3.740989605457906e-05\nEpoch 871, Training Loss: 0.1621163206043228, Validation Loss: 0.21151685834283776\nEpoch 871, Training Loss: 0.16536981783583224, Validation Loss: 0.21151685834283776\nTraining Accuracy: 0.9472248273510103, Training F1 Score: 0.9452214623405399\nValidation Accuracy: 0.9306149292995725, Validation F1 Score: 0.9280929631236876\n\nLearning Rate: 3.698954160297454e-05\nEpoch 881, Training Loss: 0.16205689729279307, Validation Loss: 0.21179010781046984\nEpoch 881, Training Loss: 0.165535218725933, Validation Loss: 0.21179010781046984\nTraining Accuracy: 0.947212647528105, Training F1 Score: 0.9452362218758305\nValidation Accuracy: 0.930505316233695, Validation F1 Score: 0.9279904728143091\n\nLearning Rate: 3.657391044342959e-05\nEpoch 891, Training Loss: 0.161990970112892, Validation Loss: 0.21209200948826332\nEpoch 891, Training Loss: 0.1657044211974898, Validation Loss: 0.21209200948826332\nTraining Accuracy: 0.9472857264655372, Training F1 Score: 0.9453365047367898\nValidation Accuracy: 0.9306149292995725, Validation F1 Score: 0.9281593548368924\n\nLearning Rate: 3.616294950290597e-05\nEpoch 901, Training Loss: 0.16193126095381163, Validation Loss: 0.21231731234393358\nEpoch 901, Training Loss: 0.16582166102624873, Validation Loss: 0.21231731234393358\nTraining Accuracy: 0.947212647528105, Training F1 Score: 0.9452795290541195\nValidation Accuracy: 0.9303957031678176, Validation F1 Score: 0.9279544934866525\n\nLearning Rate: 3.5756606304718035e-05\nEpoch 911, Training Loss: 0.1618568561575078, Validation Loss: 0.21253230686931512\nEpoch 911, Training Loss: 0.1658524601929978, Validation Loss: 0.21253230686931512\nTraining Accuracy: 0.947249186996821, Training F1 Score: 0.9453370996163366\nValidation Accuracy: 0.9301764770360627, Validation F1 Score: 0.9277275785055084\n\nLearning Rate: 3.535482896183181e-05\nEpoch 921, Training Loss: 0.16178849521377958, Validation Loss: 0.21269565561642761\nEpoch 921, Training Loss: 0.1658479997837684, Validation Loss: 0.21269565561642761\nTraining Accuracy: 0.9471152089448619, Training F1 Score: 0.9452179681069645\nValidation Accuracy: 0.9300668639701852, Validation F1 Score: 0.9276030119350813\n\nLearning Rate: 3.495756617023944e-05\nEpoch 931, Training Loss: 0.16170163636169654, Validation Loss: 0.21284288678869112\nEpoch 931, Training Loss: 0.16577232799092934, Validation Loss: 0.21284288678869112\nTraining Accuracy: 0.947212647528105, Training F1 Score: 0.9453114149652224\nValidation Accuracy: 0.9303957031678176, Validation F1 Score: 0.9279544934866525\n\nLearning Rate: 3.456476720240801e-05\nEpoch 941, Training Loss: 0.16161785732588624, Validation Loss: 0.21289201940110833\nEpoch 941, Training Loss: 0.16562338207818753, Validation Loss: 0.21289201940110833\nTraining Accuracy: 0.9472735466426319, Training F1 Score: 0.9453717014689794\nValidation Accuracy: 0.9301764770360627, Validation F1 Score: 0.9277497329137364\n\nLearning Rate: 3.417638190080203e-05\nEpoch 951, Training Loss: 0.16152188890572972, Validation Loss: 0.21285349633379305\nEpoch 951, Training Loss: 0.16543987852684824, Validation Loss: 0.21285349633379305\nTraining Accuracy: 0.9473466255800641, Training F1 Score: 0.945434329072402\nValidation Accuracy: 0.9301764770360627, Validation F1 Score: 0.9277275785055084\n\nLearning Rate: 3.3792360671478677e-05\nEpoch 961, Training Loss: 0.16143197347943217, Validation Loss: 0.2128814582721217\nEpoch 961, Training Loss: 0.16522861789362195, Validation Loss: 0.2128814582721217\nTraining Accuracy: 0.9473831650487802, Training F1 Score: 0.9454656498489227\nValidation Accuracy: 0.9302860901019402, Validation F1 Score: 0.9278299617409274\n\nLearning Rate: 3.341265447775503e-05\nEpoch 971, Training Loss: 0.16132951651258595, Validation Loss: 0.21280277682856014\nEpoch 971, Training Loss: 0.16501448705024527, Validation Loss: 0.21280277682856014\nTraining Accuracy: 0.9474318843404017, Training F1 Score: 0.9455105356380595\nValidation Accuracy: 0.9303957031678176, Validation F1 Score: 0.9279323701760296\n\nLearning Rate: 3.303721483394643e-05\nEpoch 981, Training Loss: 0.16123129078094317, Validation Loss: 0.2126638310710602\nEpoch 981, Training Loss: 0.16477613921948966, Validation Loss: 0.2126638310710602\nTraining Accuracy: 0.9474197045174964, Training F1 Score: 0.9454876166668139\nValidation Accuracy: 0.930505316233695, Validation F1 Score: 0.9280348038465105\n\nLearning Rate: 3.2665993799175216e-05\nEpoch 991, Training Loss: 0.16112296698701867, Validation Loss: 0.21251467158432974\nEpoch 991, Training Loss: 0.1645172286754232, Validation Loss: 0.21251467158432974\nTraining Accuracy: 0.947504963277834, Training F1 Score: 0.9455675914649773\nValidation Accuracy: 0.9306149292995725, Validation F1 Score: 0.9281372627881136\n\nLearning Rate: 3.229894397124905e-05\nEpoch 1001, Training Loss: 0.1610244295382856, Validation Loss: 0.21229479177131683\nEpoch 1001, Training Loss: 0.16426616119165702, Validation Loss: 0.21229479177131683\nTraining Accuracy: 0.9475293229236447, Training F1 Score: 0.9455891086890227\nValidation Accuracy: 0.930505316233695, Validation F1 Score: 0.928012657628519\n\nLearning Rate: 3.193601848060798e-05\nEpoch 1011, Training Loss: 0.16091493151532676, Validation Loss: 0.21211886482386164\nEpoch 1011, Training Loss: 0.1640084022111716, Validation Loss: 0.21211886482386164\nTraining Accuracy: 0.9476145816839823, Training F1 Score: 0.9456597573606386\nValidation Accuracy: 0.930505316233695, Validation F1 Score: 0.9279904728143091\n\nLearning Rate: 3.1577170984339554e-05\nEpoch 1021, Training Loss: 0.16081428459372682, Validation Loss: 0.21195283239444176\nEpoch 1021, Training Loss: 0.16375946755812332, Validation Loss: 0.21195283239444176\nTraining Accuracy: 0.9477120202672253, Training F1 Score: 0.9457477471135483\nValidation Accuracy: 0.9306149292995725, Validation F1 Score: 0.9280929631236876\n\nLearning Rate: 3.122235566026117e-05\nEpoch 1031, Training Loss: 0.16070914473835404, Validation Loss: 0.21180684633073638\nEpoch 1031, Training Loss: 0.1635083107472471, Validation Loss: 0.21180684633073638\nTraining Accuracy: 0.9478094588504683, Training F1 Score: 0.9458320280105772\nValidation Accuracy: 0.9306149292995725, Validation F1 Score: 0.9280707553508614\n\nLearning Rate: 3.0871527201068916e-05\nEpoch 1041, Training Loss: 0.16061113237555685, Validation Loss: 0.21167962052026862\nEpoch 1041, Training Loss: 0.1632705189991585, Validation Loss: 0.21167962052026862\nTraining Accuracy: 0.9477850992046576, Training F1 Score: 0.9457917643389796\nValidation Accuracy: 0.9306149292995725, Validation F1 Score: 0.9280707553508614\n\nLearning Rate: 3.052464080855217e-05\nEpoch 1051, Training Loss: 0.1605094172830113, Validation Loss: 0.211577200542008\nEpoch 1051, Training Loss: 0.1630247271615007, Validation Loss: 0.211577200542008\nTraining Accuracy: 0.9478216386733737, Training F1 Score: 0.9458212675571999\nValidation Accuracy: 0.93072454236545, Validation F1 Score: 0.9281732868074486\n\nLearning Rate: 3.0181652187873193e-05\nEpoch 1061, Training Loss: 0.16040659658194747, Validation Loss: 0.2114335484480134\nEpoch 1061, Training Loss: 0.1627820891081563, Validation Loss: 0.2114335484480134\nTraining Accuracy: 0.9478703579649952, Training F1 Score: 0.9458606121082754\nValidation Accuracy: 0.9308341554313274, Validation F1 Score: 0.9282758437309652\n\nLearning Rate: 2.9842517541911013e-05\nEpoch 1071, Training Loss: 0.16030319706760712, Validation Loss: 0.21128771254580678\nEpoch 1071, Training Loss: 0.16254584817088188, Validation Loss: 0.21128771254580678\nTraining Accuracy: 0.9478947176108059, Training F1 Score: 0.9458727842246986\nValidation Accuracy: 0.9310533815630824, Validation F1 Score: 0.9284810341231718\n\nLearning Rate: 2.9507193565668828e-05\nEpoch 1081, Training Loss: 0.16020322060388428, Validation Loss: 0.2111645185064096\nEpoch 1081, Training Loss: 0.16232368415529996, Validation Loss: 0.2111645185064096\nTraining Accuracy: 0.9479799763711436, Training F1 Score: 0.9459529172664389\nValidation Accuracy: 0.9311629946289598, Validation F1 Score: 0.9285836676641764\n\nLearning Rate: 2.9175637440744314e-05\nEpoch 1091, Training Loss: 0.16010602254327458, Validation Loss: 0.2110369858721637\nEpoch 1091, Training Loss: 0.16210140317713662, Validation Loss: 0.2110369858721637\nTraining Accuracy: 0.9480165158398597, Training F1 Score: 0.9459749404586872\nValidation Accuracy: 0.9312726076948372, Validation F1 Score: 0.92868632681674\n\nLearning Rate: 2.8847806829862002e-05\nEpoch 1101, Training Loss: 0.16000651606514865, Validation Loss: 0.2108777697072222\nEpoch 1101, Training Loss: 0.16187097026830835, Validation Loss: 0.2108777697072222\nTraining Accuracy: 0.9481504938918188, Training F1 Score: 0.9460963797341106\nValidation Accuracy: 0.9312726076948372, Validation F1 Score: 0.92868632681674\n\nLearning Rate: 2.852365987146714e-05\nEpoch 1111, Training Loss: 0.15991394595296315, Validation Loss: 0.21078569712600176\nEpoch 1111, Training Loss: 0.1616549228152298, Validation Loss: 0.21078569712600176\nTraining Accuracy: 0.9482235728292511, Training F1 Score: 0.9461611103043172\nValidation Accuracy: 0.9312726076948372, Validation F1 Score: 0.928664175612434\n\nLearning Rate: 2.8203155174380263e-05\nEpoch 1121, Training Loss: 0.15981465348272147, Validation Loss: 0.21066939949035435\nEpoch 1121, Training Loss: 0.16143793297636783, Validation Loss: 0.21066939949035435\nTraining Accuracy: 0.9483453710583049, Training F1 Score: 0.9462784026918164\nValidation Accuracy: 0.9314918338265922, Validation F1 Score: 0.928847445259581\n\nLearning Rate: 2.7886251812511855e-05\nEpoch 1131, Training Loss: 0.15972267849227434, Validation Loss: 0.21055487248440996\nEpoch 1131, Training Loss: 0.1612284458027457, Validation Loss: 0.21055487248440996\nTraining Accuracy: 0.9483331912353994, Training F1 Score: 0.946259178248747\nValidation Accuracy: 0.9316014468924696, Validation F1 Score: 0.9289502137139716\n\nLearning Rate: 2.7572909319636386e-05\nEpoch 1141, Training Loss: 0.1596308076830916, Validation Loss: 0.21042647160067837\nEpoch 1141, Training Loss: 0.16101301719260655, Validation Loss: 0.21042647160067837\nTraining Accuracy: 0.9484306298186425, Training F1 Score: 0.9463474251076908\nValidation Accuracy: 0.9316014468924696, Validation F1 Score: 0.9289280334181569\n\nLearning Rate: 2.7263087684225074e-05\nEpoch 1151, Training Loss: 0.15953877284860976, Validation Loss: 0.21033907411627167\nEpoch 1151, Training Loss: 0.16081394645208977, Validation Loss: 0.21033907411627167\nTraining Accuracy: 0.9485158885789801, Training F1 Score: 0.9464239649926763\nValidation Accuracy: 0.931711059958347, Validation F1 Score: 0.9290308439139745\n\nLearning Rate: 2.6956747344336702e-05\nEpoch 1161, Training Loss: 0.15944874225669795, Validation Loss: 0.21024572132881125\nEpoch 1161, Training Loss: 0.16061869902705767, Validation Loss: 0.21024572132881125\nTraining Accuracy: 0.9486498666309392, Training F1 Score: 0.9465493701260781\nValidation Accuracy: 0.9318206730242244, Validation F1 Score: 0.9291336803298303\n\nLearning Rate: 2.665384918256586e-05\nEpoch 1171, Training Loss: 0.1593563966581482, Validation Loss: 0.21008186135247103\nEpoch 1171, Training Loss: 0.16042620140920363, Validation Loss: 0.21008186135247103\nTraining Accuracy: 0.9485889675164123, Training F1 Score: 0.9464738010737762\nValidation Accuracy: 0.9321495122218568, Validation F1 Score: 0.9294423454651384\n\nLearning Rate: 2.635435452104793e-05\nEpoch 1181, Training Loss: 0.15926914396098624, Validation Loss: 0.21002593148790874\nEpoch 1181, Training Loss: 0.16024893101161344, Validation Loss: 0.21002593148790874\nTraining Accuracy: 0.9486255069851285, Training F1 Score: 0.9464977822144413\nValidation Accuracy: 0.9321495122218568, Validation F1 Score: 0.9294423454651384\n\nLearning Rate: 2.605822511652022e-05\nEpoch 1191, Training Loss: 0.15918382238193535, Validation Loss: 0.2099279920240511\nEpoch 1191, Training Loss: 0.16007041166701702, Validation Loss: 0.2099279920240511\nTraining Accuracy: 0.9487229455683714, Training F1 Score: 0.946586138516446\nValidation Accuracy: 0.9321495122218568, Validation F1 Score: 0.9294423454651384\n\nLearning Rate: 2.576542315543855e-05\nEpoch 1201, Training Loss: 0.1590971272852706, Validation Loss: 0.2098339702670647\nEpoch 1201, Training Loss: 0.159893067458741, Validation Loss: 0.2098339702670647\nTraining Accuracy: 0.9487594850370875, Training F1 Score: 0.9466157643595007\nValidation Accuracy: 0.9323687383536118, Validation F1 Score: 0.9296482524968465\n\nLearning Rate: 2.54759112491488e-05\nEpoch 1211, Training Loss: 0.15901383916398065, Validation Loss: 0.20975148436088356\nEpoch 1211, Training Loss: 0.1597232816296733, Validation Loss: 0.20975148436088356\nTraining Accuracy: 0.9488447437974252, Training F1 Score: 0.9466924115372296\nValidation Accuracy: 0.9322591252877342, Validation F1 Score: 0.9295231648332215\n\nLearning Rate: 2.5189652429112582e-05\nEpoch 1221, Training Loss: 0.15893265580198976, Validation Loss: 0.20961802453701006\nEpoch 1221, Training Loss: 0.15955887652891218, Validation Loss: 0.20961802453701006\nTraining Accuracy: 0.9488203841516144, Training F1 Score: 0.9466538881619502\nValidation Accuracy: 0.9321495122218568, Validation F1 Score: 0.9293980316645213\n\nLearning Rate: 2.4906610142186685e-05\nEpoch 1231, Training Loss: 0.15884973269317618, Validation Loss: 0.20952792830089853\nEpoch 1231, Training Loss: 0.15941767729053372, Validation Loss: 0.20952792830089853\nTraining Accuracy: 0.9488569236203306, Training F1 Score: 0.946683524591188\nValidation Accuracy: 0.9322591252877342, Validation F1 Score: 0.9295010050210643\n\nLearning Rate: 2.462674824595549e-05\nEpoch 1241, Training Loss: 0.15876606094289514, Validation Loss: 0.20942806126738697\nEpoch 1241, Training Loss: 0.15925319292792933, Validation Loss: 0.20942806126738697\nTraining Accuracy: 0.9489665420264789, Training F1 Score: 0.9467856092332237\nValidation Accuracy: 0.9321495122218568, Validation F1 Score: 0.9293758165755261\n\nLearning Rate: 2.4350031004115835e-05\nEpoch 1251, Training Loss: 0.1586862973956962, Validation Loss: 0.20935633266676443\nEpoch 1251, Training Loss: 0.159103686698277, Validation Loss: 0.20935633266676443\nTraining Accuracy: 0.9490396209639111, Training F1 Score: 0.9468580620623025\nValidation Accuracy: 0.9322591252877342, Validation F1 Score: 0.9294788064125876\n\nLearning Rate: 2.4076423081913783e-05\nEpoch 1261, Training Loss: 0.15860927529644753, Validation Loss: 0.2093091906489059\nEpoch 1261, Training Loss: 0.15895655212428567, Validation Loss: 0.2093091906489059\nTraining Accuracy: 0.9491370595471542, Training F1 Score: 0.9469484371542243\nValidation Accuracy: 0.9323687383536118, Validation F1 Score: 0.9295818224820691\n\nLearning Rate: 2.38058895416326e-05\nEpoch 1271, Training Loss: 0.15853115369720747, Validation Loss: 0.20925540565320644\nEpoch 1271, Training Loss: 0.15881226173772456, Validation Loss: 0.20925540565320644\nTraining Accuracy: 0.9491370595471542, Training F1 Score: 0.9469428148619722\nValidation Accuracy: 0.9322591252877342, Validation F1 Score: 0.9294565689277144\n\nLearning Rate: 2.3538395838131496e-05\nEpoch 1281, Training Loss: 0.15845581846356357, Validation Loss: 0.20922796960842918\nEpoch 1281, Training Loss: 0.15868646966152639, Validation Loss: 0.20922796960842918\nTraining Accuracy: 0.9492344981303972, Training F1 Score: 0.9470350971511651\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9297657457497189\n\nLearning Rate: 2.327390781443444e-05\nEpoch 1291, Training Loss: 0.15838046154344235, Validation Loss: 0.20921104828882514\nEpoch 1291, Training Loss: 0.15854990806023989, Validation Loss: 0.20921104828882514\nTraining Accuracy: 0.9492344981303972, Training F1 Score: 0.9470276027199979\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9297657457497189\n\nLearning Rate: 2.3012391697368587e-05\nEpoch 1301, Training Loss: 0.15830919751528227, Validation Loss: 0.20928125083446503\nEpoch 1301, Training Loss: 0.15843127065581408, Validation Loss: 0.20928125083446503\nTraining Accuracy: 0.9492953972449241, Training F1 Score: 0.9470845947125857\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9298466475081525\n\nLearning Rate: 2.2753814093251674e-05\nEpoch 1311, Training Loss: 0.15823753423063294, Validation Loss: 0.20932744689890917\nEpoch 1311, Training Loss: 0.15831680287989205, Validation Loss: 0.20932744689890917\nTraining Accuracy: 0.9493075770678294, Training F1 Score: 0.9470907481485702\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9301783511085757\n\nLearning Rate: 2.249814198362791e-05\nEpoch 1321, Training Loss: 0.1581660826075198, Validation Loss: 0.20937583416579494\nEpoch 1321, Training Loss: 0.15820038390777702, Validation Loss: 0.20937583416579494\nTraining Accuracy: 0.949392835828167, Training F1 Score: 0.9471731844711877\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9300751600569858\n\nLearning Rate: 2.2245342721051745e-05\nEpoch 1331, Training Loss: 0.15809858831179113, Validation Loss: 0.20938083126031945\nEpoch 1331, Training Loss: 0.15809566538195202, Validation Loss: 0.20938083126031945\nTraining Accuracy: 0.9494415551197886, Training F1 Score: 0.9472146834611817\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9299498023397005\n\nLearning Rate: 2.1995384024919048e-05\nEpoch 1341, Training Loss: 0.15802848985506227, Validation Loss: 0.20945791697131036\nEpoch 1341, Training Loss: 0.15799686614245084, Validation Loss: 0.20945791697131036\nTraining Accuracy: 0.9494902744114101, Training F1 Score: 0.947254318819997\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9298243986559709\n\nLearning Rate: 2.17482339773451e-05\nEpoch 1351, Training Loss: 0.15795975731372885, Validation Loss: 0.209493539380515\nEpoch 1351, Training Loss: 0.15789302570416097, Validation Loss: 0.209493539380515\nTraining Accuracy: 0.9495633533488423, Training F1 Score: 0.9473194061218541\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9296989489480639\n\nLearning Rate: 2.150386101908892e-05\nEpoch 1361, Training Loss: 0.1578901488546152, Validation Loss: 0.20952028026154046\nEpoch 1361, Training Loss: 0.15780058348173637, Validation Loss: 0.20952028026154046\nTraining Accuracy: 0.949551173525937, Training F1 Score: 0.9473020016195924\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9296989489480639\n\nLearning Rate: 2.126223394552338e-05\nEpoch 1371, Training Loss: 0.15782591871266685, Validation Loss: 0.20950574332863095\nEpoch 1371, Training Loss: 0.15771244139961307, Validation Loss: 0.20950574332863095\nTraining Accuracy: 0.9496242524633692, Training F1 Score: 0.9473745962014913\nValidation Accuracy: 0.9323687383536118, Validation F1 Score: 0.9294703276438298\n\nLearning Rate: 2.102332190265061e-05\nEpoch 1381, Training Loss: 0.15775918189278343, Validation Loss: 0.20950697681908542\nEpoch 1381, Training Loss: 0.15762949286537448, Validation Loss: 0.20950697681908542\nTraining Accuracy: 0.949685151577896, Training F1 Score: 0.9474316700369333\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9296766051952285\n\nLearning Rate: 2.078709438316216e-05\nEpoch 1391, Training Loss: 0.157698895053672, Validation Loss: 0.20949564066148046\nEpoch 1391, Training Loss: 0.15754746262619745, Validation Loss: 0.20949564066148046\nTraining Accuracy: 0.9497216910466122, Training F1 Score: 0.9474651717640059\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9297574176193883\n\nLearning Rate: 2.055352122254345e-05\nEpoch 1401, Training Loss: 0.15763679124243318, Validation Loss: 0.20951912003553685\nEpoch 1401, Training Loss: 0.1574690508106766, Validation Loss: 0.20951912003553685\nTraining Accuracy: 0.94964861210918, Training F1 Score: 0.9473831927253485\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9296542222311293\n\nLearning Rate: 2.0322572595221972e-05\nEpoch 1411, Training Loss: 0.15757593004607373, Validation Loss: 0.20952223156557706\nEpoch 1411, Training Loss: 0.1573926859371581, Validation Loss: 0.20952223156557706\nTraining Accuracy: 0.9496242524633692, Training F1 Score: 0.9473521107964049\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9297574176193883\n\nLearning Rate: 2.0094219010758806e-05\nEpoch 1421, Training Loss: 0.15751737190772733, Validation Loss: 0.2095267656673194\nEpoch 1421, Training Loss: 0.1573213032913773, Validation Loss: 0.2095267656673194\nTraining Accuracy: 0.9496729717549907, Training F1 Score: 0.9473974033765536\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9297574176193883\n\nLearning Rate: 1.9868431310082884e-05\nEpoch 1431, Training Loss: 0.15745912483962834, Validation Loss: 0.20951532138931925\nEpoch 1431, Training Loss: 0.15725056241062102, Validation Loss: 0.20951532138931925\nTraining Accuracy: 0.9496729717549907, Training F1 Score: 0.9473974033765536\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9297574176193883\n\nLearning Rate: 1.9645180661767605e-05\nEpoch 1441, Training Loss: 0.15740076719788226, Validation Loss: 0.20954960616817733\nEpoch 1441, Training Loss: 0.15718455395157638, Validation Loss: 0.20954960616817733\nTraining Accuracy: 0.9497095112237068, Training F1 Score: 0.9474365319052162\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9297574176193883\n\nLearning Rate: 1.9424438558349273e-05\nEpoch 1451, Training Loss: 0.15734204650415265, Validation Loss: 0.209569175887837\nEpoch 1451, Training Loss: 0.15712570971612577, Validation Loss: 0.209569175887837\nTraining Accuracy: 0.9497095112237068, Training F1 Score: 0.9474327837372918\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9298606396492226\n\nLearning Rate: 1.920617681268689e-05\nEpoch 1461, Training Loss: 0.15728615438287813, Validation Loss: 0.20959620398903028\nEpoch 1461, Training Loss: 0.15706346435592494, Validation Loss: 0.20959620398903028\nTraining Accuracy: 0.9497460506924229, Training F1 Score: 0.9474681673603671\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9298606396492226\n\nLearning Rate: 1.8990367554362898e-05\nEpoch 1471, Training Loss: 0.15722837597837738, Validation Loss: 0.20958630439777273\nEpoch 1471, Training Loss: 0.15700148156273996, Validation Loss: 0.20958630439777273\nTraining Accuracy: 0.9497947699840444, Training F1 Score: 0.9475172229702878\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9300671637848794\n\nLearning Rate: 1.877698322612429e-05\nEpoch 1481, Training Loss: 0.15717284483298222, Validation Loss: 0.20962906198864587\nEpoch 1481, Training Loss: 0.1569447610508447, Validation Loss: 0.20962906198864587\nTraining Accuracy: 0.9497582305153283, Training F1 Score: 0.9474743408841733\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9300448090460415\n\nLearning Rate: 1.8565996580363788e-05\nEpoch 1491, Training Loss: 0.15711776577302408, Validation Loss: 0.20963258821458836\nEpoch 1491, Training Loss: 0.15689459874193867, Validation Loss: 0.20963258821458836\nTraining Accuracy: 0.9497825901611391, Training F1 Score: 0.9474941855609958\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9298966553111124\n\nLearning Rate: 1.8357380675640496e-05\nEpoch 1501, Training Loss: 0.15706737251617459, Validation Loss: 0.2096675629288066\nEpoch 1501, Training Loss: 0.1568409612462281, Validation Loss: 0.2096675629288066\nTraining Accuracy: 0.9497825901611391, Training F1 Score: 0.9474923107257585\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9298741654676267\n\nLearning Rate: 1.8151108873239704e-05\nEpoch 1511, Training Loss: 0.15700937983644966, Validation Loss: 0.2097058450719655\nEpoch 1511, Training Loss: 0.15678655835356972, Validation Loss: 0.2097058450719655\nTraining Accuracy: 0.9497704103382337, Training F1 Score: 0.9474786376319368\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9298741654676267\n\nLearning Rate: 1.79471548337713e-05\nEpoch 1521, Training Loss: 0.15695579563285825, Validation Loss: 0.20972003492199118\nEpoch 1521, Training Loss: 0.15673708565137595, Validation Loss: 0.20972003492199118\nTraining Accuracy: 0.9497825901611391, Training F1 Score: 0.9474885599566256\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9298741654676267\n\nLearning Rate: 1.774549251380642e-05\nEpoch 1531, Training Loss: 0.15690276920889817, Validation Loss: 0.20972952521397437\nEpoch 1531, Training Loss: 0.15668542865162527, Validation Loss: 0.20972952521397437\nTraining Accuracy: 0.9497947699840444, Training F1 Score: 0.9475022337800133\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9298741654676267\n\nLearning Rate: 1.754609616255192e-05\nEpoch 1541, Training Loss: 0.15684877022658553, Validation Loss: 0.20976594736619725\nEpoch 1541, Training Loss: 0.15663636799322714, Validation Loss: 0.20976594736619725\nTraining Accuracy: 0.9497582305153283, Training F1 Score: 0.9474630875142083\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9298741654676267\n\nLearning Rate: 1.734894031856216e-05\nEpoch 1551, Training Loss: 0.1567967012425691, Validation Loss: 0.2098063200084993\nEpoch 1551, Training Loss: 0.15659058655129976, Validation Loss: 0.2098063200084993\nTraining Accuracy: 0.9497582305153283, Training F1 Score: 0.9474630875142083\nValidation Accuracy: 0.933136029814754, Validation F1 Score: 0.9301033348615232\n\nLearning Rate: 1.715399980648779e-05\nEpoch 1561, Training Loss: 0.15674059536042298, Validation Loss: 0.20978078361922\nEpoch 1561, Training Loss: 0.15654306120598543, Validation Loss: 0.20978078361922\nTraining Accuracy: 0.9497460506924229, Training F1 Score: 0.9474550429367974\nValidation Accuracy: 0.9326975775512442, Validation F1 Score: 0.9296223930539106\n\nLearning Rate: 1.696124973386101e-05\nEpoch 1571, Training Loss: 0.1566862250110019, Validation Loss: 0.20979028449048864\nEpoch 1571, Training Loss: 0.1564943405685896, Validation Loss: 0.20979028449048864\nTraining Accuracy: 0.9497704103382337, Training F1 Score: 0.9474786376319368\nValidation Accuracy: 0.9323687383536118, Validation F1 Score: 0.9293125837539595\n\nLearning Rate: 1.6770665487917035e-05\nEpoch 1581, Training Loss: 0.1566353832577494, Validation Loss: 0.20978776713996344\nEpoch 1581, Training Loss: 0.15644622349292456, Validation Loss: 0.20978776713996344\nTraining Accuracy: 0.9498069498069498, Training F1 Score: 0.9475159070569401\nValidation Accuracy: 0.9324783514194892, Validation F1 Score: 0.9294158266798332\n\nLearning Rate: 1.658222273245118e-05\nEpoch 1591, Training Loss: 0.1565827110708148, Validation Loss: 0.20978442430300212\nEpoch 1591, Training Loss: 0.15640241906881555, Validation Loss: 0.20978442430300212\nTraining Accuracy: 0.9497947699840444, Training F1 Score: 0.9475041087097099\nValidation Accuracy: 0.9325879644853666, Validation F1 Score: 0.9295417163836064\n\nLearning Rate: 1.6395897404711317e-05\nEpoch 1601, Training Loss: 0.1565335301341304, Validation Loss: 0.2097919956086485\nEpoch 1601, Training Loss: 0.1563548729753453, Validation Loss: 0.2097919956086485\nTraining Accuracy: 0.9498313094527605, Training F1 Score: 0.9475395048414604\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9297708490132532\n\nLearning Rate: 1.6211665712325266e-05\nEpoch 1611, Training Loss: 0.15648267718581407, Validation Loss: 0.2098311489478781\nEpoch 1611, Training Loss: 0.15631272488781872, Validation Loss: 0.2098311489478781\nTraining Accuracy: 0.9498191296298552, Training F1 Score: 0.947525831381475\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9297708490132532\n\nLearning Rate: 1.602950413026265e-05\nEpoch 1621, Training Loss: 0.15643386256672578, Validation Loss: 0.2098899108628151\nEpoch 1621, Training Loss: 0.1562673261432763, Validation Loss: 0.2098899108628151\nTraining Accuracy: 0.9498556690985713, Training F1 Score: 0.9475574822716237\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9298741654676267\n\nLearning Rate: 1.5849389397830926e-05\nEpoch 1631, Training Loss: 0.1563860468561245, Validation Loss: 0.20989742445198314\nEpoch 1631, Training Loss: 0.1562263694397316, Validation Loss: 0.20989742445198314\nTraining Accuracy: 0.9498922085672874, Training F1 Score: 0.9475985056640601\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9299775088146947\n\nLearning Rate: 1.5671298515705203e-05\nEpoch 1641, Training Loss: 0.15633988820517578, Validation Loss: 0.20992804479470945\nEpoch 1641, Training Loss: 0.1561863331407475, Validation Loss: 0.20992804479470945\nTraining Accuracy: 0.9498922085672874, Training F1 Score: 0.9475966329106541\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9299775088146947\n\nLearning Rate: 1.549520874299134e-05\nEpoch 1651, Training Loss: 0.1562928610067165, Validation Loss: 0.20991880947869557\nEpoch 1651, Training Loss: 0.1561378693511442, Validation Loss: 0.20991880947869557\nTraining Accuracy: 0.9499165682130982, Training F1 Score: 0.9476202363301401\nValidation Accuracy: 0.933136029814754, Validation F1 Score: 0.9301033348615232\n\nLearning Rate: 1.5321097594322155e-05\nEpoch 1661, Training Loss: 0.15624573550103008, Validation Loss: 0.2099722503903638\nEpoch 1661, Training Loss: 0.15610126992713785, Validation Loss: 0.2099722503903638\nTraining Accuracy: 0.9499165682130982, Training F1 Score: 0.9476202363301401\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9299775088146947\n\nLearning Rate: 1.5148942836986162e-05\nEpoch 1671, Training Loss: 0.15620030731442985, Validation Loss: 0.20995954267421757\nEpoch 1671, Training Loss: 0.15606318515520948, Validation Loss: 0.20995954267421757\nTraining Accuracy: 0.9499165682130982, Training F1 Score: 0.9476221085387966\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9299775088146947\n\nLearning Rate: 1.4978722488088668e-05\nEpoch 1681, Training Loss: 0.1561567538061797, Validation Loss: 0.21000285117521394\nEpoch 1681, Training Loss: 0.15602293684277327, Validation Loss: 0.21000285117521394\nTraining Accuracy: 0.9499409278589089, Training F1 Score: 0.9476494550994864\nValidation Accuracy: 0.9330264167488764, Validation F1 Score: 0.9299775088146947\n\nLearning Rate: 1.4810414811744667e-05\nEpoch 1691, Training Loss: 0.15611338671135985, Validation Loss: 0.21001574653524926\nEpoch 1691, Training Loss: 0.15597705284231492, Validation Loss: 0.21001574653524926\nTraining Accuracy: 0.9499652875047196, Training F1 Score: 0.9476767994740773\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9298516360732788\n\nLearning Rate: 1.4643998316303367e-05\nEpoch 1701, Training Loss: 0.15606760289549745, Validation Loss: 0.21006630327596248\nEpoch 1701, Training Loss: 0.15594049286682923, Validation Loss: 0.21006630327596248\nTraining Accuracy: 0.9499652875047196, Training F1 Score: 0.9476749298171996\nValidation Accuracy: 0.933136029814754, Validation F1 Score: 0.9300583838198697\n\nLearning Rate: 1.4479451751603842e-05\nEpoch 1711, Training Loss: 0.1560246131744951, Validation Loss: 0.21012527416649585\nEpoch 1711, Training Loss: 0.15590387317199486, Validation Loss: 0.21012527416649585\nTraining Accuracy: 0.9500018269734358, Training F1 Score: 0.9477122076111594\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9302877005942309\n\nLearning Rate: 1.4316754106261563e-05\nEpoch 1721, Training Loss: 0.1559826919240841, Validation Loss: 0.21015187277352745\nEpoch 1721, Training Loss: 0.15586153722562368, Validation Loss: 0.21015187277352745\nTraining Accuracy: 0.9500505462650574, Training F1 Score: 0.9477594235563171\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9302877005942309\n\nLearning Rate: 1.415588460498537e-05\nEpoch 1731, Training Loss: 0.15594189482683468, Validation Loss: 0.21015248838765155\nEpoch 1731, Training Loss: 0.155822827796793, Validation Loss: 0.21015248838765155\nTraining Accuracy: 0.9500383664421519, Training F1 Score: 0.94774761902389\nValidation Accuracy: 0.9332456428806314, Validation F1 Score: 0.930161798193993\n\nLearning Rate: 1.3996822705924647e-05\nEpoch 1741, Training Loss: 0.15590173258678547, Validation Loss: 0.21017085697702392\nEpoch 1741, Training Loss: 0.15578495849758292, Validation Loss: 0.21017085697702392\nTraining Accuracy: 0.9500627260879627, Training F1 Score: 0.9477749623076522\nValidation Accuracy: 0.9332456428806314, Validation F1 Score: 0.930161798193993\n\nLearning Rate: 1.3839548098046276e-05\nEpoch 1751, Training Loss: 0.15585930211968615, Validation Loss: 0.21022748384613693\nEpoch 1751, Training Loss: 0.155747086986693, Validation Loss: 0.21022748384613693\nTraining Accuracy: 0.9500627260879627, Training F1 Score: 0.9477730955626399\nValidation Accuracy: 0.9332456428806314, Validation F1 Score: 0.930161798193993\n\nLearning Rate: 1.3684040698541042e-05\nEpoch 1761, Training Loss: 0.15581768804340154, Validation Loss: 0.21027846182763388\nEpoch 1761, Training Loss: 0.15570779020930928, Validation Loss: 0.21027846182763388\nTraining Accuracy: 0.9500505462650574, Training F1 Score: 0.9477556876963492\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9302877005942309\n\nLearning Rate: 1.3530280650259245e-05\nEpoch 1771, Training Loss: 0.1557789987984635, Validation Loss: 0.21030670672958912\nEpoch 1771, Training Loss: 0.15566780569568534, Validation Loss: 0.21030670672958912\nTraining Accuracy: 0.9500627260879627, Training F1 Score: 0.9477712284529298\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9302877005942309\n\nLearning Rate: 1.3378248319175052e-05\nEpoch 1781, Training Loss: 0.1557389004179928, Validation Loss: 0.2103302885072738\nEpoch 1781, Training Loss: 0.1556267607051699, Validation Loss: 0.2103302885072738\nTraining Accuracy: 0.9500383664421519, Training F1 Score: 0.9477420138674403\nValidation Accuracy: 0.9334648690123862, Validation F1 Score: 0.9303911518945053\n\nLearning Rate: 1.3227924291879403e-05\nEpoch 1791, Training Loss: 0.15569787947591118, Validation Loss: 0.21035795538856392\nEpoch 1791, Training Loss: 0.1555886131726062, Validation Loss: 0.21035795538856392\nTraining Accuracy: 0.9500627260879627, Training F1 Score: 0.9477712284529298\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9305981357860249\n\nLearning Rate: 1.3079289373101047e-05\nEpoch 1801, Training Loss: 0.15565548472219617, Validation Loss: 0.21039051800773526\nEpoch 1801, Training Loss: 0.155546370018782, Validation Loss: 0.21039051800773526\nTraining Accuracy: 0.9500992655566788, Training F1 Score: 0.9478085116187788\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.2932324583255453e-05\nEpoch 1811, Training Loss: 0.15561386024814872, Validation Loss: 0.21041894209276463\nEpoch 1811, Training Loss: 0.1555044268905995, Validation Loss: 0.21041894209276463\nTraining Accuracy: 0.9500383664421519, Training F1 Score: 0.9477438826179398\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.2787011156021256e-05\nEpoch 1821, Training Loss: 0.15557427941782212, Validation Loss: 0.21043585163909564\nEpoch 1821, Training Loss: 0.1554682847049938, Validation Loss: 0.21043585163909564\nTraining Accuracy: 0.9500505462650574, Training F1 Score: 0.94775755580879\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930886458415425\n\nLearning Rate: 1.2643330535943931e-05\nEpoch 1831, Training Loss: 0.1555350634337238, Validation Loss: 0.2104480056194024\nEpoch 1831, Training Loss: 0.1554279686245165, Validation Loss: 0.2104480056194024\nTraining Accuracy: 0.9500992655566788, Training F1 Score: 0.9478047786734645\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930886458415425\n\nLearning Rate: 1.2501264376066408e-05\nEpoch 1841, Training Loss: 0.15549341806451067, Validation Loss: 0.21049783527883772\nEpoch 1841, Training Loss: 0.15538837905291825, Validation Loss: 0.21049783527883772\nTraining Accuracy: 0.9501114453795841, Training F1 Score: 0.9478184516823586\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309900902818069\n\nLearning Rate: 1.236079453558629e-05\nEpoch 1851, Training Loss: 0.15545478121620288, Validation Loss: 0.21049442159480122\nEpoch 1851, Training Loss: 0.1553450763485454, Validation Loss: 0.21049442159480122\nTraining Accuracy: 0.950135805025395, Training F1 Score: 0.9478401996487922\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 1.2221903077539414e-05\nEpoch 1861, Training Loss: 0.15541462282980525, Validation Loss: 0.21047082324992614\nEpoch 1861, Training Loss: 0.15530721438149142, Validation Loss: 0.21047082324992614\nTraining Accuracy: 0.9501601646712057, Training F1 Score: 0.9478619498032261\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 1.2084572266509431e-05\nEpoch 1871, Training Loss: 0.15537432661306602, Validation Loss: 0.2105252286079329\nEpoch 1871, Training Loss: 0.1552627534066266, Validation Loss: 0.2105252286079329\nTraining Accuracy: 0.950135805025395, Training F1 Score: 0.9478364668852415\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.1948784566363123e-05\nEpoch 1881, Training Loss: 0.15533576035701974, Validation Loss: 0.2105486946390554\nEpoch 1881, Training Loss: 0.15522623782826345, Validation Loss: 0.2105486946390554\nTraining Accuracy: 0.9501114453795841, Training F1 Score: 0.9478072479204421\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.1814522638011164e-05\nEpoch 1891, Training Loss: 0.15529847674841957, Validation Loss: 0.21053837630769134\nEpoch 1891, Training Loss: 0.15518570807838727, Validation Loss: 0.21053837630769134\nTraining Accuracy: 0.9501479848483003, Training F1 Score: 0.9478445414781728\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.1681769337194054e-05\nEpoch 1901, Training Loss: 0.15526079645781546, Validation Loss: 0.2105315480870034\nEpoch 1901, Training Loss: 0.15515102168394193, Validation Loss: 0.2105315480870034\nTraining Accuracy: 0.950135805025395, Training F1 Score: 0.9478289969803964\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.1550507712292917e-05\nEpoch 1911, Training Loss: 0.15522776176333797, Validation Loss: 0.21055921778910963\nEpoch 1911, Training Loss: 0.15511786974593103, Validation Loss: 0.21055921778910963\nTraining Accuracy: 0.9501479848483003, Training F1 Score: 0.9478408063434366\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.1420721002164906e-05\nEpoch 1921, Training Loss: 0.15518949386373765, Validation Loss: 0.21055052722544443\nEpoch 1921, Training Loss: 0.1550759742338399, Validation Loss: 0.21055052722544443\nTraining Accuracy: 0.9501479848483003, Training F1 Score: 0.9478389382285396\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.1292392634002931e-05\nEpoch 1931, Training Loss: 0.15515361893421395, Validation Loss: 0.2105653053569151\nEpoch 1931, Training Loss: 0.1550421172975601, Validation Loss: 0.2105653053569151\nTraining Accuracy: 0.9501236252024896, Training F1 Score: 0.9478134502921742\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.1165506221219429e-05\nEpoch 1941, Training Loss: 0.15511796046781864, Validation Loss: 0.21053975866112182\nEpoch 1941, Training Loss: 0.15500244399738194, Validation Loss: 0.21053975866112182\nTraining Accuracy: 0.950135805025395, Training F1 Score: 0.9478215212340421\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 1.104004556135392e-05\nEpoch 1951, Training Loss: 0.15508496107582417, Validation Loss: 0.21053707897401777\nEpoch 1951, Training Loss: 0.15497042679777825, Validation Loss: 0.21053707897401777\nTraining Accuracy: 0.9501236252024896, Training F1 Score: 0.9478115808991323\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310347300524056\n\nLearning Rate: 1.0915994634004075e-05\nEpoch 1961, Training Loss: 0.15505158206493763, Validation Loss: 0.21056326987756968\nEpoch 1961, Training Loss: 0.15493842863157986, Validation Loss: 0.21056326987756968\nTraining Accuracy: 0.9501601646712057, Training F1 Score: 0.9478507482305961\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 1.0793337598780021e-05\nEpoch 1971, Training Loss: 0.15501834233289236, Validation Loss: 0.21057882828728405\nEpoch 1971, Training Loss: 0.15490360860201524, Validation Loss: 0.21057882828728405\nTraining Accuracy: 0.950172344494111, Training F1 Score: 0.9478588223686536\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9308052283221308\n\nLearning Rate: 1.067205879328165e-05\nEpoch 1981, Training Loss: 0.1549848549017791, Validation Loss: 0.21058696418082676\nEpoch 1981, Training Loss: 0.15487583414992945, Validation Loss: 0.21058696418082676\nTraining Accuracy: 0.950172344494111, Training F1 Score: 0.9478606906658325\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9308052283221308\n\nLearning Rate: 1.0552142731098633e-05\nEpoch 1991, Training Loss: 0.15495446112200692, Validation Loss: 0.21058262055358984\nEpoch 1991, Training Loss: 0.15484068624545233, Validation Loss: 0.21058262055358984\nTraining Accuracy: 0.9502088839628272, Training F1 Score: 0.9478979918917354\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9308052283221308\n\nLearning Rate: 1.0433574099832933e-05\nEpoch 2001, Training Loss: 0.15492423670053898, Validation Loss: 0.21059473591468633\nEpoch 2001, Training Loss: 0.15481149000682917, Validation Loss: 0.21059473591468633\nTraining Accuracy: 0.9502210637857326, Training F1 Score: 0.9479098037205299\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9308275634363191\n\nLearning Rate: 1.0316337759143512e-05\nEpoch 2011, Training Loss: 0.1548949006507541, Validation Loss: 0.2106052496745426\nEpoch 2011, Training Loss: 0.1547820534858701, Validation Loss: 0.2106052496745426\nTraining Accuracy: 0.9502210637857326, Training F1 Score: 0.9479079368852389\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 1.0200418738813037e-05\nEpoch 2021, Training Loss: 0.1548643495957892, Validation Loss: 0.21061718328492\nEpoch 2021, Training Loss: 0.15475126692547836, Validation Loss: 0.21061718328492\nTraining Accuracy: 0.9502210637857326, Training F1 Score: 0.9479079368852389\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 1.0085802236836272e-05\nEpoch 2031, Training Loss: 0.15483699972597778, Validation Loss: 0.210645672957599\nEpoch 2031, Training Loss: 0.15472399549988194, Validation Loss: 0.210645672957599\nTraining Accuracy: 0.9502576032544486, Training F1 Score: 0.9479489723301975\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 9.97247361752999e-06\nEpoch 2041, Training Loss: 0.1548070579996998, Validation Loss: 0.21063954244870753\nEpoch 2041, Training Loss: 0.1546923368396073, Validation Loss: 0.21063954244870753\nTraining Accuracy: 0.9502819629002595, Training F1 Score: 0.9479707334465654\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 9.860418409664096e-06\nEpoch 2051, Training Loss: 0.154778973554712, Validation Loss: 0.21066504698906188\nEpoch 2051, Training Loss: 0.15466925547360147, Validation Loss: 0.21066504698906188\nTraining Accuracy: 0.9502454234315433, Training F1 Score: 0.9479296955368826\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 9.749622304613755e-06\nEpoch 2061, Training Loss: 0.1547500570077428, Validation Loss: 0.21066082698772523\nEpoch 2061, Training Loss: 0.1546388353475062, Validation Loss: 0.21066082698772523\nTraining Accuracy: 0.9502332436086379, Training F1 Score: 0.9479160151373006\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 9.640071154532291e-06\nEpoch 2071, Training Loss: 0.15472311947901335, Validation Loss: 0.2106697528976157\nEpoch 2071, Training Loss: 0.15461172612465113, Validation Loss: 0.2106697528976157\nTraining Accuracy: 0.9502941427231648, Training F1 Score: 0.9479825471946501\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 9.531750970544612e-06\nEpoch 2081, Training Loss: 0.1546961569800446, Validation Loss: 0.21068601330016823\nEpoch 2081, Training Loss: 0.1545828427746588, Validation Loss: 0.21068601330016823\nTraining Accuracy: 0.9502576032544486, Training F1 Score: 0.9479433753882356\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 9.424647920960926e-06\nEpoch 2091, Training Loss: 0.15466614289158043, Validation Loss: 0.2106970469101367\nEpoch 2091, Training Loss: 0.15455493136158527, Validation Loss: 0.2106970469101367\nTraining Accuracy: 0.9502819629002595, Training F1 Score: 0.9479670028855756\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 9.318748329510544e-06\nEpoch 2101, Training Loss: 0.15463905446824394, Validation Loss: 0.21069686341498697\nEpoch 2101, Training Loss: 0.1545255506640353, Validation Loss: 0.21069686341498697\nTraining Accuracy: 0.9502819629002595, Training F1 Score: 0.9479651370580713\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310347300524056\n\nLearning Rate: 9.214038673595515e-06\nEpoch 2111, Training Loss: 0.15461215602559264, Validation Loss: 0.2107319104218057\nEpoch 2111, Training Loss: 0.15449539689181785, Validation Loss: 0.2107319104218057\nTraining Accuracy: 0.9502697830773541, Training F1 Score: 0.9479533228518154\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310347300524056\n\nLearning Rate: 9.110505582563898e-06\nEpoch 2121, Training Loss: 0.1545827388591009, Validation Loss: 0.21073956037219727\nEpoch 2121, Training Loss: 0.15446761300932957, Validation Loss: 0.21073956037219727\nTraining Accuracy: 0.9503063225460702, Training F1 Score: 0.9479924967597129\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309311331282238\n\nLearning Rate: 9.008135836002418e-06\nEpoch 2131, Training Loss: 0.15455670189751056, Validation Loss: 0.21074796807187096\nEpoch 2131, Training Loss: 0.15444005366443417, Validation Loss: 0.21074796807187096\nTraining Accuracy: 0.9502697830773541, Training F1 Score: 0.9479514563847977\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9308052283221308\n\nLearning Rate: 8.906916362048324e-06\nEpoch 2141, Training Loss: 0.15453044264939125, Validation Loss: 0.21077996653435355\nEpoch 2141, Training Loss: 0.15441065077367697, Validation Loss: 0.21077996653435355\nTraining Accuracy: 0.9502819629002595, Training F1 Score: 0.9479632708657814\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9308052283221308\n\nLearning Rate: 8.806834235720207e-06\nEpoch 2151, Training Loss: 0.15450125056279498, Validation Loss: 0.21079089973339526\nEpoch 2151, Training Loss: 0.1543837694137388, Validation Loss: 0.21079089973339526\nTraining Accuracy: 0.9503063225460702, Training F1 Score: 0.9479906318463818\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9308052283221308\n\nLearning Rate: 8.70787667726757e-06\nEpoch 2161, Training Loss: 0.1544747264379735, Validation Loss: 0.21079359565448386\nEpoch 2161, Training Loss: 0.15435318227840972, Validation Loss: 0.21079359565448386\nTraining Accuracy: 0.9502941427231648, Training F1 Score: 0.9479769516302617\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.930908815428337\n\nLearning Rate: 8.610031050538955e-06\nEpoch 2171, Training Loss: 0.15444771541435692, Validation Loss: 0.2108127982368415\nEpoch 2171, Training Loss: 0.15432473762398966, Validation Loss: 0.2108127982368415\nTraining Accuracy: 0.9503063225460702, Training F1 Score: 0.9479887665684438\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310124298115172\n\nLearning Rate: 8.513284861368399e-06\nEpoch 2181, Training Loss: 0.15442264336044195, Validation Loss: 0.21083067439861575\nEpoch 2181, Training Loss: 0.15429822214061842, Validation Loss: 0.21083067439861575\nTraining Accuracy: 0.9503063225460702, Training F1 Score: 0.9479887665684438\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310124298115172\n\nLearning Rate: 8.417625755980011e-06\nEpoch 2191, Training Loss: 0.15439712335587494, Validation Loss: 0.21083264851255218\nEpoch 2191, Training Loss: 0.15426781529712527, Validation Loss: 0.21083264851255218\nTraining Accuracy: 0.9503063225460702, Training F1 Score: 0.9479887665684438\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310124298115172\n\nLearning Rate: 8.323041519410502e-06\nEpoch 2201, Training Loss: 0.15437301417836005, Validation Loss: 0.2108346912783253\nEpoch 2201, Training Loss: 0.1542386215814433, Validation Loss: 0.2108346912783253\nTraining Accuracy: 0.9503185023689755, Training F1 Score: 0.9480005818726733\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310124298115172\n\nLearning Rate: 8.22952007394941e-06\nEpoch 2211, Training Loss: 0.15434747733446272, Validation Loss: 0.21084363719036636\nEpoch 2211, Training Loss: 0.15420947400141016, Validation Loss: 0.21084363719036636\nTraining Accuracy: 0.9503185023689755, Training F1 Score: 0.9479968507725489\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310124298115172\n\nLearning Rate: 8.137049477596872e-06\nEpoch 2221, Training Loss: 0.1543232643613571, Validation Loss: 0.21085422635764442\nEpoch 2221, Training Loss: 0.15418461931863559, Validation Loss: 0.21085422635764442\nTraining Accuracy: 0.9503306821918809, Training F1 Score: 0.9480068011707842\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310124298115172\n\nLearning Rate: 8.045617922538717e-06\nEpoch 2231, Training Loss: 0.15430066456132274, Validation Loss: 0.2108343222299898\nEpoch 2231, Training Loss: 0.1541565586792433, Validation Loss: 0.2108343222299898\nTraining Accuracy: 0.9503063225460702, Training F1 Score: 0.947979434706681\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310124298115172\n\nLearning Rate: 7.955213733638697e-06\nEpoch 2241, Training Loss: 0.15427722067166097, Validation Loss: 0.2108413067193169\nEpoch 2241, Training Loss: 0.15412863724210202, Validation Loss: 0.2108413067193169\nTraining Accuracy: 0.9503063225460702, Training F1 Score: 0.9479775672393203\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.865825366947658e-06\nEpoch 2251, Training Loss: 0.15425390781214218, Validation Loss: 0.2108400020959489\nEpoch 2251, Training Loss: 0.15410127155386125, Validation Loss: 0.2108400020959489\nTraining Accuracy: 0.9503063225460702, Training F1 Score: 0.947975699406759\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9310124298115172\n\nLearning Rate: 7.777441408229453e-06\nEpoch 2261, Training Loss: 0.15423156765054447, Validation Loss: 0.210839709758458\nEpoch 2261, Training Loss: 0.1540724298704217, Validation Loss: 0.210839709758458\nTraining Accuracy: 0.9503428620147863, Training F1 Score: 0.9480111521957937\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.690050571503447e-06\nEpoch 2271, Training Loss: 0.15420819464643773, Validation Loss: 0.21084133022666227\nEpoch 2271, Training Loss: 0.1540431239414803, Validation Loss: 0.21084133022666227\nTraining Accuracy: 0.9503428620147863, Training F1 Score: 0.948009284823937\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.603641697603363e-06\nEpoch 2281, Training Loss: 0.15418549062593637, Validation Loss: 0.21085042285870842\nEpoch 2281, Training Loss: 0.15401633652094654, Validation Loss: 0.21085042285870842\nTraining Accuracy: 0.9503672216605971, Training F1 Score: 0.9480329224010098\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.518203752752348e-06\nEpoch 2291, Training Loss: 0.1541628469101002, Validation Loss: 0.21084442334054634\nEpoch 2291, Training Loss: 0.15398857210490707, Validation Loss: 0.21084442334054634\nTraining Accuracy: 0.9503794014835024, Training F1 Score: 0.9480447417398329\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.433725827154038e-06\nEpoch 2301, Training Loss: 0.15414226592057498, Validation Loss: 0.21084727709830153\nEpoch 2301, Training Loss: 0.15396072552657664, Validation Loss: 0.21084727709830153\nTraining Accuracy: 0.9503794014835024, Training F1 Score: 0.9480447417398329\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.350197133599457e-06\nEpoch 2311, Training Loss: 0.1541193439546878, Validation Loss: 0.21085226803505144\nEpoch 2311, Training Loss: 0.15393478153085957, Validation Loss: 0.21085226803505144\nTraining Accuracy: 0.9504037611293131, Training F1 Score: 0.9480702475121747\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.267607006089569e-06\nEpoch 2321, Training Loss: 0.15409761250959936, Validation Loss: 0.21085626062830198\nEpoch 2321, Training Loss: 0.15390462490483825, Validation Loss: 0.21085626062830198\nTraining Accuracy: 0.9503794014835024, Training F1 Score: 0.9480410075539812\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.185944898473314e-06\nEpoch 2331, Training Loss: 0.1540752727536396, Validation Loss: 0.21086393319422328\nEpoch 2331, Training Loss: 0.15387813980946893, Validation Loss: 0.21086393319422328\nTraining Accuracy: 0.9504037611293131, Training F1 Score: 0.9480665151595021\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.105200383100935e-06\nEpoch 2341, Training Loss: 0.15405296240597988, Validation Loss: 0.2108809421208296\nEpoch 2341, Training Loss: 0.15385038640754425, Validation Loss: 0.2108809421208296\nTraining Accuracy: 0.9504159409522186, Training F1 Score: 0.9480783358751503\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311160715103903\n\nLearning Rate: 7.0253631494924494e-06\nEpoch 2351, Training Loss: 0.1540319369165386, Validation Loss: 0.21089427807698788\nEpoch 2351, Training Loss: 0.1538229800816374, Validation Loss: 0.21089427807698788\nTraining Accuracy: 0.9503915813064078, Training F1 Score: 0.9480490927160138\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309900902818069\n\nLearning Rate: 6.9464230030210714e-06\nEpoch 2361, Training Loss: 0.15401060872079655, Validation Loss: 0.21088823777867766\nEpoch 2361, Training Loss: 0.15379487237136025, Validation Loss: 0.21088823777867766\nTraining Accuracy: 0.9503550418376917, Training F1 Score: 0.9480061535042463\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310937495087283\n\nLearning Rate: 6.868369863611437e-06\nEpoch 2371, Training Loss: 0.15399064466090617, Validation Loss: 0.21089242073536493\nEpoch 2371, Training Loss: 0.1537695761145264, Validation Loss: 0.21089242073536493\nTraining Accuracy: 0.9503672216605971, Training F1 Score: 0.9480179746821707\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310937495087283\n\nLearning Rate: 6.791193764452457e-06\nEpoch 2381, Training Loss: 0.1539702698414682, Validation Loss: 0.21089010596582403\nEpoch 2381, Training Loss: 0.1537428965481411, Validation Loss: 0.21089010596582403\nTraining Accuracy: 0.9504037611293131, Training F1 Score: 0.9480497014912764\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310937495087283\n\nLearning Rate: 6.7148848507246136e-06\nEpoch 2391, Training Loss: 0.15394985209899792, Validation Loss: 0.2108963560678451\nEpoch 2391, Training Loss: 0.15371625331530345, Validation Loss: 0.2108963560678451\nTraining Accuracy: 0.9504037611293131, Training F1 Score: 0.9480497014912764\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.639433378341591e-06\nEpoch 2401, Training Loss: 0.15393021626520997, Validation Loss: 0.21089328519218417\nEpoch 2401, Training Loss: 0.15369049689457517, Validation Loss: 0.21089328519218417\nTraining Accuracy: 0.9504037611293131, Training F1 Score: 0.948042219241589\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.5648297127060126e-06\nEpoch 2411, Training Loss: 0.15391077818619997, Validation Loss: 0.2108863824901907\nEpoch 2411, Training Loss: 0.15366601377873337, Validation Loss: 0.2108863824901907\nTraining Accuracy: 0.9503672216605971, Training F1 Score: 0.9480011305114266\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.491064327479185e-06\nEpoch 2421, Training Loss: 0.15389206954664464, Validation Loss: 0.21089590334074285\nEpoch 2421, Training Loss: 0.15363960449755668, Validation Loss: 0.21089590334074285\nTraining Accuracy: 0.9503306821918809, Training F1 Score: 0.9479600368192734\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.4181278033646474e-06\nEpoch 2431, Training Loss: 0.15387243164147132, Validation Loss: 0.210880911108186\nEpoch 2431, Training Loss: 0.15361610936483738, Validation Loss: 0.210880911108186\nTraining Accuracy: 0.9503672216605971, Training F1 Score: 0.9479955091924293\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.346010826905396e-06\nEpoch 2441, Training Loss: 0.15385377167774789, Validation Loss: 0.2108902379872048\nEpoch 2441, Training Loss: 0.15359145392635792, Validation Loss: 0.2108902379872048\nTraining Accuracy: 0.9503550418376917, Training F1 Score: 0.9479780592496041\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.2747041892946346e-06\nEpoch 2451, Training Loss: 0.15383425936353873, Validation Loss: 0.21089325885095578\nEpoch 2451, Training Loss: 0.1535678442777711, Validation Loss: 0.21089325885095578\nTraining Accuracy: 0.9503794014835024, Training F1 Score: 0.9480017102626124\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.204198785199862e-06\nEpoch 2461, Training Loss: 0.15381661366846056, Validation Loss: 0.21088645804788178\nEpoch 2461, Training Loss: 0.1535445253501985, Validation Loss: 0.21088645804788178\nTraining Accuracy: 0.9503794014835024, Training F1 Score: 0.9479998349317567\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.134485611600202e-06\nEpoch 2471, Training Loss: 0.1537982067963401, Validation Loss: 0.21088623873473755\nEpoch 2471, Training Loss: 0.15352227404727606, Validation Loss: 0.21088623873473755\nTraining Accuracy: 0.9503915813064078, Training F1 Score: 0.9480097858466665\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 6.0655557666367755e-06\nEpoch 2481, Training Loss: 0.15377981185523965, Validation Loss: 0.21089022563408827\nEpoch 2481, Training Loss: 0.15349855071061358, Validation Loss: 0.21089022563408827\nTraining Accuracy: 0.9503915813064078, Training F1 Score: 0.9480079100583584\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 5.997400448476004e-06\nEpoch 2491, Training Loss: 0.15376224518461123, Validation Loss: 0.21088076421504454\nEpoch 2491, Training Loss: 0.15347668564311043, Validation Loss: 0.21088076421504454\nTraining Accuracy: 0.9503794014835024, Training F1 Score: 0.9479942067360451\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 5.930010954185675e-06\nEpoch 2501, Training Loss: 0.1537457533225089, Validation Loss: 0.21088891941492566\nEpoch 2501, Training Loss: 0.15345590911720236, Validation Loss: 0.21088891941492566\nTraining Accuracy: 0.9503672216605971, Training F1 Score: 0.947974869425277\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 5.863378678623648e-06\nEpoch 2511, Training Loss: 0.1537279720773735, Validation Loss: 0.21088522029925266\nEpoch 2511, Training Loss: 0.15343404310756645, Validation Loss: 0.21088522029925266\nTraining Accuracy: 0.9503672216605971, Training F1 Score: 0.947974869425277\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 5.797495113339034e-06\nEpoch 2521, Training Loss: 0.15371052295682103, Validation Loss: 0.21088536068998015\nEpoch 2521, Training Loss: 0.15341330197198427, Validation Loss: 0.21088536068998015\nTraining Accuracy: 0.9504159409522186, Training F1 Score: 0.9480221832636737\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309677113808958\n\nLearning Rate: 5.732351845485735e-06\nEpoch 2531, Training Loss: 0.15369392077062513, Validation Loss: 0.2108707192170049\nEpoch 2531, Training Loss: 0.15339141247799637, Validation Loss: 0.2108707192170049\nTraining Accuracy: 0.9504037611293131, Training F1 Score: 0.9480047199994573\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.930715493668515\n\nLearning Rate: 5.667940556748183e-06\nEpoch 2541, Training Loss: 0.15367766562414834, Validation Loss: 0.21086928201527969\nEpoch 2541, Training Loss: 0.15337281692885857, Validation Loss: 0.21086928201527969\nTraining Accuracy: 0.9504037611293131, Training F1 Score: 0.9480009619928447\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.930715493668515\n\nLearning Rate: 5.604253022279151e-06\nEpoch 2551, Training Loss: 0.15366119235823344, Validation Loss: 0.21087148499916117\nEpoch 2551, Training Loss: 0.15335356175646142, Validation Loss: 0.21087148499916117\nTraining Accuracy: 0.9503794014835024, Training F1 Score: 0.9479754221902874\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.930715493668515\n\nLearning Rate: 5.541281109649505e-06\nEpoch 2561, Training Loss: 0.1536437913768366, Validation Loss: 0.21086392186359135\nEpoch 2561, Training Loss: 0.15333410690364022, Validation Loss: 0.21086392186359135\nTraining Accuracy: 0.9504159409522186, Training F1 Score: 0.9480071534554138\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9308191506733701\n\nLearning Rate: 5.4790167778097454e-06\nEpoch 2571, Training Loss: 0.15362875787838354, Validation Loss: 0.21086526268226044\nEpoch 2571, Training Loss: 0.15331596887494398, Validation Loss: 0.21086526268226044\nTraining Accuracy: 0.9504403005980293, Training F1 Score: 0.948028937204467\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9308191506733701\n\nLearning Rate: 5.417452076063233e-06\nEpoch 2581, Training Loss: 0.15361225467656703, Validation Loss: 0.21085633968955447\nEpoch 2581, Training Loss: 0.1532959900650765, Validation Loss: 0.21085633968955447\nTraining Accuracy: 0.9504403005980293, Training F1 Score: 0.9480232955141973\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 5.356579143050938e-06\nEpoch 2591, Training Loss: 0.15359651729385218, Validation Loss: 0.21084738953240567\nEpoch 2591, Training Loss: 0.15327852126100897, Validation Loss: 0.21084738953240567\nTraining Accuracy: 0.9504403005980293, Training F1 Score: 0.9480232955141973\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 5.296390205747601e-06\nEpoch 2601, Training Loss: 0.15358128493532575, Validation Loss: 0.21085966171748438\nEpoch 2601, Training Loss: 0.15326158640792759, Validation Loss: 0.21085966171748438\nTraining Accuracy: 0.9504403005980293, Training F1 Score: 0.9480232955141973\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 5.236877578469182e-06\nEpoch 2611, Training Loss: 0.15356591136995254, Validation Loss: 0.21085509691017051\nEpoch 2611, Training Loss: 0.15324399523367965, Validation Loss: 0.21085509691017051\nTraining Accuracy: 0.9504403005980293, Training F1 Score: 0.9480214142138345\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.930566724072295\n\nLearning Rate: 5.178033661891446e-06\nEpoch 2621, Training Loss: 0.15355036872958647, Validation Loss: 0.21085877599592573\nEpoch 2621, Training Loss: 0.1532261446937798, Validation Loss: 0.21085877599592573\nTraining Accuracy: 0.9504890198896508, Training F1 Score: 0.9480668708108726\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9304404397042556\n\nLearning Rate: 5.119850942079593e-06\nEpoch 2631, Training Loss: 0.15353451879676025, Validation Loss: 0.21085420767361693\nEpoch 2631, Training Loss: 0.15320873115230646, Validation Loss: 0.21085420767361693\nTraining Accuracy: 0.9504890198896508, Training F1 Score: 0.948064989886389\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9304404397042556\n\nLearning Rate: 5.06232198952878e-06\nEpoch 2641, Training Loss: 0.15351877222920363, Validation Loss: 0.2108493719519877\nEpoch 2641, Training Loss: 0.15319181019981257, Validation Loss: 0.2108493719519877\nTraining Accuracy: 0.9504768400667454, Training F1 Score: 0.9480475086649619\nValidation Accuracy: 0.9335744820782638, Validation F1 Score: 0.9303141078779011\n\nLearning Rate: 5.005439458215426e-06\nEpoch 2651, Training Loss: 0.1535035516552319, Validation Loss: 0.21085878199853095\nEpoch 2651, Training Loss: 0.15317486929410432, Validation Loss: 0.21085878199853095\nTraining Accuracy: 0.9504890198896508, Training F1 Score: 0.9480593449010234\nValidation Accuracy: 0.9335744820782638, Validation F1 Score: 0.9303141078779011\n\nLearning Rate: 4.949196084659187e-06\nEpoch 2661, Training Loss: 0.15348842259554846, Validation Loss: 0.21085081759329416\nEpoch 2661, Training Loss: 0.1531591284285291, Validation Loss: 0.21085081759329416\nTraining Accuracy: 0.9504768400667454, Training F1 Score: 0.9480456259869893\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9304177524918457\n\nLearning Rate: 4.893584686995453e-06\nEpoch 2671, Training Loss: 0.1534735301494912, Validation Loss: 0.2108474481897005\nEpoch 2671, Training Loss: 0.15314437271604822, Validation Loss: 0.2108474481897005\nTraining Accuracy: 0.9504768400667454, Training F1 Score: 0.9480456259869893\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9304177524918457\n\nLearning Rate: 4.838598164058284e-06\nEpoch 2681, Training Loss: 0.15345768825936815, Validation Loss: 0.21085428345344523\nEpoch 2681, Training Loss: 0.1531279933997014, Validation Loss: 0.21085428345344523\nTraining Accuracy: 0.9504524804209347, Training F1 Score: 0.9480163021504218\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9304177524918457\n\nLearning Rate: 4.7842294944736374e-06\nEpoch 2691, Training Loss: 0.15344292686868147, Validation Loss: 0.21085121176763674\nEpoch 2691, Training Loss: 0.15311276840055507, Validation Loss: 0.21085121176763674\nTraining Accuracy: 0.9504524804209347, Training F1 Score: 0.9480144174386244\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.730471735762798e-06\nEpoch 2701, Training Loss: 0.15342864522776076, Validation Loss: 0.21085279903449236\nEpoch 2701, Training Loss: 0.15309834159514024, Validation Loss: 0.21085279903449236\nTraining Accuracy: 0.9504768400667454, Training F1 Score: 0.9480399757388023\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.677318023455869e-06\nEpoch 2711, Training Loss: 0.15341400298883018, Validation Loss: 0.2108480061706477\nEpoch 2711, Training Loss: 0.15308404818128038, Validation Loss: 0.2108480061706477\nTraining Accuracy: 0.9504768400667454, Training F1 Score: 0.9480399757388023\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.624761570215227e-06\nEpoch 2721, Training Loss: 0.15340032619279934, Validation Loss: 0.2108385158018965\nEpoch 2721, Training Loss: 0.15307000926142378, Validation Loss: 0.2108385158018965\nTraining Accuracy: 0.95046466024384, Training F1 Score: 0.9480243695234363\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.572795664968839e-06\nEpoch 2731, Training Loss: 0.1533857747919122, Validation Loss: 0.2108459792354187\nEpoch 2731, Training Loss: 0.15305561671218193, Validation Loss: 0.2108459792354187\nTraining Accuracy: 0.9504524804209347, Training F1 Score: 0.9480125323573996\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.521413672053299e-06\nEpoch 2741, Training Loss: 0.15337073315492744, Validation Loss: 0.21085155967210162\nEpoch 2741, Training Loss: 0.15304180363413056, Validation Loss: 0.21085155967210162\nTraining Accuracy: 0.9504403005980293, Training F1 Score: 0.9479988098330128\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.470609030366503e-06\nEpoch 2751, Training Loss: 0.15335710446774278, Validation Loss: 0.21083275554186157\nEpoch 2751, Training Loss: 0.15302838178365882, Validation Loss: 0.21083275554186157\nTraining Accuracy: 0.950428120775124, Training F1 Score: 0.9479850867527304\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.420375252529852e-06\nEpoch 2761, Training Loss: 0.15334387168123254, Validation Loss: 0.21083780620902512\nEpoch 2761, Training Loss: 0.15301470106573484, Validation Loss: 0.21083780620902512\nTraining Accuracy: 0.950428120775124, Training F1 Score: 0.9479850867527304\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306251243180793\n\nLearning Rate: 4.370705924059854e-06\nEpoch 2771, Training Loss: 0.15333009356627134, Validation Loss: 0.2108339580000721\nEpoch 2771, Training Loss: 0.1530024913758954, Validation Loss: 0.2108339580000721\nTraining Accuracy: 0.9504403005980293, Training F1 Score: 0.9479950372651631\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306251243180793\n\nLearning Rate: 4.321594702549044e-06\nEpoch 2781, Training Loss: 0.15331666357545293, Validation Loss: 0.2108273931230668\nEpoch 2781, Training Loss: 0.15299043354747888, Validation Loss: 0.2108273931230668\nTraining Accuracy: 0.9504890198896508, Training F1 Score: 0.9480442753708342\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306251243180793\n\nLearning Rate: 4.2730353168561066e-06\nEpoch 2791, Training Loss: 0.15330291947582286, Validation Loss: 0.21081936721848538\nEpoch 2791, Training Loss: 0.15297715210056365, Validation Loss: 0.21081936721848538\nTraining Accuracy: 0.9504524804209347, Training F1 Score: 0.9480031014068335\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306251243180793\n\nLearning Rate: 4.225021566305096e-06\nEpoch 2801, Training Loss: 0.15328925564804738, Validation Loss: 0.21081886648360829\nEpoch 2801, Training Loss: 0.15296447514262954, Validation Loss: 0.21081886648360829\nTraining Accuracy: 0.9504524804209347, Training F1 Score: 0.9480031014068335\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306251243180793\n\nLearning Rate: 4.177547319893656e-06\nEpoch 2811, Training Loss: 0.15327574594473736, Validation Loss: 0.2108006581139776\nEpoch 2811, Training Loss: 0.15295143773133588, Validation Loss: 0.2108006581139776\nTraining Accuracy: 0.9504524804209347, Training F1 Score: 0.9480012141072267\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.130606515510136e-06\nEpoch 2821, Training Loss: 0.153262511190656, Validation Loss: 0.21079584757062306\nEpoch 2821, Training Loss: 0.15293838234528853, Validation Loss: 0.21079584757062306\nTraining Accuracy: 0.9504524804209347, Training F1 Score: 0.9480012141072267\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.084193159159502e-06\nEpoch 2831, Training Loss: 0.15324886423052383, Validation Loss: 0.21078818038009597\nEpoch 2831, Training Loss: 0.15292585195388583, Validation Loss: 0.21078818038009597\nTraining Accuracy: 0.9504403005980293, Training F1 Score: 0.9479874876909178\nValidation Accuracy: 0.9337937082100186, Validation F1 Score: 0.9305214246255233\n\nLearning Rate: 4.038301324197953e-06\nEpoch 2841, Training Loss: 0.15323633869915423, Validation Loss: 0.21077700790332674\nEpoch 2841, Training Loss: 0.15291469727308307, Validation Loss: 0.21077700790332674\nTraining Accuracy: 0.95046466024384, Training F1 Score: 0.9480111655558006\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.992925150576128e-06\nEpoch 2851, Training Loss: 0.15322245381138289, Validation Loss: 0.21076836747897373\nEpoch 2851, Training Loss: 0.1529028000319342, Validation Loss: 0.21076836747897373\nTraining Accuracy: 0.95046466024384, Training F1 Score: 0.9480111655558006\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.948058844090819e-06\nEpoch 2861, Training Loss: 0.15320988212204076, Validation Loss: 0.2107631140037886\nEpoch 2861, Training Loss: 0.15289121805135483, Validation Loss: 0.2107631140037886\nTraining Accuracy: 0.9504768400667454, Training F1 Score: 0.9480230050456161\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.903696675645096e-06\nEpoch 2871, Training Loss: 0.15319736920083982, Validation Loss: 0.21075493068068119\nEpoch 2871, Training Loss: 0.15287992783283638, Validation Loss: 0.21075493068068119\nTraining Accuracy: 0.9504890198896508, Training F1 Score: 0.9480386182019123\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.859832980516751e-06\nEpoch 2881, Training Loss: 0.1531834541303357, Validation Loss: 0.21076108417260886\nEpoch 2881, Training Loss: 0.15286844356091855, Validation Loss: 0.21076108417260886\nTraining Accuracy: 0.9505011997125562, Training F1 Score: 0.9480504578766844\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.816462157634938e-06\nEpoch 2891, Training Loss: 0.15317111648684967, Validation Loss: 0.2107494813278293\nEpoch 2891, Training Loss: 0.15285632976952443, Validation Loss: 0.2107494813278293\nTraining Accuracy: 0.9505377391812723, Training F1 Score: 0.9480897487129066\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.773578668864975e-06\nEpoch 2901, Training Loss: 0.1531586318265468, Validation Loss: 0.21075090088271184\nEpoch 2901, Training Loss: 0.15284558269028228, Validation Loss: 0.21075090088271184\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9481015893157824\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.7311770383011527e-06\nEpoch 2911, Training Loss: 0.1531461475934796, Validation Loss: 0.21075510927247829\nEpoch 2911, Training Loss: 0.1528344810531341, Validation Loss: 0.21075510927247829\nTraining Accuracy: 0.9505255593583669, Training F1 Score: 0.9480741383411936\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.689251851567508e-06\nEpoch 2921, Training Loss: 0.15313364399777793, Validation Loss: 0.21074964003344449\nEpoch 2921, Training Loss: 0.15282346423261936, Validation Loss: 0.21074964003344449\nTraining Accuracy: 0.9504890198896508, Training F1 Score: 0.9480348449070912\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.647797755126446e-06\nEpoch 2931, Training Loss: 0.15312148771639503, Validation Loss: 0.21074885951509656\nEpoch 2931, Training Loss: 0.15281253787046367, Validation Loss: 0.21074885951509656\nTraining Accuracy: 0.9505133795354616, Training F1 Score: 0.9480604120190681\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.606809455595133e-06\nEpoch 2941, Training Loss: 0.1531088010374873, Validation Loss: 0.21074432066353765\nEpoch 2941, Training Loss: 0.15280166297115413, Validation Loss: 0.21074432066353765\nTraining Accuracy: 0.9505133795354616, Training F1 Score: 0.9480604120190681\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.5662817190695697e-06\nEpoch 2951, Training Loss: 0.15309678152670542, Validation Loss: 0.2107567433759882\nEpoch 2951, Training Loss: 0.15279125666175647, Validation Loss: 0.2107567433759882\nTraining Accuracy: 0.9505133795354616, Training F1 Score: 0.9480604120190681\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.526209370456262e-06\nEpoch 2961, Training Loss: 0.153085171731702, Validation Loss: 0.21074918782085125\nEpoch 2961, Training Loss: 0.15278041033623982, Validation Loss: 0.21074918782085125\nTraining Accuracy: 0.9505133795354616, Training F1 Score: 0.9480604120190681\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306251243180793\n\nLearning Rate: 3.486587292811397e-06\nEpoch 2971, Training Loss: 0.1530726171971259, Validation Loss: 0.21075404446421386\nEpoch 2971, Training Loss: 0.1527702145364391, Validation Loss: 0.21075404446421386\nTraining Accuracy: 0.9505133795354616, Training F1 Score: 0.9480604120190681\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306251243180793\n\nLearning Rate: 3.4474104266874495e-06\nEpoch 2981, Training Loss: 0.15306129115904943, Validation Loss: 0.21074499197367133\nEpoch 2981, Training Loss: 0.15276084165613746, Validation Loss: 0.21074499197367133\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480959352268611\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.408673769487128e-06\nEpoch 2991, Training Loss: 0.1530502108252458, Validation Loss: 0.21075800615915613\nEpoch 2991, Training Loss: 0.1527508380755628, Validation Loss: 0.21075800615915613\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480959352268611\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.3703723748245755e-06\nEpoch 3001, Training Loss: 0.15303883685328287, Validation Loss: 0.2107686291272267\nEpoch 3001, Training Loss: 0.15274147630593052, Validation Loss: 0.2107686291272267\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480959352268611\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.3325013518937597e-06\nEpoch 3011, Training Loss: 0.15302744639263507, Validation Loss: 0.21077155426126634\nEpoch 3011, Training Loss: 0.152731815014301, Validation Loss: 0.21077155426126634\nTraining Accuracy: 0.9505133795354616, Training F1 Score: 0.9480547520878811\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.295055864843946e-06\nEpoch 3021, Training Loss: 0.1530165427258791, Validation Loss: 0.21076094818052513\nEpoch 3021, Training Loss: 0.15272262886649526, Validation Loss: 0.21076094818052513\nTraining Accuracy: 0.9505255593583669, Training F1 Score: 0.9480684803577666\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309815476412482\n\nLearning Rate: 3.258031132162199e-06\nEpoch 3031, Training Loss: 0.15300578932539968, Validation Loss: 0.21076829999009075\nEpoch 3031, Training Loss: 0.15271298372089087, Validation Loss: 0.21076829999009075\nTraining Accuracy: 0.9505255593583669, Training F1 Score: 0.9480665936235665\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.2214224260628172e-06\nEpoch 3041, Training Loss: 0.15299454296533108, Validation Loss: 0.21076244843328887\nEpoch 3041, Training Loss: 0.1527041857412288, Validation Loss: 0.21076244843328887\nTraining Accuracy: 0.9505377391812723, Training F1 Score: 0.9480803219859427\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.185225071883631e-06\nEpoch 3051, Training Loss: 0.15298402938855346, Validation Loss: 0.2107609042087877\nEpoch 3051, Training Loss: 0.15269507395929754, Validation Loss: 0.2107609042087877\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480940497913667\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.149434447489081e-06\nEpoch 3061, Training Loss: 0.15297353150969353, Validation Loss: 0.21075571376177402\nEpoch 3061, Training Loss: 0.15268602524690358, Validation Loss: 0.21075571376177402\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.9481196192249672\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.1140459826800047e-06\nEpoch 3071, Training Loss: 0.15296306391883263, Validation Loss: 0.21076932733719853\nEpoch 3071, Training Loss: 0.15267746592865888, Validation Loss: 0.21076932733719853\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480959352268611\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.07905515861006e-06\nEpoch 3081, Training Loss: 0.15295252266248066, Validation Loss: 0.21075872494785536\nEpoch 3081, Training Loss: 0.15266888549418944, Validation Loss: 0.21075872494785536\nTraining Accuracy: 0.9505377391812723, Training F1 Score: 0.9480840937857384\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 3.0444575072086957e-06\nEpoch 3091, Training Loss: 0.15294249379114916, Validation Loss: 0.21076325662242182\nEpoch 3091, Training Loss: 0.15266065026272485, Validation Loss: 0.21076325662242182\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480940497913667\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 3.0102486106106167e-06\nEpoch 3101, Training Loss: 0.15293223514595564, Validation Loss: 0.21077745066202094\nEpoch 3101, Training Loss: 0.15265238197639275, Validation Loss: 0.21077745066202094\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480959352268611\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.976424100591653e-06\nEpoch 3111, Training Loss: 0.15292235618426595, Validation Loss: 0.21078158757423449\nEpoch 3111, Training Loss: 0.15264431319552496, Validation Loss: 0.21078158757423449\nTraining Accuracy: 0.9505620988270831, Training F1 Score: 0.9481096618262281\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.94297965801097e-06\nEpoch 3121, Training Loss: 0.15291268796793325, Validation Loss: 0.21078540395386292\nEpoch 3121, Training Loss: 0.1526357344485821, Validation Loss: 0.21078540395386292\nTraining Accuracy: 0.9505864584728938, Training F1 Score: 0.9481352298667178\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.9099110122595466e-06\nEpoch 3131, Training Loss: 0.15290224060053054, Validation Loss: 0.21079266353237855\nEpoch 3131, Training Loss: 0.15262792884146295, Validation Loss: 0.21079266353237855\nTraining Accuracy: 0.9505864584728938, Training F1 Score: 0.9481352298667178\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306024321823898\n\nLearning Rate: 2.877213940714848e-06\nEpoch 3141, Training Loss: 0.15289264741361255, Validation Loss: 0.21079275769079567\nEpoch 3141, Training Loss: 0.15261983605426782, Validation Loss: 0.21079275769079567\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.9481215037316751\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306024321823898\n\nLearning Rate: 2.8448842682016296e-06\nEpoch 3151, Training Loss: 0.15288318719482524, Validation Loss: 0.21079972505922265\nEpoch 3151, Training Loss: 0.15261252119070215, Validation Loss: 0.21079972505922265\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.9481233878689144\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306024321823898\n\nLearning Rate: 2.812917866458799e-06\nEpoch 3161, Training Loss: 0.15287387232402194, Validation Loss: 0.21079988043277942\nEpoch 3161, Training Loss: 0.1526046089735725, Validation Loss: 0.21079988043277942\nTraining Accuracy: 0.9505620988270831, Training F1 Score: 0.9481096618262281\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306024321823898\n\nLearning Rate: 2.7813106536122633e-06\nEpoch 3171, Training Loss: 0.152864770411163, Validation Loss: 0.21080048575508978\nEpoch 3171, Training Loss: 0.15259752844879343, Validation Loss: 0.21080048575508978\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480997049889822\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.750058593653709e-06\nEpoch 3181, Training Loss: 0.15285517599916387, Validation Loss: 0.2108008497645036\nEpoch 3181, Training Loss: 0.15258985560163182, Validation Loss: 0.2108008497645036\nTraining Accuracy: 0.9505620988270831, Training F1 Score: 0.9481134302903846\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.7191576959252294e-06\nEpoch 3191, Training Loss: 0.15284593517898085, Validation Loss: 0.21079431719213126\nEpoch 3191, Training Loss: 0.1525823728916028, Validation Loss: 0.21079431719213126\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9480997049889822\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.688604014609749e-06\nEpoch 3201, Training Loss: 0.15283703791983094, Validation Loss: 0.210801961999066\nEpoch 3201, Training Loss: 0.1525750748292538, Validation Loss: 0.210801961999066\nTraining Accuracy: 0.9505620988270831, Training F1 Score: 0.9481134302903846\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.658393648227171e-06\nEpoch 3211, Training Loss: 0.15282763841043934, Validation Loss: 0.2108021197720315\nEpoch 3211, Training Loss: 0.15256769130796588, Validation Loss: 0.2108021197720315\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9481015893157824\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308326065366771\n\nLearning Rate: 2.6285227391361876e-06\nEpoch 3221, Training Loss: 0.15281844368162073, Validation Loss: 0.2108024530366731\nEpoch 3221, Training Loss: 0.15256062963364667, Validation Loss: 0.2108024530366731\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9481015893157824\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308326065366771\n\nLearning Rate: 2.598987473041687e-06\nEpoch 3231, Training Loss: 0.1528091237522305, Validation Loss: 0.2108078835209276\nEpoch 3231, Training Loss: 0.15255339756905115, Validation Loss: 0.2108078835209276\nTraining Accuracy: 0.9505255593583669, Training F1 Score: 0.9480779084816997\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308326065366771\n\nLearning Rate: 2.5697840785076963e-06\nEpoch 3241, Training Loss: 0.15280044411014465, Validation Loss: 0.21080699628850916\nEpoch 3241, Training Loss: 0.15254600467199025, Validation Loss: 0.21080699628850916\nTraining Accuracy: 0.9505377391812723, Training F1 Score: 0.9480897487129066\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308326065366771\n\nLearning Rate: 2.5409088264757968e-06\nEpoch 3251, Training Loss: 0.15279136708258606, Validation Loss: 0.21081151808286908\nEpoch 3251, Training Loss: 0.15253933090609745, Validation Loss: 0.21081151808286908\nTraining Accuracy: 0.9505377391812723, Training F1 Score: 0.9480897487129066\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308326065366771\n\nLearning Rate: 2.5123580297889515e-06\nEpoch 3261, Training Loss: 0.15278298361793516, Validation Loss: 0.21081415980574097\nEpoch 3261, Training Loss: 0.15253236990259528, Validation Loss: 0.21081415980574097\nTraining Accuracy: 0.9505499190041777, Training F1 Score: 0.9481015893157824\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.4841280427206797e-06\nEpoch 3271, Training Loss: 0.15277403246501509, Validation Loss: 0.2108235261647518\nEpoch 3271, Training Loss: 0.15252570719437575, Validation Loss: 0.2108235261647518\nTraining Accuracy: 0.9505620988270831, Training F1 Score: 0.9481153139684039\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.4562152605095286e-06\nEpoch 3281, Training Loss: 0.1527652826245086, Validation Loss: 0.21082572581820827\nEpoch 3281, Training Loss: 0.15251906225255535, Validation Loss: 0.21082572581820827\nTraining Accuracy: 0.9505620988270831, Training F1 Score: 0.9481171972771655\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307288516087128\n\nLearning Rate: 2.428616118898769e-06\nEpoch 3291, Training Loss: 0.1527573366310748, Validation Loss: 0.21083355126354264\nEpoch 3291, Training Loss: 0.15251272165029578, Validation Loss: 0.21083355126354264\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.948130920724909\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 2.4013270936812653e-06\nEpoch 3301, Training Loss: 0.1527490968809664, Validation Loss: 0.21084124304596746\nEpoch 3301, Training Loss: 0.1525063831215995, Validation Loss: 0.21084124304596746\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.948130920724909\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.3743447002494633e-06\nEpoch 3311, Training Loss: 0.15274069606063614, Validation Loss: 0.2108445345822962\nEpoch 3311, Training Loss: 0.15250004559148048, Validation Loss: 0.2108445345822962\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.948130920724909\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.3476654931504293e-06\nEpoch 3321, Training Loss: 0.15273261484964124, Validation Loss: 0.21084814489697934\nEpoch 3321, Training Loss: 0.15249355569339015, Validation Loss: 0.21084814489697934\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.948130920724909\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.3212860656458904e-06\nEpoch 3331, Training Loss: 0.15272426930097982, Validation Loss: 0.2108452653027046\nEpoch 3331, Training Loss: 0.152487568394372, Validation Loss: 0.2108452653027046\nTraining Accuracy: 0.9505864584728938, Training F1 Score: 0.9481446436165011\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.2952030492772216e-06\nEpoch 3341, Training Loss: 0.15271657388800486, Validation Loss: 0.21084467547936592\nEpoch 3341, Training Loss: 0.15248136861818581, Validation Loss: 0.21084467547936592\nTraining Accuracy: 0.9505986382957992, Training F1 Score: 0.9481583659520204\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.269413113435316e-06\nEpoch 3351, Training Loss: 0.15270898240855563, Validation Loss: 0.21083959074353853\nEpoch 3351, Training Loss: 0.15247546268397616, Validation Loss: 0.21083959074353853\nTraining Accuracy: 0.9505986382957992, Training F1 Score: 0.9481583659520204\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.2439129649352923e-06\nEpoch 3361, Training Loss: 0.15270081965869994, Validation Loss: 0.21084283924077957\nEpoch 3361, Training Loss: 0.15246966787460942, Validation Loss: 0.21084283924077957\nTraining Accuracy: 0.9505986382957992, Training F1 Score: 0.9481583659520204\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.218699347595979e-06\nEpoch 3371, Training Loss: 0.15269311595092733, Validation Loss: 0.2108289907095033\nEpoch 3371, Training Loss: 0.15246399778177108, Validation Loss: 0.2108289907095033\nTraining Accuracy: 0.9505986382957992, Training F1 Score: 0.9481583659520204\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.1937690418241227e-06\nEpoch 3381, Training Loss: 0.15268570730785297, Validation Loss: 0.2108429023849197\nEpoch 3381, Training Loss: 0.15245839346490117, Validation Loss: 0.2108429023849197\nTraining Accuracy: 0.9505986382957992, Training F1 Score: 0.9481583659520204\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307514861333859\n\nLearning Rate: 2.1691188642032718e-06\nEpoch 3391, Training Loss: 0.15267822467332526, Validation Loss: 0.2108417525046308\nEpoch 3391, Training Loss: 0.15245266561266255, Validation Loss: 0.2108417525046308\nTraining Accuracy: 0.9505864584728938, Training F1 Score: 0.9481465252594033\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 2.1447456670872755e-06\nEpoch 3401, Training Loss: 0.15267047667623723, Validation Loss: 0.2108414834556148\nEpoch 3401, Training Loss: 0.15244717739373906, Validation Loss: 0.2108414834556148\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.9481328030160991\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 2.1206463381983546e-06\nEpoch 3411, Training Loss: 0.15266329566467554, Validation Loss: 0.21084322905241235\nEpoch 3411, Training Loss: 0.15244163600465999, Validation Loss: 0.21084322905241235\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.9481328030160991\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 2.0968178002296854e-06\nEpoch 3421, Training Loss: 0.1526557918266247, Validation Loss: 0.21084153037230383\nEpoch 3421, Training Loss: 0.15243604522647952, Validation Loss: 0.21084153037230383\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.9481328030160991\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 2.0732570104524505e-06\nEpoch 3431, Training Loss: 0.15264874231600015, Validation Loss: 0.2108479123291028\nEpoch 3431, Training Loss: 0.15243059355127314, Validation Loss: 0.2108479123291028\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.9481328030160991\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 2.049960960327305e-06\nEpoch 3441, Training Loss: 0.15264130260341577, Validation Loss: 0.21084578887198194\nEpoch 3441, Training Loss: 0.15242542870005243, Validation Loss: 0.21084578887198194\nTraining Accuracy: 0.9505742786499884, Training F1 Score: 0.9481328030160991\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 2.0269266751202066e-06\nEpoch 3451, Training Loss: 0.15263388689316584, Validation Loss: 0.21085196928661487\nEpoch 3451, Training Loss: 0.15242002642157015, Validation Loss: 0.21085196928661487\nTraining Accuracy: 0.9505864584728938, Training F1 Score: 0.9481465252594033\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 2.004151213522568e-06\nEpoch 3461, Training Loss: 0.15262731675262284, Validation Loss: 0.21085150228392904\nEpoch 3461, Training Loss: 0.15241467363709252, Validation Loss: 0.21085150228392904\nTraining Accuracy: 0.9505864584728938, Training F1 Score: 0.9481465252594033\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 1.981631667275668e-06\nEpoch 3471, Training Loss: 0.15261990348055665, Validation Loss: 0.21085462089949344\nEpoch 3471, Training Loss: 0.1524096904706704, Validation Loss: 0.21085462089949344\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481702070162465\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.959365160799293e-06\nEpoch 3481, Training Loss: 0.15261308769272977, Validation Loss: 0.21085899375410935\nEpoch 3481, Training Loss: 0.1524047898140993, Validation Loss: 0.21085899375410935\nTraining Accuracy: 0.9506351777645153, Training F1 Score: 0.9481976502036878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.9373488508245426e-06\nEpoch 3491, Training Loss: 0.15260634579363094, Validation Loss: 0.21086115168496783\nEpoch 3491, Training Loss: 0.15239978564016704, Validation Loss: 0.21086115168496783\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.9481839288879415\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.91557992603077e-06\nEpoch 3501, Training Loss: 0.15259971514279058, Validation Loss: 0.21086583111019075\nEpoch 3501, Training Loss: 0.15239490755902846, Validation Loss: 0.21086583111019075\nTraining Accuracy: 0.9506351777645153, Training F1 Score: 0.9481976502036878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.894055606686591e-06\nEpoch 3511, Training Loss: 0.15259312493977412, Validation Loss: 0.21086682131138076\nEpoch 3511, Training Loss: 0.15239018013347, Validation Loss: 0.21086682131138076\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.9481839288879415\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.8727731442949386e-06\nEpoch 3521, Training Loss: 0.15258659275333428, Validation Loss: 0.2108722836690606\nEpoch 3521, Training Loss: 0.15238557166692152, Validation Loss: 0.2108722836690606\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481720877315456\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.8517298212420958e-06\nEpoch 3531, Training Loss: 0.15258008063336073, Validation Loss: 0.21087422988844143\nEpoch 3531, Training Loss: 0.1523808371293586, Validation Loss: 0.21087422988844143\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.9481839288879415\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.830922950450679e-06\nEpoch 3541, Training Loss: 0.1525734139885471, Validation Loss: 0.21087725543504116\nEpoch 3541, Training Loss: 0.15237633665217123, Validation Loss: 0.21087725543504116\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481720877315456\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.8103498750365169e-06\nEpoch 3551, Training Loss: 0.15256758191075964, Validation Loss: 0.2108786324261443\nEpoch 3551, Training Loss: 0.15237181379247894, Validation Loss: 0.2108786324261443\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481720877315456\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.7900079679693856e-06\nEpoch 3561, Training Loss: 0.15256113539778407, Validation Loss: 0.2108829027742301\nEpoch 3561, Training Loss: 0.1523675502891824, Validation Loss: 0.2108829027742301\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.9481839288879415\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.7698946317375574e-06\nEpoch 3571, Training Loss: 0.15255521106811878, Validation Loss: 0.2108855706749942\nEpoch 3571, Training Loss: 0.15236323925473344, Validation Loss: 0.2108855706749942\nTraining Accuracy: 0.9506351777645153, Training F1 Score: 0.9481976502036878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309589883143317\n\nLearning Rate: 1.7500072980161167e-06\nEpoch 3581, Training Loss: 0.15254914032020225, Validation Loss: 0.2108861285693732\nEpoch 3581, Training Loss: 0.15235885373172042, Validation Loss: 0.2108861285693732\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948211370963565\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 1.730343427339004e-06\nEpoch 3591, Training Loss: 0.15254317619155236, Validation Loss: 0.21088755491740815\nEpoch 3591, Training Loss: 0.1523545660315284, Validation Loss: 0.21088755491740815\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482250911676519\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 1.7109005087747452e-06\nEpoch 3601, Training Loss: 0.1525370417635544, Validation Loss: 0.21089041394928915\nEpoch 3601, Training Loss: 0.15235062497068075, Validation Loss: 0.21089041394928915\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482250911676519\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 1.6916760596058235e-06\nEpoch 3611, Training Loss: 0.15253118369480814, Validation Loss: 0.21089336528572142\nEpoch 3611, Training Loss: 0.15234650655311016, Validation Loss: 0.21089336528572142\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.9482132497349488\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 1.6726676250116548e-06\nEpoch 3621, Training Loss: 0.15252530123551283, Validation Loss: 0.21089343820879963\nEpoch 3621, Training Loss: 0.1523424921725166, Validation Loss: 0.21089343820879963\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.9482132497349488\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 1.6538727777551271e-06\nEpoch 3631, Training Loss: 0.1525195748838625, Validation Loss: 0.21089598776922275\nEpoch 3631, Training Loss: 0.1523385167767278, Validation Loss: 0.21089598776922275\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481758480563257\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 1.6352891178726557e-06\nEpoch 3641, Training Loss: 0.15251395821654112, Validation Loss: 0.21089836610757795\nEpoch 3641, Training Loss: 0.15233456623883387, Validation Loss: 0.21089836610757795\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.9481895679841695\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9308552234082351\n\nLearning Rate: 1.6169142723677303e-06\nEpoch 3651, Training Loss: 0.15250842808750056, Validation Loss: 0.2108994901088799\nEpoch 3651, Training Loss: 0.15233061288089383, Validation Loss: 0.2108994901088799\nTraining Accuracy: 0.9506351777645153, Training F1 Score: 0.948201408673807\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309815476412482\n\nLearning Rate: 1.598745894907899e-06\nEpoch 3661, Training Loss: 0.15250306940466551, Validation Loss: 0.21090127602031744\nEpoch 3661, Training Loss: 0.15232685669459314, Validation Loss: 0.21090127602031744\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.9481895679841695\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309815476412482\n\nLearning Rate: 1.580781665525157e-06\nEpoch 3671, Training Loss: 0.15249754566274434, Validation Loss: 0.2109033153919644\nEpoch 3671, Training Loss: 0.15232321148086228, Validation Loss: 0.2109033153919644\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.9482132497349488\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309815476412482\n\nLearning Rate: 1.5630192903197075e-06\nEpoch 3681, Training Loss: 0.15249202628374556, Validation Loss: 0.21090506628085473\nEpoch 3681, Training Loss: 0.15231941480227176, Validation Loss: 0.21090506628085473\nTraining Accuracy: 0.9506351777645153, Training F1 Score: 0.948199529622931\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309815476412482\n\nLearning Rate: 1.545456501167044e-06\nEpoch 3691, Training Loss: 0.15248643924251637, Validation Loss: 0.21090798704401778\nEpoch 3691, Training Loss: 0.1523158079321291, Validation Loss: 0.21090798704401778\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.94818768865387\nValidation Accuracy: 0.934341773539406, Validation F1 Score: 0.9311078243679594\n\nLearning Rate: 1.5280910554283303e-06\nEpoch 3701, Training Loss: 0.15248130245327685, Validation Loss: 0.21090838367167003\nEpoch 3701, Training Loss: 0.15231211582682896, Validation Loss: 0.21090838367167003\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.94818768865387\nValidation Accuracy: 0.934341773539406, Validation F1 Score: 0.9311078243679594\n\nLearning Rate: 1.5109207356640302e-06\nEpoch 3711, Training Loss: 0.152476228861346, Validation Loss: 0.21090725533052532\nEpoch 3711, Training Loss: 0.15230850591195125, Validation Loss: 0.21090725533052532\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481777276659787\nValidation Accuracy: 0.934341773539406, Validation F1 Score: 0.9311078243679594\n\nLearning Rate: 1.4939433493507578e-06\nEpoch 3721, Training Loss: 0.1524710553795647, Validation Loss: 0.21091003314838275\nEpoch 3721, Training Loss: 0.15230501920085365, Validation Loss: 0.21091003314838275\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481777276659787\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.477156728601308e-06\nEpoch 3731, Training Loss: 0.15246578823678997, Validation Loss: 0.21090890683914032\nEpoch 3731, Training Loss: 0.15230148414369782, Validation Loss: 0.21090890683914032\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481777276659787\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.4605587298878332e-06\nEpoch 3741, Training Loss: 0.15246075188551134, Validation Loss: 0.2109102632727498\nEpoch 3741, Training Loss: 0.1522981958710642, Validation Loss: 0.2109102632727498\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481777276659787\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.4441472337681308e-06\nEpoch 3751, Training Loss: 0.1524556246382928, Validation Loss: 0.21090947733327353\nEpoch 3751, Training Loss: 0.15229478773903127, Validation Loss: 0.21090947733327353\nTraining Accuracy: 0.9506108181187045, Training F1 Score: 0.9481777276659787\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.427920144615006e-06\nEpoch 3761, Training Loss: 0.15245088935279513, Validation Loss: 0.21090903319112175\nEpoch 3761, Training Loss: 0.15229148106622317, Validation Loss: 0.21090903319112175\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.9481895679841695\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.4118753903486755e-06\nEpoch 3771, Training Loss: 0.15244608361750833, Validation Loss: 0.21090964025786268\nEpoch 3771, Training Loss: 0.15228815319406627, Validation Loss: 0.21090964025786268\nTraining Accuracy: 0.95062299794161, Training F1 Score: 0.9481895679841695\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.3960109221721784e-06\nEpoch 3781, Training Loss: 0.15244099660685526, Validation Loss: 0.21091019565319788\nEpoch 3781, Training Loss: 0.15228489596625958, Validation Loss: 0.21091019565319788\nTraining Accuracy: 0.9506351777645153, Training F1 Score: 0.9482032873564021\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.3803247143097595e-06\nEpoch 3791, Training Loss: 0.15243644176038476, Validation Loss: 0.21091058330225942\nEpoch 3791, Training Loss: 0.15228165783084355, Validation Loss: 0.21091058330225942\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.9482170061731028\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.3648147637481936e-06\nEpoch 3801, Training Loss: 0.15243163838886936, Validation Loss: 0.21091056059689475\nEpoch 3801, Training Loss: 0.1522784229762856, Validation Loss: 0.21091056059689475\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482444421402234\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.3494790899810139e-06\nEpoch 3811, Training Loss: 0.15242684890451094, Validation Loss: 0.2109109626015746\nEpoch 3811, Training Loss: 0.15227520866606636, Validation Loss: 0.2109109626015746\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482444421402234\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.3343157347556177e-06\nEpoch 3821, Training Loss: 0.1524223140927454, Validation Loss: 0.21091272006964693\nEpoch 3821, Training Loss: 0.1522719614485339, Validation Loss: 0.21091272006964693\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482326014539478\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.3193227618232102e-06\nEpoch 3831, Training Loss: 0.15241758122165583, Validation Loss: 0.21091437113562084\nEpoch 3831, Training Loss: 0.1522690876390043, Validation Loss: 0.21091437113562084\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482326014539478\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.3044982566915615e-06\nEpoch 3841, Training Loss: 0.15241299929399504, Validation Loss: 0.21091603356979402\nEpoch 3841, Training Loss: 0.15226606670666568, Validation Loss: 0.21091603356979402\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482326014539478\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.2898403263805383e-06\nEpoch 3851, Training Loss: 0.15240849329069348, Validation Loss: 0.2109151332378126\nEpoch 3851, Training Loss: 0.15226306039871063, Validation Loss: 0.2109151332378126\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.2753470991803864e-06\nEpoch 3861, Training Loss: 0.15240430694028564, Validation Loss: 0.21091490119751197\nEpoch 3861, Training Loss: 0.15225998852187128, Validation Loss: 0.21091490119751197\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.2610167244127246e-06\nEpoch 3871, Training Loss: 0.1523995928893465, Validation Loss: 0.21091673618657644\nEpoch 3871, Training Loss: 0.1522570920519702, Validation Loss: 0.21091673618657644\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.246847372194229e-06\nEpoch 3881, Training Loss: 0.15239532831669023, Validation Loss: 0.21091685509696076\nEpoch 3881, Training Loss: 0.15225426525452157, Validation Loss: 0.21091685509696076\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.2328372332029691e-06\nEpoch 3891, Training Loss: 0.15239095519839524, Validation Loss: 0.21091734961689557\nEpoch 3891, Training Loss: 0.15225133340336927, Validation Loss: 0.21091734961689557\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.2189845184473707e-06\nEpoch 3901, Training Loss: 0.1523869292784447, Validation Loss: 0.21091851055504499\nEpoch 3901, Training Loss: 0.15224847885193393, Validation Loss: 0.21091851055504499\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.2052874590377758e-06\nEpoch 3911, Training Loss: 0.15238263125835047, Validation Loss: 0.21091859232604498\nEpoch 3911, Training Loss: 0.15224560503423712, Validation Loss: 0.21091859232604498\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482481945172452\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.191744305960567e-06\nEpoch 3921, Training Loss: 0.15237835262103658, Validation Loss: 0.2109202469560147\nEpoch 3921, Training Loss: 0.1522428159095767, Validation Loss: 0.2109202469560147\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482363543897058\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.1783533298548329e-06\nEpoch 3931, Training Loss: 0.1523742556895745, Validation Loss: 0.21092321350721366\nEpoch 3931, Training Loss: 0.15224004938775432, Validation Loss: 0.21092321350721366\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482363543897058\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.1651128207915404e-06\nEpoch 3941, Training Loss: 0.15236999178862567, Validation Loss: 0.21092395694987837\nEpoch 3941, Training Loss: 0.15223723575439255, Validation Loss: 0.21092395694987837\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482363543897058\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.1520210880551893e-06\nEpoch 3951, Training Loss: 0.15236571426604487, Validation Loss: 0.21092605760853292\nEpoch 3951, Training Loss: 0.15223440138104205, Validation Loss: 0.21092605760853292\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.139076459927921e-06\nEpoch 3961, Training Loss: 0.1523615283470471, Validation Loss: 0.2109268338605394\nEpoch 3961, Training Loss: 0.1522314694055667, Validation Loss: 0.2109268338605394\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.1262772834760526e-06\nEpoch 3971, Training Loss: 0.15235746360019115, Validation Loss: 0.21093086103532943\nEpoch 3971, Training Loss: 0.15222874455955326, Validation Loss: 0.21093086103532943\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.1136219243390081e-06\nEpoch 3981, Training Loss: 0.15235343016767997, Validation Loss: 0.21093241763091408\nEpoch 3981, Training Loss: 0.15222600957059385, Validation Loss: 0.21093241763091408\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.1011087665206239e-06\nEpoch 3991, Training Loss: 0.15234938741529583, Validation Loss: 0.21093441911999702\nEpoch 3991, Training Loss: 0.15222332180152545, Validation Loss: 0.21093441911999702\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.0887362121827979e-06\nEpoch 4001, Training Loss: 0.15234538059336228, Validation Loss: 0.2109358939707155\nEpoch 4001, Training Loss: 0.15222066493299663, Validation Loss: 0.2109358939707155\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482344781057045\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.0765026814414563e-06\nEpoch 4011, Training Loss: 0.152341638784251, Validation Loss: 0.2109381052814763\nEpoch 4011, Training Loss: 0.15221821535945182, Validation Loss: 0.2109381052814763\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.0644066121648156e-06\nEpoch 4021, Training Loss: 0.1523376801702591, Validation Loss: 0.21093894717830008\nEpoch 4021, Training Loss: 0.15221572067660394, Validation Loss: 0.21093894717830008\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.0524464597739083e-06\nEpoch 4031, Training Loss: 0.15233414427914063, Validation Loss: 0.2109397128085537\nEpoch 4031, Training Loss: 0.15221304683625453, Validation Loss: 0.2109397128085537\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482581592908009\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.0406206970453527e-06\nEpoch 4041, Training Loss: 0.15233030406588471, Validation Loss: 0.21094040426457383\nEpoch 4041, Training Loss: 0.1522106913126437, Validation Loss: 0.21094040426457383\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482581592908009\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.0289278139163372e-06\nEpoch 4051, Training Loss: 0.1523268285894165, Validation Loss: 0.2109418472957679\nEpoch 4051, Training Loss: 0.15220822568490947, Validation Loss: 0.2109418472957679\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482581592908009\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.0173663172917964e-06\nEpoch 4061, Training Loss: 0.1523230563483819, Validation Loss: 0.21094249045980823\nEpoch 4061, Training Loss: 0.1522058706433454, Validation Loss: 0.21094249045980823\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482581592908009\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 1.005934730853754e-06\nEpoch 4071, Training Loss: 0.15231940241406963, Validation Loss: 0.21094482561043973\nEpoch 4071, Training Loss: 0.1522035202803209, Validation Loss: 0.21094482561043973\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482581592908009\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 9.946315948728075e-07\nEpoch 4081, Training Loss: 0.15231593968044188, Validation Loss: 0.21094479283376522\nEpoch 4081, Training Loss: 0.15220124039013516, Validation Loss: 0.21094479283376522\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482581592908009\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 9.83455466021733e-07\nEpoch 4091, Training Loss: 0.15231236806958678, Validation Loss: 0.21094659994460768\nEpoch 4091, Training Loss: 0.15219889282628496, Validation Loss: 0.21094659994460768\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482581592908009\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 9.724049171911801e-07\nEpoch 4101, Training Loss: 0.1523090311948076, Validation Loss: 0.2109461954163836\nEpoch 4101, Training Loss: 0.15219654382899908, Validation Loss: 0.2109461954163836\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482444421402234\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 9.614785373074433e-07\nEpoch 4111, Training Loss: 0.1523055788311742, Validation Loss: 0.21094809102277726\nEpoch 4111, Training Loss: 0.15219443686074255, Validation Loss: 0.21094809102277726\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482444421402234\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 9.506749311522768e-07\nEpoch 4121, Training Loss: 0.1523022598200747, Validation Loss: 0.21094956874984613\nEpoch 4121, Training Loss: 0.15219216626647264, Validation Loss: 0.21094956874984613\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482444421402234\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 9.399927191847362e-07\nEpoch 4131, Training Loss: 0.1522989296046552, Validation Loss: 0.21095004541876808\nEpoch 4131, Training Loss: 0.15219001965023413, Validation Loss: 0.21095004541876808\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482444421402234\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 9.2943053736502e-07\nEpoch 4141, Training Loss: 0.15229562757935125, Validation Loss: 0.21095232018074106\nEpoch 4141, Training Loss: 0.15218792218624796, Validation Loss: 0.21095232018074106\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482444421402234\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 9.189870369802938e-07\nEpoch 4151, Training Loss: 0.15229225102083582, Validation Loss: 0.21095337332680103\nEpoch 4151, Training Loss: 0.15218572725407914, Validation Loss: 0.21095337332680103\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482444421402234\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 9.086608844724675e-07\nEpoch 4161, Training Loss: 0.15228913704312974, Validation Loss: 0.21095604524073547\nEpoch 4161, Training Loss: 0.15218364389631261, Validation Loss: 0.21095604524073547\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482581592908009\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.98450761267911e-07\nEpoch 4171, Training Loss: 0.15228592313110728, Validation Loss: 0.2109574095095823\nEpoch 4171, Training Loss: 0.15218149541177994, Validation Loss: 0.2109574095095823\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482718758861619\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.88355363609082e-07\nEpoch 4181, Training Loss: 0.15228290423621474, Validation Loss: 0.21095997887125248\nEpoch 4181, Training Loss: 0.15217941816580718, Validation Loss: 0.21095997887125248\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482718758861619\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.783734023880452e-07\nEpoch 4191, Training Loss: 0.15227974844385717, Validation Loss: 0.2109614515855335\nEpoch 4191, Training Loss: 0.1521774624308246, Validation Loss: 0.2109614515855335\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482718758861619\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.685036029818629e-07\nEpoch 4201, Training Loss: 0.15227660452534916, Validation Loss: 0.21096293736344351\nEpoch 4201, Training Loss: 0.1521755312179739, Validation Loss: 0.21096293736344351\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.9482837171276542\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.587447050898356e-07\nEpoch 4211, Training Loss: 0.15227354757870998, Validation Loss: 0.21096388617034129\nEpoch 4211, Training Loss: 0.15217350285128725, Validation Loss: 0.21096388617034129\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482718758861619\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.490954625725702e-07\nEpoch 4221, Training Loss: 0.1522706025607484, Validation Loss: 0.2109650471803586\nEpoch 4221, Training Loss: 0.15217159800944272, Validation Loss: 0.2109650471803586\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482718758861619\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.395546432928574e-07\nEpoch 4231, Training Loss: 0.15226761153000912, Validation Loss: 0.21096533379454918\nEpoch 4231, Training Loss: 0.15216972856772473, Validation Loss: 0.21096533379454918\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482718758861619\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.301210289583369e-07\nEpoch 4241, Training Loss: 0.15226460121885185, Validation Loss: 0.21096559475025664\nEpoch 4241, Training Loss: 0.15216774324893795, Validation Loss: 0.21096559475025664\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482718758861619\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.207934149659306e-07\nEpoch 4251, Training Loss: 0.15226159937708897, Validation Loss: 0.21096755068814116\nEpoch 4251, Training Loss: 0.15216580329808246, Validation Loss: 0.21096755068814116\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482718758861619\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.11570610248023e-07\nEpoch 4261, Training Loss: 0.15225874372925138, Validation Loss: 0.2109686598928171\nEpoch 4261, Training Loss: 0.15216389644166003, Validation Loss: 0.2109686598928171\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 8.024514371203714e-07\nEpoch 4271, Training Loss: 0.1522557461596641, Validation Loss: 0.21097018362025896\nEpoch 4271, Training Loss: 0.1521620373167588, Validation Loss: 0.21097018362025896\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482463185125878\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.934347311317243e-07\nEpoch 4281, Training Loss: 0.15225297482463399, Validation Loss: 0.2109713611843998\nEpoch 4281, Training Loss: 0.15216021632709123, Validation Loss: 0.2109713611843998\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482344781057045\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.845193409151285e-07\nEpoch 4291, Training Loss: 0.15225021182051873, Validation Loss: 0.2109722324670387\nEpoch 4291, Training Loss: 0.15215833177876142, Validation Loss: 0.2109722324670387\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482344781057045\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 7.757041280409096e-07\nEpoch 4301, Training Loss: 0.1522473742659501, Validation Loss: 0.2109746637475552\nEpoch 4301, Training Loss: 0.15215660162477787, Validation Loss: 0.2109746637475552\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482344781057045\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 7.669879668713014e-07\nEpoch 4311, Training Loss: 0.15224468755426285, Validation Loss: 0.21097524105444115\nEpoch 4311, Training Loss: 0.15215479592376016, Validation Loss: 0.21097524105444115\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482344781057045\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.583697444167115e-07\nEpoch 4321, Training Loss: 0.1522419746140418, Validation Loss: 0.21097648859834195\nEpoch 4321, Training Loss: 0.1521530489522255, Validation Loss: 0.21097648859834195\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482344781057045\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9310040672058428\n\nLearning Rate: 7.498483601935995e-07\nEpoch 4331, Training Loss: 0.15223924048917295, Validation Loss: 0.21097772922985494\nEpoch 4331, Training Loss: 0.15215135194349322, Validation Loss: 0.21097772922985494\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.414227260839547e-07\nEpoch 4341, Training Loss: 0.1522365986452209, Validation Loss: 0.21097949849243397\nEpoch 4341, Training Loss: 0.15214959171113568, Validation Loss: 0.21097949849243397\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.330917661963503e-07\nEpoch 4351, Training Loss: 0.15223391176057036, Validation Loss: 0.21098112421516366\nEpoch 4351, Training Loss: 0.15214785749514603, Validation Loss: 0.21098112421516366\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.248544167285606e-07\nEpoch 4361, Training Loss: 0.15223137840054923, Validation Loss: 0.2109832266541828\nEpoch 4361, Training Loss: 0.15214610012494104, Validation Loss: 0.2109832266541828\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482363543897058\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.167096258317211e-07\nEpoch 4371, Training Loss: 0.1522288416171976, Validation Loss: 0.2109839548347133\nEpoch 4371, Training Loss: 0.15214446078649577, Validation Loss: 0.2109839548347133\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482363543897058\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.086563534760151e-07\nEpoch 4381, Training Loss: 0.15222626488785165, Validation Loss: 0.2109849109051717\nEpoch 4381, Training Loss: 0.15214275476243663, Validation Loss: 0.2109849109051717\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482363543897058\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 7.0069357131787e-07\nEpoch 4391, Training Loss: 0.15222356412620774, Validation Loss: 0.2109875701915848\nEpoch 4391, Training Loss: 0.1521411233055283, Validation Loss: 0.2109875701915848\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.928202625686443e-07\nEpoch 4401, Training Loss: 0.1522210949388414, Validation Loss: 0.21098994180702216\nEpoch 4401, Training Loss: 0.15213948483117357, Validation Loss: 0.21098994180702216\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.850354218647929e-07\nEpoch 4411, Training Loss: 0.15221862225028387, Validation Loss: 0.210991443987153\nEpoch 4411, Training Loss: 0.15213788634836808, Validation Loss: 0.210991443987153\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.773380551394875e-07\nEpoch 4421, Training Loss: 0.1522162478934551, Validation Loss: 0.21099310286713055\nEpoch 4421, Training Loss: 0.15213632124748136, Validation Loss: 0.21099310286713055\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.697271794956836e-07\nEpoch 4431, Training Loss: 0.1522138582024216, Validation Loss: 0.2109945419259883\nEpoch 4431, Training Loss: 0.15213475298878917, Validation Loss: 0.2109945419259883\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.622018230806104e-07\nEpoch 4441, Training Loss: 0.15221140070523337, Validation Loss: 0.21099667361525345\nEpoch 4441, Training Loss: 0.15213320546572986, Validation Loss: 0.21099667361525345\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.547610249616729e-07\nEpoch 4451, Training Loss: 0.1522090410361294, Validation Loss: 0.21099850520202496\nEpoch 4451, Training Loss: 0.15213170909425536, Validation Loss: 0.21099850520202496\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.948222638070093\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.474038350037476e-07\nEpoch 4461, Training Loss: 0.15220673211224628, Validation Loss: 0.2109993147435816\nEpoch 4461, Training Loss: 0.15213022713536153, Validation Loss: 0.2109993147435816\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.9482207611390139\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.401293137478577e-07\nEpoch 4471, Training Loss: 0.1522043909215405, Validation Loss: 0.21100005862725404\nEpoch 4471, Training Loss: 0.15212866946481887, Validation Loss: 0.21100005862725404\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.9482207611390139\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.32936532291211e-07\nEpoch 4481, Training Loss: 0.15220209419002803, Validation Loss: 0.2110010042654296\nEpoch 4481, Training Loss: 0.15212725009486752, Validation Loss: 0.2110010042654296\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.9482207611390139\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.258245721685853e-07\nEpoch 4491, Training Loss: 0.15219987395603127, Validation Loss: 0.21100248907638933\nEpoch 4491, Training Loss: 0.15212577336498304, Validation Loss: 0.21100248907638933\nTraining Accuracy: 0.9506473575874207, Training F1 Score: 0.9482207611390139\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.187925252350478e-07\nEpoch 4501, Training Loss: 0.1521976531516004, Validation Loss: 0.21100302706171936\nEpoch 4501, Training Loss: 0.1521243169534779, Validation Loss: 0.21100302706171936\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482326014539478\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.118394935499914e-07\nEpoch 4511, Training Loss: 0.15219551842191595, Validation Loss: 0.2110044366841278\nEpoch 4511, Training Loss: 0.15212290663569655, Validation Loss: 0.2110044366841278\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482326014539478\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 6.049645892624742e-07\nEpoch 4521, Training Loss: 0.1521932571520563, Validation Loss: 0.21100504039267653\nEpoch 4521, Training Loss: 0.15212151168841861, Validation Loss: 0.21100504039267653\nTraining Accuracy: 0.950659537410326, Training F1 Score: 0.9482326014539478\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.981669344978481e-07\nEpoch 4531, Training Loss: 0.15219107064608642, Validation Loss: 0.2110068048956388\nEpoch 4531, Training Loss: 0.15212003081993777, Validation Loss: 0.2110068048956388\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.914456612456595e-07\nEpoch 4541, Training Loss: 0.15218873456569323, Validation Loss: 0.2110077557671061\nEpoch 4541, Training Loss: 0.15211860005655017, Validation Loss: 0.2110077557671061\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.847999112488118e-07\nEpoch 4551, Training Loss: 0.15218665605707019, Validation Loss: 0.21100842819772608\nEpoch 4551, Training Loss: 0.15211715574757637, Validation Loss: 0.21100842819772608\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.782288358939718e-07\nEpoch 4561, Training Loss: 0.15218454440646273, Validation Loss: 0.21101008415725245\nEpoch 4561, Training Loss: 0.1521157547298852, Validation Loss: 0.21101008415725245\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.717315961032085e-07\nEpoch 4571, Training Loss: 0.1521823084738223, Validation Loss: 0.21101158873515866\nEpoch 4571, Training Loss: 0.1521143476993142, Validation Loss: 0.21101158873515866\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.653073622268484e-07\nEpoch 4581, Training Loss: 0.1521802657675154, Validation Loss: 0.21101264137977652\nEpoch 4581, Training Loss: 0.15211296371932576, Validation Loss: 0.21101264137977652\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.589553139375354e-07\nEpoch 4591, Training Loss: 0.15217827377811632, Validation Loss: 0.21101409097218557\nEpoch 4591, Training Loss: 0.15211163359372337, Validation Loss: 0.21101409097218557\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.526746401254817e-07\nEpoch 4601, Training Loss: 0.15217612737622163, Validation Loss: 0.21101635556974707\nEpoch 4601, Training Loss: 0.15211028877295493, Validation Loss: 0.21101635556974707\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.464645387948945e-07\nEpoch 4611, Training Loss: 0.15217412286122986, Validation Loss: 0.21101788931133114\nEpoch 4611, Training Loss: 0.15210901544048147, Validation Loss: 0.21101788931133114\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.403242169615669e-07\nEpoch 4621, Training Loss: 0.15217213574765381, Validation Loss: 0.2110197417822687\nEpoch 4621, Training Loss: 0.15210772127400563, Validation Loss: 0.2110197417822687\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.342528905516204e-07\nEpoch 4631, Training Loss: 0.152170104689237, Validation Loss: 0.2110209597574179\nEpoch 4631, Training Loss: 0.1521064622227115, Validation Loss: 0.2110209597574179\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.282497843013835e-07\nEpoch 4641, Training Loss: 0.15216824069032772, Validation Loss: 0.2110232369008326\nEpoch 4641, Training Loss: 0.15210515105446867, Validation Loss: 0.2110232369008326\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.22314131658397e-07\nEpoch 4651, Training Loss: 0.15216621016023854, Validation Loss: 0.2110251290885997\nEpoch 4651, Training Loss: 0.15210394754526876, Validation Loss: 0.2110251290885997\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.164451746835304e-07\nEpoch 4661, Training Loss: 0.15216439513281407, Validation Loss: 0.21102791817338792\nEpoch 4661, Training Loss: 0.15210269892476935, Validation Loss: 0.21102791817338792\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9309003376235662\n\nLearning Rate: 5.106421639541989e-07\nEpoch 4671, Training Loss: 0.1521625176306066, Validation Loss: 0.21102954121903736\nEpoch 4671, Training Loss: 0.15210152673681093, Validation Loss: 0.21102954121903736\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 5.049043584686678e-07\nEpoch 4681, Training Loss: 0.15216067415171589, Validation Loss: 0.21103177901312903\nEpoch 4681, Training Loss: 0.1521003108753446, Validation Loss: 0.21103177901312903\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.992310255514316e-07\nEpoch 4691, Training Loss: 0.1521587407251889, Validation Loss: 0.2110349886461555\nEpoch 4691, Training Loss: 0.15209913251951096, Validation Loss: 0.2110349886461555\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.93621440759657e-07\nEpoch 4701, Training Loss: 0.15215699919210712, Validation Loss: 0.21103685150527515\nEpoch 4701, Training Loss: 0.1520979351190194, Validation Loss: 0.21103685150527515\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.88074887790677e-07\nEpoch 4711, Training Loss: 0.15215519323845042, Validation Loss: 0.21103782845499955\nEpoch 4711, Training Loss: 0.15209675357035202, Validation Loss: 0.21103782845499955\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.82590658390524e-07\nEpoch 4721, Training Loss: 0.15215332364881523, Validation Loss: 0.2110399502885586\nEpoch 4721, Training Loss: 0.15209559034127598, Validation Loss: 0.2110399502885586\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.771680522634915e-07\nEpoch 4731, Training Loss: 0.1521515465538962, Validation Loss: 0.21104258031492548\nEpoch 4731, Training Loss: 0.15209442475986265, Validation Loss: 0.21104258031492548\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.7180637698271066e-07\nEpoch 4741, Training Loss: 0.15214977557367482, Validation Loss: 0.21104353015247462\nEpoch 4741, Training Loss: 0.15209330616403222, Validation Loss: 0.21104353015247462\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.665049479017334e-07\nEpoch 4751, Training Loss: 0.15214805578895968, Validation Loss: 0.2110450174869786\nEpoch 4751, Training Loss: 0.1520921391237741, Validation Loss: 0.2110450174869786\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.612630880671075e-07\nEpoch 4761, Training Loss: 0.15214632954870208, Validation Loss: 0.21104633568685122\nEpoch 4761, Training Loss: 0.15209105535346176, Validation Loss: 0.21104633568685122\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.560801281319349e-07\nEpoch 4771, Training Loss: 0.15214451228564063, Validation Loss: 0.21104722930734832\nEpoch 4771, Training Loss: 0.15208994681581983, Validation Loss: 0.21104722930734832\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.509554062704008e-07\nEpoch 4781, Training Loss: 0.15214290797870858, Validation Loss: 0.21104780492697137\nEpoch 4781, Training Loss: 0.15208884980283396, Validation Loss: 0.21104780492697137\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.4588826809326367e-07\nEpoch 4791, Training Loss: 0.1521413031450824, Validation Loss: 0.21104901343188787\nEpoch 4791, Training Loss: 0.1520877650357593, Validation Loss: 0.21104901343188787\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.408780665642944e-07\nEpoch 4801, Training Loss: 0.15213957806239037, Validation Loss: 0.21105003370163825\nEpoch 4801, Training Loss: 0.15208671256926512, Validation Loss: 0.21105003370163825\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.359241619176545e-07\nEpoch 4811, Training Loss: 0.15213801518352862, Validation Loss: 0.21105167313644163\nEpoch 4811, Training Loss: 0.15208564665174287, Validation Loss: 0.21105167313644163\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.310259215762028e-07\nEpoch 4821, Training Loss: 0.15213644218295563, Validation Loss: 0.21105287673637216\nEpoch 4821, Training Loss: 0.1520846332827609, Validation Loss: 0.21105287673637216\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.261827200707199e-07\nEpoch 4831, Training Loss: 0.152134857465525, Validation Loss: 0.21105373484104673\nEpoch 4831, Training Loss: 0.15208360384634048, Validation Loss: 0.21105373484104673\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.213939389600404e-07\nEpoch 4841, Training Loss: 0.1521332804054868, Validation Loss: 0.21105434594382505\nEpoch 4841, Training Loss: 0.15208260272454022, Validation Loss: 0.21105434594382505\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.166589667520827e-07\nEpoch 4851, Training Loss: 0.15213168506179295, Validation Loss: 0.21105536527602567\nEpoch 4851, Training Loss: 0.15208162025918323, Validation Loss: 0.21105536527602567\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.1197719882576587e-07\nEpoch 4861, Training Loss: 0.15213020857946563, Validation Loss: 0.21105599095492616\nEpoch 4861, Training Loss: 0.15208065834179482, Validation Loss: 0.21105599095492616\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.073480373538036e-07\nEpoch 4871, Training Loss: 0.152128681210534, Validation Loss: 0.21105677255292635\nEpoch 4871, Training Loss: 0.15207969320961198, Validation Loss: 0.21105677255292635\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 4.0277089122636665e-07\nEpoch 4881, Training Loss: 0.1521271773281323, Validation Loss: 0.21105724685674015\nEpoch 4881, Training Loss: 0.15207873923274592, Validation Loss: 0.21105724685674015\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 3.982451759756021e-07\nEpoch 4891, Training Loss: 0.15212575333989722, Validation Loss: 0.21105810798313435\nEpoch 4891, Training Loss: 0.15207782331506772, Validation Loss: 0.21105810798313435\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.937703137010014e-07\nEpoch 4901, Training Loss: 0.15212426271614052, Validation Loss: 0.2110587562203969\nEpoch 4901, Training Loss: 0.1520769008518263, Validation Loss: 0.2110587562203969\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.8934573299560634e-07\nEpoch 4911, Training Loss: 0.15212288666614776, Validation Loss: 0.21106001678382594\nEpoch 4911, Training Loss: 0.15207598319888868, Validation Loss: 0.21106001678382594\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482481945172452\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.8497086887304497e-07\nEpoch 4921, Training Loss: 0.152121399060991, Validation Loss: 0.2110611130408416\nEpoch 4921, Training Loss: 0.1520750859287606, Validation Loss: 0.2110611130408416\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482481945172452\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.8064516269538677e-07\nEpoch 4931, Training Loss: 0.1521200467614197, Validation Loss: 0.2110624171480672\nEpoch 4931, Training Loss: 0.15207415782941988, Validation Loss: 0.2110624171480672\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482481945172452\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.7636806210180874e-07\nEpoch 4941, Training Loss: 0.1521185815217075, Validation Loss: 0.21106386250843542\nEpoch 4941, Training Loss: 0.15207326262178397, Validation Loss: 0.21106386250843542\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.9482481945172452\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.721390209380631e-07\nEpoch 4951, Training Loss: 0.15211723671364363, Validation Loss: 0.2110649550103519\nEpoch 4951, Training Loss: 0.15207237787089634, Validation Loss: 0.2110649550103519\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.679574991867372e-07\nEpoch 4961, Training Loss: 0.1521158882653645, Validation Loss: 0.21106626264400602\nEpoch 4961, Training Loss: 0.15207147869145657, Validation Loss: 0.21106626264400602\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.638229628982976e-07\nEpoch 4971, Training Loss: 0.15211450054207254, Validation Loss: 0.211067623556294\nEpoch 4971, Training Loss: 0.15207064300552292, Validation Loss: 0.211067623556294\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.5973488412290823e-07\nEpoch 4981, Training Loss: 0.1521131088388095, Validation Loss: 0.21106861956898584\nEpoch 4981, Training Loss: 0.15206976875330852, Validation Loss: 0.21106861956898584\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.556927408430156e-07\nEpoch 4991, Training Loss: 0.1521118037181117, Validation Loss: 0.21106987556553483\nEpoch 4991, Training Loss: 0.15206891355028937, Validation Loss: 0.21106987556553483\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.5169601690669033e-07\nEpoch 5001, Training Loss: 0.1521105322161817, Validation Loss: 0.2110702991436595\nEpoch 5001, Training Loss: 0.1520680536396917, Validation Loss: 0.2110702991436595\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.477442019617191e-07\nEpoch 5011, Training Loss: 0.1521091716359693, Validation Loss: 0.21107087798753904\nEpoch 5011, Training Loss: 0.15206724452295514, Validation Loss: 0.21107087798753904\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482600350160445\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.4383679139043586e-07\nEpoch 5021, Training Loss: 0.15210795408243902, Validation Loss: 0.2110721681523869\nEpoch 5021, Training Loss: 0.152066396752095, Validation Loss: 0.2110721681523869\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.399732862452861e-07\nEpoch 5031, Training Loss: 0.1521066187523289, Validation Loss: 0.21107274192141084\nEpoch 5031, Training Loss: 0.1520655978957307, Validation Loss: 0.21107274192141084\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.361531931851149e-07\nEpoch 5041, Training Loss: 0.15210534274445967, Validation Loss: 0.21107339798901067\nEpoch 5041, Training Loss: 0.15206480609420045, Validation Loss: 0.21107339798901067\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.323760244121709e-07\nEpoch 5051, Training Loss: 0.1521041459928074, Validation Loss: 0.2110740673864775\nEpoch 5051, Training Loss: 0.15206399559793177, Validation Loss: 0.2110740673864775\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.286412976098181e-07\nEpoch 5061, Training Loss: 0.15210291057559744, Validation Loss: 0.21107468656949746\nEpoch 5061, Training Loss: 0.15206322363872335, Validation Loss: 0.21107468656949746\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.249485358809476e-07\nEpoch 5071, Training Loss: 0.15210173597050855, Validation Loss: 0.21107492118887664\nEpoch 5071, Training Loss: 0.15206245916521455, Validation Loss: 0.21107492118887664\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306703886639109\n\nLearning Rate: 3.212972676870813e-07\nEpoch 5081, Training Loss: 0.15210054951897564, Validation Loss: 0.21107548764043899\nEpoch 5081, Training Loss: 0.15206170361501536, Validation Loss: 0.21107548764043899\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 3.176870267881601e-07\nEpoch 5091, Training Loss: 0.15209931828410203, Validation Loss: 0.21107617856724983\nEpoch 5091, Training Loss: 0.15206096916271009, Validation Loss: 0.21107617856724983\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 3.1411735218300807e-07\nEpoch 5101, Training Loss: 0.15209818994370383, Validation Loss: 0.21107690998673714\nEpoch 5101, Training Loss: 0.1520602231436423, Validation Loss: 0.21107690998673714\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 3.1058778805046643e-07\nEpoch 5111, Training Loss: 0.152097037647978, Validation Loss: 0.21107692596918395\nEpoch 5111, Training Loss: 0.15205949305444086, Validation Loss: 0.21107692596918395\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 3.070978836911884e-07\nEpoch 5121, Training Loss: 0.15209586563389038, Validation Loss: 0.21107778169405012\nEpoch 5121, Training Loss: 0.15205877539246268, Validation Loss: 0.21107778169405012\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 3.03647193470088e-07\nEpoch 5131, Training Loss: 0.1520947435414061, Validation Loss: 0.21107868979756775\nEpoch 5131, Training Loss: 0.15205805953743382, Validation Loss: 0.21107868979756775\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 3.002352767594361e-07\nEpoch 5141, Training Loss: 0.15209368691163241, Validation Loss: 0.21107953520121966\nEpoch 5141, Training Loss: 0.15205733522988948, Validation Loss: 0.21107953520121966\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.968616978825951e-07\nEpoch 5151, Training Loss: 0.15209258967776895, Validation Loss: 0.21108031798504062\nEpoch 5151, Training Loss: 0.15205664814593692, Validation Loss: 0.21108031798504062\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.935260260583867e-07\nEpoch 5161, Training Loss: 0.15209146867860152, Validation Loss: 0.2110810504286459\nEpoch 5161, Training Loss: 0.15205596253444115, Validation Loss: 0.2110810504286459\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.9022783534608385e-07\nEpoch 5171, Training Loss: 0.15209039256804105, Validation Loss: 0.21108136270131952\nEpoch 5171, Training Loss: 0.15205527636104152, Validation Loss: 0.21108136270131952\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.869667045910216e-07\nEpoch 5181, Training Loss: 0.152089327175035, Validation Loss: 0.21108229078902077\nEpoch 5181, Training Loss: 0.15205460774278257, Validation Loss: 0.21108229078902077\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.8374221737081855e-07\nEpoch 5191, Training Loss: 0.1520883134809982, Validation Loss: 0.21108258904744878\nEpoch 5191, Training Loss: 0.15205394344624695, Validation Loss: 0.21108258904744878\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.8055396194220285e-07\nEpoch 5201, Training Loss: 0.15208729577559194, Validation Loss: 0.21108318820218436\nEpoch 5201, Training Loss: 0.15205326936467053, Validation Loss: 0.21108318820218436\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.774015311884356e-07\nEpoch 5211, Training Loss: 0.15208624395721104, Validation Loss: 0.2110836697172912\nEpoch 5211, Training Loss: 0.15205263804078586, Validation Loss: 0.2110836697172912\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.742845225673252e-07\nEpoch 5221, Training Loss: 0.15208522173261654, Validation Loss: 0.21108425006223042\nEpoch 5221, Training Loss: 0.15205197960649044, Validation Loss: 0.21108425006223042\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.7120253805982524e-07\nEpoch 5231, Training Loss: 0.1520841969965149, Validation Loss: 0.21108470437532714\nEpoch 5231, Training Loss: 0.15205135029627617, Validation Loss: 0.21108470437532714\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.6815518411921093e-07\nEpoch 5241, Training Loss: 0.15208320743330994, Validation Loss: 0.21108566276025945\nEpoch 5241, Training Loss: 0.1520506908548733, Validation Loss: 0.21108566276025945\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.6514207162082586e-07\nEpoch 5251, Training Loss: 0.15208220088521687, Validation Loss: 0.21108602602322687\nEpoch 5251, Training Loss: 0.1520500636390941, Validation Loss: 0.21108602602322687\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.6216281581239344e-07\nEpoch 5261, Training Loss: 0.15208117189073314, Validation Loss: 0.2110867121495869\nEpoch 5261, Training Loss: 0.152049375731161, Validation Loss: 0.2110867121495869\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.592170362648871e-07\nEpoch 5271, Training Loss: 0.15208010288836576, Validation Loss: 0.2110875328290388\nEpoch 5271, Training Loss: 0.1520487048460482, Validation Loss: 0.2110875328290388\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.563043568239524e-07\nEpoch 5281, Training Loss: 0.15207910232012067, Validation Loss: 0.21108787356957812\nEpoch 5281, Training Loss: 0.15204803211133508, Validation Loss: 0.21108787356957812\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.534244055618747e-07\nEpoch 5291, Training Loss: 0.15207809932494445, Validation Loss: 0.21108875483695866\nEpoch 5291, Training Loss: 0.15204737066243257, Validation Loss: 0.21108875483695866\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.5057681473008665e-07\nEpoch 5301, Training Loss: 0.15207713516375185, Validation Loss: 0.21108938785945455\nEpoch 5301, Training Loss: 0.1520467248274162, Validation Loss: 0.21108938785945455\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.477612207122097e-07\nEpoch 5311, Training Loss: 0.15207615446614162, Validation Loss: 0.2110898115502812\nEpoch 5311, Training Loss: 0.1520460900482582, Validation Loss: 0.2110898115502812\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.449772639776226e-07\nEpoch 5321, Training Loss: 0.15207517282113525, Validation Loss: 0.21109039326234436\nEpoch 5321, Training Loss: 0.1520454581599287, Validation Loss: 0.21109039326234436\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.4222458903555244e-07\nEpoch 5331, Training Loss: 0.15207424280159326, Validation Loss: 0.21109122687475626\nEpoch 5331, Training Loss: 0.15204484496688211, Validation Loss: 0.21109122687475626\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.948250070154281\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.3950284438968067e-07\nEpoch 5341, Training Loss: 0.15207332702584297, Validation Loss: 0.21109147672850248\nEpoch 5341, Training Loss: 0.15204423646471665, Validation Loss: 0.21109147672850248\nTraining Accuracy: 0.9506717172332314, Training F1 Score: 0.948250070154281\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.3681168249325984e-07\nEpoch 5351, Training Loss: 0.15207235263095764, Validation Loss: 0.2110922981364338\nEpoch 5351, Training Loss: 0.15204363859752607, Validation Loss: 0.2110922981364338\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.341507597047344e-07\nEpoch 5361, Training Loss: 0.1520714838738221, Validation Loss: 0.21109294404778892\nEpoch 5361, Training Loss: 0.1520430393079709, Validation Loss: 0.21109294404778892\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.3151973624386012e-07\nEpoch 5371, Training Loss: 0.15207052968606055, Validation Loss: 0.21109381689028847\nEpoch 5371, Training Loss: 0.1520424409211644, Validation Loss: 0.21109381689028847\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.2891827614831683e-07\nEpoch 5381, Training Loss: 0.15206964888211216, Validation Loss: 0.21109395972615883\nEpoch 5381, Training Loss: 0.15204186562378003, Validation Loss: 0.21109395972615883\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.2634604723080826e-07\nEpoch 5391, Training Loss: 0.1520687936854453, Validation Loss: 0.21109449096897068\nEpoch 5391, Training Loss: 0.15204129847127967, Validation Loss: 0.21109449096897068\nTraining Accuracy: 0.9506838970561368, Training F1 Score: 0.9482619103737147\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.238027210366444e-07\nEpoch 5401, Training Loss: 0.1520679415033855, Validation Loss: 0.2110950664987588\nEpoch 5401, Training Loss: 0.15204073379380623, Validation Loss: 0.2110950664987588\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.212879728018002e-07\nEpoch 5411, Training Loss: 0.15206704329911036, Validation Loss: 0.2110955132738901\nEpoch 5411, Training Loss: 0.15204016701391204, Validation Loss: 0.2110955132738901\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.1880148141144546e-07\nEpoch 5421, Training Loss: 0.1520662074988358, Validation Loss: 0.21109617637964662\nEpoch 5421, Training Loss: 0.15203960610533274, Validation Loss: 0.21109617637964662\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.1634292935894099e-07\nEpoch 5431, Training Loss: 0.15206534383477094, Validation Loss: 0.21109658251019878\nEpoch 5431, Training Loss: 0.1520390528020572, Validation Loss: 0.21109658251019878\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 2.1391200270529524e-07\nEpoch 5441, Training Loss: 0.1520645169501833, Validation Loss: 0.21109716626886446\nEpoch 5441, Training Loss: 0.15203850155945894, Validation Loss: 0.21109716626886446\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.115083910390767e-07\nEpoch 5451, Training Loss: 0.15206366396029594, Validation Loss: 0.21109739583298837\nEpoch 5451, Training Loss: 0.15203796352759139, Validation Loss: 0.21109739583298837\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.0913178743677658e-07\nEpoch 5461, Training Loss: 0.15206285729989247, Validation Loss: 0.21109812639496064\nEpoch 5461, Training Loss: 0.15203742741066176, Validation Loss: 0.21109812639496064\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.0678188842361695e-07\nEpoch 5471, Training Loss: 0.15206206681836446, Validation Loss: 0.21109856832227358\nEpoch 5471, Training Loss: 0.15203690287937002, Validation Loss: 0.21109856832227358\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.0445839393479926e-07\nEpoch 5481, Training Loss: 0.15206125137349388, Validation Loss: 0.21109882714154363\nEpoch 5481, Training Loss: 0.15203639057856255, Validation Loss: 0.21109882714154363\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 2.0216100727718833e-07\nEpoch 5491, Training Loss: 0.1520604746604261, Validation Loss: 0.2110990933958773\nEpoch 5491, Training Loss: 0.15203586713496137, Validation Loss: 0.2110990933958773\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.9988943509142658e-07\nEpoch 5501, Training Loss: 0.15205967155475442, Validation Loss: 0.21109943879476492\nEpoch 5501, Training Loss: 0.15203535590768796, Validation Loss: 0.21109943879476492\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.9764338731447455e-07\nEpoch 5511, Training Loss: 0.15205890667742256, Validation Loss: 0.21110013017075033\nEpoch 5511, Training Loss: 0.1520348613750946, Validation Loss: 0.21110013017075033\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.9542257714257173e-07\nEpoch 5521, Training Loss: 0.15205812020417858, Validation Loss: 0.21110049958005883\nEpoch 5521, Training Loss: 0.15203437250763943, Validation Loss: 0.21110049958005883\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.93226720994614e-07\nEpoch 5531, Training Loss: 0.15205740123689912, Validation Loss: 0.2111007370676216\nEpoch 5531, Training Loss: 0.15203388948554558, Validation Loss: 0.2111007370676216\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.910555384759422e-07\nEpoch 5541, Training Loss: 0.15205665718776182, Validation Loss: 0.2111012538976475\nEpoch 5541, Training Loss: 0.15203340871288223, Validation Loss: 0.2111012538976475\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.8890875234253807e-07\nEpoch 5551, Training Loss: 0.1520559352850064, Validation Loss: 0.21110177459220777\nEpoch 5551, Training Loss: 0.1520329392926376, Validation Loss: 0.21110177459220777\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.8678608846562194e-07\nEpoch 5561, Training Loss: 0.15205520344965598, Validation Loss: 0.21110217046688018\nEpoch 5561, Training Loss: 0.15203248644020897, Validation Loss: 0.21110217046688018\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.8468727579664876e-07\nEpoch 5571, Training Loss: 0.15205451159514666, Validation Loss: 0.2111024515766409\nEpoch 5571, Training Loss: 0.1520320178054682, Validation Loss: 0.2111024515766409\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.8261204633269707e-07\nEpoch 5581, Training Loss: 0.15205380037146904, Validation Loss: 0.21110272817178918\nEpoch 5581, Training Loss: 0.15203156981434313, Validation Loss: 0.21110272817178918\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.8056013508224696e-07\nEpoch 5591, Training Loss: 0.15205310886833115, Validation Loss: 0.21110324639017275\nEpoch 5591, Training Loss: 0.1520311254118891, Validation Loss: 0.21110324639017275\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.785312800313427e-07\nEpoch 5601, Training Loss: 0.15205238877851435, Validation Loss: 0.21110356763490365\nEpoch 5601, Training Loss: 0.1520306921738265, Validation Loss: 0.21110356763490365\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.7652522211013547e-07\nEpoch 5611, Training Loss: 0.1520517449221402, Validation Loss: 0.21110407340216894\nEpoch 5611, Training Loss: 0.15203024415638486, Validation Loss: 0.21110407340216894\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.7454170515980194e-07\nEpoch 5621, Training Loss: 0.15205105795470647, Validation Loss: 0.2111042350805029\nEpoch 5621, Training Loss: 0.15202981683392153, Validation Loss: 0.2111042350805029\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.7258047589983492e-07\nEpoch 5631, Training Loss: 0.15205039750438118, Validation Loss: 0.2111049303602234\nEpoch 5631, Training Loss: 0.15202938519663164, Validation Loss: 0.2111049303602234\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.7064128389570094e-07\nEpoch 5641, Training Loss: 0.1520497435460786, Validation Loss: 0.21110532102283777\nEpoch 5641, Training Loss: 0.1520289649774611, Validation Loss: 0.21110532102283777\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.68723881526862e-07\nEpoch 5651, Training Loss: 0.15204906322457398, Validation Loss: 0.21110567676254\nEpoch 5651, Training Loss: 0.15202854378294448, Validation Loss: 0.21110567676254\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.6682802395515596e-07\nEpoch 5661, Training Loss: 0.15204840895010968, Validation Loss: 0.21110607645601265\nEpoch 5661, Training Loss: 0.15202812090108275, Validation Loss: 0.21110607645601265\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.649534690935326e-07\nEpoch 5671, Training Loss: 0.15204779513381442, Validation Loss: 0.211106336129531\nEpoch 5671, Training Loss: 0.1520276913970675, Validation Loss: 0.211106336129531\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.6309997757514098e-07\nEpoch 5681, Training Loss: 0.15204713709481185, Validation Loss: 0.21110719821470866\nEpoch 5681, Training Loss: 0.15202730406597192, Validation Loss: 0.21110719821470866\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.6126731272276387e-07\nEpoch 5691, Training Loss: 0.15204654337783322, Validation Loss: 0.21110780204739288\nEpoch 5691, Training Loss: 0.15202690017958334, Validation Loss: 0.21110780204739288\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.59455240518596e-07\nEpoch 5701, Training Loss: 0.15204591682033095, Validation Loss: 0.21110819981186507\nEpoch 5701, Training Loss: 0.15202650041981258, Validation Loss: 0.21110819981186507\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.5766352957436157e-07\nEpoch 5711, Training Loss: 0.15204532373222732, Validation Loss: 0.2111084039396431\nEpoch 5711, Training Loss: 0.15202609613032692, Validation Loss: 0.2111084039396431\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.558919511017678e-07\nEpoch 5721, Training Loss: 0.15204472772806754, Validation Loss: 0.21110896134238016\nEpoch 5721, Training Loss: 0.15202571335562576, Validation Loss: 0.21110896134238016\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.5414027888329014e-07\nEpoch 5731, Training Loss: 0.15204411406586024, Validation Loss: 0.2111096272820197\nEpoch 5731, Training Loss: 0.15202533745517258, Validation Loss: 0.2111096272820197\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.5240828924328627e-07\nEpoch 5741, Training Loss: 0.1520435472375073, Validation Loss: 0.21111015132497202\nEpoch 5741, Training Loss: 0.15202496140317232, Validation Loss: 0.21111015132497202\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.5069576101943403e-07\nEpoch 5751, Training Loss: 0.15204296893440902, Validation Loss: 0.21111067808583864\nEpoch 5751, Training Loss: 0.15202459674297486, Validation Loss: 0.21111067808583864\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.490024755344909e-07\nEpoch 5761, Training Loss: 0.15204238651685298, Validation Loss: 0.2111110814037415\nEpoch 5761, Training Loss: 0.15202423217769848, Validation Loss: 0.2111110814037415\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.4732821656837035e-07\nEpoch 5771, Training Loss: 0.152041833966957, Validation Loss: 0.21111142935720725\nEpoch 5771, Training Loss: 0.15202386965712794, Validation Loss: 0.21111142935720725\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.456727703305322e-07\nEpoch 5781, Training Loss: 0.15204128067075975, Validation Loss: 0.2111119050934795\nEpoch 5781, Training Loss: 0.15202350710697396, Validation Loss: 0.2111119050934795\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.4403592543268314e-07\nEpoch 5791, Training Loss: 0.15204072950892608, Validation Loss: 0.2111121777064913\nEpoch 5791, Training Loss: 0.15202315645952696, Validation Loss: 0.2111121777064913\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.4241747286178394e-07\nEpoch 5801, Training Loss: 0.15204018445852321, Validation Loss: 0.21111234158823056\nEpoch 5801, Training Loss: 0.15202281231862214, Validation Loss: 0.21111234158823056\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.4081720595336016e-07\nEpoch 5811, Training Loss: 0.1520396432085943, Validation Loss: 0.21111284800720728\nEpoch 5811, Training Loss: 0.15202247917894607, Validation Loss: 0.21111284800720728\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.3923492036511243e-07\nEpoch 5821, Training Loss: 0.15203912856869856, Validation Loss: 0.21111321798329236\nEpoch 5821, Training Loss: 0.15202214558535473, Validation Loss: 0.21111321798329236\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.3767041405082365e-07\nEpoch 5831, Training Loss: 0.15203860691389737, Validation Loss: 0.21111371678590227\nEpoch 5831, Training Loss: 0.15202181562798575, Validation Loss: 0.21111371678590227\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.3612348723455901e-07\nEpoch 5841, Training Loss: 0.15203807120550963, Validation Loss: 0.21111414406032503\nEpoch 5841, Training Loss: 0.15202149651322025, Validation Loss: 0.21111414406032503\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.3459394238515615e-07\nEpoch 5851, Training Loss: 0.15203758777650733, Validation Loss: 0.2111143946245837\nEpoch 5851, Training Loss: 0.15202116744571392, Validation Loss: 0.2111143946245837\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.3308158419100188e-07\nEpoch 5861, Training Loss: 0.152037078265981, Validation Loss: 0.21111490263445498\nEpoch 5861, Training Loss: 0.15202085023281883, Validation Loss: 0.21111490263445498\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.3158621953509226e-07\nEpoch 5871, Training Loss: 0.1520365500393, Validation Loss: 0.21111525024164798\nEpoch 5871, Training Loss: 0.15202052150053103, Validation Loss: 0.21111525024164798\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9307966355819892\n\nLearning Rate: 1.3010765747037313e-07\nEpoch 5881, Training Loss: 0.15203607589732035, Validation Loss: 0.21111561029505915\nEpoch 5881, Training Loss: 0.15202020379361061, Validation Loss: 0.21111561029505915\nTraining Accuracy: 0.9506960768790422, Training F1 Score: 0.9482737509643969\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.2864570919535748e-07\nEpoch 5891, Training Loss: 0.15203558439040518, Validation Loss: 0.21111591890736864\nEpoch 5891, Training Loss: 0.1520198927367937, Validation Loss: 0.21111591890736864\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.272001880300168e-07\nEpoch 5901, Training Loss: 0.15203510197105125, Validation Loss: 0.21111628409443645\nEpoch 5901, Training Loss: 0.15201958830612314, Validation Loss: 0.21111628409443645\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.2577090939194357e-07\nEpoch 5911, Training Loss: 0.1520346342468634, Validation Loss: 0.21111682670708093\nEpoch 5911, Training Loss: 0.15201928974404505, Validation Loss: 0.21111682670708093\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.2435769077278143e-07\nEpoch 5921, Training Loss: 0.15203415460907893, Validation Loss: 0.2111170572953228\nEpoch 5921, Training Loss: 0.15201899771881852, Validation Loss: 0.2111170572953228\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.2296035171492007e-07\nEpoch 5931, Training Loss: 0.152033684135446, Validation Loss: 0.21111726593934665\nEpoch 5931, Training Loss: 0.15201869887034367, Validation Loss: 0.21111726593934665\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.2157871378845228e-07\nEpoch 5941, Training Loss: 0.15203324116152733, Validation Loss: 0.21111773136257145\nEpoch 5941, Training Loss: 0.15201840521929832, Validation Loss: 0.21111773136257145\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.2021260056838968e-07\nEpoch 5951, Training Loss: 0.15203278839839351, Validation Loss: 0.21111814995894213\nEpoch 5951, Training Loss: 0.15201811700107953, Validation Loss: 0.21111814995894213\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.1886183761213459e-07\nEpoch 5961, Training Loss: 0.15203231522849306, Validation Loss: 0.2111181962598537\nEpoch 5961, Training Loss: 0.15201782681057083, Validation Loss: 0.2111181962598537\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.1752625243720495e-07\nEpoch 5971, Training Loss: 0.1520318868148908, Validation Loss: 0.2111183078152091\nEpoch 5971, Training Loss: 0.15201753787327477, Validation Loss: 0.2111183078152091\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.1620567449920964e-07\nEpoch 5981, Training Loss: 0.15203146370725115, Validation Loss: 0.21111844997976767\nEpoch 5981, Training Loss: 0.15201726017369352, Validation Loss: 0.21111844997976767\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.1489993517007109e-07\nEpoch 5991, Training Loss: 0.15203100662783883, Validation Loss: 0.21111866567991522\nEpoch 5991, Training Loss: 0.15201697939090061, Validation Loss: 0.21111866567991522\nTraining Accuracy: 0.9507082567019476, Training F1 Score: 0.948285591926385\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.1360886771649289e-07\nEpoch 6001, Training Loss: 0.1520305654911789, Validation Loss: 0.21111895608677228\nEpoch 6001, Training Loss: 0.15201671799560684, Validation Loss: 0.21111895608677228\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.1233230727866908e-07\nEpoch 6011, Training Loss: 0.1520301472720668, Validation Loss: 0.21111949503088578\nEpoch 6011, Training Loss: 0.1520164485933641, Validation Loss: 0.21111949503088578\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.1107009084923274e-07\nEpoch 6021, Training Loss: 0.15202972250920638, Validation Loss: 0.2111197274501264\nEpoch 6021, Training Loss: 0.15201618465371292, Validation Loss: 0.2111197274501264\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.0982205725244123e-07\nEpoch 6031, Training Loss: 0.15202932435674207, Validation Loss: 0.211120033084817\nEpoch 6031, Training Loss: 0.15201592498387786, Validation Loss: 0.211120033084817\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.0858804712359513e-07\nEpoch 6041, Training Loss: 0.15202891179714192, Validation Loss: 0.21112033828993346\nEpoch 6041, Training Loss: 0.15201566511131462, Validation Loss: 0.21112033828993346\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.0736790288868868e-07\nEpoch 6051, Training Loss: 0.15202849963192713, Validation Loss: 0.21112069687658558\nEpoch 6051, Training Loss: 0.15201540891744317, Validation Loss: 0.21112069687658558\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.0616146874428859e-07\nEpoch 6061, Training Loss: 0.1520281209827548, Validation Loss: 0.21112095363781952\nEpoch 6061, Training Loss: 0.15201515721626196, Validation Loss: 0.21112095363781952\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.0496859063763923e-07\nEpoch 6071, Training Loss: 0.152027695043998, Validation Loss: 0.2111209804951903\nEpoch 6071, Training Loss: 0.15201490482377197, Validation Loss: 0.2111209804951903\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.037891162469911e-07\nEpoch 6081, Training Loss: 0.15202730460083327, Validation Loss: 0.21112128290399104\nEpoch 6081, Training Loss: 0.1520146528672294, Validation Loss: 0.21112128290399104\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.0262289496215058e-07\nEpoch 6091, Training Loss: 0.1520269307173174, Validation Loss: 0.21112165321818205\nEpoch 6091, Training Loss: 0.1520144046267663, Validation Loss: 0.21112165321818205\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.0146977786524801e-07\nEpoch 6101, Training Loss: 0.152026538910955, Validation Loss: 0.21112221982164706\nEpoch 6101, Training Loss: 0.15201417165226636, Validation Loss: 0.21112221982164706\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 1.0032961771172205e-07\nEpoch 6111, Training Loss: 0.15202617304473318, Validation Loss: 0.21112263228637693\nEpoch 6111, Training Loss: 0.15201392859652824, Validation Loss: 0.21112263228637693\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.920226891151764e-08\nEpoch 6121, Training Loss: 0.15202580148143027, Validation Loss: 0.21112286196156943\nEpoch 6121, Training Loss: 0.152013688030155, Validation Loss: 0.21112286196156943\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.808758751049509e-08\nEpoch 6131, Training Loss: 0.15202542913988323, Validation Loss: 0.21112321934933387\nEpoch 6131, Training Loss: 0.1520134518326934, Validation Loss: 0.21112321934933387\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.698543117204845e-08\nEpoch 6141, Training Loss: 0.1520250506703895, Validation Loss: 0.21112353806072037\nEpoch 6141, Training Loss: 0.15201322391042812, Validation Loss: 0.21112353806072037\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.589565915892991e-08\nEpoch 6151, Training Loss: 0.1520247019872467, Validation Loss: 0.21112401468390815\nEpoch 6151, Training Loss: 0.15201299331440057, Validation Loss: 0.21112401468390815\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.481813231527882e-08\nEpoch 6161, Training Loss: 0.15202432629914092, Validation Loss: 0.21112431788162275\nEpoch 6161, Training Loss: 0.15201276592118887, Validation Loss: 0.21112431788162275\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.375271304885252e-08\nEpoch 6171, Training Loss: 0.15202396914696675, Validation Loss: 0.21112464620371105\nEpoch 6171, Training Loss: 0.152012540265596, Validation Loss: 0.21112464620371105\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.269926531345678e-08\nEpoch 6181, Training Loss: 0.15202362518392554, Validation Loss: 0.2111249191368618\nEpoch 6181, Training Loss: 0.15201232729149874, Validation Loss: 0.2111249191368618\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.165765459157373e-08\nEpoch 6191, Training Loss: 0.1520232771839243, Validation Loss: 0.21112510954276598\nEpoch 6191, Training Loss: 0.1520121012407945, Validation Loss: 0.21112510954276598\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 9.062774787718494e-08\nEpoch 6201, Training Loss: 0.15202293526250352, Validation Loss: 0.21112521431476913\nEpoch 6201, Training Loss: 0.15201188037554117, Validation Loss: 0.21112521431476913\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.960941365878757e-08\nEpoch 6211, Training Loss: 0.15202259121797174, Validation Loss: 0.21112532408975998\nEpoch 6211, Training Loss: 0.1520116616971031, Validation Loss: 0.21112532408975998\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.860252190260127e-08\nEpoch 6221, Training Loss: 0.1520222426034335, Validation Loss: 0.21112558654489375\nEpoch 6221, Training Loss: 0.15201145084847625, Validation Loss: 0.21112558654489375\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.760694403596385e-08\nEpoch 6231, Training Loss: 0.15202192776991824, Validation Loss: 0.2111260212919475\nEpoch 6231, Training Loss: 0.1520112384059735, Validation Loss: 0.2111260212919475\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.66225529309135e-08\nEpoch 6241, Training Loss: 0.152021600432771, Validation Loss: 0.21112635963471146\nEpoch 6241, Training Loss: 0.15201103803678162, Validation Loss: 0.21112635963471146\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.56492228879555e-08\nEpoch 6251, Training Loss: 0.15202126452132614, Validation Loss: 0.21112669602234113\nEpoch 6251, Training Loss: 0.15201083320847583, Validation Loss: 0.21112669602234113\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.46868296200113e-08\nEpoch 6261, Training Loss: 0.15202096082261887, Validation Loss: 0.21112693801798293\nEpoch 6261, Training Loss: 0.15201063216176872, Validation Loss: 0.21112693801798293\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.373525023654792e-08\nEpoch 6271, Training Loss: 0.15202064838754029, Validation Loss: 0.2111270788137842\nEpoch 6271, Training Loss: 0.1520104291556577, Validation Loss: 0.2111270788137842\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.279436322788586e-08\nEpoch 6281, Training Loss: 0.15202033418525945, Validation Loss: 0.21112738167829292\nEpoch 6281, Training Loss: 0.1520102392315985, Validation Loss: 0.21112738167829292\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.186404844968312e-08\nEpoch 6291, Training Loss: 0.15202002084289484, Validation Loss: 0.21112779253906133\nEpoch 6291, Training Loss: 0.15201005857423466, Validation Loss: 0.21112779253906133\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.094418710759365e-08\nEpoch 6301, Training Loss: 0.15201975131070278, Validation Loss: 0.21112839293841873\nEpoch 6301, Training Loss: 0.15200986627587743, Validation Loss: 0.21112839293841873\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 8.003466174209825e-08\nEpoch 6311, Training Loss: 0.1520194563666977, Validation Loss: 0.21112853602092674\nEpoch 6311, Training Loss: 0.15200969073191156, Validation Loss: 0.21112853602092674\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.913535621350577e-08\nEpoch 6321, Training Loss: 0.1520191469749022, Validation Loss: 0.21112865532168457\nEpoch 6321, Training Loss: 0.15200950194055335, Validation Loss: 0.21112865532168457\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.824615568712299e-08\nEpoch 6331, Training Loss: 0.15201885137334617, Validation Loss: 0.21112905599844112\nEpoch 6331, Training Loss: 0.152009324901807, Validation Loss: 0.21112905599844112\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.736694661859107e-08\nEpoch 6341, Training Loss: 0.1520185655232546, Validation Loss: 0.2111290937960703\nEpoch 6341, Training Loss: 0.15200914549565936, Validation Loss: 0.2111290937960703\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.649761673938673e-08\nEpoch 6351, Training Loss: 0.15201830270813715, Validation Loss: 0.2111290409355771\nEpoch 6351, Training Loss: 0.15200897116806295, Validation Loss: 0.2111290409355771\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.563805504248644e-08\nEpoch 6361, Training Loss: 0.15201801172922066, Validation Loss: 0.21112912560579455\nEpoch 6361, Training Loss: 0.15200878587245112, Validation Loss: 0.21112912560579455\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.478815176819158e-08\nEpoch 6371, Training Loss: 0.15201772385184667, Validation Loss: 0.21112919646920336\nEpoch 6371, Training Loss: 0.15200861426725729, Validation Loss: 0.21112919646920336\nTraining Accuracy: 0.9507326163477583, Training F1 Score: 0.9483111488367253\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.394779839011302e-08\nEpoch 6381, Training Loss: 0.15201745409768805, Validation Loss: 0.21112922516410632\nEpoch 6381, Training Loss: 0.1520084442926011, Validation Loss: 0.21112922516410632\nTraining Accuracy: 0.9507326163477583, Training F1 Score: 0.9483111488367253\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.311688760131298e-08\nEpoch 6391, Training Loss: 0.15201718238811843, Validation Loss: 0.21112948811414875\nEpoch 6391, Training Loss: 0.15200826432454959, Validation Loss: 0.21112948811414875\nTraining Accuracy: 0.9507326163477583, Training F1 Score: 0.9483111488367253\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.229531330060286e-08\nEpoch 6401, Training Loss: 0.1520169009884291, Validation Loss: 0.21112971512369455\nEpoch 6401, Training Loss: 0.15200810771071924, Validation Loss: 0.21112971512369455\nTraining Accuracy: 0.9507326163477583, Training F1 Score: 0.9483111488367253\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.148297057899479e-08\nEpoch 6411, Training Loss: 0.15201664377220475, Validation Loss: 0.2111299054577308\nEpoch 6411, Training Loss: 0.15200793666343643, Validation Loss: 0.2111299054577308\nTraining Accuracy: 0.9507326163477583, Training F1 Score: 0.9483111488367253\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 7.067975570630558e-08\nEpoch 6421, Training Loss: 0.15201638043583796, Validation Loss: 0.21113022206371374\nEpoch 6421, Training Loss: 0.15200777234756624, Validation Loss: 0.21113022206371374\nTraining Accuracy: 0.9507326163477583, Training F1 Score: 0.9483111488367253\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 6.988556611791111e-08\nEpoch 6431, Training Loss: 0.15201610926657447, Validation Loss: 0.21113045094999242\nEpoch 6431, Training Loss: 0.15200760780101777, Validation Loss: 0.21113045094999242\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\nLearning Rate: 6.910030040164965e-08\nEpoch 6441, Training Loss: 0.152015860199227, Validation Loss: 0.21113051770222915\nEpoch 6441, Training Loss: 0.15200744722518422, Validation Loss: 0.21113051770222915\nTraining Accuracy: 0.9507204365248529, Training F1 Score: 0.9482993074115491\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9306929610420259\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[95], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m LambdaLR(optimizer, lr_lambda\u001b[38;5;241m=\u001b[39mcustom_lr_lambda)\n\u001b[1;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m CustomLoss(nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[8], line 21\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer, num_epochs, scheduler, batch_size, num_features, early_stopping_patience)\u001b[0m\n\u001b[1;32m     19\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels, model)\n\u001b[0;32m---> 21\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     22\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     23\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:521\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    512\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    513\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    514\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    519\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    520\u001b[0m     )\n\u001b[0;32m--> 521\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    522\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    523\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:289\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    284\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    286\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    287\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    288\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 289\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/graph.py:768\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    766\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    767\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 768\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    769\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    771\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    772\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":95},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 0.1)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 10000, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T02:40:42.879528Z","iopub.execute_input":"2025-01-23T02:40:42.880140Z","iopub.status.idle":"2025-01-23T02:48:51.705564Z","shell.execute_reply.started":"2025-01-23T02:40:42.880109Z","shell.execute_reply":"2025-01-23T02:48:51.704381Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"here\nLearning Rate: 9.993501949642547e-05\nEpoch 1, Training Loss: 0.34543187213408943, Validation Loss: 0.2689781817711198\nEpoch 1, Training Loss: 0.26728370172882226, Validation Loss: 0.2689781817711198\nTraining Accuracy: 0.8973119130847838, Training F1 Score: 0.8914560382205152\nValidation Accuracy: 0.898059848733969, Validation F1 Score: 0.8924544424941138\n\nLearning Rate: 9.444510414519057e-05\nEpoch 11, Training Loss: 0.21289476665799534, Validation Loss: 0.2224465758065755\nEpoch 11, Training Loss: 0.21131804840854507, Validation Loss: 0.2224465758065755\nTraining Accuracy: 0.932889175791384, Training F1 Score: 0.9291719103274619\nValidation Accuracy: 0.9287515071796558, Validation F1 Score: 0.9248588465848174\n\nLearning Rate: 8.925677647278535e-05\nEpoch 21, Training Loss: 0.2036504547566547, Validation Loss: 0.21515626204120972\nEpoch 21, Training Loss: 0.20259356287623168, Validation Loss: 0.21515626204120972\nTraining Accuracy: 0.9355687368305665, Training F1 Score: 0.9319644311150924\nValidation Accuracy: 0.9303957031678176, Validation F1 Score: 0.9266295677394131\n\nLearning Rate: 8.435346880517426e-05\nEpoch 31, Training Loss: 0.19865154455835188, Validation Loss: 0.21223438373295922\nEpoch 31, Training Loss: 0.19813190339654915, Validation Loss: 0.21223438373295922\nTraining Accuracy: 0.9376149470786694, Training F1 Score: 0.9341985657855923\nValidation Accuracy: 0.9321495122218568, Validation F1 Score: 0.9285731945857261\n\nLearning Rate: 7.971952361101734e-05\nEpoch 41, Training Loss: 0.19531339607245246, Validation Loss: 0.21080165324792074\nEpoch 41, Training Loss: 0.1946959236518719, Validation Loss: 0.21080165324792074\nTraining Accuracy: 0.9390156267127876, Training F1 Score: 0.9356914533960395\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.929345813347905\n\nLearning Rate: 7.53401435031172e-05\nEpoch 51, Training Loss: 0.19281747065888438, Validation Loss: 0.21035066668393776\nEpoch 51, Training Loss: 0.19227451972803425, Validation Loss: 0.21035066668393776\nTraining Accuracy: 0.939709876618394, Training F1 Score: 0.9364811382944203\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9304309337555222\n\nLearning Rate: 7.120134398652935e-05\nEpoch 61, Training Loss: 0.19099128852786068, Validation Loss: 0.20975547841272632\nEpoch 61, Training Loss: 0.19059243991292413, Validation Loss: 0.20975547841272632\nTraining Accuracy: 0.9403188677636627, Training F1 Score: 0.9371505663718261\nValidation Accuracy: 0.9348898388687932, Validation F1 Score: 0.9313554396192363\n\nLearning Rate: 6.728990880244771e-05\nEpoch 71, Training Loss: 0.18956911029011933, Validation Loss: 0.20928821903917333\nEpoch 71, Training Loss: 0.18933896024472552, Validation Loss: 0.20928821903917333\nTraining Accuracy: 0.9405990036904863, Training F1 Score: 0.9374812471708688\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9306731649673498\n\nLearning Rate: 6.359334772526728e-05\nEpoch 81, Training Loss: 0.18837972407729953, Validation Loss: 0.20932861412060205\nEpoch 81, Training Loss: 0.18859056165188937, Validation Loss: 0.20932861412060205\nTraining Accuracy: 0.9406720826279186, Training F1 Score: 0.9376700852183\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9303266022819772\n\nLearning Rate: 6.009985667805884e-05\nEpoch 91, Training Loss: 0.1873922745255479, Validation Loss: 0.20960377225008997\nEpoch 91, Training Loss: 0.18828747579121102, Validation Loss: 0.20960377225008997\nTraining Accuracy: 0.9410618369608906, Training F1 Score: 0.9382120297674577\nValidation Accuracy: 0.9332456428806314, Validation F1 Score: 0.930003338763837\n\nLearning Rate: 5.679828003909402e-05\nEpoch 101, Training Loss: 0.18654300644925723, Validation Loss: 0.20991342939182447\nEpoch 101, Training Loss: 0.18800481687853496, Validation Loss: 0.20991342939182447\nTraining Accuracy: 0.9412323544815658, Training F1 Score: 0.9384684295913797\nValidation Accuracy: 0.933903321275896, Validation F1 Score: 0.9308275634363191\n\nLearning Rate: 5.367807501905584e-05\nEpoch 111, Training Loss: 0.18577756255655653, Validation Loss: 0.20988475296380527\nEpoch 111, Training Loss: 0.18741577367998177, Validation Loss: 0.20988475296380527\nTraining Accuracy: 0.9414394114709572, Training F1 Score: 0.9387149238165126\nValidation Accuracy: 0.934122547407651, Validation F1 Score: 0.9311013958623583\n\nLearning Rate: 5.07292779951818e-05\nEpoch 121, Training Loss: 0.1851064466243002, Validation Loss: 0.2094517259267578\nEpoch 121, Training Loss: 0.18645140315641817, Validation Loss: 0.2094517259267578\nTraining Accuracy: 0.9416464684603486, Training F1 Score: 0.9388954328611754\nValidation Accuracy: 0.934341773539406, Validation F1 Score: 0.9313306757430159\n\nLearning Rate: 4.7942472694835886e-05\nEpoch 131, Training Loss: 0.1844388846795167, Validation Loss: 0.20886208312194965\nEpoch 131, Training Loss: 0.18535970665631804, Validation Loss: 0.20886208312194965\nTraining Accuracy: 0.9420727622620367, Training F1 Score: 0.939288278654058\nValidation Accuracy: 0.934341773539406, Validation F1 Score: 0.9312864187369073\n\nLearning Rate: 4.530876012691115e-05\nEpoch 141, Training Loss: 0.1838220991080361, Validation Loss: 0.20839327833480797\nEpoch 141, Training Loss: 0.1845113875336977, Validation Loss: 0.20839327833480797\nTraining Accuracy: 0.9423650780117657, Training F1 Score: 0.9395619018774842\nValidation Accuracy: 0.9344513866052834, Validation F1 Score: 0.9313678930666872\n\nLearning Rate: 4.2819730165046316e-05\nEpoch 151, Training Loss: 0.1832431456319566, Validation Loss: 0.2080940646415973\nEpoch 151, Training Loss: 0.1839304983787568, Validation Loss: 0.2080940646415973\nTraining Accuracy: 0.9426452139385894, Training F1 Score: 0.9398458686490407\nValidation Accuracy: 0.9346706127370382, Validation F1 Score: 0.9315309122390962\n\nLearning Rate: 4.046743469191408e-05\nEpoch 161, Training Loss: 0.1827667051270814, Validation Loss: 0.20815659696355693\nEpoch 161, Training Loss: 0.18367328280325418, Validation Loss: 0.20815659696355693\nTraining Accuracy: 0.9428157314592646, Training F1 Score: 0.9400507294395978\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9311383542475123\n\nLearning Rate: 3.824436221882389e-05\nEpoch 171, Training Loss: 0.18237825862577567, Validation Loss: 0.20858818448277194\nEpoch 171, Training Loss: 0.1837799647969555, Validation Loss: 0.20858818448277194\nTraining Accuracy: 0.9425721350011571, Training F1 Score: 0.9398582529057442\nValidation Accuracy: 0.9340129343417736, Validation F1 Score: 0.9309978511701207\n\nLearning Rate: 3.614341389959312e-05\nEpoch 181, Training Loss: 0.18206331544743762, Validation Loss: 0.20919360903504255\nEpoch 181, Training Loss: 0.18413921149093126, Validation Loss: 0.20919360903504255\nTraining Accuracy: 0.9425964946469678, Training F1 Score: 0.9399806200700881\nValidation Accuracy: 0.9346706127370382, Validation F1 Score: 0.9317948978131163\n\nLearning Rate: 3.415788086209259e-05\nEpoch 191, Training Loss: 0.1818169364305602, Validation Loss: 0.20969486184141348\nEpoch 191, Training Loss: 0.18444866559097406, Validation Loss: 0.20969486184141348\nTraining Accuracy: 0.9423650780117657, Training F1 Score: 0.9397955267175063\nValidation Accuracy: 0.9348898388687932, Validation F1 Score: 0.9321317729964864\n\nLearning Rate: 3.228142278508023e-05\nEpoch 201, Training Loss: 0.1814927595082894, Validation Loss: 0.2093138019907021\nEpoch 201, Training Loss: 0.18396640659382624, Validation Loss: 0.2093138019907021\nTraining Accuracy: 0.9424990560637249, Training F1 Score: 0.9399322742604991\nValidation Accuracy: 0.935109065000548, Validation F1 Score: 0.9323602855453197\n\nLearning Rate: 3.050804765191328e-05\nEpoch 211, Training Loss: 0.18110099177149974, Validation Loss: 0.2084119051766738\nEpoch 211, Training Loss: 0.18293445710708817, Validation Loss: 0.2084119051766738\nTraining Accuracy: 0.942961889334129, Training F1 Score: 0.9403456182673089\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9325460022131786\n\nLearning Rate: 2.8832092616487133e-05\nEpoch 221, Training Loss: 0.18069238364663834, Validation Loss: 0.2075723581547723\nEpoch 221, Training Loss: 0.18194568289123672, Validation Loss: 0.2075723581547723\nTraining Accuracy: 0.9433151041983849, Training F1 Score: 0.940643801952928\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9324815263586217\n\nLearning Rate: 2.7248205920301112e-05\nEpoch 231, Training Loss: 0.18031227997050248, Validation Loss: 0.20685399315616718\nEpoch 231, Training Loss: 0.18109584965070702, Validation Loss: 0.20685399315616718\nTraining Accuracy: 0.9436074199481139, Training F1 Score: 0.9408924389590977\nValidation Accuracy: 0.935109065000548, Validation F1 Score: 0.9321876142878733\n\nLearning Rate: 2.5751329802907438e-05\nEpoch 241, Training Loss: 0.17994825071759743, Validation Loss: 0.20626393252430184\nEpoch 241, Training Loss: 0.18037994471440388, Validation Loss: 0.20626393252430184\nTraining Accuracy: 0.9438753760520322, Training F1 Score: 0.9411222134599471\nValidation Accuracy: 0.9356571303299354, Validation F1 Score: 0.9326846888996285\n\nLearning Rate: 2.4336684351172162e-05\nEpoch 251, Training Loss: 0.17962037587352261, Validation Loss: 0.20576350052315168\nEpoch 251, Training Loss: 0.1797646062746656, Validation Loss: 0.20576350052315168\nTraining Accuracy: 0.9440702532185182, Training F1 Score: 0.9412690954137081\nValidation Accuracy: 0.9357667433958128, Validation F1 Score: 0.932745125981737\n\nLearning Rate: 2.2999752235774546e-05\nEpoch 261, Training Loss: 0.17930961127966683, Validation Loss: 0.20534481311542194\nEpoch 261, Training Loss: 0.179230621502437, Validation Loss: 0.20534481311542194\nTraining Accuracy: 0.9443625689682472, Training F1 Score: 0.9415334450756442\nValidation Accuracy: 0.9355475172640578, Validation F1 Score: 0.9324499603969605\n\nLearning Rate: 2.1736264286204537e-05\nEpoch 271, Training Loss: 0.17901627042685633, Validation Loss: 0.204991551226565\nEpoch 271, Training Loss: 0.17878638274901698, Validation Loss: 0.204991551226565\nTraining Accuracy: 0.9444965470202064, Training F1 Score: 0.9416326337357818\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9321761046401555\n\nLearning Rate: 2.054218585819561e-05\nEpoch 281, Training Loss: 0.17873806238774093, Validation Loss: 0.2047229357407593\nEpoch 281, Training Loss: 0.1784170167017565, Validation Loss: 0.2047229357407593\nTraining Accuracy: 0.9445209066660171, Training F1 Score: 0.9416347224022662\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9321539994190788\n\nLearning Rate: 1.941370395006067e-05\nEpoch 291, Training Loss: 0.1784822815512411, Validation Loss: 0.20452291737728626\nEpoch 291, Training Loss: 0.17811383812693635, Validation Loss: 0.20452291737728626\nTraining Accuracy: 0.9445087268431117, Training F1 Score: 0.9416015439469431\nValidation Accuracy: 0.9355475172640578, Validation F1 Score: 0.9323619166884233\n\nLearning Rate: 1.8347215026790087e-05\nEpoch 301, Training Loss: 0.17824491630943953, Validation Loss: 0.2043516281553231\nEpoch 301, Training Loss: 0.17786128382351726, Validation Loss: 0.2043516281553231\nTraining Accuracy: 0.9446305250721655, Training F1 Score: 0.9417190130237683\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9321318551805609\n\nLearning Rate: 1.733931351303109e-05\nEpoch 311, Training Loss: 0.17802170180945404, Validation Loss: 0.20422318154562333\nEpoch 311, Training Loss: 0.17765278158247483, Validation Loss: 0.20422318154562333\nTraining Accuracy: 0.944581805780544, Training F1 Score: 0.9416591486571596\nValidation Accuracy: 0.9355475172640578, Validation F1 Score: 0.932339808548045\n\nLearning Rate: 1.638678091820362e-05\nEpoch 321, Training Loss: 0.1778088561457208, Validation Loss: 0.2041335213730553\nEpoch 321, Training Loss: 0.17745854798288085, Validation Loss: 0.2041335213730553\nTraining Accuracy: 0.9446061654263547, Training F1 Score: 0.9416783539471913\nValidation Accuracy: 0.935328291132303, Validation F1 Score: 0.9321318551805609\n\nLearning Rate: 1.548657555902633e-05\nEpoch 331, Training Loss: 0.17761366406168808, Validation Loss: 0.2040621046073654\nEpoch 331, Training Loss: 0.17728577299880924, Validation Loss: 0.2040621046073654\nTraining Accuracy: 0.9446670645408816, Training F1 Score: 0.9417435441089601\nValidation Accuracy: 0.9354379041981804, Validation F1 Score: 0.9322358179491689\n\nLearning Rate: 1.4635822846634064e-05\nEpoch 341, Training Loss: 0.17743045467411328, Validation Loss: 0.2040029499521776\nEpoch 341, Training Loss: 0.1771253402570876, Validation Loss: 0.2040029499521776\nTraining Accuracy: 0.9447401434783138, Training F1 Score: 0.9418162001823831\nValidation Accuracy: 0.9356571303299354, Validation F1 Score: 0.9324438270166879\n\nLearning Rate: 1.3831806107271095e-05\nEpoch 351, Training Loss: 0.17725846696494246, Validation Loss: 0.2039307552521184\nEpoch 351, Training Loss: 0.17696783172745664, Validation Loss: 0.2039307552521184\nTraining Accuracy: 0.9447279636554085, Training F1 Score: 0.9417958731899128\nValidation Accuracy: 0.9357667433958128, Validation F1 Score: 0.9325478733946504\n\nLearning Rate: 1.3071957907248198e-05\nEpoch 361, Training Loss: 0.17709590181792367, Validation Loss: 0.2038633749632149\nEpoch 361, Training Loss: 0.17681460263135163, Validation Loss: 0.2038633749632149\nTraining Accuracy: 0.9447888627699353, Training F1 Score: 0.9418546465724553\nValidation Accuracy: 0.9359859695275677, Validation F1 Score: 0.9327339756957573\n\nLearning Rate: 1.2353851854461915e-05\nEpoch 371, Training Loss: 0.17694572023279204, Validation Loss: 0.20380085695767292\nEpoch 371, Training Loss: 0.1766715059649568, Validation Loss: 0.20380085695767292\nTraining Accuracy: 0.9448375820615569, Training F1 Score: 0.9418973870259748\nValidation Accuracy: 0.9358763564616902, Validation F1 Score: 0.9326077234213417\n\nLearning Rate: 1.1675194850296142e-05\nEpoch 381, Training Loss: 0.1768048844480422, Validation Loss: 0.20372412900685297\nEpoch 381, Training Loss: 0.17653478527626495, Validation Loss: 0.20372412900685297\nTraining Accuracy: 0.9448132224157461, Training F1 Score: 0.941867440549995\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9330465060921612\n\nLearning Rate: 1.1033819767164328e-05\nEpoch 391, Training Loss: 0.17667115590064844, Validation Loss: 0.20365551132866\nEpoch 391, Training Loss: 0.17640331571372755, Validation Loss: 0.20365551132866\nTraining Accuracy: 0.9448375820615569, Training F1 Score: 0.9418845223084621\nValidation Accuracy: 0.9362051956593226, Validation F1 Score: 0.9328981088543735\n\nLearning Rate: 1.0427678528309802e-05\nEpoch 401, Training Loss: 0.17654561915423111, Validation Loss: 0.20359471079178917\nEpoch 401, Training Loss: 0.17628000861936796, Validation Loss: 0.20359471079178917\nTraining Accuracy: 0.9449106609989891, Training F1 Score: 0.9419550839174574\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9330244479193441\n\nLearning Rate: 9.854835567766246e-06\nEpoch 411, Training Loss: 0.17642700112242196, Validation Loss: 0.20353031798235147\nEpoch 411, Training Loss: 0.17615901210592716, Validation Loss: 0.20353031798235147\nTraining Accuracy: 0.9449350206447998, Training F1 Score: 0.9419721756515245\nValidation Accuracy: 0.9362051956593226, Validation F1 Score: 0.9328981088543735\n\nLearning Rate: 9.313461649594241e-06\nEpoch 421, Training Loss: 0.17631464634542263, Validation Loss: 0.20345021366981592\nEpoch 421, Training Loss: 0.1760413435294364, Validation Loss: 0.20345021366981592\nTraining Accuracy: 0.9449593802906106, Training F1 Score: 0.941993557954435\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9331066208560207\n\nLearning Rate: 8.801828026657151e-06\nEpoch 431, Training Loss: 0.17620651241076415, Validation Loss: 0.20335771253688364\nEpoch 431, Training Loss: 0.17592166579226468, Validation Loss: 0.20335771253688364\nTraining Accuracy: 0.9449715601135159, Training F1 Score: 0.941994595850225\nValidation Accuracy: 0.936534034856955, Validation F1 Score: 0.933210919327946\n\nLearning Rate: 8.318300920283765e-06\nEpoch 441, Training Loss: 0.17610479655140854, Validation Loss: 0.2032793694066855\nEpoch 441, Training Loss: 0.17580415973939578, Validation Loss: 0.2032793694066855\nTraining Accuracy: 0.9449959197593267, Training F1 Score: 0.9420095413150777\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9329580388599463\n\nLearning Rate: 7.861336303189847e-06\nEpoch 451, Training Loss: 0.1760073641946632, Validation Loss: 0.20320343853977052\nEpoch 451, Training Loss: 0.17569201717821384, Validation Loss: 0.20320343853977052\nTraining Accuracy: 0.9450446390509482, Training F1 Score: 0.9420544671896298\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9329580388599463\n\nLearning Rate: 7.429474968999126e-06\nEpoch 461, Training Loss: 0.17591602343689713, Validation Loss: 0.2031267455902641\nEpoch 461, Training Loss: 0.1755835063113116, Validation Loss: 0.2031267455902641\nTraining Accuracy: 0.9450933583425697, Training F1 Score: 0.9420886644407351\nValidation Accuracy: 0.9362051956593226, Validation F1 Score: 0.9328092538700664\n\nLearning Rate: 7.021337872619386e-06\nEpoch 471, Training Loss: 0.1758289643143547, Validation Loss: 0.2030670168099795\nEpoch 471, Training Loss: 0.1754844067608609, Validation Loss: 0.2030670168099795\nTraining Accuracy: 0.9451542574570966, Training F1 Score: 0.942138938744247\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9330179143497537\n\nLearning Rate: 6.635621726594329e-06\nEpoch 481, Training Loss: 0.17574618956413943, Validation Loss: 0.20300796105975868\nEpoch 481, Training Loss: 0.17539454040169525, Validation Loss: 0.20300796105975868\nTraining Accuracy: 0.9452516960403395, Training F1 Score: 0.9422288575704579\nValidation Accuracy: 0.9360955825934452, Validation F1 Score: 0.9326378551056345\n\nLearning Rate: 6.271094839369167e-06\nEpoch 491, Training Loss: 0.17566881815414342, Validation Loss: 0.2029612161383273\nEpoch 491, Training Loss: 0.17531480423823625, Validation Loss: 0.2029612161383273\nTraining Accuracy: 0.9453125951548664, Training F1 Score: 0.9422727224693748\nValidation Accuracy: 0.9360955825934452, Validation F1 Score: 0.9326154053085995\n\nLearning Rate: 5.926593182180475e-06\nEpoch 501, Training Loss: 0.17559444098151394, Validation Loss: 0.20292886592644577\nEpoch 501, Training Loss: 0.17524434634687092, Validation Loss: 0.20292886592644577\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.9423187450308506\nValidation Accuracy: 0.9360955825934452, Validation F1 Score: 0.9325703861089035\n\nLearning Rate: 5.60101667201088e-06\nEpoch 511, Training Loss: 0.17552305452146566, Validation Loss: 0.20290689658899128\nEpoch 511, Training Loss: 0.1751818884577764, Validation Loss: 0.20290689658899128\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.9423058359575964\nValidation Accuracy: 0.9362051956593226, Validation F1 Score: 0.9326747853920122\n\nLearning Rate: 5.293325658739052e-06\nEpoch 521, Training Loss: 0.17545425247084248, Validation Loss: 0.20288377316044073\nEpoch 521, Training Loss: 0.17512580303339662, Validation Loss: 0.20288377316044073\nTraining Accuracy: 0.9453247749777718, Training F1 Score: 0.9422457585104103\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327792133918374\n\nLearning Rate: 5.0025376052676005e-06\nEpoch 531, Training Loss: 0.17538801198070114, Validation Loss: 0.20286166074701167\nEpoch 531, Training Loss: 0.1750750015662573, Validation Loss: 0.20286166074701167\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9422960771094299\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327792133918374\n\nLearning Rate: 4.727723950027649e-06\nEpoch 541, Training Loss: 0.17532530684917633, Validation Loss: 0.20284024667422343\nEpoch 541, Training Loss: 0.17502826796366933, Validation Loss: 0.20284024667422343\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.942275655263314\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327566812862702\n\nLearning Rate: 4.468007141841246e-06\nEpoch 551, Training Loss: 0.17526555947264574, Validation Loss: 0.20281351100198927\nEpoch 551, Training Loss: 0.17498360468652532, Validation Loss: 0.20281351100198927\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.9422713369210212\nValidation Accuracy: 0.9360955825934452, Validation F1 Score: 0.9325025570169139\n\nLearning Rate: 4.222557837673164e-06\nEpoch 561, Training Loss: 0.17520863056337493, Validation Loss: 0.2027880756982152\nEpoch 561, Training Loss: 0.1749409430094059, Validation Loss: 0.2027880756982152\nTraining Accuracy: 0.9454100337381095, Training F1 Score: 0.9423045546965156\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 3.9905922543237915e-06\nEpoch 571, Training Loss: 0.17515444729219493, Validation Loss: 0.20276352462147354\nEpoch 571, Training Loss: 0.17489953845811598, Validation Loss: 0.20276352462147354\nTraining Accuracy: 0.945397853915204, Training F1 Score: 0.9422884419646383\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 3.7713696656063815e-06\nEpoch 581, Training Loss: 0.17510297164873956, Validation Loss: 0.20273546980528354\nEpoch 581, Training Loss: 0.1748592681922255, Validation Loss: 0.20273546980528354\nTraining Accuracy: 0.945361314446488, Training F1 Score: 0.9422444158931895\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 3.5641900370164793e-06\nEpoch 591, Training Loss: 0.17505400953532504, Validation Loss: 0.20270781648416444\nEpoch 591, Training Loss: 0.17482010965354375, Validation Loss: 0.20270781648416444\nTraining Accuracy: 0.9453247749777718, Training F1 Score: 0.9422047098034856\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 3.3683917903404466e-06\nEpoch 601, Training Loss: 0.1750077238316635, Validation Loss: 0.2026840191190342\nEpoch 601, Training Loss: 0.17478205881001108, Validation Loss: 0.2026840191190342\nTraining Accuracy: 0.9453125951548664, Training F1 Score: 0.9421929173786049\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328386035302219\n\nLearning Rate: 3.183349691064877e-06\nEpoch 611, Training Loss: 0.17496349726019697, Validation Loss: 0.20265607462174456\nEpoch 611, Training Loss: 0.17474507814583115, Validation Loss: 0.20265607462174456\nTraining Accuracy: 0.9453125951548664, Training F1 Score: 0.9421950819475664\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 3.0084728518408546e-06\nEpoch 621, Training Loss: 0.17492156687957375, Validation Loss: 0.20263741142124145\nEpoch 621, Training Loss: 0.17470940123769935, Validation Loss: 0.20263741142124145\nTraining Accuracy: 0.9453004153319611, Training F1 Score: 0.9421811253289448\nValidation Accuracy: 0.9362051956593226, Validation F1 Score: 0.9326070125079123\n\nLearning Rate: 2.843202845627614e-06\nEpoch 631, Training Loss: 0.17488171331369476, Validation Loss: 0.20261852745390194\nEpoch 631, Training Loss: 0.17467518183384512, Validation Loss: 0.20261852745390194\nTraining Accuracy: 0.9453247749777718, Training F1 Score: 0.9422090379772609\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 2.687011922490364e-06\nEpoch 641, Training Loss: 0.1748439682152086, Validation Loss: 0.20259954218218676\nEpoch 641, Training Loss: 0.17464275921278077, Validation Loss: 0.20259954218218676\nTraining Accuracy: 0.9453369548006771, Training F1 Score: 0.9422229934181126\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 2.539401324358058e-06\nEpoch 651, Training Loss: 0.17480819128927338, Validation Loss: 0.20258103976820196\nEpoch 651, Training Loss: 0.17461224262724376, Validation Loss: 0.20258103976820196\nTraining Accuracy: 0.9453491346235826, Training F1 Score: 0.9422369482702058\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 2.3998996923596953e-06\nEpoch 661, Training Loss: 0.17477475098530798, Validation Loss: 0.20256487124879333\nEpoch 661, Training Loss: 0.1745837056280212, Validation Loss: 0.20256487124879333\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.9422691771101502\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 2.2680615616533654e-06\nEpoch 671, Training Loss: 0.17474279759555358, Validation Loss: 0.20254956816458772\nEpoch 671, Training Loss: 0.17455704978555933, Validation Loss: 0.20254956816458772\nTraining Accuracy: 0.945361314446488, Training F1 Score: 0.9422573853313524\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 2.1434659389416294e-06\nEpoch 681, Training Loss: 0.17471229542531963, Validation Loss: 0.20253736795360394\nEpoch 681, Training Loss: 0.17453208136570583, Validation Loss: 0.20253736795360394\nTraining Accuracy: 0.945361314446488, Training F1 Score: 0.942261705063022\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 2.0257149581308867e-06\nEpoch 691, Training Loss: 0.17468362373867846, Validation Loss: 0.20252705080316058\nEpoch 691, Training Loss: 0.17450882780392632, Validation Loss: 0.20252705080316058\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9422896048757019\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 1.91443260984189e-06\nEpoch 701, Training Loss: 0.1746561483005896, Validation Loss: 0.20251880977990844\nEpoch 701, Training Loss: 0.1744872463942547, Validation Loss: 0.20251880977990844\nTraining Accuracy: 0.945397853915204, Training F1 Score: 0.94230355390027\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 1.8092635407144097e-06\nEpoch 711, Training Loss: 0.1746301180152378, Validation Loss: 0.20250880712841107\nEpoch 711, Training Loss: 0.17446724685855497, Validation Loss: 0.20250880712841107\nTraining Accuracy: 0.945397853915204, Training F1 Score: 0.94230355390027\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 1.7098719186719192e-06\nEpoch 721, Training Loss: 0.17460543397683043, Validation Loss: 0.20249946842711836\nEpoch 721, Training Loss: 0.17444855299438583, Validation Loss: 0.20249946842711836\nTraining Accuracy: 0.9454100337381095, Training F1 Score: 0.9423218148092026\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 1.6159403605227944e-06\nEpoch 731, Training Loss: 0.17458227198560214, Validation Loss: 0.20249337545941826\nEpoch 731, Training Loss: 0.17443161284060515, Validation Loss: 0.20249337545941826\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.9422864436603277\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 1.527168918473579e-06\nEpoch 741, Training Loss: 0.17455999236243327, Validation Loss: 0.20248594369841788\nEpoch 741, Training Loss: 0.1744157316509676, Validation Loss: 0.20248594369841788\nTraining Accuracy: 0.945361314446488, Training F1 Score: 0.9422746540262447\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327114968581122\n\nLearning Rate: 1.4432741223179954e-06\nEpoch 751, Training Loss: 0.17453918955826217, Validation Loss: 0.2024780075013422\nEpoch 751, Training Loss: 0.1744008291808426, Validation Loss: 0.2024780075013422\nTraining Accuracy: 0.9453491346235826, Training F1 Score: 0.9422650217037886\nValidation Accuracy: 0.9362051956593226, Validation F1 Score: 0.9326070125079123\n\nLearning Rate: 1.3639880742431556e-06\nEpoch 761, Training Loss: 0.17451920098731105, Validation Loss: 0.20247336687336598\nEpoch 761, Training Loss: 0.1743871376836564, Validation Loss: 0.20247336687336598\nTraining Accuracy: 0.945361314446488, Training F1 Score: 0.9422811227574935\nValidation Accuracy: 0.9363148087252, Validation F1 Score: 0.9327341091369242\n\nLearning Rate: 1.2890575933624603e-06\nEpoch 771, Training Loss: 0.17450054783032, Validation Loss: 0.20246938449026108\nEpoch 771, Training Loss: 0.17437434584323788, Validation Loss: 0.20246938449026108\nTraining Accuracy: 0.9453491346235826, Training F1 Score: 0.9422693343010787\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 1.2182434072434532e-06\nEpoch 781, Training Loss: 0.17448281213896527, Validation Loss: 0.20246638770553216\nEpoch 781, Training Loss: 0.17436250404672118, Validation Loss: 0.20246638770553216\nTraining Accuracy: 0.945361314446488, Training F1 Score: 0.9422832781500123\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 1.1513193878489729e-06\nEpoch 791, Training Loss: 0.1744660413781541, Validation Loss: 0.20246260286285653\nEpoch 791, Training Loss: 0.17435149573208103, Validation Loss: 0.20246260286285653\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.9422972214121607\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 1.0880718294517635e-06\nEpoch 801, Training Loss: 0.17445020983225332, Validation Loss: 0.20246071353510625\nEpoch 801, Training Loss: 0.17434112011940575, Validation Loss: 0.20246071353510625\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9423111640876076\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 1.0282987662167366e-06\nEpoch 811, Training Loss: 0.17443517830336777, Validation Loss: 0.2024574381396604\nEpoch 811, Training Loss: 0.17433145898131971, Validation Loss: 0.2024574381396604\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9423111640876076\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 9.718093272717521e-07\nEpoch 821, Training Loss: 0.17442101953554598, Validation Loss: 0.20245568719523577\nEpoch 821, Training Loss: 0.1743224207476347, Validation Loss: 0.20245568719523577\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.942299375686219\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 9.184231272074868e-07\nEpoch 831, Training Loss: 0.17440755923277143, Validation Loss: 0.20245363676082823\nEpoch 831, Training Loss: 0.1743139895376691, Validation Loss: 0.20245363676082823\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.942301529535077\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 8.679696900601022e-07\nEpoch 841, Training Loss: 0.17439497880306512, Validation Loss: 0.2024518514668015\nEpoch 841, Training Loss: 0.1743060522949446, Validation Loss: 0.2024518514668015\nTraining Accuracy: 0.945397853915204, Training F1 Score: 0.9423294115283076\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 8.202879049373407e-07\nEpoch 851, Training Loss: 0.17438307079989593, Validation Loss: 0.2024499072564559\nEpoch 851, Training Loss: 0.17429865643554673, Validation Loss: 0.2024499072564559\nTraining Accuracy: 0.945397853915204, Training F1 Score: 0.9423294115283076\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 7.752255115497165e-07\nEpoch 861, Training Loss: 0.17437179327122182, Validation Loss: 0.20244899683519765\nEpoch 861, Training Loss: 0.17429171955398323, Validation Loss: 0.20244899683519765\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9423176235560365\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 7.326386140039774e-07\nEpoch 871, Training Loss: 0.17436113954842697, Validation Loss: 0.20244830589858662\nEpoch 871, Training Loss: 0.17428516489592513, Validation Loss: 0.20244830589858662\nTraining Accuracy: 0.945397853915204, Training F1 Score: 0.9423315635669799\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 6.923912213062479e-07\nEpoch 881, Training Loss: 0.17435100669166256, Validation Loss: 0.20244789909182262\nEpoch 881, Training Loss: 0.1742790065390976, Validation Loss: 0.20244789909182262\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9423219277438896\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 6.543548131075642e-07\nEpoch 891, Training Loss: 0.17434141886188836, Validation Loss: 0.20244751550166554\nEpoch 891, Training Loss: 0.17427322952317248, Validation Loss: 0.20244751550166554\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9423240792007886\nValidation Accuracy: 0.9364244217910775, Validation F1 Score: 0.9328611568485424\n\nLearning Rate: 6.184079293051135e-07\nEpoch 901, Training Loss: 0.17433241143981112, Validation Loss: 0.2024472585803621\nEpoch 901, Training Loss: 0.1742677771042057, Validation Loss: 0.2024472585803621\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9423240792007886\nValidation Accuracy: 0.936534034856955, Validation F1 Score: 0.9329881557052503\n\nLearning Rate: 5.844357821886669e-07\nEpoch 911, Training Loss: 0.1743238819057395, Validation Loss: 0.20244719825377136\nEpoch 911, Training Loss: 0.17426267480635477, Validation Loss: 0.20244719825377136\nTraining Accuracy: 0.9453734942693933, Training F1 Score: 0.9423122924048987\nValidation Accuracy: 0.936534034856955, Validation F1 Score: 0.9329881557052503\n\nLearning Rate: 5.523298898936911e-07\nEpoch 921, Training Loss: 0.17431585143379463, Validation Loss: 0.20244661243870293\nEpoch 921, Training Loss: 0.17425786910555174, Validation Loss: 0.20244661243870293\nTraining Accuracy: 0.9453856740922987, Training F1 Score: 0.9423262302331379\nValidation Accuracy: 0.936534034856955, Validation F1 Score: 0.9329881557052503\n\nLearning Rate: 5.219877299906583e-07\nEpoch 931, Training Loss: 0.17430828857405614, Validation Loss: 0.20244627211793764\nEpoch 931, Training Loss: 0.17425336339608813, Validation Loss: 0.20244627211793764\nTraining Accuracy: 0.945397853915204, Training F1 Score: 0.9423401674755991\nValidation Accuracy: 0.936534034856955, Validation F1 Score: 0.9329881557052503\n\nLearning Rate: 4.933124121043744e-07\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[94], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m LambdaLR(optimizer, lr_lambda\u001b[38;5;241m=\u001b[39mcustom_lr_lambda)\n\u001b[1;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m CustomLoss(nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[8], line 58\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer, num_epochs, scheduler, batch_size, num_features, early_stopping_patience)\u001b[0m\n\u001b[1;32m     55\u001b[0m avg_val_loss \u001b[38;5;241m=\u001b[39m val_loss \u001b[38;5;241m/\u001b[39m \u001b[38;5;28mlen\u001b[39m(custom_train_loader\u001b[38;5;241m.\u001b[39mval_data_tensor)\n\u001b[1;32m     57\u001b[0m train_accuracy, train_f1 \u001b[38;5;241m=\u001b[39m calculate_metrics(model, custom_train_loader\u001b[38;5;241m.\u001b[39mtrain_data_tensor, custom_train_loader\u001b[38;5;241m.\u001b[39mtrain_labels_tensor, batch_size, num_features)\n\u001b[0;32m---> 58\u001b[0m val_accuracy, val_f1 \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_data_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mval_labels_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_train_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     61\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mepoch\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Training Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtrain_reg_loss\u001b[38;5;250m \u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;28mlen\u001b[39m(custom_train_loader\u001b[38;5;241m.\u001b[39mtrain_data_tensor)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Validation Loss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mavg_val_loss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n","Cell \u001b[0;32mIn[6], line 14\u001b[0m, in \u001b[0;36mcalculate_metrics\u001b[0;34m(model, data_tensor, labels_tensor, batch_size, num_features)\u001b[0m\n\u001b[1;32m     12\u001b[0m         outputs \u001b[38;5;241m=\u001b[39m model(inputs)\n\u001b[1;32m     13\u001b[0m         _, preds \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(outputs, \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m         all_preds\u001b[38;5;241m.\u001b[39mextend(\u001b[43mpreds\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     15\u001b[0m         all_labels\u001b[38;5;241m.\u001b[39mextend(labels\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy())\n\u001b[1;32m     17\u001b[0m accuracy \u001b[38;5;241m=\u001b[39m accuracy_score(all_labels, all_preds)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":94},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 1).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 1.0)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 1000, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T02:29:07.093907Z","iopub.execute_input":"2025-01-23T02:29:07.094839Z","iopub.status.idle":"2025-01-23T02:34:31.277009Z","shell.execute_reply.started":"2025-01-23T02:29:07.094789Z","shell.execute_reply":"2025-01-23T02:34:31.276190Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"here\nLearning Rate: 0.0009993501949642546\nEpoch 1, Training Loss: 0.32546490229846003, Validation Loss: 0.2659295236745529\nEpoch 1, Training Loss: 0.26357052380919055, Validation Loss: 0.2659295236745529\nTraining Accuracy: 0.902354359767609, Training F1 Score: 0.8975328304177069\nValidation Accuracy: 0.9020059191055574, Validation F1 Score: 0.8970952198205078\n\nLearning Rate: 0.0009444510414519056\nEpoch 11, Training Loss: 0.20728066678364604, Validation Loss: 0.21831160964417534\nEpoch 11, Training Loss: 0.20480267187329348, Validation Loss: 0.21831160964417534\nTraining Accuracy: 0.9343994738316505, Training F1 Score: 0.9313326827915461\nValidation Accuracy: 0.9296284117066754, Validation F1 Score: 0.9262941965161179\n\nLearning Rate: 0.0008925677647278533\nEpoch 21, Training Loss: 0.20160902751758486, Validation Loss: 0.21422199292734606\nEpoch 21, Training Loss: 0.19994564647568017, Validation Loss: 0.21422199292734606\nTraining Accuracy: 0.9369694164646846, Training F1 Score: 0.9338666993206033\nValidation Accuracy: 0.932916803682999, Validation F1 Score: 0.9296011785940732\n\nLearning Rate: 0.0008435346880517426\nEpoch 31, Training Loss: 0.1991788623480074, Validation Loss: 0.21328766441464123\nEpoch 31, Training Loss: 0.1968338370741342, Validation Loss: 0.21328766441464123\nTraining Accuracy: 0.9387598504317747, Training F1 Score: 0.9357557485409316\nValidation Accuracy: 0.9342321604735284, Validation F1 Score: 0.9309815476412482\n\nLearning Rate: 0.0007971952361101733\nEpoch 41, Training Loss: 0.1968815051887729, Validation Loss: 0.2134673720511326\nEpoch 41, Training Loss: 0.19652451917516583, Validation Loss: 0.2134673720511326\nTraining Accuracy: 0.93893036795245, Training F1 Score: 0.9360248204887816\nValidation Accuracy: 0.9333552559465088, Validation F1 Score: 0.9301523400022995\n\nLearning Rate: 0.0007534014350311721\nEpoch 51, Training Loss: 0.1951139331446184, Validation Loss: 0.21351176888733908\nEpoch 51, Training Loss: 0.19617996625683465, Validation Loss: 0.21351176888733908\nTraining Accuracy: 0.939514999451908, Training F1 Score: 0.9367394928042072\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9297030907929682\n\nLearning Rate: 0.0007120134398652936\nEpoch 61, Training Loss: 0.19348071887639984, Validation Loss: 0.2144445984735701\nEpoch 61, Training Loss: 0.19644919337392086, Validation Loss: 0.2144445984735701\nTraining Accuracy: 0.9390034468898822, Training F1 Score: 0.936381023728909\nValidation Accuracy: 0.9328071906171216, Validation F1 Score: 0.9298829889881012\n\nLearning Rate: 0.000672899088024477\nEpoch 71, Training Loss: 0.19209687464636035, Validation Loss: 0.21274825175002154\nEpoch 71, Training Loss: 0.19374521649872015, Validation Loss: 0.21274825175002154\nTraining Accuracy: 0.9396124380351509, Training F1 Score: 0.9370117484305133\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9307539019473848\n\nLearning Rate: 0.0006359334772526728\nEpoch 81, Training Loss: 0.19104639374938148, Validation Loss: 0.2122356631061846\nEpoch 81, Training Loss: 0.19309628309187826, Validation Loss: 0.2122356631061846\nTraining Accuracy: 0.9394541003373811, Training F1 Score: 0.9369099893259573\nValidation Accuracy: 0.9334648690123862, Validation F1 Score: 0.9306134341649998\n\nLearning Rate: 0.0006009985667805884\nEpoch 91, Training Loss: 0.18994210199010375, Validation Loss: 0.2109765816183058\nEpoch 91, Training Loss: 0.19139361323307647, Validation Loss: 0.2109765816183058\nTraining Accuracy: 0.9397220564412994, Training F1 Score: 0.9371116434767452\nValidation Accuracy: 0.9336840951441412, Validation F1 Score: 0.9308200750294525\n\nLearning Rate: 0.0005679828003909402\nEpoch 101, Training Loss: 0.18879629085222574, Validation Loss: 0.20932741890145173\nEpoch 101, Training Loss: 0.18945543754957883, Validation Loss: 0.20932741890145173\nTraining Accuracy: 0.9404163063469058, Training F1 Score: 0.937668782609331\nValidation Accuracy: 0.9344513866052834, Validation F1 Score: 0.9315003265948452\n\nLearning Rate: 0.0005367807501905584\nEpoch 111, Training Loss: 0.18741611984907652, Validation Loss: 0.20678598904549572\nEpoch 111, Training Loss: 0.18696268115997075, Validation Loss: 0.20678598904549572\nTraining Accuracy: 0.9413541527106196, Training F1 Score: 0.9385273610509716\nValidation Accuracy: 0.9356571303299354, Validation F1 Score: 0.9326846888996285\n\nLearning Rate: 0.000507292779951818\nEpoch 121, Training Loss: 0.185908839280975, Validation Loss: 0.2045497107855991\nEpoch 121, Training Loss: 0.18487765136040132, Validation Loss: 0.2045497107855991\nTraining Accuracy: 0.9423772578346711, Training F1 Score: 0.9395012135314295\nValidation Accuracy: 0.9370821001863422, Validation F1 Score: 0.9340368645955388\n\nLearning Rate: 0.0004794247269483588\nEpoch 131, Training Loss: 0.18497258210868817, Validation Loss: 0.2031205449448099\nEpoch 131, Training Loss: 0.18356981852404575, Validation Loss: 0.2031205449448099\nTraining Accuracy: 0.9430836875631828, Training F1 Score: 0.9401775173832998\nValidation Accuracy: 0.9385070700427491, Validation F1 Score: 0.9354360936224223\n\nLearning Rate: 0.00045308760126911145\nEpoch 141, Training Loss: 0.18399146805396535, Validation Loss: 0.201853610301611\nEpoch 141, Training Loss: 0.1824965294341943, Validation Loss: 0.201853610301611\nTraining Accuracy: 0.9435343410106817, Training F1 Score: 0.9406175166638641\nValidation Accuracy: 0.9388359092403814, Validation F1 Score: 0.9357497875353745\n\nLearning Rate: 0.0004281973016504632\nEpoch 151, Training Loss: 0.18319141594496485, Validation Loss: 0.2005117065868892\nEpoch 151, Training Loss: 0.18113499771394667, Validation Loss: 0.2005117065868892\nTraining Accuracy: 0.943997174281086, Training F1 Score: 0.9410371749008762\nValidation Accuracy: 0.938726296174504, Validation F1 Score: 0.9354752592838788\n\nLearning Rate: 0.0004046743469191408\nEpoch 161, Training Loss: 0.1823625396541249, Validation Loss: 0.19909056073627776\nEpoch 161, Training Loss: 0.18002605170983238, Validation Loss: 0.19909056073627776\nTraining Accuracy: 0.9444112882598688, Training F1 Score: 0.9413714437459318\nValidation Accuracy: 0.9391647484380138, Validation F1 Score: 0.9358303056562568\n\nLearning Rate: 0.0003824436221882389\nEpoch 171, Training Loss: 0.18152597398242812, Validation Loss: 0.19812824096639703\nEpoch 171, Training Loss: 0.1792577166506523, Validation Loss: 0.19812824096639703\nTraining Accuracy: 0.9447888627699353, Training F1 Score: 0.9417404697145465\nValidation Accuracy: 0.9392743615038912, Validation F1 Score: 0.9359137991532215\n\nLearning Rate: 0.00036143413899593124\nEpoch 181, Training Loss: 0.18087215901322076, Validation Loss: 0.19740403765102207\nEpoch 181, Training Loss: 0.17858561131073092, Validation Loss: 0.19740403765102207\nTraining Accuracy: 0.9450446390509482, Training F1 Score: 0.9420006641374787\nValidation Accuracy: 0.9396032007015236, Validation F1 Score: 0.9362714969914336\n\nLearning Rate: 0.0003415788086209259\nEpoch 191, Training Loss: 0.18024004269594798, Validation Loss: 0.19707604515393104\nEpoch 191, Training Loss: 0.178089943926844, Validation Loss: 0.19707604515393104\nTraining Accuracy: 0.9452638758632449, Training F1 Score: 0.9422363412659602\nValidation Accuracy: 0.9396032007015236, Validation F1 Score: 0.9362714969914336\n\nLearning Rate: 0.00032281422785080234\nEpoch 201, Training Loss: 0.17974336925563386, Validation Loss: 0.19681052095917748\nEpoch 201, Training Loss: 0.17777230922905576, Validation Loss: 0.19681052095917748\nTraining Accuracy: 0.9452029767487181, Training F1 Score: 0.9421838943337414\nValidation Accuracy: 0.9391647484380138, Validation F1 Score: 0.9358303056562568\n\nLearning Rate: 0.0003050804765191328\nEpoch 211, Training Loss: 0.1792659138880852, Validation Loss: 0.19675034177116457\nEpoch 211, Training Loss: 0.1776991394185518, Validation Loss: 0.19675034177116457\nTraining Accuracy: 0.9451664372800019, Training F1 Score: 0.9421935976318317\nValidation Accuracy: 0.9394935876356462, Validation F1 Score: 0.9362726943922279\n\nLearning Rate: 0.0002883209261648713\nEpoch 221, Training Loss: 0.17894167028183394, Validation Loss: 0.19690476903969764\nEpoch 221, Training Loss: 0.17780453425269702, Validation Loss: 0.19690476903969764\nTraining Accuracy: 0.9448497618844622, Training F1 Score: 0.9419284110571203\nValidation Accuracy: 0.9391647484380138, Validation F1 Score: 0.9359793786304142\n\nLearning Rate: 0.0002724820592030111\nEpoch 231, Training Loss: 0.17859198737373588, Validation Loss: 0.1974014394392795\nEpoch 231, Training Loss: 0.17829488190806275, Validation Loss: 0.1974014394392795\nTraining Accuracy: 0.9446305250721655, Training F1 Score: 0.9417852465919028\nValidation Accuracy: 0.9392743615038912, Validation F1 Score: 0.9361894221497423\n\nLearning Rate: 0.00025751329802907436\nEpoch 241, Training Loss: 0.17828075292641044, Validation Loss: 0.19797548996824635\nEpoch 241, Training Loss: 0.17880186660254802, Validation Loss: 0.19797548996824635\nTraining Accuracy: 0.9443869286140579, Training F1 Score: 0.9416186193401646\nValidation Accuracy: 0.9390551353721364, Validation F1 Score: 0.9360219958379473\n\nLearning Rate: 0.0002433668435117216\nEpoch 251, Training Loss: 0.17807716592566816, Validation Loss: 0.1983341805495597\nEpoch 251, Training Loss: 0.17910463133914625, Validation Loss: 0.1983341805495597\nTraining Accuracy: 0.9442529505620988, Training F1 Score: 0.9415214878306472\nValidation Accuracy: 0.9391647484380138, Validation F1 Score: 0.9361683514594615\n\nLearning Rate: 0.00022999752235774545\nEpoch 261, Training Loss: 0.177856996436583, Validation Loss: 0.1984810245431699\nEpoch 261, Training Loss: 0.17916810031639385, Validation Loss: 0.1984810245431699\nTraining Accuracy: 0.9442042312704774, Training F1 Score: 0.941504253215266\nValidation Accuracy: 0.9392743615038912, Validation F1 Score: 0.9363352316828023\n\nLearning Rate: 0.00021736264286204536\nEpoch 271, Training Loss: 0.17762917749230808, Validation Loss: 0.19830168074132265\nEpoch 271, Training Loss: 0.17887367130221718, Validation Loss: 0.19830168074132265\nTraining Accuracy: 0.9442407707391934, Training F1 Score: 0.941524591445162\nValidation Accuracy: 0.9393839745697687, Validation F1 Score: 0.9364398133602657\n\nLearning Rate: 0.00020542185858195608\nEpoch 281, Training Loss: 0.17741819767127665, Validation Loss: 0.19805830618758402\nEpoch 281, Training Loss: 0.17850393048593402, Validation Loss: 0.19805830618758402\nTraining Accuracy: 0.9445209066660171, Training F1 Score: 0.9418004646182565\nValidation Accuracy: 0.9397128137674011, Validation F1 Score: 0.9367743348340434\n\nLearning Rate: 0.0001941370395006067\nEpoch 291, Training Loss: 0.1772199809638719, Validation Loss: 0.19803490616061847\nEpoch 291, Training Loss: 0.17843437648975416, Validation Loss: 0.19803490616061847\nTraining Accuracy: 0.9443869286140579, Training F1 Score: 0.9416778690560529\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9368995615457251\n\nLearning Rate: 0.00018347215026790086\nEpoch 301, Training Loss: 0.17708623364896078, Validation Loss: 0.19842601483960326\nEpoch 301, Training Loss: 0.17882284838726445, Validation Loss: 0.19842601483960326\nTraining Accuracy: 0.9442529505620988, Training F1 Score: 0.941589066398466\nValidation Accuracy: 0.9396032007015236, Validation F1 Score: 0.9367313473299093\n\nLearning Rate: 0.00017339313513031087\nEpoch 311, Training Loss: 0.17698106066448968, Validation Loss: 0.19927851524835719\nEpoch 311, Training Loss: 0.17964894453864289, Validation Loss: 0.19927851524835719\nTraining Accuracy: 0.944033713749802, Training F1 Score: 0.9414561382516905\nValidation Accuracy: 0.9391647484380138, Validation F1 Score: 0.9363748331174857\n\nLearning Rate: 0.00016386780918203618\nEpoch 321, Training Loss: 0.1769431651541692, Validation Loss: 0.2003666912285654\nEpoch 321, Training Loss: 0.18075586813123543, Validation Loss: 0.2003666912285654\nTraining Accuracy: 0.943704858531357, Training F1 Score: 0.9412180119813752\nValidation Accuracy: 0.9389455223062589, Validation F1 Score: 0.9363087302337274\n\nLearning Rate: 0.00015486575559026328\nEpoch 331, Training Loss: 0.17692679930155503, Validation Loss: 0.20125209104429403\nEpoch 331, Training Loss: 0.18163010642053543, Validation Loss: 0.20125209104429403\nTraining Accuracy: 0.943254205083858, Training F1 Score: 0.9408406258693764\nValidation Accuracy: 0.9385070700427491, Validation F1 Score: 0.9359932683342006\n\nLearning Rate: 0.00014635822846634065\nEpoch 341, Training Loss: 0.17683716683869483, Validation Loss: 0.20121510603063844\nEpoch 341, Training Loss: 0.1815312253512394, Validation Loss: 0.20121510603063844\nTraining Accuracy: 0.9433638234900065, Training F1 Score: 0.9409497036028919\nValidation Accuracy: 0.9386166831086266, Validation F1 Score: 0.9361374956417542\n\nLearning Rate: 0.00013831806107271095\nEpoch 351, Training Loss: 0.1766559694022637, Validation Loss: 0.20041270932025662\nEpoch 351, Training Loss: 0.18069307847419275, Validation Loss: 0.20041270932025662\nTraining Accuracy: 0.9437292181771677, Training F1 Score: 0.9412746816918105\nValidation Accuracy: 0.9388359092403814, Validation F1 Score: 0.9362853320505895\n\nLearning Rate: 0.00013071957907248198\nEpoch 361, Training Loss: 0.17645197862094353, Validation Loss: 0.1995868016449647\nEpoch 361, Training Loss: 0.17981284372063414, Validation Loss: 0.1995868016449647\nTraining Accuracy: 0.943997174281086, Training F1 Score: 0.9414837354096169\nValidation Accuracy: 0.9388359092403814, Validation F1 Score: 0.9361842334793107\n\nLearning Rate: 0.00012353851854461913\nEpoch 371, Training Loss: 0.17625089457025975, Validation Loss: 0.1987261905307429\nEpoch 371, Training Loss: 0.17900985405432554, Validation Loss: 0.1987261905307429\nTraining Accuracy: 0.9444112882598688, Training F1 Score: 0.9418521424516582\nValidation Accuracy: 0.9389455223062589, Validation F1 Score: 0.9362274282138218\n\nLearning Rate: 0.00011675194850296142\nEpoch 381, Training Loss: 0.17606049070285332, Validation Loss: 0.19807296470142463\nEpoch 381, Training Loss: 0.17833172194018584, Validation Loss: 0.19807296470142463\nTraining Accuracy: 0.9446914241866923, Training F1 Score: 0.9421026599181153\nValidation Accuracy: 0.9391647484380138, Validation F1 Score: 0.9363952821475541\n\nLearning Rate: 0.00011033819767164328\nEpoch 391, Training Loss: 0.17588504585096212, Validation Loss: 0.19746090027796756\nEpoch 391, Training Loss: 0.17773265813823774, Validation Loss: 0.19746090027796756\nTraining Accuracy: 0.9448619417073676, Training F1 Score: 0.9422396443191787\nValidation Accuracy: 0.9392743615038912, Validation F1 Score: 0.9364177470885363\n\nLearning Rate: 0.00010427678528309803\nEpoch 401, Training Loss: 0.17573111518100762, Validation Loss: 0.19696557486702787\nEpoch 401, Training Loss: 0.1772007517385121, Validation Loss: 0.19696557486702787\nTraining Accuracy: 0.9450568188738536, Training F1 Score: 0.942404340138156\nValidation Accuracy: 0.9390551353721364, Validation F1 Score: 0.936105394974076\n\nLearning Rate: 9.854835567766246e-05\nEpoch 411, Training Loss: 0.1755881264086898, Validation Loss: 0.19655603588208886\nEpoch 411, Training Loss: 0.17675236589554064, Validation Loss: 0.19655603588208886\nTraining Accuracy: 0.9451786171029073, Training F1 Score: 0.9425008395144776\nValidation Accuracy: 0.9390551353721364, Validation F1 Score: 0.936105394974076\n\nLearning Rate: 9.313461649594241e-05\nEpoch 421, Training Loss: 0.17545226558159238, Validation Loss: 0.1961793212919764\nEpoch 421, Training Loss: 0.1763779050330434, Validation Loss: 0.1961793212919764\nTraining Accuracy: 0.9452882355090557, Training F1 Score: 0.9425898118976775\nValidation Accuracy: 0.9392743615038912, Validation F1 Score: 0.9362729623220859\n\nLearning Rate: 8.80182802665715e-05\nEpoch 431, Training Loss: 0.1753342243590085, Validation Loss: 0.19586384390335548\nEpoch 431, Training Loss: 0.1760652821023312, Validation Loss: 0.19586384390335548\nTraining Accuracy: 0.9454831126755417, Training F1 Score: 0.9427589639363013\nValidation Accuracy: 0.9396032007015236, Validation F1 Score: 0.9365869653938587\n\nLearning Rate: 8.318300920283764e-05\nEpoch 441, Training Loss: 0.17522833992907472, Validation Loss: 0.1956300201870613\nEpoch 441, Training Loss: 0.17583158839100013, Validation Loss: 0.1956300201870613\nTraining Accuracy: 0.9455074723213525, Training F1 Score: 0.9427699626770342\nValidation Accuracy: 0.9397128137674011, Validation F1 Score: 0.9366709375348673\n\nLearning Rate: 7.861336303189846e-05\nEpoch 451, Training Loss: 0.1751272885620862, Validation Loss: 0.1954280438097007\nEpoch 451, Training Loss: 0.1756361150659034, Validation Loss: 0.1954280438097007\nTraining Accuracy: 0.9455927310816901, Training F1 Score: 0.9428438873472655\nValidation Accuracy: 0.9397128137674011, Validation F1 Score: 0.9366709375348673\n\nLearning Rate: 7.429474968999126e-05\nEpoch 461, Training Loss: 0.17503401927212847, Validation Loss: 0.19529376774585314\nEpoch 461, Training Loss: 0.175488681411307, Validation Loss: 0.19529376774585314\nTraining Accuracy: 0.9456779898420277, Training F1 Score: 0.9429282510028941\nValidation Accuracy: 0.9398224268332785, Validation F1 Score: 0.9367757101699264\n\nLearning Rate: 7.021337872619387e-05\nEpoch 471, Training Loss: 0.17495241652402224, Validation Loss: 0.19517962087060517\nEpoch 471, Training Loss: 0.17536011930084267, Validation Loss: 0.19517962087060517\nTraining Accuracy: 0.9457754284252707, Training F1 Score: 0.9430181474336182\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9370902000501986\n\nLearning Rate: 6.635621726594329e-05\nEpoch 481, Training Loss: 0.17487553438185605, Validation Loss: 0.19505465006659745\nEpoch 481, Training Loss: 0.17523108576517493, Validation Loss: 0.19505465006659745\nTraining Accuracy: 0.9457754284252707, Training F1 Score: 0.9430160669348866\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9370694889956289\n\nLearning Rate: 6.271094839369167e-05\nEpoch 491, Training Loss: 0.17479997318843618, Validation Loss: 0.1949137899353749\nEpoch 491, Training Loss: 0.1751117566209437, Validation Loss: 0.1949137899353749\nTraining Accuracy: 0.9458972266543244, Training F1 Score: 0.943131599674985\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.93717439606892\n\nLearning Rate: 5.926593182180475e-05\nEpoch 501, Training Loss: 0.17473223050541617, Validation Loss: 0.19478051691584244\nEpoch 501, Training Loss: 0.1749921117095946, Validation Loss: 0.19478051691584244\nTraining Accuracy: 0.9459215863001352, Training F1 Score: 0.9431343268877725\nValidation Accuracy: 0.9401512660309109, Validation F1 Score: 0.9370279568748059\n\nLearning Rate: 5.60101667201088e-05\nEpoch 511, Training Loss: 0.17466388585708226, Validation Loss: 0.19467391804633244\nEpoch 511, Training Loss: 0.17487381606887173, Validation Loss: 0.19467391804633244\nTraining Accuracy: 0.9459946652375675, Training F1 Score: 0.9432028522413715\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9372170970492827\n\nLearning Rate: 5.293325658739052e-05\nEpoch 521, Training Loss: 0.1746019008818009, Validation Loss: 0.19455153052513893\nEpoch 521, Training Loss: 0.17476760108318493, Validation Loss: 0.19455153052513893\nTraining Accuracy: 0.9459459459459459, Training F1 Score: 0.9431411956208581\nValidation Accuracy: 0.9402608790967883, Validation F1 Score: 0.9370912635236386\n\nLearning Rate: 5.002537605267601e-05\nEpoch 531, Training Loss: 0.1745425430371561, Validation Loss: 0.1944503861290706\nEpoch 531, Training Loss: 0.1746759612232161, Validation Loss: 0.1944503861290706\nTraining Accuracy: 0.9459215863001352, Training F1 Score: 0.9431009619234045\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.9371754231142516\n\nLearning Rate: 4.727723950027649e-05\nEpoch 541, Training Loss: 0.17448373350235608, Validation Loss: 0.194361557852251\nEpoch 541, Training Loss: 0.17458878096210817, Validation Loss: 0.194361557852251\nTraining Accuracy: 0.9459703055917567, Training F1 Score: 0.9431438721994374\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9372596146181122\n\nLearning Rate: 4.4680071418412456e-05\nEpoch 551, Training Loss: 0.17442858010211407, Validation Loss: 0.19428603017256996\nEpoch 551, Training Loss: 0.17450433616075378, Validation Loss: 0.19428603017256996\nTraining Accuracy: 0.9459946652375675, Training F1 Score: 0.943159063984539\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9372387051158997\n\nLearning Rate: 4.222557837673163e-05\nEpoch 561, Training Loss: 0.17437632980663118, Validation Loss: 0.1941959011075163\nEpoch 561, Training Loss: 0.17441972708944709, Validation Loss: 0.1941959011075163\nTraining Accuracy: 0.9460799239979051, Training F1 Score: 0.9432373192301449\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9373229116471071\n\nLearning Rate: 3.990592254323792e-05\nEpoch 571, Training Loss: 0.17432957631072168, Validation Loss: 0.19410937052670504\nEpoch 571, Training Loss: 0.17433378081047995, Validation Loss: 0.19410937052670504\nTraining Accuracy: 0.9460799239979051, Training F1 Score: 0.9432289622581485\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9371967747120662\n\nLearning Rate: 3.771369665606381e-05\nEpoch 581, Training Loss: 0.17428005589043724, Validation Loss: 0.19402847484213132\nEpoch 581, Training Loss: 0.17423948221532162, Validation Loss: 0.19402847484213132\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.9433127595680346\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9373019479080251\n\nLearning Rate: 3.564190037016479e-05\nEpoch 591, Training Loss: 0.17423287996422185, Validation Loss: 0.1939462063886951\nEpoch 591, Training Loss: 0.174144124856389, Validation Loss: 0.1939462063886951\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.9432981195867605\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9372809469325918\n\nLearning Rate: 3.3683917903404465e-05\nEpoch 601, Training Loss: 0.17418824917151124, Validation Loss: 0.19387012618676255\nEpoch 601, Training Loss: 0.17404805737508136, Validation Loss: 0.19387012618676255\nTraining Accuracy: 0.9461042836437158, Training F1 Score: 0.9432064512179303\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9372809469325918\n\nLearning Rate: 3.183349691064877e-05\nEpoch 611, Training Loss: 0.17414329894424355, Validation Loss: 0.19380100251590032\nEpoch 611, Training Loss: 0.17395710006826126, Validation Loss: 0.19380100251590032\nTraining Accuracy: 0.9461286432895266, Training F1 Score: 0.9432195272804641\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9372809469325918\n\nLearning Rate: 3.0084728518408545e-05\nEpoch 621, Training Loss: 0.17410152338320592, Validation Loss: 0.19372665160164607\nEpoch 621, Training Loss: 0.17387284549587517, Validation Loss: 0.19372665160164607\nTraining Accuracy: 0.9461164634666211, Training F1 Score: 0.943197232821694\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9371335994171256\n\nLearning Rate: 2.8432028456276142e-05\nEpoch 631, Training Loss: 0.1740625288331616, Validation Loss: 0.19366853966676886\nEpoch 631, Training Loss: 0.1737976819993709, Validation Loss: 0.19366853966676886\nTraining Accuracy: 0.946140823112432, Training F1 Score: 0.9432081914271266\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9372388329541037\n\nLearning Rate: 2.687011922490364e-05\nEpoch 641, Training Loss: 0.1740234442561683, Validation Loss: 0.19360751748757968\nEpoch 641, Training Loss: 0.1737308111880965, Validation Loss: 0.19360751748757968\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9432157732932973\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9372388329541037\n\nLearning Rate: 2.539401324358058e-05\nEpoch 651, Training Loss: 0.17398627849747134, Validation Loss: 0.19355164847718406\nEpoch 651, Training Loss: 0.17367097351292116, Validation Loss: 0.19355164847718406\nTraining Accuracy: 0.9460799239979051, Training F1 Score: 0.9431302734069577\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9371124660825385\n\nLearning Rate: 2.3998996923596954e-05\nEpoch 661, Training Loss: 0.17394910615909034, Validation Loss: 0.19348985803476174\nEpoch 661, Training Loss: 0.17362020696023175, Validation Loss: 0.19348985803476174\nTraining Accuracy: 0.9460799239979051, Training F1 Score: 0.9431239430461396\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 2.268061561653365e-05\nEpoch 671, Training Loss: 0.173914462625788, Validation Loss: 0.19344972503116017\nEpoch 671, Training Loss: 0.17357817007885715, Validation Loss: 0.19344972503116017\nTraining Accuracy: 0.9461164634666211, Training F1 Score: 0.9431529895412464\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 2.1434659389416294e-05\nEpoch 681, Training Loss: 0.17388135105465488, Validation Loss: 0.1934120831789579\nEpoch 681, Training Loss: 0.17354127561737656, Validation Loss: 0.1934120831789579\nTraining Accuracy: 0.9461286432895266, Training F1 Score: 0.9431605611553985\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 2.025714958130887e-05\nEpoch 691, Training Loss: 0.17384828771868746, Validation Loss: 0.19337542076082354\nEpoch 691, Training Loss: 0.17350965110564925, Validation Loss: 0.19337542076082354\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.943199298145835\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 1.9144326098418903e-05\nEpoch 701, Training Loss: 0.17381740961170164, Validation Loss: 0.19334626054242424\nEpoch 701, Training Loss: 0.17348288705313017, Validation Loss: 0.19334626054242424\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.9431929592603232\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 1.8092635407144095e-05\nEpoch 711, Training Loss: 0.17378759026667517, Validation Loss: 0.19332020502987887\nEpoch 711, Training Loss: 0.17346001827101057, Validation Loss: 0.19332020502987887\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431651341480695\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 1.7098719186719192e-05\nEpoch 721, Training Loss: 0.17375980704754565, Validation Loss: 0.1933029205910433\nEpoch 721, Training Loss: 0.17344117374690549, Validation Loss: 0.1933029205910433\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431609033923115\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 1.6159403605227943e-05\nEpoch 731, Training Loss: 0.1737324929459296, Validation Loss: 0.1932826574602292\nEpoch 731, Training Loss: 0.17342241708816172, Validation Loss: 0.1932826574602292\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431609033923115\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 1.527168918473579e-05\nEpoch 741, Training Loss: 0.17370677599114534, Validation Loss: 0.19325662177833147\nEpoch 741, Training Loss: 0.1734063359513047, Validation Loss: 0.19325662177833147\nTraining Accuracy: 0.946140823112432, Training F1 Score: 0.9431427547878323\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370912951628106\n\nLearning Rate: 1.4432741223179953e-05\nEpoch 751, Training Loss: 0.17368153732546734, Validation Loss: 0.19323662901302316\nEpoch 751, Training Loss: 0.17339193591890417, Validation Loss: 0.19323662901302316\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.94315455412834\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370700865773836\n\nLearning Rate: 1.3639880742431556e-05\nEpoch 761, Training Loss: 0.17365840036473423, Validation Loss: 0.19321779468682046\nEpoch 761, Training Loss: 0.17337871546560352, Validation Loss: 0.19321779468682046\nTraining Accuracy: 0.9461286432895266, Training F1 Score: 0.9431309558217168\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370700865773836\n\nLearning Rate: 1.2890575933624603e-05\nEpoch 771, Training Loss: 0.17363585460475378, Validation Loss: 0.19319682817154388\nEpoch 771, Training Loss: 0.17336694330070324, Validation Loss: 0.19319682817154388\nTraining Accuracy: 0.946140823112432, Training F1 Score: 0.9431427547878323\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370700865773836\n\nLearning Rate: 1.218243407243453e-05\nEpoch 781, Training Loss: 0.17361447137092503, Validation Loss: 0.19318069790383904\nEpoch 781, Training Loss: 0.17335618207240897, Validation Loss: 0.19318069790383904\nTraining Accuracy: 0.9461286432895266, Training F1 Score: 0.9431309558217168\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370700865773836\n\nLearning Rate: 1.151319387848973e-05\nEpoch 791, Training Loss: 0.17359424614442268, Validation Loss: 0.19316690552754712\nEpoch 791, Training Loss: 0.17334655468485502, Validation Loss: 0.19316690552754712\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431566709671739\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370700865773836\n\nLearning Rate: 1.0880718294517635e-05\nEpoch 801, Training Loss: 0.17357534777990652, Validation Loss: 0.19315547868241922\nEpoch 801, Training Loss: 0.1733381581693692, Validation Loss: 0.19315547868241922\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.94315455412834\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370700865773836\n\nLearning Rate: 1.0282987662167367e-05\nEpoch 811, Training Loss: 0.1735575779753957, Validation Loss: 0.19314237036791781\nEpoch 811, Training Loss: 0.17333027350458696, Validation Loss: 0.19314237036791781\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.94315455412834\nValidation Accuracy: 0.9403704921626658, Validation F1 Score: 0.936943555553089\n\nLearning Rate: 9.718093272717521e-06\nEpoch 821, Training Loss: 0.17354039883278333, Validation Loss: 0.1931339859305852\nEpoch 821, Training Loss: 0.17332329496264148, Validation Loss: 0.1931339859305852\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.94315455412834\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 9.184231272074868e-06\nEpoch 831, Training Loss: 0.1735242609162279, Validation Loss: 0.19312439852216637\nEpoch 831, Training Loss: 0.17331684507878706, Validation Loss: 0.19312439852216637\nTraining Accuracy: 0.9461651827582427, Training F1 Score: 0.9431663538432992\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 8.679696900601022e-06\nEpoch 841, Training Loss: 0.17350886663427864, Validation Loss: 0.19311685289787014\nEpoch 841, Training Loss: 0.17331089735733146, Validation Loss: 0.19311685289787014\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.94315455412834\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 8.202879049373406e-06\nEpoch 851, Training Loss: 0.17349440950384012, Validation Loss: 0.19310997136424773\nEpoch 851, Training Loss: 0.1733057276036082, Validation Loss: 0.19310997136424773\nTraining Accuracy: 0.9461651827582427, Training F1 Score: 0.9431663538432992\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 7.752255115497165e-06\nEpoch 861, Training Loss: 0.17348078344921877, Validation Loss: 0.19310154308747998\nEpoch 861, Training Loss: 0.17330078072046004, Validation Loss: 0.19310154308747998\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.943152436871864\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 7.326386140039774e-06\nEpoch 871, Training Loss: 0.17346787050036264, Validation Loss: 0.19309711130443116\nEpoch 871, Training Loss: 0.17329657600962484, Validation Loss: 0.19309711130443116\nTraining Accuracy: 0.9461651827582427, Training F1 Score: 0.9431663538432992\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 6.923912213062478e-06\nEpoch 881, Training Loss: 0.17345556953671384, Validation Loss: 0.19309241720998443\nEpoch 881, Training Loss: 0.17329241703261183, Validation Loss: 0.19309241720998443\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431566709671739\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 6.543548131075642e-06\nEpoch 891, Training Loss: 0.17344382935641386, Validation Loss: 0.19308625621275854\nEpoch 891, Training Loss: 0.173288796559168, Validation Loss: 0.19308625621275854\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431566709671739\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 6.184079293051135e-06\nEpoch 901, Training Loss: 0.17343304874915066, Validation Loss: 0.1930819291919127\nEpoch 901, Training Loss: 0.1732853734223411, Validation Loss: 0.1930819291919127\nTraining Accuracy: 0.9461651827582427, Training F1 Score: 0.9431705865633628\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 5.844357821886669e-06\nEpoch 911, Training Loss: 0.1734225721509486, Validation Loss: 0.1930788243602899\nEpoch 911, Training Loss: 0.17328225881848244, Validation Loss: 0.1930788243602899\nTraining Accuracy: 0.9461651827582427, Training F1 Score: 0.9431705865633628\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9370488402454592\n\nLearning Rate: 5.523298898936912e-06\nEpoch 921, Training Loss: 0.17341268522060507, Validation Loss: 0.19307474529032356\nEpoch 921, Training Loss: 0.1732796335523286, Validation Loss: 0.19307474529032356\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431587873884647\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9371753807164964\n\nLearning Rate: 5.2198772999065824e-06\nEpoch 931, Training Loss: 0.1734034720834448, Validation Loss: 0.19307031814275596\nEpoch 931, Training Loss: 0.17327684679289151, Validation Loss: 0.19307031814275596\nTraining Accuracy: 0.9461530029353373, Training F1 Score: 0.9431587873884647\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9371753807164964\n\nLearning Rate: 4.933124121043744e-06\nEpoch 941, Training Loss: 0.1733946403238487, Validation Loss: 0.19306770350429214\nEpoch 941, Training Loss: 0.17327455601436598, Validation Loss: 0.19306770350429214\nTraining Accuracy: 0.9461651827582427, Training F1 Score: 0.9431705865633628\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9371753807164964\n\nLearning Rate: 4.662123685179178e-06\nEpoch 951, Training Loss: 0.17338636814230302, Validation Loss: 0.19306501324280279\nEpoch 951, Training Loss: 0.17327231307988764, Validation Loss: 0.19306501324280279\nTraining Accuracy: 0.9461651827582427, Training F1 Score: 0.9431705865633628\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9371753807164964\n\nLearning Rate: 4.406010617732021e-06\nEpoch 961, Training Loss: 0.17337857311244376, Validation Loss: 0.19306226404961377\nEpoch 961, Training Loss: 0.17327028821003637, Validation Loss: 0.19306226404961377\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.9431823861126309\nValidation Accuracy: 0.9406993313602982, Validation F1 Score: 0.9372807045539473\n\nLearning Rate: 4.163967083344597e-06\nEpoch 971, Training Loss: 0.1733711757134365, Validation Loss: 0.19305945468337\nEpoch 971, Training Loss: 0.17326848514611926, Validation Loss: 0.19305945468337\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.9431823861126309\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9371541546434461\n\nLearning Rate: 3.9352201743223e-06\nEpoch 981, Training Loss: 0.1733641364052878, Validation Loss: 0.19305638884499737\nEpoch 981, Training Loss: 0.17326671558154721, Validation Loss: 0.19305638884499737\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.9431823861126309\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9371541546434461\n\nLearning Rate: 3.719039442539144e-06\nEpoch 991, Training Loss: 0.1733574550041448, Validation Loss: 0.19305349863713658\nEpoch 991, Training Loss: 0.17326515841936788, Validation Loss: 0.19305349863713658\nTraining Accuracy: 0.946177362581148, Training F1 Score: 0.9431823861126309\nValidation Accuracy: 0.9405897182944207, Validation F1 Score: 0.9371541546434461\n\nBest Validation Loss after 1000 epochs: 0.19305349863713658 from Epoch 991\nExecution time: 324.174936 seconds\n","output_type":"stream"}],"execution_count":87},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 0.1)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 100, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 0.1)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 100, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T02:16:57.429612Z","iopub.execute_input":"2025-01-23T02:16:57.429987Z","iopub.status.idle":"2025-01-23T02:17:56.286370Z","shell.execute_reply.started":"2025-01-23T02:16:57.429955Z","shell.execute_reply":"2025-01-23T02:17:56.285392Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"here\nLearning Rate: 9.988006897470666e-05\nEpoch 1, Training Loss: 0.32685440889212714, Validation Loss: 0.257282424665098\nEpoch 1, Training Loss: 0.2592016404864994, Validation Loss: 0.257282424665098\nTraining Accuracy: 0.9026828917210147, Training F1 Score: 0.8963617331047248\nValidation Accuracy: 0.9036144578313253, Validation F1 Score: 0.8958853391757421\n\nLearning Rate: 9.387542204897366e-05\nEpoch 11, Training Loss: 0.21140293809030944, Validation Loss: 0.22028404990005077\nEpoch 11, Training Loss: 0.20871767396398924, Validation Loss: 0.22028404990005077\nTraining Accuracy: 0.932457121344657, Training F1 Score: 0.9286888325130336\nValidation Accuracy: 0.932092004381161, Validation F1 Score: 0.9274332304769843\n\nLearning Rate: 8.823176591021984e-05\nEpoch 21, Training Loss: 0.2023875090350066, Validation Loss: 0.21680489771663816\nEpoch 21, Training Loss: 0.19974285401390293, Validation Loss: 0.21680489771663816\nTraining Accuracy: 0.9368086543465504, Training F1 Score: 0.9333338854847838\nValidation Accuracy: 0.9309967141292442, Validation F1 Score: 0.9266466205116652\n\nLearning Rate: 8.292739830852181e-05\nEpoch 31, Training Loss: 0.19757817911283768, Validation Loss: 0.21883972542439992\nEpoch 31, Training Loss: 0.19621808189846054, Validation Loss: 0.21883972542439992\nTraining Accuracy: 0.9390121023551427, Training F1 Score: 0.9353271187296743\nValidation Accuracy: 0.9309967141292442, Validation F1 Score: 0.9261325467087682\n\nLearning Rate: 7.794192170218906e-05\nEpoch 41, Training Loss: 0.19448548185175665, Validation Loss: 0.21867109812298322\nEpoch 41, Training Loss: 0.19418035193192262, Validation Loss: 0.21867109812298322\nTraining Accuracy: 0.9396543133325214, Training F1 Score: 0.9359305987222775\nValidation Accuracy: 0.9331872946330778, Validation F1 Score: 0.9282218797052688\n\nLearning Rate: 7.325616482057046e-05\nEpoch 51, Training Loss: 0.19237598162228775, Validation Loss: 0.217288441996846\nEpoch 51, Training Loss: 0.19155710808926263, Validation Loss: 0.217288441996846\nTraining Accuracy: 0.9402411612946088, Training F1 Score: 0.9366773647991707\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.929271120379436\n\nLearning Rate: 6.885210894239297e-05\nEpoch 61, Training Loss: 0.19061629353089987, Validation Loss: 0.21577513417043404\nEpoch 61, Training Loss: 0.18960225038432454, Validation Loss: 0.21577513417043404\nTraining Accuracy: 0.9408058640505796, Training F1 Score: 0.9375181691912585\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.9295248740275966\n\nLearning Rate: 6.47128186061411e-05\nEpoch 71, Training Loss: 0.18897134575923483, Validation Loss: 0.2150773639257218\nEpoch 71, Training Loss: 0.18893050712436063, Validation Loss: 0.2150773639257218\nTraining Accuracy: 0.9412376955698515, Training F1 Score: 0.9381355170041719\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9310654176064025\n\nLearning Rate: 6.0822376486029175e-05\nEpoch 81, Training Loss: 0.18762868021866166, Validation Loss: 0.21472314945121193\nEpoch 81, Training Loss: 0.18831701479065918, Validation Loss: 0.21472314945121193\nTraining Accuracy: 0.941304131188201, Training F1 Score: 0.9382384929605958\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9310654176064025\n\nLearning Rate: 5.7165822183137205e-05\nEpoch 91, Training Loss: 0.18647189918246468, Validation Loss: 0.21442724503209531\nEpoch 91, Training Loss: 0.18671541165800923, Validation Loss: 0.21442724503209531\nTraining Accuracy: 0.941735962707473, Training F1 Score: 0.9385993854762744\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9310654176064025\n\nBest Validation Loss after 100 epochs: 0.21442724503209531 from Epoch 91\nExecution time: 58.850016 seconds\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 0.1)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 100, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T02:15:35.319504Z","iopub.execute_input":"2025-01-23T02:15:35.319839Z","iopub.status.idle":"2025-01-23T02:16:34.613484Z","shell.execute_reply.started":"2025-01-23T02:15:35.319811Z","shell.execute_reply":"2025-01-23T02:16:34.612614Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"here\nLearning Rate: 9.988006897470666e-05\nEpoch 1, Training Loss: 0.32683102810382714, Validation Loss: 0.25724726628108197\nEpoch 1, Training Loss: 0.25916707453942556, Validation Loss: 0.25724726628108197\nTraining Accuracy: 0.9026939643240729, Training F1 Score: 0.8963753450799378\nValidation Accuracy: 0.9036144578313253, Validation F1 Score: 0.8958853391757421\n\nLearning Rate: 9.387542204897366e-05\nEpoch 11, Training Loss: 0.21122512396874166, Validation Loss: 0.22014264380487922\nEpoch 11, Training Loss: 0.2085638572099276, Validation Loss: 0.22014264380487922\nTraining Accuracy: 0.9326896460088803, Training F1 Score: 0.9289523711871929\nValidation Accuracy: 0.932092004381161, Validation F1 Score: 0.9274332304769843\n\nLearning Rate: 8.823176591021984e-05\nEpoch 21, Training Loss: 0.20216124986696216, Validation Loss: 0.21774567759964056\nEpoch 21, Training Loss: 0.1997491588014111, Validation Loss: 0.21774567759964056\nTraining Accuracy: 0.9367754365373756, Training F1 Score: 0.9332525922781548\nValidation Accuracy: 0.9309967141292442, Validation F1 Score: 0.9266466205116652\n\nLearning Rate: 8.292739830852181e-05\nEpoch 31, Training Loss: 0.1973834289440491, Validation Loss: 0.21917235219661405\nEpoch 31, Training Loss: 0.19625192533696256, Validation Loss: 0.21917235219661405\nTraining Accuracy: 0.938591343438929, Training F1 Score: 0.9348921677632006\nValidation Accuracy: 0.9309967141292442, Validation F1 Score: 0.9261325467087682\n\nLearning Rate: 7.794192170218906e-05\nEpoch 41, Training Loss: 0.19448092512523799, Validation Loss: 0.21923675566813772\nEpoch 41, Training Loss: 0.1943708590332988, Validation Loss: 0.21923675566813772\nTraining Accuracy: 0.9394328612713563, Training F1 Score: 0.9356977118751157\nValidation Accuracy: 0.932092004381161, Validation F1 Score: 0.9271757031618502\n\nLearning Rate: 7.325616482057046e-05\nEpoch 51, Training Loss: 0.19241722967932398, Validation Loss: 0.21745428131222072\nEpoch 51, Training Loss: 0.19181706750256827, Validation Loss: 0.21745428131222072\nTraining Accuracy: 0.9401747256762593, Training F1 Score: 0.9365873242830216\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9305752606985389\n\nLearning Rate: 6.885210894239297e-05\nEpoch 61, Training Loss: 0.19060650702791992, Validation Loss: 0.21543450929379543\nEpoch 61, Training Loss: 0.1897051447153292, Validation Loss: 0.21543450929379543\nTraining Accuracy: 0.9405401215771816, Training F1 Score: 0.9372397906559371\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.9295248740275966\n\nLearning Rate: 6.47128186061411e-05\nEpoch 71, Training Loss: 0.18904418173675452, Validation Loss: 0.21491788254249006\nEpoch 71, Training Loss: 0.1891373846051585, Validation Loss: 0.21491788254249006\nTraining Accuracy: 0.9407062106230554, Training F1 Score: 0.9375989257433491\nValidation Accuracy: 0.9331872946330778, Validation F1 Score: 0.92847754522595\n\nLearning Rate: 6.0822376486029175e-05\nEpoch 81, Training Loss: 0.18771868780460407, Validation Loss: 0.2143030658707039\nEpoch 81, Training Loss: 0.18828014034743684, Validation Loss: 0.2143030658707039\nTraining Accuracy: 0.94099409830257, Training F1 Score: 0.9379433132626931\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9310654176064025\n\nLearning Rate: 5.7165822183137205e-05\nEpoch 91, Training Loss: 0.18649425807429829, Validation Loss: 0.21314904258585446\nEpoch 91, Training Loss: 0.18667759193440794, Validation Loss: 0.21314904258585446\nTraining Accuracy: 0.9415809462646574, Training F1 Score: 0.9384463625750341\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9310654176064025\n\nBest Validation Loss after 100 epochs: 0.21314904258585446 from Epoch 91\nExecution time: 59.288362 seconds\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 0.1)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 100, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T02:14:16.855159Z","iopub.execute_input":"2025-01-23T02:14:16.855815Z","iopub.status.idle":"2025-01-23T02:15:13.804131Z","shell.execute_reply.started":"2025-01-23T02:14:16.855783Z","shell.execute_reply":"2025-01-23T02:15:13.803246Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"here\nLearning Rate: 9.988006897470666e-05\nEpoch 1, Training Loss: 0.3291932054214368, Validation Loss: 0.2653030287984428\nEpoch 1, Training Loss: 0.26775688525463903, Validation Loss: 0.2653030287984428\nTraining Accuracy: 0.8969251381307232, Training F1 Score: 0.8884591794766488\nValidation Accuracy: 0.8893756845564075, Validation F1 Score: 0.8798373129465867\n\nLearning Rate: 9.387542204897366e-05\nEpoch 11, Training Loss: 0.21218193280767222, Validation Loss: 0.22185845713887\nEpoch 11, Training Loss: 0.20957746431130028, Validation Loss: 0.22185845713887\nTraining Accuracy: 0.932457121344657, Training F1 Score: 0.9291982888669961\nValidation Accuracy: 0.9299014238773274, Validation F1 Score: 0.925861893260901\n\nLearning Rate: 8.823176591021984e-05\nEpoch 21, Training Loss: 0.20438041422660602, Validation Loss: 0.2158162516642766\nEpoch 21, Training Loss: 0.20188207492690513, Validation Loss: 0.2158162516642766\nTraining Accuracy: 0.9356460310254338, Training F1 Score: 0.9326249312383817\nValidation Accuracy: 0.9309967141292442, Validation F1 Score: 0.9268968475599535\n\nLearning Rate: 8.292739830852181e-05\nEpoch 31, Training Loss: 0.1996128939425201, Validation Loss: 0.2128043286216742\nEpoch 31, Training Loss: 0.19736118020263912, Validation Loss: 0.2128043286216742\nTraining Accuracy: 0.9379602050646086, Training F1 Score: 0.9347068348383928\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9315383175561469\n\nLearning Rate: 7.794192170218906e-05\nEpoch 41, Training Loss: 0.19644126176587273, Validation Loss: 0.21155941677315473\nEpoch 41, Training Loss: 0.19493383172573084, Validation Loss: 0.21155941677315473\nTraining Accuracy: 0.9394217886682981, Training F1 Score: 0.9359866972113717\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9310654176064025\n\nLearning Rate: 7.325616482057046e-05\nEpoch 51, Training Loss: 0.19399223527755421, Validation Loss: 0.21124385374007584\nEpoch 51, Training Loss: 0.1931530767017124, Validation Loss: 0.21124385374007584\nTraining Accuracy: 0.9404072503404826, Training F1 Score: 0.9368739780176321\nValidation Accuracy: 0.9364731653888281, Validation F1 Score: 0.9318740448933436\n\nLearning Rate: 6.885210894239297e-05\nEpoch 61, Training Loss: 0.19235335353360933, Validation Loss: 0.21027797977934792\nEpoch 61, Training Loss: 0.19138220082318602, Validation Loss: 0.21027797977934792\nTraining Accuracy: 0.9411823325545603, Training F1 Score: 0.9378565777383655\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9310654176064025\n\nLearning Rate: 6.47128186061411e-05\nEpoch 71, Training Loss: 0.1906452030504448, Validation Loss: 0.21022295698866264\nEpoch 71, Training Loss: 0.1906558285459046, Validation Loss: 0.21022295698866264\nTraining Accuracy: 0.9414480750279584, Training F1 Score: 0.9383353267313396\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.9302593250621868\n\nLearning Rate: 6.0822376486029175e-05\nEpoch 81, Training Loss: 0.18910592902176337, Validation Loss: 0.20952592558367228\nEpoch 81, Training Loss: 0.18929367270343134, Validation Loss: 0.20952592558367228\nTraining Accuracy: 0.9421456490206283, Training F1 Score: 0.9390628370596694\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.9302593250621868\n\nLearning Rate: 5.7165822183137205e-05\nEpoch 91, Training Loss: 0.18795757749653969, Validation Loss: 0.20905283552075268\nEpoch 91, Training Loss: 0.18794787997088086, Validation Loss: 0.20905283552075268\nTraining Accuracy: 0.9424556819062594, Training F1 Score: 0.9393221345163403\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.931303977939496\n\nBest Validation Loss after 100 epochs: 0.20905283552075268 from Epoch 91\nExecution time: 56.942889 seconds\n","output_type":"stream"}],"execution_count":50},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 2).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 1.0)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 1000, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T02:03:43.744965Z","iopub.execute_input":"2025-01-23T02:03:43.745715Z","iopub.status.idle":"2025-01-23T02:06:01.752009Z","shell.execute_reply.started":"2025-01-23T02:03:43.745678Z","shell.execute_reply":"2025-01-23T02:06:01.750772Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"here\nLearning Rate: 0.0009988006897470665\nEpoch 1, Training Loss: 5.350201307207334, Validation Loss: 0.5957513029186253\nEpoch 1, Training Loss: 0.6417104434654475, Validation Loss: 0.5957513029186253\nTraining Accuracy: 0.8694650825462558, Training F1 Score: 0.8710187293421613\nValidation Accuracy: 0.8608981380065718, Validation F1 Score: 0.8624450227725788\n\nLearning Rate: 0.0009387542204897365\nEpoch 11, Training Loss: 0.2374368070791836, Validation Loss: 0.23177352914870242\nEpoch 11, Training Loss: 0.22682396977971253, Validation Loss: 0.23177352914870242\nTraining Accuracy: 0.926378262265676, Training F1 Score: 0.9221026871069838\nValidation Accuracy: 0.91894852135816, Validation F1 Score: 0.9130806779673695\n\nLearning Rate: 0.0008823176591021983\nEpoch 21, Training Loss: 0.22958999733777136, Validation Loss: 0.22737190346075437\nEpoch 21, Training Loss: 0.21862793333916145, Validation Loss: 0.22737190346075437\nTraining Accuracy: 0.9295450267403363, Training F1 Score: 0.9257459259884844\nValidation Accuracy: 0.9244249726177437, Validation F1 Score: 0.919381590082064\n\nLearning Rate: 0.0008292739830852182\nEpoch 31, Training Loss: 0.2236797522452403, Validation Loss: 0.22601285527857085\nEpoch 31, Training Loss: 0.21358806849989173, Validation Loss: 0.22601285527857085\nTraining Accuracy: 0.9303533267635888, Training F1 Score: 0.9269881952195619\nValidation Accuracy: 0.9233296823658269, Validation F1 Score: 0.9191821637723085\n\nLearning Rate: 0.0007794192170218906\nEpoch 41, Training Loss: 0.21967287520231207, Validation Loss: 0.22490953547147643\nEpoch 41, Training Loss: 0.21168817705703158, Validation Loss: 0.22490953547147643\nTraining Accuracy: 0.9299104226412588, Training F1 Score: 0.9273472656455055\nValidation Accuracy: 0.9255202628696605, Validation F1 Score: 0.922252913470046\n\nLearning Rate: 0.0007325616482057046\nEpoch 51, Training Loss: 0.21457593837184757, Validation Loss: 0.22967346578934367\nEpoch 51, Training Loss: 0.21763141015551854, Validation Loss: 0.22967346578934367\nTraining Accuracy: 0.9262675362350935, Training F1 Score: 0.9247685220928602\nValidation Accuracy: 0.9233296823658269, Validation F1 Score: 0.9209496594566784\n\nLearning Rate: 0.0006885210894239297\nEpoch 61, Training Loss: 0.20912591663952115, Validation Loss: 0.22554609238252712\nEpoch 61, Training Loss: 0.21414654479362144, Validation Loss: 0.22554609238252712\nTraining Accuracy: 0.9290799774118897, Training F1 Score: 0.9274483135717947\nValidation Accuracy: 0.9266155531215772, Validation F1 Score: 0.9239922034716775\n\nLearning Rate: 0.000647128186061411\nEpoch 71, Training Loss: 0.20527110430405446, Validation Loss: 0.22614994248516065\nEpoch 71, Training Loss: 0.21384188653258876, Validation Loss: 0.22614994248516065\nTraining Accuracy: 0.9294343007097539, Training F1 Score: 0.9278572324896875\nValidation Accuracy: 0.9244249726177437, Validation F1 Score: 0.9219614306457186\n\nLearning Rate: 0.0006082237648602917\nEpoch 81, Training Loss: 0.2020636679818297, Validation Loss: 0.22311330158243042\nEpoch 81, Training Loss: 0.2099252963593952, Validation Loss: 0.22311330158243042\nTraining Accuracy: 0.9318259829703365, Training F1 Score: 0.9300201343351401\nValidation Accuracy: 0.9255202628696605, Validation F1 Score: 0.9229756005221503\n\nLearning Rate: 0.000571658221831372\nEpoch 91, Training Loss: 0.19890905407599854, Validation Loss: 0.2207588039314107\nEpoch 91, Training Loss: 0.20617278013154608, Validation Loss: 0.2207588039314107\nTraining Accuracy: 0.9339297775514046, Training F1 Score: 0.931930518156571\nValidation Accuracy: 0.9288061336254108, Validation F1 Score: 0.9260328484436557\n\nLearning Rate: 0.00053729094696336\nEpoch 101, Training Loss: 0.19601216689114337, Validation Loss: 0.21986369444271558\nEpoch 101, Training Loss: 0.20372107969483444, Validation Loss: 0.21986369444271558\nTraining Accuracy: 0.9354024337581522, Training F1 Score: 0.9333453773591155\nValidation Accuracy: 0.9331872946330778, Validation F1 Score: 0.9301449003787772\n\nLearning Rate: 0.0005049897835177809\nEpoch 111, Training Loss: 0.19394418632827218, Validation Loss: 0.21636432595347\nEpoch 111, Training Loss: 0.20003894808411501, Validation Loss: 0.21636432595347\nTraining Accuracy: 0.937273703674997, Training F1 Score: 0.9350193171202034\nValidation Accuracy: 0.9299014238773274, Validation F1 Score: 0.9268262715012198\n\nLearning Rate: 0.00047463051983030275\nEpoch 121, Training Loss: 0.1922541971125184, Validation Loss: 0.2132277028290361\nEpoch 121, Training Loss: 0.19689628803950973, Validation Loss: 0.2132277028290361\nTraining Accuracy: 0.9390342475612592, Training F1 Score: 0.9365917374442961\nValidation Accuracy: 0.9299014238773274, Validation F1 Score: 0.9268262715012198\n\nLearning Rate: 0.00044609641166424\nEpoch 131, Training Loss: 0.19071688366749637, Validation Loss: 0.21136864205375558\nEpoch 131, Training Loss: 0.19458726141873012, Validation Loss: 0.21136864205375558\nTraining Accuracy: 0.9402300886915504, Training F1 Score: 0.9376907343440468\nValidation Accuracy: 0.9309967141292442, Validation F1 Score: 0.9278545692436548\n\nLearning Rate: 0.000419277733279481\nEpoch 141, Training Loss: 0.18996485052576373, Validation Loss: 0.21421627096448254\nEpoch 141, Training Loss: 0.19669216582669466, Validation Loss: 0.21421627096448254\nTraining Accuracy: 0.9398979105998029, Training F1 Score: 0.9375216551006685\nValidation Accuracy: 0.932092004381161, Validation F1 Score: 0.9291129505168066\n\nLearning Rate: 0.00039407135549051\nEpoch 151, Training Loss: 0.1895264483697152, Validation Loss: 0.21720827907030058\nEpoch 151, Training Loss: 0.19906074851304192, Validation Loss: 0.21720827907030058\nTraining Accuracy: 0.9385691982328126, Training F1 Score: 0.936401894161051\nValidation Accuracy: 0.9309967141292442, Validation F1 Score: 0.9280836500067985\n\nLearning Rate: 0.0003703803490909774\nEpoch 161, Training Loss: 0.18833123015178435, Validation Loss: 0.2083672065071574\nEpoch 161, Training Loss: 0.1897336458234693, Validation Loss: 0.2083672065071574\nTraining Accuracy: 0.942090286005337, Training F1 Score: 0.939430937789964\nValidation Accuracy: 0.932092004381161, Validation F1 Score: 0.9286540628918837\n\nLearning Rate: 0.00034811361211981793\nEpoch 171, Training Loss: 0.18738199850720486, Validation Loss: 0.2052369296616035\nEpoch 171, Training Loss: 0.18698171775459277, Validation Loss: 0.2052369296616035\nTraining Accuracy: 0.9431532558989293, Training F1 Score: 0.9403398410581147\nValidation Accuracy: 0.9331872946330778, Validation F1 Score: 0.929689427659645\n\nLearning Rate: 0.00032718551953559653\nEpoch 181, Training Loss: 0.18674622868375684, Validation Loss: 0.20368355275963118\nEpoch 181, Training Loss: 0.1856198604984701, Validation Loss: 0.20368355275963118\nTraining Accuracy: 0.9434743613876186, Training F1 Score: 0.9406031761533462\nValidation Accuracy: 0.9331872946330778, Validation F1 Score: 0.929689427659645\n\nLearning Rate: 0.00030751559395193187\nEpoch 191, Training Loss: 0.1862419054029144, Validation Loss: 0.20179359926582036\nEpoch 191, Training Loss: 0.18383565543168154, Validation Loss: 0.20179359926582036\nTraining Accuracy: 0.9441165723649972, Training F1 Score: 0.9410714826835899\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.930727568947693\n\nLearning Rate: 0.00028902819616783505\nEpoch 201, Training Loss: 0.18570943440787296, Validation Loss: 0.20118339576830868\nEpoch 201, Training Loss: 0.1835003939764736, Validation Loss: 0.20118339576830868\nTraining Accuracy: 0.9442494436016963, Training F1 Score: 0.9410499852567963\nValidation Accuracy: 0.9364731653888281, Validation F1 Score: 0.9328123407676917\n\nLearning Rate: 0.0002716522343029224\nEpoch 211, Training Loss: 0.18575463176463958, Validation Loss: 0.20045827451567008\nEpoch 211, Training Loss: 0.1830497242517496, Validation Loss: 0.20045827451567008\nTraining Accuracy: 0.9443490970292207, Training F1 Score: 0.941158366445104\nValidation Accuracy: 0.9364731653888281, Validation F1 Score: 0.9328123407676917\n\nLearning Rate: 0.0002553208904190028\nEpoch 221, Training Loss: 0.1853278958051217, Validation Loss: 0.20196336595931164\nEpoch 221, Training Loss: 0.1845619931137112, Validation Loss: 0.20196336595931164\nTraining Accuracy: 0.9440501367466477, Training F1 Score: 0.9411318498203389\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9317685265365231\n\nLearning Rate: 0.00023997136357678444\nEpoch 231, Training Loss: 0.18453586064919672, Validation Loss: 0.20226274435648128\nEpoch 231, Training Loss: 0.18449492205165804, Validation Loss: 0.20226274435648128\nTraining Accuracy: 0.9441387175711138, Training F1 Score: 0.9412446469525599\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.930727568947693\n\nLearning Rate: 0.00022554462833964523\nEpoch 241, Training Loss: 0.18396227643717608, Validation Loss: 0.2018250829059741\nEpoch 241, Training Loss: 0.183742677481335, Validation Loss: 0.2018250829059741\nTraining Accuracy: 0.9442715888078128, Training F1 Score: 0.9413589809527224\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.930727568947693\n\nLearning Rate: 0.0002119852077958107\nEpoch 251, Training Loss: 0.18338610530467178, Validation Loss: 0.20050051542323363\nEpoch 251, Training Loss: 0.18241103866903954, Validation Loss: 0.20050051542323363\nTraining Accuracy: 0.9446591299148517, Training F1 Score: 0.9417053639752102\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9317685265365231\n\nLearning Rate: 0.00019924096022611457\nEpoch 261, Training Loss: 0.18281190911795056, Validation Loss: 0.19907379112852103\nEpoch 261, Training Loss: 0.18117972872003352, Validation Loss: 0.19907379112852103\nTraining Accuracy: 0.9449913080065993, Training F1 Score: 0.941990950762829\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9317685265365231\n\nLearning Rate: 0.000187262878596988\nEpoch 271, Training Loss: 0.18229117831359737, Validation Loss: 0.1981611999826912\nEpoch 271, Training Loss: 0.18043688202595823, Validation Loss: 0.1981611999826912\nTraining Accuracy: 0.9451241792432983, Training F1 Score: 0.9420861229249434\nValidation Accuracy: 0.9364731653888281, Validation F1 Score: 0.9328123407676917\n\nLearning Rate: 0.00017600490210764385\nEpoch 281, Training Loss: 0.18183498973420775, Validation Loss: 0.19797412313414822\nEpoch 281, Training Loss: 0.18010575498473547, Validation Loss: 0.19797412313414822\nTraining Accuracy: 0.9451020340371818, Training F1 Score: 0.942090143442253\nValidation Accuracy: 0.9364731653888281, Validation F1 Score: 0.9328123407676917\n\nLearning Rate: 0.00016542373906677495\nEpoch 291, Training Loss: 0.1813260059754102, Validation Loss: 0.19808203562979892\nEpoch 291, Training Loss: 0.1800744220656177, Validation Loss: 0.19808203562979892\nTraining Accuracy: 0.9451463244494148, Training F1 Score: 0.9421836237231042\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9317685265365231\n\nLearning Rate: 0.00015547870041765152\nEpoch 301, Training Loss: 0.1808352442007321, Validation Loss: 0.19812037357560647\nEpoch 301, Training Loss: 0.18017719689298237, Validation Loss: 0.19812037357560647\nTraining Accuracy: 0.9449913080065993, Training F1 Score: 0.9420746880821051\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.9317685265365231\n\nLearning Rate: 0.00014613154327145219\nEpoch 311, Training Loss: 0.18037069598939537, Validation Loss: 0.19828207338757217\nEpoch 311, Training Loss: 0.18041411170678268, Validation Loss: 0.19828207338757217\nTraining Accuracy: 0.9448584367699002, Training F1 Score: 0.9419755315239088\nValidation Accuracy: 0.9353778751369113, Validation F1 Score: 0.931994692326542\n\nLearning Rate: 0.00013734632384714688\nEpoch 321, Training Loss: 0.17997905505157852, Validation Loss: 0.19862260691503314\nEpoch 321, Training Loss: 0.180798955964007, Validation Loss: 0.19862260691503314\nTraining Accuracy: 0.9447698559454342, Training F1 Score: 0.9419345843488433\nValidation Accuracy: 0.9342825848849945, Validation F1 Score: 0.9309555447340809\n\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[35], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m scheduler \u001b[38;5;241m=\u001b[39m LambdaLR(optimizer, lr_lambda\u001b[38;5;241m=\u001b[39mcustom_lr_lambda)\n\u001b[1;32m     16\u001b[0m criterion \u001b[38;5;241m=\u001b[39m CustomLoss(nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(), \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m, \u001b[38;5;241m0.0\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscheduler\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mearly_stopping_patience\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10000\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExecution time: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m(time\u001b[38;5;241m.\u001b[39mtime()\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time)\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m.6f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","Cell \u001b[0;32mIn[8], line 22\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer, num_epochs, scheduler, batch_size, num_features, early_stopping_patience)\u001b[0m\n\u001b[1;32m     20\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, labels, model)\n\u001b[1;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[0;32m---> 22\u001b[0m \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     23\u001b[0m scheduler\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     24\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem() \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mlen\u001b[39m(labels)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/lr_scheduler.py:130\u001b[0m, in \u001b[0;36mLRScheduler.__init__.<locals>.patch_track_step_called.<locals>.wrap_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    128\u001b[0m opt \u001b[38;5;241m=\u001b[39m opt_ref()\n\u001b[1;32m    129\u001b[0m opt\u001b[38;5;241m.\u001b[39m_opt_called \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[union-attr]\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__get__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mopt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mopt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:484\u001b[0m, in \u001b[0;36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    480\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    481\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m must return None or a tuple of (new_args, new_kwargs), but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    482\u001b[0m             )\n\u001b[0;32m--> 484\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    485\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_optimizer_step_code()\n\u001b[1;32m    487\u001b[0m \u001b[38;5;66;03m# call optimizer step post hooks\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:89\u001b[0m, in \u001b[0;36m_use_grad_for_differentiable.<locals>._use_grad\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m     torch\u001b[38;5;241m.\u001b[39mset_grad_enabled(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdefaults[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdifferentiable\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     88\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n\u001b[0;32m---> 89\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     91\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mgraph_break()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:226\u001b[0m, in \u001b[0;36mAdam.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    214\u001b[0m     beta1, beta2 \u001b[38;5;241m=\u001b[39m group[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbetas\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    216\u001b[0m     has_complex \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_group(\n\u001b[1;32m    217\u001b[0m         group,\n\u001b[1;32m    218\u001b[0m         params_with_grad,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    223\u001b[0m         state_steps,\n\u001b[1;32m    224\u001b[0m     )\n\u001b[0;32m--> 226\u001b[0m     \u001b[43madam\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    227\u001b[0m \u001b[43m        \u001b[49m\u001b[43mparams_with_grad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    228\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    229\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    230\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mamsgrad\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    238\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mweight_decay\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    239\u001b[0m \u001b[43m        \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43meps\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    240\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmaximize\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    241\u001b[0m \u001b[43m        \u001b[49m\u001b[43mforeach\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mforeach\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcapturable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdifferentiable\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    244\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgroup\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfused\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    245\u001b[0m \u001b[43m        \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mgrad_scale\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    246\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfound_inf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    247\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/optimizer.py:161\u001b[0m, in \u001b[0;36m_disable_dynamo_if_unsupported.<locals>.wrapper.<locals>.maybe_fallback\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m disabled_func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    160\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 161\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:766\u001b[0m, in \u001b[0;36madam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, foreach, capturable, differentiable, fused, grad_scale, found_inf, has_complex, amsgrad, beta1, beta2, lr, weight_decay, eps, maximize)\u001b[0m\n\u001b[1;32m    763\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    764\u001b[0m     func \u001b[38;5;241m=\u001b[39m _single_tensor_adam\n\u001b[0;32m--> 766\u001b[0m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    767\u001b[0m \u001b[43m    \u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    768\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    769\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avgs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    770\u001b[0m \u001b[43m    \u001b[49m\u001b[43mexp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    771\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_exp_avg_sqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    772\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstate_steps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    773\u001b[0m \u001b[43m    \u001b[49m\u001b[43mamsgrad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamsgrad\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    774\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhas_complex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhas_complex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    775\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta1\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta1\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    776\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbeta2\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbeta2\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    777\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlr\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    778\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_decay\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_decay\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    779\u001b[0m \u001b[43m    \u001b[49m\u001b[43meps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    780\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmaximize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmaximize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    781\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcapturable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcapturable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    782\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdifferentiable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdifferentiable\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    783\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_scale\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgrad_scale\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    784\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfound_inf\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfound_inf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    785\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/optim/adam.py:519\u001b[0m, in \u001b[0;36m_multi_tensor_adam\u001b[0;34m(params, grads, exp_avgs, exp_avg_sqs, max_exp_avg_sqs, state_steps, grad_scale, found_inf, amsgrad, has_complex, beta1, beta2, lr, weight_decay, eps, maximize, capturable, differentiable)\u001b[0m\n\u001b[1;32m    513\u001b[0m \u001b[38;5;66;03m# Update steps\u001b[39;00m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;66;03m# If steps are on CPU, foreach will fall back to the slow path, which is a for-loop calling t.add(1) over\u001b[39;00m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;66;03m# and over. 1 will then be wrapped into a Tensor over and over again, which is slower than if we just\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;66;03m# wrapped it once now. The alpha is required to assure we go to the right overload.\u001b[39;00m\n\u001b[1;32m    517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device_state_steps[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mis_cpu:\n\u001b[1;32m    518\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(\n\u001b[0;32m--> 519\u001b[0m         device_state_steps, \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcpu\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m, alpha\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1.0\u001b[39m\n\u001b[1;32m    520\u001b[0m     )\n\u001b[1;32m    521\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    522\u001b[0m     torch\u001b[38;5;241m.\u001b[39m_foreach_add_(device_state_steps, \u001b[38;5;241m1\u001b[39m)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}],"execution_count":35},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 8).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 0.01)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 1000, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T05:32:52.333161Z","iopub.execute_input":"2025-01-22T05:32:52.333562Z","iopub.status.idle":"2025-01-22T05:43:29.354823Z","shell.execute_reply.started":"2025-01-22T05:32:52.333527Z","shell.execute_reply":"2025-01-22T05:43:29.353659Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"def custom_lr_lambda(step):\n    num_step_threshold = 100\n\n    if step < num_step_threshold:\n        return step / num_step_threshold\n    if step == num_step_threshold:\n        print(\"here\")\n    return 0.99995 ** (step - num_step_threshold)\n\nstart_time = time.time()\nmodel = TabularDenseNet(num_features, num_classes, 1, 10).to(device)\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 0.01)\nscheduler = LambdaLR(optimizer, lr_lambda=custom_lr_lambda)\n\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.0, 0.0, 0.0, 0.0, 0.0)\nevaluate_model(model, custom_train_loader, criterion, optimizer, 1000, scheduler, batch_size, num_features, early_stopping_patience=10000)\n\nprint(f\"Execution time: {(time.time() - start_time):.6f} seconds\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-22T02:53:15.284592Z","iopub.execute_input":"2025-01-22T02:53:15.285010Z","iopub.status.idle":"2025-01-22T03:03:05.372751Z","shell.execute_reply.started":"2025-01-22T02:53:15.284965Z","shell.execute_reply":"2025-01-22T03:03:05.371389Z"},"collapsed":true,"jupyter":{"source_hidden":true,"outputs_hidden":true}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\nprint(f\"Total number of trainable parameters: {total_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:36:27.194080Z","iopub.execute_input":"2025-01-23T18:36:27.194562Z","iopub.status.idle":"2025-01-23T18:36:27.200300Z","shell.execute_reply.started":"2025-01-23T18:36:27.194526Z","shell.execute_reply":"2025-01-23T18:36:27.199188Z"}},"outputs":[{"name":"stdout","text":"Total number of trainable parameters: 2051\n","output_type":"stream"}],"execution_count":51},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(f\"Total number of parameters (trainable + non-trainable): {total_params}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:36:28.972400Z","iopub.execute_input":"2025-01-23T18:36:28.972807Z","iopub.status.idle":"2025-01-23T18:36:28.978250Z","shell.execute_reply.started":"2025-01-23T18:36:28.972771Z","shell.execute_reply":"2025-01-23T18:36:28.977318Z"}},"outputs":[{"name":"stdout","text":"Total number of parameters (trainable + non-trainable): 2051\n","output_type":"stream"}],"execution_count":52},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\n\ndata = data.drop([\"id\"], axis=1)\ndata['source'] = 0\n\ndata['person_emp_length_missing'] = data['person_emp_length'].isna().astype(int)\ndata['loan_int_rate_missing'] = data['loan_int_rate'].isna().astype(int)\n\ndata['person_emp_length'] = data['person_emp_length'].fillna(median_emp_length)\ndata['loan_int_rate'] = data['loan_int_rate'].fillna(median_int_rate)\n\n# grade_mapping = {'A': 7, 'B': 6, 'C': 5, 'D': 4, 'E': 3, 'F': 2, 'G': 1}\n# data['loan_grade'] = data['loan_grade'].map(grade_mapping)\n\n# purpose_mapping = {\n#     'DEBTCONSOLIDATION': 1,\n#     'HOMEIMPROVEMENT': 2,\n#     'MEDICAL': 3,\n#     'PERSONAL': 4,\n#     'EDUCATION': 5,\n#     'VENTURE': 6\n# }\n# data['loan_intent'] = data['loan_intent'].map(purpose_mapping)\n\n# home_ownership_mapping = {\n#     'OWN': 1,\n#     'MORTGAGE': 2,\n#     'OTHER': 3,\n#     'RENT': 4\n# }\n# data['person_home_ownership'] = data['person_home_ownership'].map(home_ownership_mapping)\n\nX = data.drop([], axis=1)\nX = pd.get_dummies(X, drop_first=True)\n\ncolumn_to_log = [\n    'person_age',\n    'person_income',\n]\n\ncolumn_to_sqrt = [\n    'person_emp_length',\n    'loan_percent_income',\n]\n\nfor col in column_to_log:\n    if (X[col] <= 0).any():\n        print(f\"Column '{col}' contains non-positive values. Adding 1 to avoid log of non-positive numbers.\")\n        X[col] = np.log(X[col] + 1)\n    else:\n        X[col] = np.log(X[col])\n\nfor col in column_to_sqrt:\n    if (X[col] < 0).any():\n        print(f\"Column '{col}' contains negative values. Setting negative values to NaN before applying sqrt.\")\n        X[col] = np.sqrt(X[col].clip(lower=0))\n    else:\n        X[col] = np.sqrt(X[col])\n\nprint(data.isnull().sum())\nprint(X.columns)\nprint(X.columns.get_loc('source'))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:36:56.363770Z","iopub.execute_input":"2025-01-23T18:36:56.364149Z","iopub.status.idle":"2025-01-23T18:36:56.477792Z","shell.execute_reply.started":"2025-01-23T18:36:56.364096Z","shell.execute_reply":"2025-01-23T18:36:56.476773Z"}},"outputs":[{"name":"stdout","text":"person_age                    0\nperson_income                 0\nperson_home_ownership         0\nperson_emp_length             0\nloan_intent                   0\nloan_grade                    0\nloan_amnt                     0\nloan_int_rate                 0\nloan_percent_income           0\ncb_person_default_on_file     0\ncb_person_cred_hist_length    0\nsource                        0\nperson_emp_length_missing     0\nloan_int_rate_missing         0\ndtype: int64\nIndex(['person_age', 'person_income', 'person_emp_length', 'loan_amnt',\n       'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n       'source', 'person_emp_length_missing', 'loan_int_rate_missing',\n       'person_home_ownership_OTHER', 'person_home_ownership_OWN',\n       'person_home_ownership_RENT', 'loan_intent_EDUCATION',\n       'loan_intent_HOMEIMPROVEMENT', 'loan_intent_MEDICAL',\n       'loan_intent_PERSONAL', 'loan_intent_VENTURE', 'loan_grade_B',\n       'loan_grade_C', 'loan_grade_D', 'loan_grade_E', 'loan_grade_F',\n       'loan_grade_G', 'cb_person_default_on_file_Y'],\n      dtype='object')\n7\n","output_type":"stream"}],"execution_count":53},{"cell_type":"code","source":"print(X)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:36:58.057443Z","iopub.execute_input":"2025-01-23T18:36:58.057821Z","iopub.status.idle":"2025-01-23T18:36:58.076637Z","shell.execute_reply.started":"2025-01-23T18:36:58.057788Z","shell.execute_reply":"2025-01-23T18:36:58.075610Z"}},"outputs":[{"name":"stdout","text":"       person_age  person_income  person_emp_length  loan_amnt  loan_int_rate  \\\n0        3.135494      11.141862           1.732051      25000          15.76   \n1        3.258097      11.472103           2.449490      10000          12.68   \n2        3.258097      10.308953           2.236068       4000          17.19   \n3        3.496508      10.819778           2.000000       7000           8.90   \n4        3.258097      11.532728           2.828427      15000          16.32   \n...           ...            ...                ...        ...            ...   \n39093    3.091042      10.348173           1.414214       3000          10.37   \n39094    3.091042      10.778956           2.449490       7000           6.03   \n39095    3.931826      11.002100           0.000000      15000           7.51   \n39096    3.091042      10.491274           2.000000      14000          15.62   \n39097    3.433987      10.714418           2.449490      19450           9.91   \n\n       loan_percent_income  cb_person_cred_hist_length  source  \\\n0                 0.600000                           2       0   \n1                 0.316228                           4       0   \n2                 0.360555                           2       0   \n3                 0.374166                           7       0   \n4                 0.387298                           4       0   \n...                    ...                         ...     ...   \n39093             0.316228                           4       0   \n39094             0.387298                           3       0   \n39095             0.500000                          25       0   \n39096             0.624500                           4       0   \n39097             0.663325                           9       0   \n\n       person_emp_length_missing  loan_int_rate_missing  ...  \\\n0                              0                      0  ...   \n1                              0                      0  ...   \n2                              0                      0  ...   \n3                              0                      0  ...   \n4                              0                      0  ...   \n...                          ...                    ...  ...   \n39093                          0                      0  ...   \n39094                          0                      0  ...   \n39095                          0                      0  ...   \n39096                          0                      0  ...   \n39097                          0                      0  ...   \n\n       loan_intent_MEDICAL  loan_intent_PERSONAL  loan_intent_VENTURE  \\\n0                    False                 False                False   \n1                    False                  True                False   \n2                    False                 False                 True   \n3                    False                 False                False   \n4                    False                 False                False   \n...                    ...                   ...                  ...   \n39093                False                 False                False   \n39094                False                 False                False   \n39095                False                  True                False   \n39096                False                  True                False   \n39097                False                 False                False   \n\n       loan_grade_B  loan_grade_C  loan_grade_D  loan_grade_E  loan_grade_F  \\\n0             False         False         False         False          True   \n1             False          True         False         False         False   \n2             False         False         False          True         False   \n3             False         False         False         False         False   \n4             False         False          True         False         False   \n...             ...           ...           ...           ...           ...   \n39093          True         False         False         False         False   \n39094         False         False         False         False         False   \n39095         False         False         False         False         False   \n39096         False         False          True         False         False   \n39097          True         False         False         False         False   \n\n       loan_grade_G  cb_person_default_on_file_Y  \n0             False                        False  \n1             False                         True  \n2             False                         True  \n3             False                        False  \n4             False                         True  \n...             ...                          ...  \n39093         False                        False  \n39094         False                        False  \n39095         False                        False  \n39096         False                         True  \n39097         False                        False  \n\n[39098 rows x 25 columns]\n","output_type":"stream"}],"execution_count":54},{"cell_type":"code","source":"print(X.shape)\nX_scaled_test = x_scaler.transform(X)\nprint(X_scaled_test.shape)\nprint(X_scaled_test)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:37:01.766300Z","iopub.execute_input":"2025-01-23T18:37:01.766688Z","iopub.status.idle":"2025-01-23T18:37:01.801417Z","shell.execute_reply.started":"2025-01-23T18:37:01.766656Z","shell.execute_reply":"2025-01-23T18:37:01.800499Z"}},"outputs":[{"name":"stdout","text":"(39098, 25)\n(39098, 25)\n[[-0.83835155  0.38266958 -0.18616973 ... 11.58407836 -0.04436441\n  -0.46268575]\n [-0.21875715  0.96598481  0.50889981 ... -0.08632538 -0.04436441\n   2.16129414]\n [-0.21875715 -1.08852135  0.30213243 ... -0.08632538 -0.04436441\n   2.16129414]\n ...\n [ 3.18606232  0.13580411 -1.86421602 ... -0.08632538 -0.04436441\n  -0.46268575]\n [-1.06299707 -0.76648163  0.07342494 ... -0.08632538 -0.04436441\n   2.16129414]\n [ 0.67014014 -0.37233687  0.50889981 ... -0.08632538 -0.04436441\n  -0.46268575]]\n","output_type":"stream"}],"execution_count":55},{"cell_type":"code","source":"X_scaled_test_tensor = torch.tensor(X_scaled_test).float().to(device)\noutputs = model(X_scaled_test_tensor)\nprint(outputs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:37:07.561930Z","iopub.execute_input":"2025-01-23T18:37:07.563002Z","iopub.status.idle":"2025-01-23T18:37:08.043329Z","shell.execute_reply.started":"2025-01-23T18:37:07.562921Z","shell.execute_reply":"2025-01-23T18:37:08.042293Z"}},"outputs":[{"name":"stdout","text":"tensor([[-3.5235,  3.5235],\n        [ 1.6366, -1.6366],\n        [ 0.4044, -0.4044],\n        ...,\n        [ 2.3884, -2.3884],\n        [ 0.6305, -0.6305],\n        [-2.2837,  2.2837]], grad_fn=<StackBackward0>)\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"probabilities = F.softmax(outputs, dim=1)\nprint(probabilities)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:37:09.930898Z","iopub.execute_input":"2025-01-23T18:37:09.931796Z","iopub.status.idle":"2025-01-23T18:37:09.939116Z","shell.execute_reply.started":"2025-01-23T18:37:09.931756Z","shell.execute_reply":"2025-01-23T18:37:09.937988Z"}},"outputs":[{"name":"stdout","text":"tensor([[8.6921e-04, 9.9913e-01],\n        [9.6350e-01, 3.6503e-02],\n        [6.9185e-01, 3.0815e-01],\n        ...,\n        [9.9165e-01, 8.3532e-03],\n        [7.7921e-01, 2.2079e-01],\n        [1.0278e-02, 9.8972e-01]], grad_fn=<SoftmaxBackward0>)\n","output_type":"stream"}],"execution_count":57},{"cell_type":"code","source":"positive_class_probs = probabilities[:, 1]\nprint(positive_class_probs)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:37:12.126073Z","iopub.execute_input":"2025-01-23T18:37:12.126802Z","iopub.status.idle":"2025-01-23T18:37:12.133103Z","shell.execute_reply.started":"2025-01-23T18:37:12.126753Z","shell.execute_reply":"2025-01-23T18:37:12.132062Z"}},"outputs":[{"name":"stdout","text":"tensor([0.9991, 0.0365, 0.3081,  ..., 0.0084, 0.2208, 0.9897],\n       grad_fn=<SelectBackward0>)\n","output_type":"stream"}],"execution_count":58},{"cell_type":"code","source":"import pandas as pd\n\ntest_df = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\nids = test_df['id']\n\npositive_class_probs = positive_class_probs.cpu().detach().numpy()\n\nsubmission_df = pd.DataFrame({\n    'id': ids,\n    'loan_status': positive_class_probs\n})\n\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-01-23T18:37:12.847137Z","iopub.execute_input":"2025-01-23T18:37:12.847514Z","iopub.status.idle":"2025-01-23T18:37:12.954437Z","shell.execute_reply.started":"2025-01-23T18:37:12.847482Z","shell.execute_reply":"2025-01-23T18:37:12.953431Z"}},"outputs":[{"name":"stdout","text":"Submission file created successfully.\n","output_type":"stream"}],"execution_count":59},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}