{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":84894,"databundleVersionId":9709193,"sourceType":"competition"},{"sourceId":408,"sourceType":"datasetVersion","datasetId":180},{"sourceId":668,"sourceType":"datasetVersion","datasetId":308},{"sourceId":7949759,"sourceType":"datasetVersion","datasetId":4675026},{"sourceId":9738619,"sourceType":"datasetVersion","datasetId":5960716}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport math\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom scipy.special import logit\nfrom scipy.stats import norm\n\nimport tensorflow as tf\nfrom keras import layers, models, datasets\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.data import TensorDataset, DataLoader\nfrom torchinfo import summary\nfrom torch.optim.lr_scheduler import StepLR\nimport torch.autograd.profiler as profiler\n\nfrom sklearn.model_selection import train_test_split, LeaveOneOut, StratifiedKFold, cross_val_predict\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder, PowerTransformer\nfrom sklearn.metrics import f1_score, log_loss, accuracy_score\nfrom sklearn.linear_model import LogisticRegression\n\nimport sys\nimport time\n\nfrom learnable_activation import LearnableActivation\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-10-31T06:23:17.834272Z","iopub.execute_input":"2024-10-31T06:23:17.834708Z","iopub.status.idle":"2024-10-31T06:23:17.851508Z","shell.execute_reply.started":"2024-10-31T06:23:17.834664Z","shell.execute_reply":"2024-10-31T06:23:17.850309Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"cpu\n","output_type":"stream"}]},{"cell_type":"code","source":"pip install learnable-activation","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:21:41.045225Z","iopub.execute_input":"2024-10-31T06:21:41.045708Z","iopub.status.idle":"2024-10-31T06:21:56.480975Z","shell.execute_reply.started":"2024-10-31T06:21:41.045666Z","shell.execute_reply":"2024-10-31T06:21:56.479558Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Collecting learnable-activation\n  Downloading learnable_activation-0.0.3-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: torch in /opt/conda/lib/python3.10/site-packages (from learnable-activation) (2.4.0+cpu)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from torch->learnable-activation) (3.15.1)\nRequirement already satisfied: typing-extensions>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from torch->learnable-activation) (4.12.2)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch->learnable-activation) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch->learnable-activation) (3.3)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch->learnable-activation) (3.1.4)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from torch->learnable-activation) (2024.6.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch->learnable-activation) (2.1.5)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch->learnable-activation) (1.3.0)\nDownloading learnable_activation-0.0.3-py3-none-any.whl (5.0 kB)\nInstalling collected packages: learnable-activation\nSuccessfully installed learnable-activation-0.0.3\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"An interpolation based learning technique, driven through explicit regularization","metadata":{}},{"cell_type":"code","source":"def calculate_metrics(model, data_tensor, labels_tensor, batch_size=1024, num_features=22):\n    model.eval()\n    all_preds = []\n    all_labels = []\n\n    with torch.no_grad():\n        for start_idx in range(0, len(data_tensor), batch_size):\n            end_idx = min(start_idx + batch_size, len(data_tensor))\n            inputs = data_tensor[start_idx:end_idx].view(-1, num_features)\n            labels = labels_tensor[start_idx:end_idx]\n\n            outputs = model(inputs)\n            _, preds = torch.max(outputs, 1)\n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n\n    accuracy = accuracy_score(all_labels, all_preds)\n    f1 = f1_score(all_labels, all_preds, average='weighted')\n    return accuracy, f1","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:16:48.317072Z","iopub.execute_input":"2024-10-31T06:16:48.317548Z","iopub.status.idle":"2024-10-31T06:16:48.330363Z","shell.execute_reply.started":"2024-10-31T06:16:48.317500Z","shell.execute_reply":"2024-10-31T06:16:48.328964Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"class CustomDataLoader:\n    def __init__(self, features, labels, validation_size=0.2, random_state=42):\n        if validation_size > 0.0:\n            train_data, val_data, train_labels, val_labels = train_test_split(\n                features, labels, test_size=validation_size, stratify=labels, random_state=random_state\n            )\n            \n            self.val_data_tensor = torch.tensor(val_data).float().to(device)\n            self.val_labels_tensor = torch.tensor(val_labels).long().to(device)\n        else:\n            train_data, train_labels = features, labels\n            self.val_data_tensor, self.val_labels_tensor = None, None\n        \n        self.train_data_tensor = torch.tensor(train_data).float().to(device)\n        self.train_labels_tensor = torch.tensor(train_labels).long().to(device)\n\n        torch.manual_seed(random_state)\n\n        indices = torch.randperm(len(self.train_data_tensor))\n\n        self.train_data_tensor = self.train_data_tensor[indices]\n        self.train_labels_tensor = self.train_labels_tensor[indices]","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:16:48.693218Z","iopub.execute_input":"2024-10-31T06:16:48.693760Z","iopub.status.idle":"2024-10-31T06:16:48.706550Z","shell.execute_reply.started":"2024-10-31T06:16:48.693707Z","shell.execute_reply":"2024-10-31T06:16:48.705201Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, custom_train_loader, criterion, optimizer, num_epochs, scheduler, batch_size=1024, num_features=22):\n    unregularized_criterion = nn.CrossEntropyLoss()\n\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        \n        model.train()\n        for start_idx in range(0, len(custom_train_loader.train_data_tensor), batch_size):\n            end_idx = min(start_idx + batch_size, len(custom_train_loader.train_data_tensor))\n            inputs = custom_train_loader.train_data_tensor[start_idx:end_idx].view(-1, num_features)\n            labels = custom_train_loader.train_labels_tensor[start_idx:end_idx]\n\n            optimizer.zero_grad()\n            outputs = model(inputs)\n            loss = criterion(outputs, labels, model)\n            loss.backward()\n            optimizer.step()\n            scheduler.step()\n            running_loss += loss.item() * len(labels)\n                      \n        model.eval()\n        val_loss = 0.0\n        with torch.no_grad():\n            for start_idx in range(0, len(custom_train_loader.val_data_tensor), batch_size):\n                end_idx = min(start_idx + batch_size, len(custom_train_loader.val_data_tensor))\n                val_inputs = custom_train_loader.val_data_tensor[start_idx:end_idx].view(-1, num_features)\n                val_labels = custom_train_loader.val_labels_tensor[start_idx:end_idx]\n\n                val_outputs = model(val_inputs)\n                val_loss += unregularized_criterion(val_outputs, val_labels).item() * len(val_labels)\n\n        avg_train_loss = running_loss / len(custom_train_loader.train_data_tensor)\n#         print(f'Epoch {epoch + 1}: {avg_train_loss}')\n        avg_val_loss = val_loss / len(custom_train_loader.val_data_tensor)\n\n        train_accuracy, train_f1 = calculate_metrics(model, custom_train_loader.train_data_tensor, custom_train_loader.train_labels_tensor, batch_size, num_features)\n        val_accuracy, val_f1 = calculate_metrics(model, custom_train_loader.val_data_tensor, custom_train_loader.val_labels_tensor, batch_size, num_features)\n\n        print(f'Epoch {epoch + 1}, Training Loss: {avg_train_loss}, Validation Loss: {avg_val_loss}')\n        print(f'Training Accuracy: {train_accuracy}, Training F1 Score: {train_f1}')\n        print(f'Validation Accuracy: {val_accuracy}, Validation F1 Score: {val_f1}')\n        print()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:26:02.142177Z","iopub.execute_input":"2024-10-31T06:26:02.142673Z","iopub.status.idle":"2024-10-31T06:26:02.157447Z","shell.execute_reply.started":"2024-10-31T06:26:02.142628Z","shell.execute_reply":"2024-10-31T06:26:02.156248Z"},"trusted":true},"execution_count":34,"outputs":[]},{"cell_type":"code","source":"class CustomLoss(nn.Module):\n    def __init__(self, criterion, l1_lambda=0.0, l2_lambda=0.0, f1_lambda=0.0, f2_lambda=0.0):\n        super(CustomLoss, self).__init__()\n        self.criterion = criterion\n        self.l1_lambda = l1_lambda\n        self.l2_lambda = l2_lambda\n        self.f1_lambda = f1_lambda\n        self.f2_lambda = f2_lambda\n\n    def forward(self, outputs, labels, model):\n        l1_norm = sum(\n            p.abs().sum()\n            for name, module in model.named_modules()\n            if isinstance(module, nn.Linear)\n            for p in module.parameters()\n            if \"bias\" not in name\n        )\n        l1_loss = self.l1_lambda * l1_norm\n\n        l2_norm = sum(\n            p.pow(2.0).sum()\n            for name, module in model.named_modules()\n            if isinstance(module, nn.Linear)\n            for p in module.parameters()\n            if \"bias\" not in name\n        )\n        l2_loss = self.l2_lambda * l2_norm\n\n        f1_loss = 0\n        f2_loss = 0\n        for name, module in model.named_modules():\n            if isinstance(module, LearnableActivation):\n                interp_tensor = module.interp_tensor\n\n                f1_diff = interp_tensor[:, 1:] - interp_tensor[:, :-1]\n                f1_loss += self.f1_lambda * f1_diff.abs().sum()\n\n                f2_diff = f1_diff[:, 1:] - f1_diff[:, :-1]\n                f2_loss += self.f2_lambda * f2_diff.abs().sum()\n\n        return self.criterion(outputs, labels) + l1_loss + l2_loss + f1_loss + f2_loss\n\n    def regular_loss(self, outputs, labels):\n        return self.criterion(outputs, labels)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:26:02.417027Z","iopub.execute_input":"2024-10-31T06:26:02.417770Z","iopub.status.idle":"2024-10-31T06:26:02.433104Z","shell.execute_reply.started":"2024-10-31T06:26:02.417700Z","shell.execute_reply":"2024-10-31T06:26:02.431759Z"},"trusted":true},"execution_count":35,"outputs":[]},{"cell_type":"code","source":"data_dl = pd.read_csv('/kaggle/input/playground-series-s4e10/train.csv')\ndata_og = pd.read_csv('/kaggle/input/loan-approval-prediction/credit_risk_dataset.csv')\n\ndata_dl = data_dl.drop([\"id\"], axis=1)\ndata_og['person_emp_length'] = data_og['person_emp_length'].fillna(data_og['person_emp_length'].mean())\ndata_og['loan_int_rate'] = data_og['loan_int_rate'].fillna(data_og['loan_int_rate'].mean())\n\ndata_dl['source'] = 0\ndata_og['source'] = 1\n\ndata = pd.concat([data_dl, data_og], ignore_index=True)\n\ngrade_mapping = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\ndata['loan_grade'] = data['loan_grade'].map(grade_mapping)\n\npurpose_mapping = {\n    'DEBTCONSOLIDATION': 1,\n    'HOMEIMPROVEMENT': 2,\n    'MEDICAL': 3,\n    'PERSONAL': 4,\n    'EDUCATION': 5,\n    'VENTURE': 6\n}\ndata['loan_intent'] = data['loan_intent'].map(purpose_mapping)\n\nhome_ownership_mapping = {\n    'OWN': 1,\n    'MORTGAGE': 2,\n    'OTHER': 3,\n    'RENT': 4\n}\ndata['person_home_ownership'] = data['person_home_ownership'].map(home_ownership_mapping)\n\nprint(data.columns)\nprint(data.isnull().sum())\n\nX = data.drop([\"loan_status\"], axis=1)\nX['loan_percent_income_ratio'] = (X['person_income'] / X['loan_amnt'])\nX['loan_to_income_ratio'] = X['loan_amnt'] / X['person_income']\nX['financial_burden'] = X['loan_amnt'] * X['loan_int_rate']\nX['loan_int_emp_interaction'] = X['loan_int_rate'] * X['person_emp_length']\nX['debt_to_credit_ratio'] = X['loan_amnt'] / X['cb_person_cred_hist_length']\n\ny = data[\"loan_status\"]\n\nexclude_columns = [\n    \"loan_percent_income_ratio\",\n    \"loan_to_income_ratio\",\n    \"financial_burden\",\n    \"debt_to_credit_ratio\"\n]\n\nX = pd.get_dummies(X, drop_first=True)\n\nfor col in X.columns:\n    if col not in exclude_columns:\n        if (X[col] > 0).all():\n            X[col] = np.log(X[col])\n\nprint(X.shape, y.shape)\nprint(X.columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:18:57.897683Z","iopub.execute_input":"2024-10-31T06:18:57.898715Z","iopub.status.idle":"2024-10-31T06:18:58.202110Z","shell.execute_reply.started":"2024-10-31T06:18:57.898665Z","shell.execute_reply":"2024-10-31T06:18:58.200785Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Index(['person_age', 'person_income', 'person_home_ownership',\n       'person_emp_length', 'loan_intent', 'loan_grade', 'loan_amnt',\n       'loan_int_rate', 'loan_percent_income', 'cb_person_default_on_file',\n       'cb_person_cred_hist_length', 'loan_status', 'source'],\n      dtype='object')\nperson_age                    0\nperson_income                 0\nperson_home_ownership         0\nperson_emp_length             0\nloan_intent                   0\nloan_grade                    0\nloan_amnt                     0\nloan_int_rate                 0\nloan_percent_income           0\ncb_person_default_on_file     0\ncb_person_cred_hist_length    0\nloan_status                   0\nsource                        0\ndtype: int64\n(91226, 17) (91226,)\nIndex(['person_age', 'person_income', 'person_home_ownership',\n       'person_emp_length', 'loan_intent', 'loan_grade', 'loan_amnt',\n       'loan_int_rate', 'loan_percent_income', 'cb_person_cred_hist_length',\n       'source', 'loan_percent_income_ratio', 'loan_to_income_ratio',\n       'financial_burden', 'loan_int_emp_interaction', 'debt_to_credit_ratio',\n       'cb_person_default_on_file_Y'],\n      dtype='object')\n","output_type":"stream"}]},{"cell_type":"code","source":"x_scaler = StandardScaler()\nx_scaled = x_scaler.fit_transform(X)\n\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\nprint(x_scaled.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:16:51.921026Z","iopub.execute_input":"2024-10-31T06:16:51.921467Z","iopub.status.idle":"2024-10-31T06:16:52.117470Z","shell.execute_reply.started":"2024-10-31T06:16:51.921422Z","shell.execute_reply":"2024-10-31T06:16:52.116088Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"(91226, 17)\n","output_type":"stream"}]},{"cell_type":"code","source":"class CustomLoss(nn.Module):\n    def __init__(self, base_loss_fn, first_order_weight=0.0, second_order_weight=0.0):\n        super(CustomLoss, self).__init__()\n        self.first_order_weight = first_order_weight\n        self.second_order_weight = second_order_weight\n        self.base_loss_fn = base_loss_fn\n\n    def forward(self, outputs, labels, optimized_tensor):\n        base_loss = self.base_loss_fn(outputs, labels)\n        \n        first_order_x = (optimized_tensor[:, :, :-1, :] - optimized_tensor[:, :, 1:, :])\n        first_order_y = (optimized_tensor[:, :, :, :-1] - optimized_tensor[:, :, :, 1:])\n        first_order_loss = self.first_order_weight * (torch.sum(first_order_x ** 2) + torch.sum(first_order_y ** 2))\n        \n        second_order_x = (first_order_x[:, :, :-1:, :] - first_order_x[:, :, 1:, :])\n        second_order_y = (first_order_x[:, :, :, :-1] - first_order_x[:, :, :, 1:])\n        second_order_loss = self.second_order_weight * (torch.sum(second_order_x ** 2) + torch.sum(second_order_y ** 2))\n\n        return base_loss + first_order_loss + second_order_loss","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:23:34.002060Z","iopub.execute_input":"2024-10-31T06:23:34.002479Z","iopub.status.idle":"2024-10-31T06:23:34.013634Z","shell.execute_reply.started":"2024-10-31T06:23:34.002438Z","shell.execute_reply":"2024-10-31T06:23:34.012394Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Assuming X is a DataFrame, retrieve the feature names\nfeature_names = X.columns\n\n# Step 1: Scale the features\nx_scaler = StandardScaler()\nx_scaled = x_scaler.fit_transform(X)\n\n# Step 2: Encode the labels\nlabel_encoder = LabelEncoder()\ny_encoded = label_encoder.fit_transform(y)\n\n# Step 3: Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(x_scaled, y_encoded, test_size=0.2, random_state=42)\n\n# Step 4: Initialize and train the Logistic Regression model\nlog_reg = LogisticRegression(penalty=None)\nlog_reg.fit(X_train, y_train)\n\n# Step 5: Make predictions for accuracy and log loss\ny_train_pred_proba = log_reg.predict_proba(X_train)\ny_test_pred_proba = log_reg.predict_proba(X_test)\ny_pred = log_reg.predict(X_test)\n\n# Step 6: Evaluate the model\n# Accuracy\naccuracy = accuracy_score(y_test, y_pred)\nprint(f\"Accuracy: {accuracy * 100:.2f}%\")\n\n# Classification report\nprint(\"Classification Report:\")\nprint(classification_report(y_test, y_pred))\n\n# Log loss\ntrain_log_loss = log_loss(y_train, y_train_pred_proba)\ntest_log_loss = log_loss(y_test, y_test_pred_proba)\nprint(f\"Training Log Loss: {train_log_loss:.4f}\")\nprint(f\"Testing Log Loss: {test_log_loss:.4f}\")\n\n# Display feature coefficients\ncoefficients = log_reg.coef_[0]  # Assuming binary classification, adjust if multi-class\ncoef_df = pd.DataFrame({\"Feature\": feature_names, \"Coefficient\": coefficients})\nprint(coef_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:16:55.271962Z","iopub.execute_input":"2024-10-31T06:16:55.272918Z","iopub.status.idle":"2024-10-31T06:16:56.896389Z","shell.execute_reply.started":"2024-10-31T06:16:55.272851Z","shell.execute_reply":"2024-10-31T06:16:56.894902Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Accuracy: 88.31%\nClassification Report:\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","Cell \u001b[0;32mIn[10], line 33\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# Classification report\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClassification Report:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 33\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mclassification_report\u001b[49m(y_test, y_pred))\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Log loss\u001b[39;00m\n\u001b[1;32m     36\u001b[0m train_log_loss \u001b[38;5;241m=\u001b[39m log_loss(y_train, y_train_pred_proba)\n","\u001b[0;31mNameError\u001b[0m: name 'classification_report' is not defined"],"ename":"NameError","evalue":"name 'classification_report' is not defined","output_type":"error"}]},{"cell_type":"code","source":"features = concatenated_result.detach().cpu().numpy()\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:35:40.692524Z","iopub.execute_input":"2024-10-31T06:35:40.693007Z","iopub.status.idle":"2024-10-31T06:35:40.698424Z","shell.execute_reply.started":"2024-10-31T06:35:40.692964Z","shell.execute_reply":"2024-10-31T06:35:40.697265Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"from sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n\n# Step 1: Split the data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features, y, test_size=0.2, random_state=0)\n\n# Step 2: Initialize the Gradient Boosted Tree model\ngbt_model = GradientBoostingClassifier(random_state=42)\n\n# Step 3: Train the model\ngbt_model.fit(X_train, y_train)\n\n# Step 4: Make predictions\ny_pred = gbt_model.predict(X_test)\n\n# Step 5: Evaluate the model\naccuracy = accuracy_score(y_test, y_pred)\nconf_matrix = confusion_matrix(y_test, y_pred)\nclass_report = classification_report(y_test, y_pred)\n    \nprint(\"Accuracy:\", accuracy)\nprint(\"Confusion Matrix:\\n\", conf_matrix)\nprint(\"Classification Report:\\n\", class_report)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:35:55.941413Z","iopub.execute_input":"2024-10-31T06:35:55.942088Z","iopub.status.idle":"2024-10-31T06:37:19.185052Z","shell.execute_reply.started":"2024-10-31T06:35:55.942021Z","shell.execute_reply":"2024-10-31T06:37:19.183646Z"},"trusted":true},"execution_count":54,"outputs":[{"name":"stdout","text":"Accuracy: 0.9434396580072345\nConfusion Matrix:\n [[15032   136]\n [  896  2182]]\nClassification Report:\n               precision    recall  f1-score   support\n\n           0       0.94      0.99      0.97     15168\n           1       0.94      0.71      0.81      3078\n\n    accuracy                           0.94     18246\n   macro avg       0.94      0.85      0.89     18246\nweighted avg       0.94      0.94      0.94     18246\n\n","output_type":"stream"}]},{"cell_type":"code","source":"class TabularDenseNet(nn.Module):\n    def __init__(self, input_size, output_size, num_layers=2, width=2, density=10):\n        super(TabularDenseNet, self).__init__()\n\n        self.layers = nn.ModuleList()\n        self.activations = nn.ModuleList()\n\n        for i in range(num_layers):\n            self.activations.append(LearnableActivation(input_size, width, density))\n            self.layers.append(nn.Linear(input_size, input_size, bias=False))\n\n            with torch.no_grad():\n                self.layers[-1].weight.copy_(torch.eye(input_size))\n\n            input_size *= 2\n\n        self.activation_second_last_layer = LearnableActivation(input_size, width, density)\n        self.last_layer = nn.Linear(input_size, output_size, bias=False)\n\n        with torch.no_grad():\n            self.last_layer.weight.copy_(torch.zeros(output_size, input_size))\n\n        self.activation_last_layer = LearnableActivation(output_size, width, density)\n        \n        print(LearnableActivation.__module__)\n\n    def forward(self, x):\n        outputs = [x]\n\n        for i in range(len(self.layers)):\n            concatenated_outputs = torch.cat(outputs, dim=1)\n            outputs.append(self.layers[i](self.activations[i](concatenated_outputs)))\n\n        outputs = torch.cat(outputs, dim=1)\n        outputs = self.activation_second_last_layer(outputs)\n        outputs = self.last_layer(outputs)\n        outputs = self.activation_last_layer(outputs)\n        return outputs.squeeze()\n    \n    def extract_features(self, x):\n        # Forward pass up to the first layer's activation output\n        concatenated_outputs = torch.cat([x], dim=1)  # Initial input\n        activated_output = self.activations[0](concatenated_outputs)\n        first_layer_output = self.layers[0](activated_output)\n        \n        return first_layer_output","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:30:08.431811Z","iopub.execute_input":"2024-10-31T06:30:08.432341Z","iopub.status.idle":"2024-10-31T06:30:08.447441Z","shell.execute_reply.started":"2024-10-31T06:30:08.432296Z","shell.execute_reply":"2024-10-31T06:30:08.446221Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"class CustomLoss(nn.Module):\n    def __init__(self, criterion, l1_lambda=0.0, l2_lambda=0.0, f1_lambda=0.0, f2_lambda=0.0):\n        super(CustomLoss, self).__init__()\n        self.criterion = criterion\n        self.l1_lambda = l1_lambda\n        self.l2_lambda = l2_lambda\n        self.f1_lambda = f1_lambda\n        self.f2_lambda = f2_lambda\n\n    def forward(self, outputs, labels, model):\n        l1_norm = sum(\n            p.abs().sum()\n            for name, module in model.named_modules()\n            if isinstance(module, nn.Linear)\n            for p in module.parameters()\n            if \"bias\" not in name\n        )\n        l1_loss = self.l1_lambda * l1_norm\n\n        l2_norm = sum(\n            p.pow(2.0).sum()\n            for name, module in model.named_modules()\n            if isinstance(module, nn.Linear)\n            for p in module.parameters()\n            if \"bias\" not in name\n        )\n        l2_loss = self.l2_lambda * l2_norm\n\n        f1_loss = 0\n        f2_loss = 0\n        for name, module in model.named_modules():\n            if isinstance(module, LearnableActivation):\n                interp_tensor = module.interp_tensor\n\n                f1_diff = interp_tensor[:, 1:] - interp_tensor[:, :-1]\n                f1_loss += self.f1_lambda * f1_diff.abs().sum()\n\n                f2_diff = f1_diff[:, 1:] - f1_diff[:, :-1]\n                f2_loss += self.f2_lambda * f2_diff.abs().sum()\n\n        return self.criterion(outputs, labels) + l1_loss + l2_loss + f1_loss + f2_loss\n\n    def regular_loss(self, outputs, labels):\n        return self.criterion(outputs, labels)\n","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:30:09.293277Z","iopub.execute_input":"2024-10-31T06:30:09.293756Z","iopub.status.idle":"2024-10-31T06:30:09.308534Z","shell.execute_reply.started":"2024-10-31T06:30:09.293716Z","shell.execute_reply":"2024-10-31T06:30:09.307151Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"num_epochs = 1\nnum_features = 17\nnum_classes = 2\n\nmodel = TabularDenseNet(num_features, num_classes, 1).to(device)\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.001 * 0, 0.001 * 0, 0.001 * 0, 0.001 * 0)\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.001 * 1.0, 0.001 * 0.1, 0.001 * 0.01, 0.001 * 0.005)\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.001 * 1.0, 0.001 * 0.1, 0.001 * 0.01, 0.001 * 0.005)\ncustom_train_loader = CustomDataLoader(x_scaled, y_encoded, validation_size=0.2, random_state=0)\ncriterion = CustomLoss(nn.CrossEntropyLoss(), 0.001 * 0, 0.001 * 0, 0.001 * 0, 0.001 * 0)\n\nfor name, param in model.named_parameters():\n    break\n    print(f\"Layer: {name}\")\n    print(f\"Shape: {param.shape}\")\n    print(param)\n    \ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f'Total number of parameters: {total_params}')\n\n# 3 layers 0.001 * 0.5 l1 val loss = 0.16691114300471785\n# 2 layers no regularization Epoch 75, Training Loss: 0.15852869824943036, Validation Loss: 0.18101713914600992","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:30:12.258514Z","iopub.execute_input":"2024-10-31T06:30:12.258983Z","iopub.status.idle":"2024-10-31T06:30:12.342154Z","shell.execute_reply.started":"2024-10-31T06:30:12.258939Z","shell.execute_reply":"2024-10-31T06:30:12.340969Z"},"trusted":true},"execution_count":48,"outputs":[{"name":"stdout","text":"learnable_activation.learnable_activation\nTotal number of parameters: 1470\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 10)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9995)\n\nstart_time = time.time()\n\nevaluate_model(model, custom_train_loader, criterion, optimizer, 150, scheduler, 1024 * 16, num_features)\n\nelapsed_time = time.time() - start_time\nprint(f\"Execution time: {elapsed_time:.6f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:30:13.692947Z","iopub.execute_input":"2024-10-31T06:30:13.693968Z","iopub.status.idle":"2024-10-31T06:31:31.924632Z","shell.execute_reply.started":"2024-10-31T06:30:13.693878Z","shell.execute_reply":"2024-10-31T06:31:31.923415Z"},"trusted":true},"execution_count":49,"outputs":[{"name":"stdout","text":"Epoch 1, Training Loss: 0.6284685704570236, Validation Loss: 0.5040036569715238\nTraining Accuracy: 0.7461359276514113, Training F1 Score: 0.775094988179223\nValidation Accuracy: 0.7471226570207169, Validation F1 Score: 0.7759626395948441\n\nEpoch 2, Training Loss: 0.45116154482737736, Validation Loss: 0.3656772183480786\nTraining Accuracy: 0.8371197588380378, Training F1 Score: 0.8374865932775295\nValidation Accuracy: 0.8397456976871643, Validation F1 Score: 0.8403969035158311\n\nEpoch 3, Training Loss: 0.3537841805793645, Validation Loss: 0.32507977159115015\nTraining Accuracy: 0.8631542888462592, Training F1 Score: 0.8430357767051797\nValidation Accuracy: 0.8627644415214294, Validation F1 Score: 0.8431513635340138\n\nEpoch 4, Training Loss: 0.31331122279428525, Validation Loss: 0.288688952291298\nTraining Accuracy: 0.8865031515483695, Training F1 Score: 0.8798749419444711\nValidation Accuracy: 0.88726296174504, Validation F1 Score: 0.8810340356310372\n\nEpoch 5, Training Loss: 0.28311647448385535, Validation Loss: 0.2707196826816167\nTraining Accuracy: 0.8969717730885174, Training F1 Score: 0.8929794904199962\nValidation Accuracy: 0.8989367532609888, Validation F1 Score: 0.8955837590228936\n\nEpoch 6, Training Loss: 0.2707706330965303, Validation Loss: 0.2607323760743545\nTraining Accuracy: 0.903548917511647, Training F1 Score: 0.8991591686449236\nValidation Accuracy: 0.9048558588183712, Validation F1 Score: 0.9011679254867425\n\nEpoch 7, Training Loss: 0.2601651320737759, Validation Loss: 0.25385056752117396\nTraining Accuracy: 0.9076322280076733, Training F1 Score: 0.9019415855694045\nValidation Accuracy: 0.908692316124082, Validation F1 Score: 0.9035261220013896\n\nEpoch 8, Training Loss: 0.25348880558054426, Validation Loss: 0.2468451931100789\nTraining Accuracy: 0.9116881337352699, Training F1 Score: 0.9075982270389075\nValidation Accuracy: 0.9124739668968541, Validation F1 Score: 0.9086866731496729\n\nEpoch 9, Training Loss: 0.24799972847001983, Validation Loss: 0.24258665340806287\nTraining Accuracy: 0.9132090983831187, Training F1 Score: 0.9082974027117405\nValidation Accuracy: 0.9153787131426065, Validation F1 Score: 0.9110506125251894\n\nEpoch 10, Training Loss: 0.24331471352062345, Validation Loss: 0.23771348590065772\nTraining Accuracy: 0.9152096464784872, Training F1 Score: 0.910772708451048\nValidation Accuracy: 0.9167488764660747, Validation F1 Score: 0.9127832399018674\n\nEpoch 11, Training Loss: 0.23835739546702248, Validation Loss: 0.2327813933740566\nTraining Accuracy: 0.9175938613318717, Training F1 Score: 0.9132242452030023\nValidation Accuracy: 0.9189959443165625, Validation F1 Score: 0.9149227168653313\n\nEpoch 12, Training Loss: 0.2334610376408016, Validation Loss: 0.22814525623508652\nTraining Accuracy: 0.9191833379007948, Training F1 Score: 0.9153328467164752\nValidation Accuracy: 0.9216814644305601, Validation F1 Score: 0.918396191411279\n\nEpoch 13, Training Loss: 0.22959164023546363, Validation Loss: 0.22438842813775006\nTraining Accuracy: 0.9223622910386408, Training F1 Score: 0.9188824763160737\nValidation Accuracy: 0.9248054368080675, Validation F1 Score: 0.9216574009500929\n\nEpoch 14, Training Loss: 0.22624414439771756, Validation Loss: 0.22150323087939383\nTraining Accuracy: 0.9247053987393806, Training F1 Score: 0.9216097665776805\nValidation Accuracy: 0.927107311191494, Validation F1 Score: 0.9243525442897745\n\nEpoch 15, Training Loss: 0.2233026520328412, Validation Loss: 0.21905781555715445\nTraining Accuracy: 0.925979720471362, Training F1 Score: 0.9229743831702727\nValidation Accuracy: 0.9296284117066754, Validation F1 Score: 0.926968922457196\n\nEpoch 16, Training Loss: 0.22061282914529012, Validation Loss: 0.216361908283553\nTraining Accuracy: 0.9285831734721841, Training F1 Score: 0.9250250341081121\nValidation Accuracy: 0.9308341554313274, Validation F1 Score: 0.9276505576890783\n\nEpoch 17, Training Loss: 0.21805679837982436, Validation Loss: 0.21413134207501297\nTraining Accuracy: 0.9297067689778021, Training F1 Score: 0.9261410849610182\nValidation Accuracy: 0.931711059958347, Validation F1 Score: 0.9284407390853544\n\nEpoch 18, Training Loss: 0.21593794379619155, Validation Loss: 0.21275651116492938\nTraining Accuracy: 0.9303918881885448, Training F1 Score: 0.9267039296881191\nValidation Accuracy: 0.9324235448865504, Validation F1 Score: 0.9290777491078707\n\nEpoch 19, Training Loss: 0.21408501889859854, Validation Loss: 0.2111851134269394\nTraining Accuracy: 0.9312277336256508, Training F1 Score: 0.9274468379265022\nValidation Accuracy: 0.9331908363476926, Validation F1 Score: 0.9297216902822139\n\nEpoch 20, Training Loss: 0.2123189386855285, Validation Loss: 0.20963996369646892\nTraining Accuracy: 0.9322965195944094, Training F1 Score: 0.9286220418057726\nValidation Accuracy: 0.934341773539406, Validation F1 Score: 0.9309608496490509\n\nEpoch 21, Training Loss: 0.21073065259320078, Validation Loss: 0.2076807177182445\nTraining Accuracy: 0.9335160317895314, Training F1 Score: 0.9297535519351697\nValidation Accuracy: 0.9347802258029158, Validation F1 Score: 0.9312856190312128\n\nEpoch 22, Training Loss: 0.20904010760356184, Validation Loss: 0.20581509063644496\nTraining Accuracy: 0.9346807344477939, Training F1 Score: 0.9307218067832826\nValidation Accuracy: 0.935711936862874, Validation F1 Score: 0.9319770485864393\n\nEpoch 23, Training Loss: 0.20730746737340602, Validation Loss: 0.20461843309532612\nTraining Accuracy: 0.9353658536585366, Training F1 Score: 0.9313336943650624\nValidation Accuracy: 0.9364792283240162, Validation F1 Score: 0.9327547533413181\n\nEpoch 24, Training Loss: 0.2056864794761261, Validation Loss: 0.20324757044956662\nTraining Accuracy: 0.9362016990956427, Training F1 Score: 0.9322697266174075\nValidation Accuracy: 0.9379041981804231, Validation F1 Score: 0.9343077843523295\n\nEpoch 25, Training Loss: 0.20382858173394405, Validation Loss: 0.20145439492706196\nTraining Accuracy: 0.9364620443957249, Training F1 Score: 0.9327172010887519\nValidation Accuracy: 0.9376849720486682, Validation F1 Score: 0.9342309494620388\n\nEpoch 26, Training Loss: 0.2020756931231753, Validation Loss: 0.19990604734010475\nTraining Accuracy: 0.9372978898328309, Training F1 Score: 0.9336206188283551\nValidation Accuracy: 0.938726296174504, Validation F1 Score: 0.9353137441611048\n\nEpoch 27, Training Loss: 0.20058205079284228, Validation Loss: 0.19907949852940807\nTraining Accuracy: 0.9374623184434091, Training F1 Score: 0.9339509244409772\nValidation Accuracy: 0.93932916803683, Validation F1 Score: 0.9361365664097598\n\nEpoch 28, Training Loss: 0.19953171299251343, Validation Loss: 0.1988822420650468\nTraining Accuracy: 0.9378322828172102, Training F1 Score: 0.9344199644793421\nValidation Accuracy: 0.9392195549709526, Validation F1 Score: 0.9360740020255497\n\nEpoch 29, Training Loss: 0.1987234852769075, Validation Loss: 0.19744142441455306\nTraining Accuracy: 0.9384351877226638, Training F1 Score: 0.9349906951426175\nValidation Accuracy: 0.9396032007015236, Validation F1 Score: 0.9364302779209727\n\nEpoch 30, Training Loss: 0.19696992129275295, Validation Loss: 0.19670919913263235\nTraining Accuracy: 0.9381200328857221, Training F1 Score: 0.9349436935603949\nValidation Accuracy: 0.9397676203003398, Validation F1 Score: 0.936847229781418\n\nEpoch 31, Training Loss: 0.1962848445280639, Validation Loss: 0.1965773684256147\nTraining Accuracy: 0.9383392710331597, Training F1 Score: 0.9352406986560432\nValidation Accuracy: 0.9395483941685849, Validation F1 Score: 0.9367097853694917\n\nEpoch 32, Training Loss: 0.19588743213530468, Validation Loss: 0.19503077089779997\nTraining Accuracy: 0.9390791997807618, Training F1 Score: 0.9358939647500646\nValidation Accuracy: 0.9404252986956045, Validation F1 Score: 0.9375164598485318\n\nEpoch 33, Training Loss: 0.1944651557112694, Validation Loss: 0.19330634044592127\nTraining Accuracy: 0.9400383666758015, Training F1 Score: 0.9366636360625905\nValidation Accuracy: 0.9404801052285432, Validation F1 Score: 0.9373013226176865\n\nEpoch 34, Training Loss: 0.19337030295542934, Validation Loss: 0.19238712667608737\nTraining Accuracy: 0.9404768429706769, Training F1 Score: 0.9368002156938217\nValidation Accuracy: 0.9410829770908692, Validation F1 Score: 0.9376601255161313\n\nEpoch 35, Training Loss: 0.19275592413543838, Validation Loss: 0.192452324669272\nTraining Accuracy: 0.9406960811181145, Training F1 Score: 0.9368257807668383\nValidation Accuracy: 0.9406993313602982, Validation F1 Score: 0.9370345423178459\n\nEpoch 36, Training Loss: 0.1921276217904866, Validation Loss: 0.19291293099204085\nTraining Accuracy: 0.9405179501233215, Training F1 Score: 0.9365015296190221\nValidation Accuracy: 0.9408637509591143, Validation F1 Score: 0.9370517533766702\n\nEpoch 37, Training Loss: 0.19178945974850858, Validation Loss: 0.19178487168720754\nTraining Accuracy: 0.9408331049602631, Training F1 Score: 0.9369139993927446\nValidation Accuracy: 0.9414666228214403, Validation F1 Score: 0.9377957683207674\n\nEpoch 38, Training Loss: 0.19129433170610272, Validation Loss: 0.191133948045643\nTraining Accuracy: 0.9411071526445601, Training F1 Score: 0.9372582170470427\nValidation Accuracy: 0.9422339142825825, Validation F1 Score: 0.9386850099597172\n\nEpoch 39, Training Loss: 0.19087015612627192, Validation Loss: 0.19037431471803581\nTraining Accuracy: 0.9413812003288572, Training F1 Score: 0.9377202834847712\nValidation Accuracy: 0.9425627534802148, Validation F1 Score: 0.9392001340349492\n\nEpoch 40, Training Loss: 0.19012084545975483, Validation Loss: 0.1904164687865635\nTraining Accuracy: 0.9419018909290217, Training F1 Score: 0.9383872111828753\nValidation Accuracy: 0.9431108188096021, Validation F1 Score: 0.9398717904042336\n\nEpoch 41, Training Loss: 0.18959711660225445, Validation Loss: 0.1900573508899933\nTraining Accuracy: 0.9419567004658811, Training F1 Score: 0.9387156582357638\nValidation Accuracy: 0.942727173079031, Validation F1 Score: 0.9397532127521848\n\nEpoch 42, Training Loss: 0.18919947092730433, Validation Loss: 0.18997489947388338\nTraining Accuracy: 0.9417511647026583, Training F1 Score: 0.9385179676990141\nValidation Accuracy: 0.9432204318754795, Validation F1 Score: 0.9402572924196877\n\nEpoch 43, Training Loss: 0.18909115900925397, Validation Loss: 0.19021197712161386\nTraining Accuracy: 0.9421759386133187, Training F1 Score: 0.9389009731215969\nValidation Accuracy: 0.9428367861449085, Validation F1 Score: 0.939768862348426\n\nEpoch 44, Training Loss: 0.1886872870190629, Validation Loss: 0.18981715218482226\nTraining Accuracy: 0.9421759386133187, Training F1 Score: 0.9389112479997739\nValidation Accuracy: 0.9428367861449085, Validation F1 Score: 0.9398088303285709\n\nEpoch 45, Training Loss: 0.18764125881994806, Validation Loss: 0.18851918480276839\nTraining Accuracy: 0.942436283913401, Training F1 Score: 0.939138908491325\nValidation Accuracy: 0.9431656253425408, Validation F1 Score: 0.940095428309919\n\nEpoch 46, Training Loss: 0.18696406261909168, Validation Loss: 0.18820706627112294\nTraining Accuracy: 0.9426555220608386, Training F1 Score: 0.9392007128415119\nValidation Accuracy: 0.9429463992107859, Validation F1 Score: 0.9397334997296497\n\nEpoch 47, Training Loss: 0.18667127985714493, Validation Loss: 0.1883155684123943\nTraining Accuracy: 0.942614414908194, Training F1 Score: 0.9391688074209706\nValidation Accuracy: 0.9430012057437247, Validation F1 Score: 0.9397964487972473\n\nEpoch 48, Training Loss: 0.18647481642559346, Validation Loss: 0.18760865039173663\nTraining Accuracy: 0.9429295697451356, Training F1 Score: 0.9394680076469017\nValidation Accuracy: 0.9431108188096021, Validation F1 Score: 0.9398515192148472\n\nEpoch 49, Training Loss: 0.18599502769487464, Validation Loss: 0.18789970350477186\nTraining Accuracy: 0.9431899150452179, Training F1 Score: 0.939742856112265\nValidation Accuracy: 0.9431656253425408, Validation F1 Score: 0.9399549813953102\n\nEpoch 50, Training Loss: 0.1858193406293607, Validation Loss: 0.1872888737298229\nTraining Accuracy: 0.9432036174294327, Training F1 Score: 0.9396837607759704\nValidation Accuracy: 0.9431656253425408, Validation F1 Score: 0.9398332003580215\n\nEpoch 51, Training Loss: 0.18596415813817296, Validation Loss: 0.18760598052277136\nTraining Accuracy: 0.9427925459029871, Training F1 Score: 0.9391948876710929\nValidation Accuracy: 0.9431108188096021, Validation F1 Score: 0.9397700729001588\n\nEpoch 52, Training Loss: 0.18598401524099986, Validation Loss: 0.18732454281234565\nTraining Accuracy: 0.9432310221978625, Training F1 Score: 0.9396973107452454\nValidation Accuracy: 0.9434396580072345, Validation F1 Score: 0.94009788863254\n\nEpoch 53, Training Loss: 0.1857243449639281, Validation Loss: 0.18763873851490062\nTraining Accuracy: 0.943176212661003, Training F1 Score: 0.9396286990801463\nValidation Accuracy: 0.9432752384084183, Validation F1 Score: 0.9399797487527403\n\nEpoch 54, Training Loss: 0.18654528662713465, Validation Loss: 0.18759933822767574\nTraining Accuracy: 0.9431899150452179, Training F1 Score: 0.9396989827823888\nValidation Accuracy: 0.9429463992107859, Validation F1 Score: 0.9397334997296497\n\nEpoch 55, Training Loss: 0.1868182747788415, Validation Loss: 0.187207156588317\nTraining Accuracy: 0.9432310221978625, Training F1 Score: 0.9399791711210566\nValidation Accuracy: 0.9434396580072345, Validation F1 Score: 0.9404189364101773\n\nEpoch 56, Training Loss: 0.18623860618714666, Validation Loss: 0.19053245490905055\nTraining Accuracy: 0.9421074266922445, Training F1 Score: 0.9393700200478812\nValidation Accuracy: 0.9423983338813987, Validation F1 Score: 0.9398771683717492\n\nEpoch 57, Training Loss: 0.1861437385924779, Validation Loss: 0.18787882929731328\nTraining Accuracy: 0.9427514387503425, Training F1 Score: 0.9397781010611342\nValidation Accuracy: 0.9428915926778472, Validation F1 Score: 0.9400982960097803\n\nEpoch 58, Training Loss: 0.18517035247202146, Validation Loss: 0.18650271006644745\nTraining Accuracy: 0.9434639627295149, Training F1 Score: 0.9400078688739563\nValidation Accuracy: 0.9436588841389894, Validation F1 Score: 0.9404811072664379\n\nEpoch 59, Training Loss: 0.18426212283577714, Validation Loss: 0.18660985656955661\nTraining Accuracy: 0.9435872841874486, Training F1 Score: 0.9401092099317474\nValidation Accuracy: 0.9435492710731119, Validation F1 Score: 0.940264647135748\n\nEpoch 60, Training Loss: 0.18410605373824254, Validation Loss: 0.18657466026365424\nTraining Accuracy: 0.9434913674979446, Training F1 Score: 0.9402077227187289\nValidation Accuracy: 0.9430560122766634, Validation F1 Score: 0.9400197792251743\n\nEpoch 61, Training Loss: 0.18363456315097826, Validation Loss: 0.18606434130040123\nTraining Accuracy: 0.9438202247191011, Training F1 Score: 0.940477449520078\nValidation Accuracy: 0.9433848514742957, Validation F1 Score: 0.9402567616951197\n\nEpoch 62, Training Loss: 0.18402189724443382, Validation Loss: 0.1869483322156674\nTraining Accuracy: 0.9436969032611674, Training F1 Score: 0.9405492920413271\nValidation Accuracy: 0.9439877233366217, Validation F1 Score: 0.941064626305908\n\nEpoch 63, Training Loss: 0.18366433273409777, Validation Loss: 0.18633358160922575\nTraining Accuracy: 0.9434639627295149, Training F1 Score: 0.9403270865323897\nValidation Accuracy: 0.943330044941357, Validation F1 Score: 0.9403824704266318\n\nEpoch 64, Training Loss: 0.18367753452995308, Validation Loss: 0.1871366781270074\nTraining Accuracy: 0.9432310221978625, Training F1 Score: 0.9401947819474354\nValidation Accuracy: 0.9430012057437247, Validation F1 Score: 0.9401937707367929\n\nEpoch 65, Training Loss: 0.18343077849757022, Validation Loss: 0.18768590644931343\nTraining Accuracy: 0.9435735818032338, Training F1 Score: 0.9403827886228355\nValidation Accuracy: 0.9430560122766634, Validation F1 Score: 0.9400496006096971\n\nEpoch 66, Training Loss: 0.18364725985668168, Validation Loss: 0.18594220131194658\nTraining Accuracy: 0.9437106056453823, Training F1 Score: 0.9405225586690809\nValidation Accuracy: 0.9441521429354379, Validation F1 Score: 0.941223057652601\n\nEpoch 67, Training Loss: 0.1822268263906216, Validation Loss: 0.18556997835779876\nTraining Accuracy: 0.9442861057824061, Training F1 Score: 0.9411997683786576\nValidation Accuracy: 0.9438781102707443, Validation F1 Score: 0.9409882387651318\n\nEpoch 68, Training Loss: 0.182246631749789, Validation Loss: 0.1865765341071331\nTraining Accuracy: 0.9436557961085229, Training F1 Score: 0.9403488656824834\nValidation Accuracy: 0.9433848514742957, Validation F1 Score: 0.9403364239700681\n\nEpoch 69, Training Loss: 0.18269569295241297, Validation Loss: 0.186875974112444\nTraining Accuracy: 0.9444779391614141, Training F1 Score: 0.9411742988915502\nValidation Accuracy: 0.9440973364024992, Validation F1 Score: 0.9410135453096756\n\nEpoch 70, Training Loss: 0.18242108603884796, Validation Loss: 0.18565416262558282\nTraining Accuracy: 0.9439435461770348, Training F1 Score: 0.9405891402031437\nValidation Accuracy: 0.9433848514742957, Validation F1 Score: 0.9402367576511739\n\nEpoch 71, Training Loss: 0.18226613636358563, Validation Loss: 0.1863966001193408\nTraining Accuracy: 0.9442449986297616, Training F1 Score: 0.9410512303383005\nValidation Accuracy: 0.943330044941357, Validation F1 Score: 0.9403133750014165\n\nEpoch 72, Training Loss: 0.18246605631732785, Validation Loss: 0.1854565052982617\nTraining Accuracy: 0.9441627843244724, Training F1 Score: 0.9409144043476264\nValidation Accuracy: 0.943932916803683, Validation F1 Score: 0.9409041689113282\n\nEpoch 73, Training Loss: 0.1823028228509325, Validation Loss: 0.18615712407883694\nTraining Accuracy: 0.944395724856125, Training F1 Score: 0.941167120260607\nValidation Accuracy: 0.943932916803683, Validation F1 Score: 0.9409532360380314\n\nEpoch 74, Training Loss: 0.18256026603369296, Validation Loss: 0.18621496492626244\nTraining Accuracy: 0.9442449986297616, Training F1 Score: 0.9411156774805906\nValidation Accuracy: 0.9432204318754795, Validation F1 Score: 0.9402078431288895\n\nEpoch 75, Training Loss: 0.18157546415283896, Validation Loss: 0.18603739183741966\nTraining Accuracy: 0.9437517127980268, Training F1 Score: 0.9406220998622087\nValidation Accuracy: 0.9435492710731119, Validation F1 Score: 0.9406717565162241\n\nEpoch 76, Training Loss: 0.18130462194884042, Validation Loss: 0.18545979491539016\nTraining Accuracy: 0.9443272129350507, Training F1 Score: 0.9410983675181804\nValidation Accuracy: 0.943932916803683, Validation F1 Score: 0.9408450006508081\n\nEpoch 77, Training Loss: 0.18195671149151527, Validation Loss: 0.18638859363053303\nTraining Accuracy: 0.944299808166621, Training F1 Score: 0.9412203784413545\nValidation Accuracy: 0.9441521429354379, Validation F1 Score: 0.9412715451593024\n\nEpoch 78, Training Loss: 0.1817182150016781, Validation Loss: 0.18691597226568185\nTraining Accuracy: 0.9440805700191833, Training F1 Score: 0.9411337095300181\nValidation Accuracy: 0.9430012057437247, Validation F1 Score: 0.940213270489608\n\nEpoch 79, Training Loss: 0.1808379526047159, Validation Loss: 0.18541085118985054\nTraining Accuracy: 0.944299808166621, Training F1 Score: 0.9412767860636441\nValidation Accuracy: 0.9431108188096021, Validation F1 Score: 0.940279524891897\n\nEpoch 80, Training Loss: 0.18098209557728626, Validation Loss: 0.18520781456130542\nTraining Accuracy: 0.9446697725404221, Training F1 Score: 0.941565518682882\nValidation Accuracy: 0.9431108188096021, Validation F1 Score: 0.9401221674065061\n\nEpoch 81, Training Loss: 0.18078401644986503, Validation Loss: 0.18554729977374562\nTraining Accuracy: 0.9444368320087695, Training F1 Score: 0.9414236865842538\nValidation Accuracy: 0.9431108188096021, Validation F1 Score: 0.940240393782902\n\nEpoch 82, Training Loss: 0.1804629125956739, Validation Loss: 0.18564153927584875\nTraining Accuracy: 0.9447793916141408, Training F1 Score: 0.9416002194503433\nValidation Accuracy: 0.9438781102707443, Validation F1 Score: 0.9408414782402825\n\nEpoch 83, Training Loss: 0.18108145679372994, Validation Loss: 0.18603764964563863\nTraining Accuracy: 0.9447519868457112, Training F1 Score: 0.941568769793246\nValidation Accuracy: 0.9439877233366217, Validation F1 Score: 0.9409766646487256\n\nEpoch 84, Training Loss: 0.18026712139556428, Validation Loss: 0.18504663160478912\nTraining Accuracy: 0.9445601534667032, Training F1 Score: 0.9414300733192146\nValidation Accuracy: 0.9440973364024992, Validation F1 Score: 0.9411507742144107\n\nEpoch 85, Training Loss: 0.18050884556593913, Validation Loss: 0.18488122974455545\nTraining Accuracy: 0.9446423677719923, Training F1 Score: 0.9415439350366811\nValidation Accuracy: 0.943932916803683, Validation F1 Score: 0.9410410114798495\n\nEpoch 86, Training Loss: 0.1803448282176091, Validation Loss: 0.18587813602751654\nTraining Accuracy: 0.9449986297615786, Training F1 Score: 0.9419225734480777\nValidation Accuracy: 0.9437136906719281, Validation F1 Score: 0.940820225537417\n\nEpoch 87, Training Loss: 0.1798509886499038, Validation Loss: 0.1854647756305609\nTraining Accuracy: 0.9450260345300082, Training F1 Score: 0.9418438663863328\nValidation Accuracy: 0.9443165625342541, Validation F1 Score: 0.9413329318787497\n\nEpoch 88, Training Loss: 0.18006078087653027, Validation Loss: 0.18514349659087953\nTraining Accuracy: 0.9451493559879419, Training F1 Score: 0.9419460814443701\nValidation Accuracy: 0.9433848514742957, Validation F1 Score: 0.9403264970531787\n\nEpoch 89, Training Loss: 0.1798033343084416, Validation Loss: 0.1854938533952149\nTraining Accuracy: 0.944587558235133, Training F1 Score: 0.9415007748931155\nValidation Accuracy: 0.9433848514742957, Validation F1 Score: 0.9404744819670416\n\nEpoch 90, Training Loss: 0.17983162805017427, Validation Loss: 0.18661309401383724\nTraining Accuracy: 0.944587558235133, Training F1 Score: 0.9415130242212759\nValidation Accuracy: 0.9435492710731119, Validation F1 Score: 0.9406522386186971\n\nEpoch 91, Training Loss: 0.17943130769723734, Validation Loss: 0.1841031133860699\nTraining Accuracy: 0.9448204987667854, Training F1 Score: 0.9417381449751042\nValidation Accuracy: 0.9438781102707443, Validation F1 Score: 0.9410657187338924\n\nEpoch 92, Training Loss: 0.179737787268429, Validation Loss: 0.18601525119296242\nTraining Accuracy: 0.9448890106878597, Training F1 Score: 0.9418700965428644\nValidation Accuracy: 0.9448646278636413, Validation F1 Score: 0.9420255548805886\n\nEpoch 93, Training Loss: 0.18004853400049814, Validation Loss: 0.1852211590795471\nTraining Accuracy: 0.945231570293231, Training F1 Score: 0.9421721791570629\nValidation Accuracy: 0.9442069494683766, Validation F1 Score: 0.94137259183072\n\nEpoch 94, Training Loss: 0.17881843301246317, Validation Loss: 0.18551045858251097\nTraining Accuracy: 0.9451493559879419, Training F1 Score: 0.9421483252893232\nValidation Accuracy: 0.9438781102707443, Validation F1 Score: 0.9410560636468873\n\nEpoch 95, Training Loss: 0.17902067269518396, Validation Loss: 0.1847632446336626\nTraining Accuracy: 0.9448067963825706, Training F1 Score: 0.9415102760696665\nValidation Accuracy: 0.9441521429354379, Validation F1 Score: 0.9410565853138236\n\nEpoch 96, Training Loss: 0.17906504824214453, Validation Loss: 0.18528817629985325\nTraining Accuracy: 0.9449986297615786, Training F1 Score: 0.9417110845586244\nValidation Accuracy: 0.943932916803683, Validation F1 Score: 0.9408152982353832\n\nEpoch 97, Training Loss: 0.17992539703029253, Validation Loss: 0.1851677997575757\nTraining Accuracy: 0.9447382844614963, Training F1 Score: 0.94144639767133\nValidation Accuracy: 0.9441521429354379, Validation F1 Score: 0.9410467144690668\n\nEpoch 98, Training Loss: 0.17914111041212513, Validation Loss: 0.1859716862312707\nTraining Accuracy: 0.9450260345300082, Training F1 Score: 0.9419002663766651\nValidation Accuracy: 0.9434944645401732, Validation F1 Score: 0.9404717282036404\n\nEpoch 99, Training Loss: 0.17897928747192543, Validation Loss: 0.1858923912495881\nTraining Accuracy: 0.9454645108248835, Training F1 Score: 0.9423951717388278\nValidation Accuracy: 0.9438781102707443, Validation F1 Score: 0.9409882387651318\n\nEpoch 100, Training Loss: 0.17947393985570834, Validation Loss: 0.1858376046273317\nTraining Accuracy: 0.944765689229926, Training F1 Score: 0.9416851631538272\nValidation Accuracy: 0.9441521429354379, Validation F1 Score: 0.9412715451593024\n\nEpoch 101, Training Loss: 0.17993448533303577, Validation Loss: 0.18637712880647275\nTraining Accuracy: 0.9443272129350507, Training F1 Score: 0.9415283485276729\nValidation Accuracy: 0.9433848514742957, Validation F1 Score: 0.9407263901057888\n\nEpoch 102, Training Loss: 0.1798650876075544, Validation Loss: 0.18527798015049748\nTraining Accuracy: 0.9449438202247191, Training F1 Score: 0.9418720106584905\nValidation Accuracy: 0.9438781102707443, Validation F1 Score: 0.9410367278816073\n\nEpoch 103, Training Loss: 0.18104187320702433, Validation Loss: 0.1849710350740012\nTraining Accuracy: 0.9444231296245547, Training F1 Score: 0.9409725081920846\nValidation Accuracy: 0.9438233037378055, Validation F1 Score: 0.9405797521399392\n\nEpoch 104, Training Loss: 0.17967132533877214, Validation Loss: 0.18621113600731418\nTraining Accuracy: 0.9454645108248835, Training F1 Score: 0.9423393830236519\nValidation Accuracy: 0.9432752384084183, Validation F1 Score: 0.9403001616000412\n\nEpoch 105, Training Loss: 0.17902905516230463, Validation Loss: 0.184786868137212\nTraining Accuracy: 0.9451904631405864, Training F1 Score: 0.942088666063619\nValidation Accuracy: 0.9443165625342541, Validation F1 Score: 0.9413912544171582\n\nEpoch 106, Training Loss: 0.17932461994613613, Validation Loss: 0.18599442039863145\nTraining Accuracy: 0.9449712249931488, Training F1 Score: 0.942103619586144\nValidation Accuracy: 0.9438233037378055, Validation F1 Score: 0.941099554618702\n\nEpoch 107, Training Loss: 0.1793208823575814, Validation Loss: 0.18500850549833198\nTraining Accuracy: 0.9449164154562893, Training F1 Score: 0.9419159668128334\nValidation Accuracy: 0.9440425298695605, Validation F1 Score: 0.9412046467410681\n\nEpoch 108, Training Loss: 0.17890840275593412, Validation Loss: 0.18506413471159097\nTraining Accuracy: 0.9449164154562893, Training F1 Score: 0.9417106451179854\nValidation Accuracy: 0.9447002082648251, Validation F1 Score: 0.9416934911517761\n\nEpoch 109, Training Loss: 0.17888096449766527, Validation Loss: 0.1863412876296668\nTraining Accuracy: 0.944573855850918, Training F1 Score: 0.9413915090233294\nValidation Accuracy: 0.9442617560013153, Validation F1 Score: 0.9413674807358583\n\nEpoch 110, Training Loss: 0.17876549148582438, Validation Loss: 0.18520240382929715\nTraining Accuracy: 0.9451356536037271, Training F1 Score: 0.9421640176282734\nValidation Accuracy: 0.9445905951989477, Validation F1 Score: 0.9418756645781335\n\nEpoch 111, Training Loss: 0.17729575007410694, Validation Loss: 0.1849410010967863\nTraining Accuracy: 0.9447930939983558, Training F1 Score: 0.9418909959627153\nValidation Accuracy: 0.9442617560013153, Validation F1 Score: 0.9415782584364222\n\nEpoch 112, Training Loss: 0.1773743414820041, Validation Loss: 0.18555764968289654\nTraining Accuracy: 0.9457522608933955, Training F1 Score: 0.9425890592556266\nValidation Accuracy: 0.9449742409295188, Validation F1 Score: 0.942025850006166\n\nEpoch 113, Training Loss: 0.17762440773404503, Validation Loss: 0.18538029045830245\nTraining Accuracy: 0.9453548917511647, Training F1 Score: 0.9422210453265842\nValidation Accuracy: 0.9440973364024992, Validation F1 Score: 0.9412284304767682\n\nEpoch 114, Training Loss: 0.17701881228652383, Validation Loss: 0.1858613986930708\nTraining Accuracy: 0.9454919155933132, Training F1 Score: 0.9426063607859017\nValidation Accuracy: 0.9448098213307026, Validation F1 Score: 0.9421902234642487\n\nEpoch 115, Training Loss: 0.17741997341859436, Validation Loss: 0.1856964099590786\nTraining Accuracy: 0.9453822965195944, Training F1 Score: 0.9423518581963417\nValidation Accuracy: 0.9444809821330703, Validation F1 Score: 0.9416557541767662\n\nEpoch 116, Training Loss: 0.17739265043136354, Validation Loss: 0.18548634593278762\nTraining Accuracy: 0.9457385585091806, Training F1 Score: 0.9428209922710489\nValidation Accuracy: 0.944535788666009, Validation F1 Score: 0.9417563548424798\n\nEpoch 117, Training Loss: 0.17657696703552514, Validation Loss: 0.18514222036514263\nTraining Accuracy: 0.9458344751986846, Training F1 Score: 0.942870929270221\nValidation Accuracy: 0.9439877233366217, Validation F1 Score: 0.9412096824652381\n\nEpoch 118, Training Loss: 0.17641653419439354, Validation Loss: 0.18547700661081737\nTraining Accuracy: 0.9460263085776925, Training F1 Score: 0.9429921794351941\nValidation Accuracy: 0.9446454017318865, Validation F1 Score: 0.9417566267798113\n\nEpoch 119, Training Loss: 0.17603274768886581, Validation Loss: 0.18561566252497014\nTraining Accuracy: 0.94579336804604, Training F1 Score: 0.9427184626567304\nValidation Accuracy: 0.9443165625342541, Validation F1 Score: 0.9414396205559842\n\nEpoch 120, Training Loss: 0.17674049178062318, Validation Loss: 0.1862149033779169\nTraining Accuracy: 0.9452178679090162, Training F1 Score: 0.9421589238967382\nValidation Accuracy: 0.9438781102707443, Validation F1 Score: 0.9409492928935909\n\nEpoch 121, Training Loss: 0.17678360386919276, Validation Loss: 0.18649238459892498\nTraining Accuracy: 0.9462181419567005, Training F1 Score: 0.9432637446875466\nValidation Accuracy: 0.9434396580072345, Validation F1 Score: 0.9406052946615011\n\nEpoch 122, Training Loss: 0.17709636448115054, Validation Loss: 0.1860956827789679\nTraining Accuracy: 0.9452041655248014, Training F1 Score: 0.9422205952708383\nValidation Accuracy: 0.9437684972048668, Validation F1 Score: 0.9409602781253168\n\nEpoch 123, Training Loss: 0.17653616627590987, Validation Loss: 0.18590163286711242\nTraining Accuracy: 0.9459029871197588, Training F1 Score: 0.9430250251268706\nValidation Accuracy: 0.9436040776060507, Validation F1 Score: 0.9408696992220918\n\nEpoch 124, Training Loss: 0.1761498819494548, Validation Loss: 0.18589512465960048\nTraining Accuracy: 0.9454919155933132, Training F1 Score: 0.9426253662509418\nValidation Accuracy: 0.943932916803683, Validation F1 Score: 0.9413001907824026\n\nEpoch 125, Training Loss: 0.17653200861590304, Validation Loss: 0.1868547452073681\nTraining Accuracy: 0.945423403672239, Training F1 Score: 0.942446971544891\nValidation Accuracy: 0.9448098213307026, Validation F1 Score: 0.9420772857677416\n\nEpoch 126, Training Loss: 0.17697562321256893, Validation Loss: 0.1865589840101409\nTraining Accuracy: 0.94579336804604, Training F1 Score: 0.9428120531979763\nValidation Accuracy: 0.9433848514742957, Validation F1 Score: 0.9405233756547479\n\nEpoch 127, Training Loss: 0.17593575913012927, Validation Loss: 0.18547885143598758\nTraining Accuracy: 0.9459303918881885, Training F1 Score: 0.9429112340411528\nValidation Accuracy: 0.9437684972048668, Validation F1 Score: 0.9409021574617921\n\nEpoch 128, Training Loss: 0.17629149078212067, Validation Loss: 0.1859127001978386\nTraining Accuracy: 0.945889284735544, Training F1 Score: 0.9427752195386091\nValidation Accuracy: 0.9443713690671928, Validation F1 Score: 0.9414440965726341\n\nEpoch 129, Training Loss: 0.17711663608209308, Validation Loss: 0.18675815847918847\nTraining Accuracy: 0.9452863798300905, Training F1 Score: 0.942295254080422\nValidation Accuracy: 0.9436040776060507, Validation F1 Score: 0.9408889163530763\n\nEpoch 130, Training Loss: 0.17680699406878267, Validation Loss: 0.18629224187127202\nTraining Accuracy: 0.945423403672239, Training F1 Score: 0.9426018606144919\nValidation Accuracy: 0.9432204318754795, Validation F1 Score: 0.9405302084039704\n\nEpoch 131, Training Loss: 0.17611726401651942, Validation Loss: 0.18604549249934482\nTraining Accuracy: 0.9462181419567005, Training F1 Score: 0.9431947967207763\nValidation Accuracy: 0.9441521429354379, Validation F1 Score: 0.9413294480079264\n\nEpoch 132, Training Loss: 0.17621204142914826, Validation Loss: 0.18596749625112696\nTraining Accuracy: 0.9454645108248835, Training F1 Score: 0.9422097347045018\nValidation Accuracy: 0.9439877233366217, Validation F1 Score: 0.9408681990453034\n\nEpoch 133, Training Loss: 0.17636684835136804, Validation Loss: 0.18585632601472143\nTraining Accuracy: 0.9453274869827349, Training F1 Score: 0.9420817874524222\nValidation Accuracy: 0.9442617560013153, Validation F1 Score: 0.9412409902018296\n\nEpoch 134, Training Loss: 0.1765426066419006, Validation Loss: 0.18598978984849854\nTraining Accuracy: 0.9454097012880242, Training F1 Score: 0.9424887917741935\nValidation Accuracy: 0.9433848514742957, Validation F1 Score: 0.9406108422445224\n\nEpoch 135, Training Loss: 0.17647510188986223, Validation Loss: 0.18583175034281535\nTraining Accuracy: 0.9455878322828172, Training F1 Score: 0.9427132874883967\nValidation Accuracy: 0.943330044941357, Validation F1 Score: 0.9406546193220537\n\nEpoch 136, Training Loss: 0.1760732519010806, Validation Loss: 0.1847057751245461\nTraining Accuracy: 0.9459714990408331, Training F1 Score: 0.9428790371227832\nValidation Accuracy: 0.9443713690671928, Validation F1 Score: 0.9414440965726341\n\nEpoch 137, Training Loss: 0.17597253648066527, Validation Loss: 0.1862439326529543\nTraining Accuracy: 0.9458070704302549, Training F1 Score: 0.9427413724777628\nValidation Accuracy: 0.9430560122766634, Validation F1 Score: 0.9400991273201149\n\nEpoch 138, Training Loss: 0.1757464293528335, Validation Loss: 0.18619129149737124\nTraining Accuracy: 0.9453822965195944, Training F1 Score: 0.9425621790789119\nValidation Accuracy: 0.9432204318754795, Validation F1 Score: 0.9405782385738197\n\nEpoch 139, Training Loss: 0.1773133314490547, Validation Loss: 0.18604979002494032\nTraining Accuracy: 0.9456015346670321, Training F1 Score: 0.9425928712157557\nValidation Accuracy: 0.9435492710731119, Validation F1 Score: 0.9407204006795991\n\nEpoch 140, Training Loss: 0.17620967723353656, Validation Loss: 0.18501119454460005\nTraining Accuracy: 0.9460126061934777, Training F1 Score: 0.9429020220697888\nValidation Accuracy: 0.9442617560013153, Validation F1 Score: 0.9412311997040201\n\nEpoch 141, Training Loss: 0.17584431185383245, Validation Loss: 0.18557875445246316\nTraining Accuracy: 0.9455330227459579, Training F1 Score: 0.9426246671272197\nValidation Accuracy: 0.9434944645401732, Validation F1 Score: 0.9407258260930325\n\nEpoch 142, Training Loss: 0.17610418881478784, Validation Loss: 0.18578261664421244\nTraining Accuracy: 0.9458344751986846, Training F1 Score: 0.9428207456163974\nValidation Accuracy: 0.9432204318754795, Validation F1 Score: 0.9403359578945243\n\nEpoch 143, Training Loss: 0.17638865071523677, Validation Loss: 0.18595767025262605\nTraining Accuracy: 0.9459714990408331, Training F1 Score: 0.942953440684588\nValidation Accuracy: 0.9443165625342541, Validation F1 Score: 0.9414299644295905\n\nEpoch 144, Training Loss: 0.17651817696278765, Validation Loss: 0.18605459419491652\nTraining Accuracy: 0.945039736914223, Training F1 Score: 0.9421601721131696\nValidation Accuracy: 0.943330044941357, Validation F1 Score: 0.9405775470293987\n\nEpoch 145, Training Loss: 0.17606668702443354, Validation Loss: 0.18715132527264877\nTraining Accuracy: 0.94579336804604, Training F1 Score: 0.9429568252476319\nValidation Accuracy: 0.9431656253425408, Validation F1 Score: 0.9404679858316045\n\nEpoch 146, Training Loss: 0.17584549203069938, Validation Loss: 0.18692049874289052\nTraining Accuracy: 0.9457796656618251, Training F1 Score: 0.9427892289758365\nValidation Accuracy: 0.9434944645401732, Validation F1 Score: 0.9406385288480591\n\nEpoch 147, Training Loss: 0.17571860449906734, Validation Loss: 0.18628097174069108\nTraining Accuracy: 0.9460263085776925, Training F1 Score: 0.9431678662206415\nValidation Accuracy: 0.9436588841389894, Validation F1 Score: 0.9409511558572072\n\nEpoch 148, Training Loss: 0.17517463151364498, Validation Loss: 0.18557267429848767\nTraining Accuracy: 0.946081118114552, Training F1 Score: 0.9430045402717205\nValidation Accuracy: 0.9429463992107859, Validation F1 Score: 0.9399441423961699\n\nEpoch 149, Training Loss: 0.17527651151473242, Validation Loss: 0.18615349634924858\nTraining Accuracy: 0.9464647848725678, Training F1 Score: 0.9434362938737342\nValidation Accuracy: 0.9435492710731119, Validation F1 Score: 0.9406032926566391\n\nEpoch 150, Training Loss: 0.17487245411146304, Validation Loss: 0.1861449713692858\nTraining Accuracy: 0.9460126061934777, Training F1 Score: 0.943050486039542\nValidation Accuracy: 0.9438233037378055, Validation F1 Score: 0.9409839884279927\n\nExecution time: 78.223554 seconds\n","output_type":"stream"}]},{"cell_type":"code","source":"x_scaled_tensor = torch.tensor(x_scaled, dtype=torch.float32)\n\n# Now you can pass it to the model\noutputs = model.extract_features(x_scaled_tensor)\nprint(outputs.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:32:01.003943Z","iopub.execute_input":"2024-10-31T06:32:01.004445Z","iopub.status.idle":"2024-10-31T06:32:01.051800Z","shell.execute_reply.started":"2024-10-31T06:32:01.004401Z","shell.execute_reply":"2024-10-31T06:32:01.050593Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"torch.Size([91226, 17])\n","output_type":"stream"}]},{"cell_type":"code","source":"# Ensure x_scaled is a tensor\nx_scaled_tensor = torch.tensor(x_scaled, dtype=torch.float32) if not torch.is_tensor(x_scaled) else x_scaled\n\n# Concatenate along the feature dimension (dim=1), assuming both have the same batch size\nconcatenated_result = torch.cat((x_scaled_tensor, outputs), dim=1)\nprint(concatenated_result.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:34:03.009765Z","iopub.execute_input":"2024-10-31T06:34:03.010246Z","iopub.status.idle":"2024-10-31T06:34:03.020994Z","shell.execute_reply.started":"2024-10-31T06:34:03.010203Z","shell.execute_reply":"2024-10-31T06:34:03.019827Z"},"trusted":true},"execution_count":52,"outputs":[{"name":"stdout","text":"torch.Size([91226, 34])\n","output_type":"stream"}]},{"cell_type":"code","source":"class TestClass(torch.nn.Module):\n    def __init__(self, control_points, num_features, num_classes):\n        super(TestClass, self).__init__()\n        self.control_points = control_points\n        self.num_features = num_features\n        self.num_classes = num_classes\n        self.num_pairs = num_features * (num_features - 1) // 2\n        \n        self.copy_tensor = nn.Parameter(torch.zeros(self.num_pairs, self.num_classes, self.control_points + 2, self.control_points + 2))\n        self.i_indices, self.j_indices = torch.triu_indices(num_features, num_features, offset=1).to(device)\n        self.feature_idx = torch.arange(self.num_pairs).view(1, -1, 1, 1).to(device)\n        self.class_idx = torch.arange(self.num_classes).view(1, 1, -1, 1).to(device)\n        \n    def forward(self, x):\n        x = torch.sigmoid(x)\n        \n        batch_size = x.shape[0]\n        feature_idx = self.feature_idx.expand(batch_size, -1, self.num_classes, 1)\n        class_idx = self.class_idx.expand(batch_size, self.num_pairs, -1, 1)\n        x = x * self.control_points\n        \n        x_i = x[:, self.i_indices]\n        x_j = x[:, self.j_indices]        \n        feature_pairs = torch.stack([x_i, x_j], dim=2)\n        \n        lower_idx = torch.floor(feature_pairs).long()\n        upper_idx = lower_idx + 1\n        \n        lower_idx_i_og = lower_idx[:, :, 0]\n        upper_idx_i_og = upper_idx[:, :, 0]\n        lower_idx_j_og = lower_idx[:, :, 1]\n        upper_idx_j_og = upper_idx[:, :, 1]\n        \n        lower_idx_i = lower_idx_i_og.unsqueeze(-1).unsqueeze(-1)\n        upper_idx_i = upper_idx_i_og.unsqueeze(-1).unsqueeze(-1)\n        lower_idx_j = lower_idx_j_og.unsqueeze(-1).unsqueeze(-1)\n        upper_idx_j = upper_idx_j_og.unsqueeze(-1).unsqueeze(-1)\n        \n        index_0_0 = self.copy_tensor[feature_idx, class_idx, lower_idx_i, lower_idx_j].squeeze(-1)\n        index_0_1 = self.copy_tensor[feature_idx, class_idx, lower_idx_i, upper_idx_j].squeeze(-1)\n        index_1_0 = self.copy_tensor[feature_idx, class_idx, upper_idx_i, lower_idx_j].squeeze(-1)\n        index_1_1 = self.copy_tensor[feature_idx, class_idx, upper_idx_i, upper_idx_j].squeeze(-1)\n        \n        lower_weight_i = (x_i - lower_idx_i_og.float()).unsqueeze(-1)\n        lower_weight_j = (x_j - lower_idx_j_og.float()).unsqueeze(-1)\n        upper_weight_i = (x_i - upper_idx_i_og.float()).unsqueeze(-1)\n        upper_weight_j = (x_j - upper_idx_j_og.float()).unsqueeze(-1)\n\n        lower_triangle_interpolated = index_0_0 + (index_1_0 - index_0_0) * lower_weight_i + (index_0_1 - index_0_0) * lower_weight_j\n        upper_triangle_interpolated = index_1_1 + (index_1_1 - index_0_1) * upper_weight_i + (index_1_1 - index_1_0) * upper_weight_j\n        selected_triangle = torch.where(lower_weight_i + lower_weight_j < 1, lower_triangle_interpolated, upper_triangle_interpolated).sum(dim=-2)\n        return selected_triangle","metadata":{"execution":{"iopub.status.busy":"2024-10-31T06:24:54.404474Z","iopub.execute_input":"2024-10-31T06:24:54.404917Z","iopub.status.idle":"2024-10-31T06:24:54.426949Z","shell.execute_reply.started":"2024-10-31T06:24:54.404860Z","shell.execute_reply":"2024-10-31T06:24:54.425657Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"num_epochs = 1\nnum_features = 17\nnum_classes = 2\n\nmodel = TestClass(20, num_features, num_classes).to(device)\ncriterion = nn.CrossEntropyLoss()\ncustom_train_loader = CustomDataLoader(x_scaled, y_encoded, validation_size=0.2, random_state=0)\n\nfor name, param in model.named_parameters():\n    break\n    print(f\"Layer: {name}\")\n    print(f\"Shape: {param.shape}\")\n    print(param)\n    \ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f'Total number of parameters: {total_params}')\n\n# 3 layers 0.001 * 0.5 l1 val loss = 0.16691114300471785\n# 2 layers no regularization Epoch 75, Training Loss: 0.15852869824943036, Validation Loss: 0.18101713914600992","metadata":{"execution":{"iopub.status.busy":"2024-10-28T02:03:11.887464Z","iopub.execute_input":"2024-10-28T02:03:11.888012Z","iopub.status.idle":"2024-10-28T02:03:11.955847Z","shell.execute_reply.started":"2024-10-28T02:03:11.887942Z","shell.execute_reply":"2024-10-28T02:03:11.954884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 10 * 2)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9995)\n\ntorch.cuda.synchronize()\nstart_time = time.time()\n\nevaluate_model(model, custom_train_loader, criterion, optimizer, 150, scheduler, 1024 * 16, num_features)\n\nelapsed_time = time.time() - start_time\nprint(f\"Execution time: {elapsed_time:.6f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T02:03:13.926794Z","iopub.execute_input":"2024-10-28T02:03:13.927719Z","iopub.status.idle":"2024-10-28T02:03:34.535807Z","shell.execute_reply.started":"2024-10-28T02:03:13.927671Z","shell.execute_reply":"2024-10-28T02:03:34.534650Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 10 * 2)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9995)\n\ntorch.cuda.synchronize()\nstart_time = time.time()\n\nevaluate_model(model, custom_train_loader, criterion, optimizer, 150, scheduler, 1024 * 16, num_features)\n\nelapsed_time = time.time() - start_time\nprint(f\"Execution time: {elapsed_time:.6f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T01:23:08.904570Z","iopub.execute_input":"2024-10-28T01:23:08.905073Z","iopub.status.idle":"2024-10-28T01:24:02.363104Z","shell.execute_reply.started":"2024-10-28T01:23:08.905034Z","shell.execute_reply":"2024-10-28T01:24:02.362003Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, custom_train_loader, criterion, optimizer, 150, scheduler, 1024 * 16, num_features)","metadata":{"execution":{"iopub.status.busy":"2024-10-28T01:24:58.589027Z","iopub.execute_input":"2024-10-28T01:24:58.589716Z","iopub.status.idle":"2024-10-28T01:25:52.162291Z","shell.execute_reply.started":"2024-10-28T01:24:58.589676Z","shell.execute_reply":"2024-10-28T01:25:52.161329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\noptimizer = optim.Adam(model.parameters(), lr=0.001 * 10)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9995)\n\ntorch.cuda.synchronize()\nstart_time = time.time()\n\nevaluate_model(model, custom_train_loader, criterion, optimizer, 150, scheduler, 1024 * 16, num_features)\n\nelapsed_time = time.time() - start_time\nprint(f\"Execution time: {elapsed_time:.6f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-10-28T01:08:30.689336Z","iopub.execute_input":"2024-10-28T01:08:30.690214Z","iopub.status.idle":"2024-10-28T01:09:06.967415Z","shell.execute_reply.started":"2024-10-28T01:08:30.690171Z","shell.execute_reply":"2024-10-28T01:09:06.966177Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"data = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\ndata['source'] = 0\n\nprint(data.columns)\n\nX_test = data.drop([\"id\"], axis=1)\nX_test['loan_percent_income_ratio'] = (X_test['person_income'] / X_test['loan_amnt'])\nX_test['loan_to_income_ratio'] = X_test['loan_amnt'] / X_test['person_income']\nX_test['financial_burden'] = X_test['loan_amnt'] * X_test['loan_int_rate']\nX_test['loan_int_emp_interaction'] = X_test['loan_int_rate'] * X_test['person_emp_length']\nX_test['debt_to_credit_ratio'] = X_test['loan_amnt'] / X_test['cb_person_cred_hist_length']\n\nexclude_columns = [\n    \"loan_percent_income_ratio\",\n    \"loan_to_income_ratio\",\n    \"financial_burden\",\n    \"debt_to_credit_ratio\"\n]\n\nX_test = pd.get_dummies(X_test, drop_first=True)\nfor col in X_test.columns:\n    if col not in exclude_columns:\n        if (X_test[col] > 0).all():\n            X_test[col] = np.log(X_test[col])\n\nprint(X_test.shape)\nprint(X_test.columns)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:18:17.027072Z","iopub.execute_input":"2024-10-27T20:18:17.027421Z","iopub.status.idle":"2024-10-27T20:18:17.133299Z","shell.execute_reply.started":"2024-10-27T20:18:17.027390Z","shell.execute_reply":"2024-10-27T20:18:17.132335Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled_test = x_scaler.transform(X_test)\nprint(X_scaled_test)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:18:18.445862Z","iopub.execute_input":"2024-10-27T20:18:18.446707Z","iopub.status.idle":"2024-10-27T20:18:18.502461Z","shell.execute_reply.started":"2024-10-27T20:18:18.446663Z","shell.execute_reply":"2024-10-27T20:18:18.501441Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(X_scaled_test.shape)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:18:19.446097Z","iopub.execute_input":"2024-10-27T20:18:19.446735Z","iopub.status.idle":"2024-10-27T20:18:19.451244Z","shell.execute_reply.started":"2024-10-27T20:18:19.446697Z","shell.execute_reply":"2024-10-27T20:18:19.450350Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled_test_tensor = torch.tensor(X_scaled_test).float().to(device)\noutputs = model(X_scaled_test_tensor)\nprint(outputs)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:18:20.360403Z","iopub.execute_input":"2024-10-27T20:18:20.361280Z","iopub.status.idle":"2024-10-27T20:18:20.376637Z","shell.execute_reply.started":"2024-10-27T20:18:20.361236Z","shell.execute_reply":"2024-10-27T20:18:20.375761Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"probabilities = F.softmax(outputs, dim=1)\nprint(probabilities)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:18:21.393555Z","iopub.execute_input":"2024-10-27T20:18:21.394212Z","iopub.status.idle":"2024-10-27T20:18:21.401288Z","shell.execute_reply.started":"2024-10-27T20:18:21.394173Z","shell.execute_reply":"2024-10-27T20:18:21.400385Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"positive_class_probs = probabilities[:, 1]\nprint(positive_class_probs)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:18:23.023865Z","iopub.execute_input":"2024-10-27T20:18:23.024492Z","iopub.status.idle":"2024-10-27T20:18:23.032363Z","shell.execute_reply.started":"2024-10-27T20:18:23.024452Z","shell.execute_reply":"2024-10-27T20:18:23.031329Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\ntest_df = pd.read_csv('/kaggle/input/playground-series-s4e10/test.csv')\nids = test_df['id']\n\npositive_class_probs = positive_class_probs.cpu().detach().numpy()\n\nsubmission_df = pd.DataFrame({\n    'id': ids,\n    'loan_status': positive_class_probs\n})\n\nsubmission_df.to_csv('submission.csv', index=False)\nprint(\"Submission file created successfully.\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:18:27.664195Z","iopub.execute_input":"2024-10-27T20:18:27.664799Z","iopub.status.idle":"2024-10-27T20:18:27.807597Z","shell.execute_reply.started":"2024-10-27T20:18:27.664758Z","shell.execute_reply":"2024-10-27T20:18:27.806627Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(custom_train_loader.train_labels_tensor)\nprint(model(custom_train_loader.train_data_tensor))","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:06:35.466453Z","iopub.execute_input":"2024-10-27T20:06:35.466824Z","iopub.status.idle":"2024-10-27T20:06:35.488727Z","shell.execute_reply.started":"2024-10-27T20:06:35.466787Z","shell.execute_reply":"2024-10-27T20:06:35.487851Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import pandas as pd\n\n# Path to the directory containing the model CSV files\nfile_path = '/kaggle/input/predictions/'\n\n# List to store each model's DataFrame\ndfs = []\n\n# Loop to read each model file from model_0 to model_9\nfor i in range(10):\n    file_name = f'{file_path}model_{i}.csv'\n    df = pd.read_csv(file_name)\n    dfs.append(df)\n\n# Concatenate all DataFrames vertically\nall_data = pd.concat(dfs)\n\n# Calculate the average 'loan_status' for each 'id'\nresult_df = all_data.groupby('id', as_index=False)['loan_status'].mean()\n\n# Save the result to a new CSV in the /kaggle/working directory for output\nresult_df.to_csv('submission.csv', index=False)\n\nprint(\"Averaging completed and saved to '/kaggle/working/average_loan_status.csv'\")\nprint(result_df)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T20:26:46.730592Z","iopub.execute_input":"2024-10-27T20:26:46.731016Z","iopub.status.idle":"2024-10-27T20:26:46.981563Z","shell.execute_reply.started":"2024-10-27T20:26:46.730965Z","shell.execute_reply":"2024-10-27T20:26:46.980528Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch.optim as optim\nimport torch.optim.lr_scheduler as lr_scheduler\n\noptimizer = optim.Adam(model.parameters(), lr=0.001)\nscheduler = lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9995)\n\ntorch.cuda.synchronize()\nstart_time = time.time()\n\nevaluate_model(model, custom_train_loader, criterion, optimizer, 100, scheduler, 1024 * 16, num_features)\n\nelapsed_time = time.time() - start_time\nprint(f\"Execution time: {elapsed_time:.6f} seconds\")","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:00:03.735549Z","iopub.execute_input":"2024-10-27T16:00:03.736591Z","iopub.status.idle":"2024-10-27T16:01:26.092823Z","shell.execute_reply.started":"2024-10-27T16:00:03.736541Z","shell.execute_reply":"2024-10-27T16:01:26.091824Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"evaluate_model(model, custom_train_loader, criterion, optimizer, 10, scheduler, 1024 * 16, num_features)","metadata":{"execution":{"iopub.status.busy":"2024-10-27T16:01:28.602098Z","iopub.execute_input":"2024-10-27T16:01:28.602494Z","iopub.status.idle":"2024-10-27T16:01:48.962236Z","shell.execute_reply.started":"2024-10-27T16:01:28.602457Z","shell.execute_reply":"2024-10-27T16:01:48.960888Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}