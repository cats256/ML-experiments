{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nimport keras\nimport tensorflow as tf\nfrom keras import layers\nfrom keras import models\nfrom keras.datasets import mnist\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import TensorDataset, DataLoader\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchinfo import summary\nfrom torch.optim.lr_scheduler import StepLR\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.preprocessing import StandardScaler\n\nimport sys\nimport math\n\nimport numpy as np\nimport math","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-27T01:37:58.325155Z","iopub.execute_input":"2024-05-27T01:37:58.325522Z","iopub.status.idle":"2024-05-27T01:37:58.333190Z","shell.execute_reply.started":"2024-05-27T01:37:58.325494Z","shell.execute_reply":"2024-05-27T01:37:58.332259Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-05-27T01:37:59.235778Z","iopub.execute_input":"2024-05-27T01:37:59.236110Z","iopub.status.idle":"2024-05-27T01:37:59.262971Z","shell.execute_reply.started":"2024-05-27T01:37:59.236086Z","shell.execute_reply":"2024-05-27T01:37:59.262000Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class CustomDataLoader:\n    def __init__(self, features, labels, batch_size=1, validation_size=0.0, shuffle=False):\n\n        if validation_size > 0:\n            train_data, val_data, train_labels, val_labels = train_test_split(features, labels, test_size=validation_size, stratify=labels, random_state=42)\n            train_data_tensor = torch.tensor(train_data).float().to(device)\n            train_labels_tensor = torch.tensor(train_labels).long().to(device)\n            val_data_tensor = torch.tensor(val_data).float().to(device)\n            val_labels_tensor = torch.tensor(val_labels).long().to(device)\n    \n            train_dataset = TensorDataset(train_data_tensor, train_labels_tensor)\n            val_dataset = TensorDataset(val_data_tensor, val_labels_tensor)\n\n            self.train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=shuffle)\n            self.val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=shuffle)\n        else:\n            features_tensor = torch.tensor(features).float().to(device)\n            labels_tensor = torch.tensor(labels).long().to(device)\n\n            dataset = TensorDataset(features_tensor, labels_tensor)\n\n            self.train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=shuffle)\n            self.val_loader = None\n\n    def get_train_loader(self):\n        return self.train_loader\n    \n    def get_val_loader(self):\n        return self.val_loader","metadata":{"execution":{"iopub.status.busy":"2024-05-27T01:37:59.824608Z","iopub.execute_input":"2024-05-27T01:37:59.825300Z","iopub.status.idle":"2024-05-27T01:37:59.834841Z","shell.execute_reply.started":"2024-05-27T01:37:59.825271Z","shell.execute_reply":"2024-05-27T01:37:59.833932Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def evaluate_model(model, custom_train_loader, criterion, optimizer):\n    num_epochs = 20\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for inputs, labels in custom_train_loader.get_train_loader():        \n            optimizer.zero_grad()\n            outputs = model(inputs.view(-1, 1, 28, 28))\n            loss = criterion(outputs, labels)\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n\n        print(f'Epoch {epoch+1}, Loss: {running_loss / len(custom_train_loader.get_train_loader())}')\n\n        model.eval()\n        running_val_loss = 0.0\n        with torch.no_grad():\n            for inputs, labels in custom_train_loader.get_val_loader():\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs.view(-1, 1, 28, 28))\n                val_loss = criterion(outputs, labels)\n                running_val_loss += val_loss.item()\n\n            avg_val_loss = running_val_loss / len(custom_train_loader.get_val_loader())\n            print(f'Validation Loss: {avg_val_loss}')\n            print()\n\n    model.eval()\n    running_val_loss = 0.0\n    with torch.no_grad():\n        for inputs, labels in custom_train_loader.get_val_loader():\n            outputs = model(inputs.view(-1, 1, 28, 28))\n            val_loss = criterion(outputs, labels)\n            running_val_loss += val_loss.item()\n\n    avg_val_loss = running_val_loss / len(custom_train_loader.get_val_loader())\n    print(f'Validation Loss: {avg_val_loss}')","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:38:44.949556Z","iopub.execute_input":"2024-05-27T04:38:44.949894Z","iopub.status.idle":"2024-05-27T04:38:44.960097Z","shell.execute_reply.started":"2024-05-27T04:38:44.949870Z","shell.execute_reply":"2024-05-27T04:38:44.959171Z"},"trusted":true},"execution_count":219,"outputs":[]},{"cell_type":"code","source":"def custom_activation(x, b, eps):\n    b_sign = b.sign()\n    x_sign = x.sign()\n    abs_b = b.abs()\n    abs_x = x.abs()\n    \n    return b_sign * x_sign * (torch.min(torch.zeros_like(x), abs_x - abs_b) + abs_b)\n#     max_part = torch.max(torch.zeros_like(x), -abs_x + abs_b) - abs_b\n\n#     output = b_sign * x_sign * max_part\n#     return output\n#     return (torch.log1p(torch.exp(-torch.abs(x) / (torch.abs(b) + eps))) - 0.5 * math.log(2.0)) * (torch.abs(b) + eps) + torch.maximum(torch.tensor(0.0), x)\n\nclass CustomActivationLayer(nn.Module):\n    def __init__(self, num_channels, beta=0.0):\n        super(CustomActivationLayer, self).__init__()\n\n        self.eps = sys.float_info.epsilon\n        \n        if beta == 0.0:\n            beta = self.eps\n        self.betas = nn.Parameter(torch.full((1, num_channels, 1, 1), self.eps))\n\n    def forward(self, inputs):\n        return custom_activation(inputs, self.betas, self.s)\n\nclass CustomActivationLayerTwo(nn.Module):\n    def __init__(self, num_features, beta=0.0):\n        super(CustomActivationLayerTwo, self).__init__()\n        \n        self.eps = sys.float_info.epsilon\n        \n        if beta == 0.0:\n            beta = self.eps\n\n        self.betas = nn.Parameter(torch.full((num_features,), self.eps))\n\n    def forward(self, x):\n        return custom_activation(x, self.betas, self.eps)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:03:24.502309Z","iopub.execute_input":"2024-05-27T02:03:24.502675Z","iopub.status.idle":"2024-05-27T02:03:24.513598Z","shell.execute_reply.started":"2024-05-27T02:03:24.502648Z","shell.execute_reply":"2024-05-27T02:03:24.512505Z"},"trusted":true},"execution_count":39,"outputs":[]},{"cell_type":"code","source":"import torch\n\nclass CustomActivation(torch.autograd.Function):\n    @staticmethod\n    def forward(ctx, x, b):\n        abs_b = b.abs()\n        ctx.save_for_backward(x, abs_b)\n        \n        return b.sign() * x.sign() * torch.min(abs_b, x.abs())\n        \n    @staticmethod\n    def backward(ctx, grad_output):\n        x, abs_b = ctx.saved_tensors\n        mask = x.abs() < abs_b\n\n        grad_x = mask * grad_output\n        grad_b = ~mask * grad_output * (x >= 0)\n\n        return grad_x, grad_b\n    \nclass CustomActivationLayer(nn.Module):\n    def __init__(self, num_channels):\n        super(CustomActivationLayer, self).__init__()\n        self.eps = sys.float_info.epsilon\n        self.betas = nn.Parameter(torch.full((1, num_channels, 1, 1), 0.0))\n\n    def forward(self, x):\n        return CustomActivation.apply(x, self.betas) \n\nclass CustomActivationLayerTwo(nn.Module):\n    def __init__(self, num_features, beta=0.0):\n        super(CustomActivationLayerTwo, self).__init__()\n        self.eps = sys.float_info.epsilon\n        self.betas = nn.Parameter(torch.full((num_features,), 0.0))\n\n    def forward(self, x):\n        return CustomActivation.apply(x, self.betas) ","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:35:38.197379Z","iopub.execute_input":"2024-05-27T04:35:38.197741Z","iopub.status.idle":"2024-05-27T04:35:38.208390Z","shell.execute_reply.started":"2024-05-27T04:35:38.197711Z","shell.execute_reply":"2024-05-27T04:35:38.207433Z"},"trusted":true},"execution_count":213,"outputs":[]},{"cell_type":"code","source":"(X_train, y_train), (X_test, y_test) = mnist.load_data()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:29:03.484603Z","iopub.execute_input":"2024-05-27T02:29:03.485258Z","iopub.status.idle":"2024-05-27T02:29:03.751259Z","shell.execute_reply.started":"2024-05-27T02:29:03.485221Z","shell.execute_reply":"2024-05-27T02:29:03.750051Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"X_train_flat = X_train.reshape(-1, X_train.shape[1] * X_train.shape[2])\n\nmean = np.mean(X_train_flat)\nstd = np.std(X_train_flat)\n\nX_scaled = (X_train_flat - mean) / std","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:29:04.096139Z","iopub.execute_input":"2024-05-27T02:29:04.096778Z","iopub.status.idle":"2024-05-27T02:29:04.488420Z","shell.execute_reply.started":"2024-05-27T02:29:04.096748Z","shell.execute_reply":"2024-05-27T02:29:04.487365Z"},"trusted":true},"execution_count":57,"outputs":[]},{"cell_type":"code","source":"custom_train_loader = CustomDataLoader(X_scaled, y_train, batch_size=1024, validation_size=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T02:29:04.490033Z","iopub.execute_input":"2024-05-27T02:29:04.490345Z","iopub.status.idle":"2024-05-27T02:29:04.915715Z","shell.execute_reply.started":"2024-05-27T02:29:04.490321Z","shell.execute_reply":"2024-05-27T02:29:04.914572Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"class MNIST_CNN(nn.Module):\n    def __init__(self, activation='relu'):\n        super(MNIST_CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 32 * 2, kernel_size=3, stride=1, padding=1)        \n        self.conv2 = nn.Conv2d(32 * 2, 64, kernel_size=3, stride=1, padding=1)\n        \n        self.fc1 = nn.Linear(64 * 7 * 7, 64 * 7 * 7)\n        self.fc2 = nn.Linear(64 * 7 * 7, 10)\n\n        self.pool = nn.AvgPool2d(2, 2)\n        self.flatten = nn.Flatten()\n\n        self.relu = nn.ReLU()\n        self.gelu = nn.GELU()\n\n        if activation == 'relu':\n            self.activation1 = nn.ReLU()\n            self.activation2 = nn.ReLU()\n            self.activation3 = nn.ReLU()\n        elif activation == 'custom':\n            self.activation1 = CustomActivationLayer(32 * 2)\n            self.activation2 = CustomActivationLayer(64)\n            self.activation3 = CustomActivationLayerTwo(64 * 7 * 7)\n\n        nn.init.kaiming_normal_(self.conv1.weight, a=3, mode='fan_out', nonlinearity='leaky_relu')\n        nn.init.kaiming_normal_(self.conv2.weight, a=3, mode='fan_out', nonlinearity='leaky_relu')\n        nn.init.kaiming_normal_(self.fc1.weight, a=3, mode='fan_out', nonlinearity='leaky_relu')\n        nn.init.kaiming_normal_(self.fc2.weight, a=3, mode='fan_out', nonlinearity='leaky_relu')\n\n        self.conv1.bias.data.zero_()\n        self.conv2.bias.data.zero_()\n        self.fc1.bias.data.zero_()\n        self.fc2.bias.data.zero_()\n\n    def forward(self, x):\n        x = self.pool(self.activation1(self.conv1(x)))\n        x = self.pool(self.activation2(self.conv2(x)))\n        \n        x = self.flatten(x)\n        x = self.activation3(self.fc1(x))\n        x = self.fc2(x)\n        return x\n        \nmodel = MNIST_CNN().to(device)\nsummary(model, input_size=(1, 1, 28, 28))","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:49:24.494133Z","iopub.execute_input":"2024-05-27T04:49:24.494909Z","iopub.status.idle":"2024-05-27T04:49:24.705046Z","shell.execute_reply.started":"2024-05-27T04:49:24.494875Z","shell.execute_reply":"2024-05-27T04:49:24.704115Z"},"trusted":true},"execution_count":229,"outputs":[{"execution_count":229,"output_type":"execute_result","data":{"text/plain":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nMNIST_CNN                                [1, 10]                   --\n├─Conv2d: 1-1                            [1, 64, 28, 28]           640\n├─ReLU: 1-2                              [1, 64, 28, 28]           --\n├─AvgPool2d: 1-3                         [1, 64, 14, 14]           --\n├─Conv2d: 1-4                            [1, 64, 14, 14]           36,928\n├─ReLU: 1-5                              [1, 64, 14, 14]           --\n├─AvgPool2d: 1-6                         [1, 64, 7, 7]             --\n├─Flatten: 1-7                           [1, 3136]                 --\n├─Linear: 1-8                            [1, 3136]                 9,837,632\n├─ReLU: 1-9                              [1, 3136]                 --\n├─Linear: 1-10                           [1, 10]                   31,370\n==========================================================================================\nTotal params: 9,906,570\nTrainable params: 9,906,570\nNon-trainable params: 0\nTotal mult-adds (M): 17.61\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.53\nParams size (MB): 39.63\nEstimated Total Size (MB): 40.16\n=========================================================================================="},"metadata":{}}]},{"cell_type":"code","source":"model_relu = MNIST_CNN(activation='relu').to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T01:52:31.004320Z","iopub.execute_input":"2024-05-27T01:52:31.005037Z","iopub.status.idle":"2024-05-27T01:52:31.201705Z","shell.execute_reply.started":"2024-05-27T01:52:31.005007Z","shell.execute_reply":"2024-05-27T01:52:31.200350Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_relu.parameters(), lr=0.00001)\nevaluate_model(model_relu, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T01:52:31.911780Z","iopub.execute_input":"2024-05-27T01:52:31.912172Z","iopub.status.idle":"2024-05-27T01:56:32.664887Z","shell.execute_reply.started":"2024-05-27T01:52:31.912140Z","shell.execute_reply":"2024-05-27T01:56:32.664029Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.6637614952757003\nValidation Loss: 0.6915233731269836\n\nEpoch 2, Loss: 0.5074865938501155\nValidation Loss: 0.38196735580762226\n\nEpoch 3, Loss: 0.32931756402583834\nValidation Loss: 0.2818109194437663\n\nEpoch 4, Loss: 0.25568879316461846\nValidation Loss: 0.2300460177163283\n\nEpoch 5, Loss: 0.21273544620960316\nValidation Loss: 0.19712168350815773\n\nEpoch 6, Loss: 0.18333101684742786\nValidation Loss: 0.17346159120400748\n\nEpoch 7, Loss: 0.16106986872693327\nValidation Loss: 0.15510118876894316\n\nEpoch 8, Loss: 0.14327432357884468\nValidation Loss: 0.14028940287729105\n\nEpoch 9, Loss: 0.12875452780343116\nValidation Loss: 0.12827937304973602\n\nEpoch 10, Loss: 0.11677494407334227\nValidation Loss: 0.11817524209618568\n\nEpoch 11, Loss: 0.10672035464581023\nValidation Loss: 0.10978241699437301\n\nEpoch 12, Loss: 0.09815661276274538\nValidation Loss: 0.10265752797325452\n\nEpoch 13, Loss: 0.09079545577789874\nValidation Loss: 0.09649818949401379\n\nEpoch 14, Loss: 0.08440040701881368\nValidation Loss: 0.09116596293946107\n\nEpoch 15, Loss: 0.07880091801919836\nValidation Loss: 0.08650935254991055\n\nEpoch 16, Loss: 0.07386199369075451\nValidation Loss: 0.0824377325673898\n\nEpoch 17, Loss: 0.06947978863373716\nValidation Loss: 0.07879357691854239\n\nEpoch 18, Loss: 0.06555158692471524\nValidation Loss: 0.07554252042124669\n\nEpoch 19, Loss: 0.062024687991497365\nValidation Loss: 0.07263242298116286\n\nEpoch 20, Loss: 0.05884000104158483\nValidation Loss: 0.07003720042606194\n\nEpoch 21, Loss: 0.05595243286262167\nValidation Loss: 0.06770338397473097\n\nEpoch 22, Loss: 0.05331855409956993\nValidation Loss: 0.06558384311695893\n\nEpoch 23, Loss: 0.050901342579659\nValidation Loss: 0.06370130212356646\n\nEpoch 24, Loss: 0.04867257835700157\nValidation Loss: 0.06196976142625014\n\nEpoch 25, Loss: 0.04660108899499508\nValidation Loss: 0.0603737353036801\n\nEpoch 26, Loss: 0.044675431194457604\nValidation Loss: 0.058920664712786674\n\nEpoch 27, Loss: 0.04289173687550616\nValidation Loss: 0.05759581892440716\n\nEpoch 28, Loss: 0.04123250910259308\nValidation Loss: 0.05638108650843302\n\nEpoch 29, Loss: 0.039676837623119354\nValidation Loss: 0.05523198811958233\n\nEpoch 30, Loss: 0.03821416314136475\nValidation Loss: 0.0541943209245801\n\nEpoch 31, Loss: 0.036839820523845386\nValidation Loss: 0.053203193160394825\n\nEpoch 32, Loss: 0.03554637389297181\nValidation Loss: 0.052304472463826336\n\nEpoch 33, Loss: 0.0343249620513079\nValidation Loss: 0.0514547498896718\n\nEpoch 34, Loss: 0.03316742863426817\nValidation Loss: 0.050682593447466694\n\nEpoch 35, Loss: 0.03207364892388912\nValidation Loss: 0.04993645412226518\n\nEpoch 36, Loss: 0.03103469098184971\nValidation Loss: 0.04925126706560453\n\nEpoch 37, Loss: 0.030054770132645646\nValidation Loss: 0.048599560745060444\n\nEpoch 38, Loss: 0.02911558243981067\nValidation Loss: 0.047990615790088974\n\nEpoch 39, Loss: 0.0282170009660594\nValidation Loss: 0.047424301505088806\n\nEpoch 40, Loss: 0.027359121221494167\nValidation Loss: 0.04688654405375322\n\nEpoch 41, Loss: 0.026535415467112623\nValidation Loss: 0.04636728732536236\n\nEpoch 42, Loss: 0.025748798702942565\nValidation Loss: 0.0458945312226812\n\nEpoch 43, Loss: 0.024994065311360867\nValidation Loss: 0.04544877540320158\n\nEpoch 44, Loss: 0.024272174950926862\nValidation Loss: 0.045027715153992176\n\nEpoch 45, Loss: 0.02357657097200764\nValidation Loss: 0.044638649094849825\n\nEpoch 46, Loss: 0.022907425411679644\nValidation Loss: 0.04426643283416828\n\nEpoch 47, Loss: 0.022266890794197296\nValidation Loss: 0.04391609520340959\n\nEpoch 48, Loss: 0.021649668904695104\nValidation Loss: 0.04359014440948764\n\nEpoch 49, Loss: 0.021056416761526402\nValidation Loss: 0.04328307074805101\n\nEpoch 50, Loss: 0.020479771288785528\nValidation Loss: 0.04300137904162208\n\nEpoch 51, Loss: 0.019927588509435348\nValidation Loss: 0.04273472990219792\n\nEpoch 52, Loss: 0.019391598318644027\nValidation Loss: 0.0424828731144468\n\nEpoch 53, Loss: 0.018873030775563515\nValidation Loss: 0.04223537134627501\n\nEpoch 54, Loss: 0.018373868309278438\nValidation Loss: 0.04201279782379667\n\nEpoch 55, Loss: 0.017889829015636696\nValidation Loss: 0.04179461176196734\n\nEpoch 56, Loss: 0.017422024933423135\nValidation Loss: 0.041601442731916904\n\nEpoch 57, Loss: 0.016967599577409155\nValidation Loss: 0.041429344564676285\n\nEpoch 58, Loss: 0.016522403469586625\nValidation Loss: 0.041255073777089514\n\nEpoch 59, Loss: 0.01609216979209413\nValidation Loss: 0.04110693124433359\n\nEpoch 60, Loss: 0.01567863558042557\nValidation Loss: 0.04095230810344219\n\nEpoch 61, Loss: 0.015272046498795773\nValidation Loss: 0.040817234509934984\n\nEpoch 62, Loss: 0.014879667200148106\nValidation Loss: 0.040685832810898624\n\nEpoch 63, Loss: 0.014499937481385596\nValidation Loss: 0.040570053116728864\n\nEpoch 64, Loss: 0.014131850087420737\nValidation Loss: 0.040455866139382124\n\nEpoch 65, Loss: 0.013772326699913816\nValidation Loss: 0.04033813035736481\n\nEpoch 66, Loss: 0.013422357433653892\nValidation Loss: 0.040246301951507725\n\nEpoch 67, Loss: 0.0130859130121609\nValidation Loss: 0.0401465759302179\n\nEpoch 68, Loss: 0.012753949758220227\nValidation Loss: 0.04005530430004001\n\nEpoch 69, Loss: 0.012433996542971185\nValidation Loss: 0.0399753013625741\n\nEpoch 70, Loss: 0.012124215094174476\nValidation Loss: 0.0398913479099671\n\nEpoch 71, Loss: 0.01182101936416423\nValidation Loss: 0.03982939074436823\n\nEpoch 72, Loss: 0.011526535651547478\nValidation Loss: 0.039757921205212675\n\nEpoch 73, Loss: 0.011241944714825838\nValidation Loss: 0.039714950447281204\n\nEpoch 74, Loss: 0.010963880684860844\nValidation Loss: 0.0396509263664484\n\nEpoch 75, Loss: 0.010693780849984985\nValidation Loss: 0.03960821342964967\n\nEpoch 76, Loss: 0.01043135259657147\nValidation Loss: 0.03957147958377997\n\nEpoch 77, Loss: 0.010175837520906266\nValidation Loss: 0.03952306477973858\n\nEpoch 78, Loss: 0.0099276447212918\nValidation Loss: 0.03948862152174115\n\nEpoch 79, Loss: 0.009687725613091855\nValidation Loss: 0.039446559424201645\n\nEpoch 80, Loss: 0.009453450656555434\nValidation Loss: 0.03942770650610328\n\nEpoch 81, Loss: 0.009223735148206036\nValidation Loss: 0.039386475613961615\n\nEpoch 82, Loss: 0.009003043620589566\nValidation Loss: 0.039364715572446585\n\nEpoch 83, Loss: 0.008787136356485016\nValidation Loss: 0.039343807846307755\n\nEpoch 84, Loss: 0.00857857766343241\nValidation Loss: 0.03933568003897866\n\nEpoch 85, Loss: 0.008371175940525024\nValidation Loss: 0.03931359682853023\n\nEpoch 86, Loss: 0.008172057053827226\nValidation Loss: 0.0393255657205979\n\nEpoch 87, Loss: 0.00797731110310935\nValidation Loss: 0.0393197531811893\n\nEpoch 88, Loss: 0.007788958206297236\nValidation Loss: 0.03931937894473473\n\nEpoch 89, Loss: 0.00760524775436584\nValidation Loss: 0.03932654640326897\n\nEpoch 90, Loss: 0.007423759913666451\nValidation Loss: 0.03934848494827747\n\nEpoch 91, Loss: 0.007248964556988249\nValidation Loss: 0.039362084275732435\n\nEpoch 92, Loss: 0.007077894262731709\nValidation Loss: 0.03936416314293941\n\nEpoch 93, Loss: 0.006907882664273394\nValidation Loss: 0.03937343476961056\n\nEpoch 94, Loss: 0.006746470502161599\nValidation Loss: 0.03940189955756068\n\nEpoch 95, Loss: 0.006584737063484623\nValidation Loss: 0.03942823534210523\n\nEpoch 96, Loss: 0.006429795661267448\nValidation Loss: 0.03943988603229324\n\nEpoch 97, Loss: 0.006278187313929517\nValidation Loss: 0.03947522879267732\n\nEpoch 98, Loss: 0.006129826082194105\nValidation Loss: 0.039507525662581124\n\nEpoch 99, Loss: 0.005983805650488493\nValidation Loss: 0.03954185716186961\n\nEpoch 100, Loss: 0.005843935360973503\nValidation Loss: 0.039575161101917423\n\nValidation Loss: 0.039575161101917423\n","output_type":"stream"}]},{"cell_type":"code","source":"model_custom = MNIST_CNN(activation='custom').to(device)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:49:27.731873Z","iopub.execute_input":"2024-05-27T04:49:27.732529Z","iopub.status.idle":"2024-05-27T04:49:27.925986Z","shell.execute_reply.started":"2024-05-27T04:49:27.732498Z","shell.execute_reply":"2024-05-27T04:49:27.925216Z"},"trusted":true},"execution_count":230,"outputs":[]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_custom.parameters(), lr=0.0005)\nevaluate_model(model_custom, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:49:33.273849Z","iopub.execute_input":"2024-05-27T04:49:33.274213Z","iopub.status.idle":"2024-05-27T04:50:34.237085Z","shell.execute_reply.started":"2024-05-27T04:49:33.274172Z","shell.execute_reply":"2024-05-27T04:50:34.236185Z"},"trusted":true},"execution_count":231,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.5491448209640828\nValidation Loss: 0.4516686523954074\n\nEpoch 2, Loss: 0.2828554561797609\nValidation Loss: 0.19018733128905296\n\nEpoch 3, Loss: 0.14865569278914878\nValidation Loss: 0.11441567974785964\n\nEpoch 4, Loss: 0.09192678110396608\nValidation Loss: 0.0814644576360782\n\nEpoch 5, Loss: 0.06613621947930214\nValidation Loss: 0.06503917121638854\n\nEpoch 6, Loss: 0.05207185225283846\nValidation Loss: 0.05632945646842321\n\nEpoch 7, Loss: 0.043261564950993724\nValidation Loss: 0.05199352651834488\n\nEpoch 8, Loss: 0.03691664972203843\nValidation Loss: 0.04919694301982721\n\nEpoch 9, Loss: 0.03211231422709658\nValidation Loss: 0.04685664394249519\n\nEpoch 10, Loss: 0.028802518911184148\nValidation Loss: 0.04330325545743108\n\nEpoch 11, Loss: 0.02544724546927721\nValidation Loss: 0.04137865034863353\n\nEpoch 12, Loss: 0.023108883523085016\nValidation Loss: 0.039659743352482714\n\nEpoch 13, Loss: 0.021010462075788924\nValidation Loss: 0.03960475868855914\n\nEpoch 14, Loss: 0.017823115328049408\nValidation Loss: 0.03889088099822402\n\nEpoch 15, Loss: 0.015813719857721887\nValidation Loss: 0.03999105840921402\n\nEpoch 16, Loss: 0.014360902077974157\nValidation Loss: 0.035298806770394243\n\nEpoch 17, Loss: 0.012653015177459159\nValidation Loss: 0.03661225891361634\n\nEpoch 18, Loss: 0.011646929127659569\nValidation Loss: 0.03715353971347213\n\nEpoch 19, Loss: 0.01060147060358778\nValidation Loss: 0.03452373808249831\n\nEpoch 20, Loss: 0.009872501537679358\nValidation Loss: 0.03533289053787788\n\nValidation Loss: 0.03533289053787788\n","output_type":"stream"}]},{"cell_type":"code","source":"# when a = 3\nfor name, param in model_custom.named_parameters():\n    print(f\"Parameter name: {name}\")\n#     print(f\"Parameter shape: {param.shape}\")\n#     print(f\"Parameter value: {param.data}\")\n    print(f\"Parameter variance: {param.data.var()}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:50:41.296486Z","iopub.execute_input":"2024-05-27T04:50:41.297127Z","iopub.status.idle":"2024-05-27T04:50:41.304134Z","shell.execute_reply.started":"2024-05-27T04:50:41.297095Z","shell.execute_reply":"2024-05-27T04:50:41.303081Z"},"trusted":true},"execution_count":232,"outputs":[{"name":"stdout","text":"Parameter name: conv1.weight\nParameter variance: 0.0006355533841997385\n\nParameter name: conv1.bias\nParameter variance: 0.00013336823030840605\n\nParameter name: conv2.weight\nParameter variance: 0.000985803548246622\n\nParameter name: conv2.bias\nParameter variance: 7.137360807973891e-05\n\nParameter name: fc1.weight\nParameter variance: 0.0002946029999293387\n\nParameter name: fc1.bias\nParameter variance: 1.2639691703952849e-05\n\nParameter name: fc2.weight\nParameter variance: 0.03812466561794281\n\nParameter name: fc2.bias\nParameter variance: 0.00013573089381679893\n\nParameter name: activation1.betas\nParameter variance: 0.0008865435374900699\n\nParameter name: activation2.betas\nParameter variance: 0.0008369925781153142\n\nParameter name: activation3.betas\nParameter variance: 0.00015496532432734966\n\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_custom.parameters(), lr=0.0005)\nevaluate_model(model_custom, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:44:18.155814Z","iopub.execute_input":"2024-05-27T04:44:18.156434Z","iopub.status.idle":"2024-05-27T04:45:19.058780Z","shell.execute_reply.started":"2024-05-27T04:44:18.156400Z","shell.execute_reply":"2024-05-27T04:45:19.057921Z"},"trusted":true},"execution_count":227,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.4818552326648793\nValidation Loss: 0.40043382346630096\n\nEpoch 2, Loss: 0.26688173666913456\nValidation Loss: 0.18577498818437257\n\nEpoch 3, Loss: 0.14871822947517355\nValidation Loss: 0.11704253467420737\n\nEpoch 4, Loss: 0.09296186109806628\nValidation Loss: 0.08259222904841106\n\nEpoch 5, Loss: 0.06553197446021627\nValidation Loss: 0.06504188633213441\n\nEpoch 6, Loss: 0.05112552547708471\nValidation Loss: 0.05490450530002514\n\nEpoch 7, Loss: 0.042206110393113276\nValidation Loss: 0.05003295373171568\n\nEpoch 8, Loss: 0.03493129283665342\nValidation Loss: 0.047702200089891754\n\nEpoch 9, Loss: 0.029734921344417208\nValidation Loss: 0.04511323198676109\n\nEpoch 10, Loss: 0.02677077589992513\nValidation Loss: 0.04203771955023209\n\nEpoch 11, Loss: 0.023735610748383592\nValidation Loss: 0.039934143889695406\n\nEpoch 12, Loss: 0.021402673696742414\nValidation Loss: 0.03774016754080852\n\nEpoch 13, Loss: 0.019188172936915084\nValidation Loss: 0.03740476521973809\n\nEpoch 14, Loss: 0.017679247271982914\nValidation Loss: 0.03661862652127942\n\nEpoch 15, Loss: 0.01533592531972743\nValidation Loss: 0.03672005562111735\n\nEpoch 16, Loss: 0.013351346792138003\nValidation Loss: 0.035025665226082005\n\nEpoch 17, Loss: 0.011732170774423062\nValidation Loss: 0.03278472367674112\n\nEpoch 18, Loss: 0.010350584092133857\nValidation Loss: 0.03423357227196296\n\nEpoch 19, Loss: 0.00886802812245615\nValidation Loss: 0.032295124450077616\n\nEpoch 20, Loss: 0.00809386053538703\nValidation Loss: 0.030819654775162537\n\nValidation Loss: 0.030819654775162537\n","output_type":"stream"}]},{"cell_type":"code","source":"# when a = 2\nfor name, param in model_custom.named_parameters():\n    print(f\"Parameter name: {name}\")\n#     print(f\"Parameter shape: {param.shape}\")\n#     print(f\"Parameter value: {param.data}\")\n    print(f\"Parameter variance: {param.data.var()}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:47:48.047979Z","iopub.execute_input":"2024-05-27T04:47:48.048379Z","iopub.status.idle":"2024-05-27T04:47:48.055725Z","shell.execute_reply.started":"2024-05-27T04:47:48.048350Z","shell.execute_reply":"2024-05-27T04:47:48.054783Z"},"trusted":true},"execution_count":228,"outputs":[{"name":"stdout","text":"Parameter name: conv1.weight\nParameter variance: 0.0009577867458574474\n\nParameter name: conv1.bias\nParameter variance: 0.0002525431918911636\n\nParameter name: conv2.weight\nParameter variance: 0.001273691770620644\n\nParameter name: conv2.bias\nParameter variance: 9.694890468381345e-05\n\nParameter name: fc1.weight\nParameter variance: 0.00034902256447821856\n\nParameter name: fc1.bias\nParameter variance: 9.303772458224557e-06\n\nParameter name: fc2.weight\nParameter variance: 0.06146855652332306\n\nParameter name: fc2.bias\nParameter variance: 7.941333024064079e-05\n\nParameter name: activation1.betas\nParameter variance: 0.0008800862706266344\n\nParameter name: activation2.betas\nParameter variance: 0.0004912934964522719\n\nParameter name: activation3.betas\nParameter variance: 0.00019973397138528526\n\n","output_type":"stream"}]},{"cell_type":"code","source":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_custom.parameters(), lr=0.0005)\nevaluate_model(model_custom, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:39:05.303754Z","iopub.execute_input":"2024-05-27T04:39:05.304106Z","iopub.status.idle":"2024-05-27T04:40:05.777661Z","shell.execute_reply.started":"2024-05-27T04:39:05.304078Z","shell.execute_reply":"2024-05-27T04:40:05.776678Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":222,"outputs":[{"name":"stdout","text":"Epoch 1, Loss: 1.205354855415669\nValidation Loss: 0.31648394217093784\n\nEpoch 2, Loss: 0.237759567955707\nValidation Loss: 0.17504819855093956\n\nEpoch 3, Loss: 0.14309636170559742\nValidation Loss: 0.11747782863676548\n\nEpoch 4, Loss: 0.09642025035746554\nValidation Loss: 0.08785507331291835\n\nEpoch 5, Loss: 0.07011663105259551\nValidation Loss: 0.07257502463956673\n\nEpoch 6, Loss: 0.05520873635690263\nValidation Loss: 0.061878583393990993\n\nEpoch 7, Loss: 0.04611251447746094\nValidation Loss: 0.05678046712030967\n\nEpoch 8, Loss: 0.03884015676188976\nValidation Loss: 0.05142528905222813\n\nEpoch 9, Loss: 0.03376430716920406\nValidation Loss: 0.048939445366462074\n\nEpoch 10, Loss: 0.0297009473309872\nValidation Loss: 0.048226588095227875\n\nEpoch 11, Loss: 0.026926996067483375\nValidation Loss: 0.04502180560181538\n\nEpoch 12, Loss: 0.024028027132946127\nValidation Loss: 0.04497269929076234\n\nEpoch 13, Loss: 0.02056928537786007\nValidation Loss: 0.04279967304319143\n\nEpoch 14, Loss: 0.017948913070908252\nValidation Loss: 0.03875554259866476\n\nEpoch 15, Loss: 0.01573996939399141\nValidation Loss: 0.037479551974684\n\nEpoch 16, Loss: 0.01408270647392628\nValidation Loss: 0.03727917574966947\n\nEpoch 17, Loss: 0.012913694872738832\nValidation Loss: 0.036628703431536756\n\nEpoch 18, Loss: 0.011712034549960431\nValidation Loss: 0.037845093136032425\n\nEpoch 19, Loss: 0.010417661768324833\nValidation Loss: 0.03622038150206208\n\nEpoch 20, Loss: 0.010308500617108446\nValidation Loss: 0.03575627009073893\n\nValidation Loss: 0.03575627009073893\n","output_type":"stream"}]},{"cell_type":"code","source":"# when a = 1\nfor name, param in model_custom.named_parameters():\n    print(f\"Parameter name: {name}\")\n#     print(f\"Parameter shape: {param.shape}\")\n#     print(f\"Parameter value: {param.data}\")\n    print(f\"Parameter variance: {param.data.var()}\")\n    print()","metadata":{"execution":{"iopub.status.busy":"2024-05-27T04:40:27.613082Z","iopub.execute_input":"2024-05-27T04:40:27.613447Z","iopub.status.idle":"2024-05-27T04:40:27.620729Z","shell.execute_reply.started":"2024-05-27T04:40:27.613421Z","shell.execute_reply":"2024-05-27T04:40:27.619695Z"},"trusted":true},"execution_count":224,"outputs":[{"name":"stdout","text":"Parameter name: conv1.weight\nParameter variance: 0.002005618531256914\n\nParameter name: conv1.bias\nParameter variance: 0.00025421546888537705\n\nParameter name: conv2.weight\nParameter variance: 0.0022366989869624376\n\nParameter name: conv2.bias\nParameter variance: 0.0001088862627511844\n\nParameter name: fc1.weight\nParameter variance: 0.0004937440971843898\n\nParameter name: fc1.bias\nParameter variance: 9.684428732725792e-06\n\nParameter name: fc2.weight\nParameter variance: 0.12768074870109558\n\nParameter name: fc2.bias\nParameter variance: 4.89032972836867e-05\n\nParameter name: activation1.betas\nParameter variance: 0.0007480555213987827\n\nParameter name: activation2.betas\nParameter variance: 0.0006396957323886454\n\nParameter name: activation3.betas\nParameter variance: 0.0001468024856876582\n\n","output_type":"stream"}]}]}