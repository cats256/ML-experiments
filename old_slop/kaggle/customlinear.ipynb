{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport numpy as np\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchinfo import summary\nimport torch.nn.functional as F\nfrom sklearn.model_selection import train_test_split\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom torch.profiler import profile, record_function, ProfilerActivity\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport torch","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-06-16T21:58:17.187548Z","iopub.execute_input":"2024-06-16T21:58:17.188423Z","iopub.status.idle":"2024-06-16T21:58:17.194465Z","shell.execute_reply.started":"2024-06-16T21:58:17.188389Z","shell.execute_reply":"2024-06-16T21:58:17.193500Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader, TensorDataset\nfrom sklearn.model_selection import train_test_split\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport imageio\nimport os\n\nclass CustomDataLoader:\n    def __init__(self, features, labels, batch_size=1, validation_size=0.0, shuffle=False):\n        if validation_size > 0:\n            train_data, val_data, train_labels, val_labels = train_test_split(\n                features, labels, test_size=validation_size, random_state=42\n            )\n            self.train_loader = DataLoader(\n                TensorDataset(torch.tensor(train_data).float(), torch.tensor(train_labels).float()),\n                batch_size=batch_size,\n                shuffle=shuffle,\n            )\n            self.val_loader = DataLoader(\n                TensorDataset(torch.tensor(val_data).float(), torch.tensor(val_labels).float()), batch_size=batch_size, shuffle=shuffle\n            )\n        else:\n            self.train_loader = DataLoader(\n                TensorDataset(torch.tensor(features).float(), torch.tensor(labels).float()), batch_size=batch_size, shuffle=shuffle\n            )\n            self.val_loader = None\n\n    def get_train_loader(self):\n        return self.train_loader\n\n    def get_val_loader(self):\n        return self.val_loader\n\ndef evaluate_model(model, custom_train_loader, criterion, optimizer):\n    num_epochs = 1200\n    parameters = []\n    image_folder = 'training_images'\n    os.makedirs(image_folder, exist_ok=True)\n    \n#     num = 10000\n#     x = np.linspace(-6, 6, num)\n#     y = np.linspace(-0, 0, num)\n#     random_feature1 = np.linspace(-0, 0, num)\n#     random_feature2 = np.linspace(-0, 0, num)\n\n#     inputs = np.stack([x], axis=1)\n#     inputs_tensor = torch.from_numpy(inputs).float().to(device)\n\n#     model.eval()\n#     with torch.no_grad():\n#         y_pred_model = model(inputs_tensor).cpu().numpy()\n\n#     a = x\n#     y_pred_manual = np.sin(a) + 2 * np.cos(a + 3 * np.sin(a)) + 3 * np.cos(a) ** 2 * np.sin(a) ** 2 + 0.5 * np.cos(a)\n\n#     plt.figure(figsize=(10, 5))\n#     plt.scatter(x, y_pred_model.flatten(), label='Model Output', s=1, alpha=0.1)\n#     plt.scatter(x, y_pred_manual, label='Manual Calculation', s=1, alpha=0.1)\n#     plt.xlabel('Input Feature 1')\n#     plt.ylabel('Output')\n#     plt.legend()\n#     plt.grid(True)\n#     plt.savefig(f\"{image_folder}/epoch_0000.png\")\n#     plt.close()\n\n    for epoch in range(num_epochs):\n        running_loss = 0.0\n        for inputs, labels in custom_train_loader.get_train_loader():\n            inputs, labels = inputs.to(device), labels.to(device)\n            optimizer.zero_grad()\n            outputs = model(inputs.view(-1, 1))\n            loss = criterion(outputs, labels.view(-1, 1))\n\n            if torch.isnan(loss):\n                print(\"Loss is NaN or Inf\")\n                print(parameters)\n\n                for name, param in model.named_parameters():\n                    print(f\"{name}: {param}\")\n                break\n\n            parameters = []\n            for name, param in model.named_parameters():\n                parameters.append(f\"{name}: {param}\")\n\n            loss.backward()\n            optimizer.step()\n\n            running_loss += loss.item()\n        avg_train_loss = running_loss / len(custom_train_loader.get_train_loader())\n            \n        model.eval()\n        running_val_loss = 0.0\n        with torch.no_grad():\n            for inputs, labels in custom_train_loader.get_val_loader():\n                inputs, labels = inputs.to(device), labels.to(device)\n                outputs = model(inputs.view(-1, 1))\n                val_loss = criterion(outputs, labels.view(-1, 1))\n                running_val_loss += val_loss.item()\n\n        avg_val_loss = running_val_loss / len(custom_train_loader.get_val_loader())\n        print(f\"Epoch {epoch+1:4d} | Train Loss: {avg_train_loss:10.4f} | Validation Loss: {avg_val_loss:10.4f}\")\n\n        num = 10000\n        \n        columns = []\n        \n        x = np.linspace(-6, 6, num).reshape(-1, 1)\n        y = np.linspace(-0, 0, num)\n        random_feature1 = np.linspace(-0, 0, num)\n        random_feature2 = np.linspace(-0, 0, num)\n\n#         const_array = np.full((num, 1), const)\n\n#         inputs = np.hstack([x, const_array])\n#         inputs_tensor = torch.from_numpy(inputs).float().to(device)\n\n        for bias in biases:\n            column = x + 0\n            columns.append(column)\n#         columns.append(x)\n        \n        inputs = np.column_stack(columns)\n        inputs_tensor = torch.from_numpy(inputs).float().to(device)\n\n        model.eval()\n        with torch.no_grad():\n            y_pred_model = model(inputs_tensor).cpu().numpy()\n\n        a = x\n        y_pred_manual = np.sin(a) + 2 * np.cos(a + 3 * np.sin(a)) + 3 * np.cos(a) ** 2 * np.sin(a) ** 2 + 0.5 * np.cos(a)\n        \n        plt.figure(figsize=(10, 5))\n        plt.scatter(x, y_pred_model.flatten(), label='Model Output', s=1, alpha=0.1)\n        plt.scatter(x, y_pred_manual, label='Manual Calculation', s=1, alpha=0.1)\n        plt.xlabel('Input Feature 1')\n        plt.ylabel('Output')\n        plt.legend()\n        plt.grid(True)\n        plt.savefig(f\"{image_folder}/epoch_{epoch+1:04d}.png\")\n        plt.close()\n\n    images = []\n    for epoch in range(num_epochs):\n        filename = f\"{image_folder}/epoch_{epoch+1:04d}.png\"\n        images.append(imageio.imread(filename))\n    imageio.mimsave('training_progress.gif', images, duration=0.2)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:58:18.124585Z","iopub.execute_input":"2024-06-16T21:58:18.124975Z","iopub.status.idle":"2024-06-16T21:58:18.207134Z","shell.execute_reply.started":"2024-06-16T21:58:18.124947Z","shell.execute_reply":"2024-06-16T21:58:18.206147Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nnum_samples = 128 * 100\nimport math\n\na = (np.random.rand(num_samples, 1) - 0.5) * 12\nb = (np.random.rand(num_samples, 1) - 0.5) * 8\nc = (np.random.rand(num_samples, 1) - 0.5) * 4\nd = (np.random.rand(num_samples, 1) - 0.5) * 4\ne = (np.random.rand(num_samples, 1) - 0.5) * 4\n\nconst = 1\nconst_array = np.full((num_samples, 1), const)\n\n# x_train = np.hstack([a, const_array])\ncolumns = []\nbiases = []\n\nfor _ in range(1):\n    bias = np.random.uniform(-1, 1) \n    biases.append(bias)\n    column = a + 0\n    columns.append(column)\n\n# columns.append(a)\nbiases = np.array(biases)\n\nx_train = np.column_stack(columns)\ny_train = np.abs(a)\ny_train = np.sin(a) + 2 * np.cos(a + 3 * np.sin(a)) + 3 * np.cos(a) ** 2 * np.sin(a) ** 2 + 0.5 * np.cos(a)\n\ncustom_train_loader = CustomDataLoader(x_train, y_train, batch_size=128, validation_size=0.2, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:58:19.102751Z","iopub.execute_input":"2024-06-16T21:58:19.103215Z","iopub.status.idle":"2024-06-16T21:58:19.148669Z","shell.execute_reply.started":"2024-06-16T21:58:19.103182Z","shell.execute_reply":"2024-06-16T21:58:19.147586Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:58:20.556804Z","iopub.execute_input":"2024-06-16T21:58:20.557501Z","iopub.status.idle":"2024-06-16T21:58:20.581888Z","shell.execute_reply.started":"2024-06-16T21:58:20.557471Z","shell.execute_reply":"2024-06-16T21:58:20.581026Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"class CustomLinearLayer(nn.Module):\n    def __init__(self, input_size, output_size, init_zero=False):\n        super(CustomLinearLayer, self).__init__()\n        self.bias = nn.Parameter(torch.zeros(1, output_size))\n        self.outer_bias = nn.Parameter(torch.zeros(input_size, output_size))\n        \n        if init_zero:\n            self.alpha = nn.Parameter(torch.zeros(input_size, output_size))\n            self.beta = nn.Parameter(torch.zeros(input_size, output_size))\n        else:\n            self.alpha = nn.Parameter(torch.eye(input_size, output_size))\n            self.beta = nn.Parameter(torch.eye(input_size, output_size))\n\n    def forward(self, x):\n        if x.dim() == 1:\n            x = x.unsqueeze(0)\n        \n        x_expanded = x.unsqueeze(-1) + self.outer_bias\n        \n        weighted_x = torch.where(x_expanded > 0, x_expanded * self.alpha, x_expanded * self.beta)\n        output = weighted_x.sum(dim=1)\n        \n        return output + self.bias\n\n#     def forward(self, x):\n#         if x.dim() == 1:\n#             x = x.unsqueeze(0)\n            \n#         positive_contrib = torch.matmul(x.clamp(min=0), self.alpha)\n#         negative_contrib = torch.matmul(x.clamp(max=0), self.beta)\n        \n#         return positive_contrib + negative_contrib\n#         batch_size, input_size = x.size()\n        \n#         x_square = x.unsqueeze(2).repeat(1, 1, input_size)\n        \n#         bias_expanded = self.bias.expand(batch_size, input_size, -1)\n#         x_with_bias = x_square + bias_expanded\n        \n#         x_with_bias = x_with_bias.reshape(batch_size, input_size, -1)\n        \n#         positive_contrib = torch.matmul(x_with_bias.clamp(min=0), self.alpha.unsqueeze(0).expand(batch_size, -1, -1))\n#         negative_contrib = torch.matmul(x_with_bias.clamp(max=0), self.beta.unsqueeze(0).expand(batch_size, -1, -1))\n\n#         positive_contrib_sum = positive_contrib.sum(dim=1)\n#         negative_contrib_sum = negative_contrib.sum(dim=1)\n        \n#         return positive_contrib_sum + negative_contrib_sum + self.outer_bias\n","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:58:21.201008Z","iopub.execute_input":"2024-06-16T21:58:21.201730Z","iopub.status.idle":"2024-06-16T21:58:21.211353Z","shell.execute_reply.started":"2024-06-16T21:58:21.201699Z","shell.execute_reply":"2024-06-16T21:58:21.210446Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"class PairwiseCustomActivationNetwork(nn.Module):\n    def __init__(self, input_size, num_layers, output_size):\n        super(PairwiseCustomActivationNetwork, self).__init__()\n\n        self.num_layers = num_layers\n        self.layers = nn.ModuleList()\n   \n        layer_size = input_size\n        for i in range(1, num_layers):\n            self.layers.append(CustomLinearLayer(layer_size, layer_size))\n            layer_size *= 2\n            \n        self.layers.append(CustomLinearLayer(layer_size, output_size, init_zero=True))\n\n    def forward(self, x):\n        outputs = [x]\n        \n        for layer in self.layers:\n            concatenated_outputs = torch.cat(outputs, dim=1)\n            out = layer(concatenated_outputs)\n            outputs.append(layer(concatenated_outputs))\n\n        return outputs[-1]\n    \nmodel = PairwiseCustomActivationNetwork(1, 10, 1).to(device)\ncriterion = nn.MSELoss()\nprint(summary(model, input_size=(1, 1)))","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:58:21.749213Z","iopub.execute_input":"2024-06-16T21:58:21.749579Z","iopub.status.idle":"2024-06-16T21:58:22.095941Z","shell.execute_reply.started":"2024-06-16T21:58:21.749542Z","shell.execute_reply":"2024-06-16T21:58:22.095044Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"==========================================================================================\nLayer (type:depth-idx)                   Output Shape              Param #\n==========================================================================================\nPairwiseCustomActivationNetwork          [1, 1]                    --\n├─ModuleList: 1-1                        --                        --\n│    └─CustomLinearLayer: 2-1            [1, 1]                    4\n│    └─CustomLinearLayer: 2-2            [1, 1]                    (recursive)\n│    └─CustomLinearLayer: 2-3            [1, 2]                    14\n│    └─CustomLinearLayer: 2-4            [1, 2]                    (recursive)\n│    └─CustomLinearLayer: 2-5            [1, 4]                    52\n│    └─CustomLinearLayer: 2-6            [1, 4]                    (recursive)\n│    └─CustomLinearLayer: 2-7            [1, 8]                    200\n│    └─CustomLinearLayer: 2-8            [1, 8]                    (recursive)\n│    └─CustomLinearLayer: 2-9            [1, 16]                   784\n│    └─CustomLinearLayer: 2-10           [1, 16]                   (recursive)\n│    └─CustomLinearLayer: 2-11           [1, 32]                   3,104\n│    └─CustomLinearLayer: 2-12           [1, 32]                   (recursive)\n│    └─CustomLinearLayer: 2-13           [1, 64]                   12,352\n│    └─CustomLinearLayer: 2-14           [1, 64]                   (recursive)\n│    └─CustomLinearLayer: 2-15           [1, 128]                  49,280\n│    └─CustomLinearLayer: 2-16           [1, 128]                  (recursive)\n│    └─CustomLinearLayer: 2-17           [1, 256]                  196,864\n│    └─CustomLinearLayer: 2-18           [1, 256]                  (recursive)\n│    └─CustomLinearLayer: 2-19           [1, 1]                    1,537\n│    └─CustomLinearLayer: 2-20           [1, 1]                    (recursive)\n==========================================================================================\nTotal params: 264,191\nTrainable params: 264,191\nNon-trainable params: 0\nTotal mult-adds (M): 38.35\n==========================================================================================\nInput size (MB): 0.00\nForward/backward pass size (MB): 0.01\nParams size (MB): 1.06\nEstimated Total Size (MB): 1.07\n==========================================================================================\n","output_type":"stream"}]},{"cell_type":"code","source":"for name, param in model.named_parameters():\n    print(name, param)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:58:22.628871Z","iopub.execute_input":"2024-06-16T21:58:22.629267Z","iopub.status.idle":"2024-06-16T21:58:22.923692Z","shell.execute_reply.started":"2024-06-16T21:58:22.629239Z","shell.execute_reply":"2024-06-16T21:58:22.922722Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"layers.0.bias Parameter containing:\ntensor([[0.]], device='cuda:0', requires_grad=True)\nlayers.0.outer_bias Parameter containing:\ntensor([[0.]], device='cuda:0', requires_grad=True)\nlayers.0.alpha Parameter containing:\ntensor([[1.]], device='cuda:0', requires_grad=True)\nlayers.0.beta Parameter containing:\ntensor([[1.]], device='cuda:0', requires_grad=True)\nlayers.1.bias Parameter containing:\ntensor([[0., 0.]], device='cuda:0', requires_grad=True)\nlayers.1.outer_bias Parameter containing:\ntensor([[0., 0.],\n        [0., 0.]], device='cuda:0', requires_grad=True)\nlayers.1.alpha Parameter containing:\ntensor([[1., 0.],\n        [0., 1.]], device='cuda:0', requires_grad=True)\nlayers.1.beta Parameter containing:\ntensor([[1., 0.],\n        [0., 1.]], device='cuda:0', requires_grad=True)\nlayers.2.bias Parameter containing:\ntensor([[0., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.2.outer_bias Parameter containing:\ntensor([[0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.],\n        [0., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.2.alpha Parameter containing:\ntensor([[1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.2.beta Parameter containing:\ntensor([[1., 0., 0., 0.],\n        [0., 1., 0., 0.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.3.bias Parameter containing:\ntensor([[0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.3.outer_bias Parameter containing:\ntensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.3.alpha Parameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.3.beta Parameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.4.bias Parameter containing:\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n       device='cuda:0', requires_grad=True)\nlayers.4.outer_bias Parameter containing:\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n       device='cuda:0', requires_grad=True)\nlayers.4.alpha Parameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n       device='cuda:0', requires_grad=True)\nlayers.4.beta Parameter containing:\ntensor([[1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0.],\n        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]],\n       device='cuda:0', requires_grad=True)\nlayers.5.bias Parameter containing:\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.5.outer_bias Parameter containing:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.5.alpha Parameter containing:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 1., 0.],\n        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.5.beta Parameter containing:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 1., 0.],\n        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.6.bias Parameter containing:\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n       device='cuda:0', requires_grad=True)\nlayers.6.outer_bias Parameter containing:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.6.alpha Parameter containing:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 1., 0.],\n        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.6.beta Parameter containing:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 1., 0.],\n        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.7.bias Parameter containing:\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.7.outer_bias Parameter containing:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.7.alpha Parameter containing:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 1., 0.],\n        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.7.beta Parameter containing:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 1., 0.],\n        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.8.bias Parameter containing:\ntensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]],\n       device='cuda:0', requires_grad=True)\nlayers.8.outer_bias Parameter containing:\ntensor([[0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.],\n        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0', requires_grad=True)\nlayers.8.alpha Parameter containing:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 1., 0.],\n        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.8.beta Parameter containing:\ntensor([[1., 0., 0.,  ..., 0., 0., 0.],\n        [0., 1., 0.,  ..., 0., 0., 0.],\n        [0., 0., 1.,  ..., 0., 0., 0.],\n        ...,\n        [0., 0., 0.,  ..., 1., 0., 0.],\n        [0., 0., 0.,  ..., 0., 1., 0.],\n        [0., 0., 0.,  ..., 0., 0., 1.]], device='cuda:0', requires_grad=True)\nlayers.9.bias Parameter containing:\ntensor([[0.]], device='cuda:0', requires_grad=True)\nlayers.9.outer_bias Parameter containing:\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], device='cuda:0', requires_grad=True)\nlayers.9.alpha Parameter containing:\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], device='cuda:0', requires_grad=True)\nlayers.9.beta Parameter containing:\ntensor([[0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.],\n        [0.]], device='cuda:0', requires_grad=True)\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optim.Adam(model.parameters(), lr=0.0000001 * 1000)\nevaluate_model(model, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:59:08.574592Z","iopub.execute_input":"2024-06-16T21:59:08.575291Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Epoch    1 | Train Loss:     1.4205 | Validation Loss:     1.3899\nEpoch    2 | Train Loss:     1.4106 | Validation Loss:     1.3898\nEpoch    3 | Train Loss:     1.4060 | Validation Loss:     1.3868\nEpoch    4 | Train Loss:     1.3946 | Validation Loss:     1.3690\nEpoch    5 | Train Loss:     1.3782 | Validation Loss:     1.3383\nEpoch    6 | Train Loss:     1.2971 | Validation Loss:     1.1993\nEpoch    7 | Train Loss:     1.0187 | Validation Loss:     0.8885\nEpoch    8 | Train Loss:     0.7877 | Validation Loss:     0.7069\nEpoch    9 | Train Loss:     0.6908 | Validation Loss:     0.6738\nEpoch   10 | Train Loss:     0.6531 | Validation Loss:     0.6296\nEpoch   11 | Train Loss:     0.6259 | Validation Loss:     0.6145\nEpoch   12 | Train Loss:     0.6076 | Validation Loss:     0.5965\nEpoch   13 | Train Loss:     0.5732 | Validation Loss:     0.5760\nEpoch   14 | Train Loss:     0.5542 | Validation Loss:     0.5452\nEpoch   15 | Train Loss:     0.5256 | Validation Loss:     0.5024\nEpoch   16 | Train Loss:     0.5022 | Validation Loss:     0.4931\nEpoch   17 | Train Loss:     0.4585 | Validation Loss:     0.4279\nEpoch   18 | Train Loss:     0.4148 | Validation Loss:     0.3989\nEpoch   19 | Train Loss:     0.3705 | Validation Loss:     0.3460\n","output_type":"stream"}]},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=0.000001 * 10)\noptimizer = optim.Adam(model.parameters(), lr=0.0000001 * 10000)\nevaluate_model(model, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:29:43.370952Z","iopub.execute_input":"2024-06-16T21:29:43.371652Z","iopub.status.idle":"2024-06-16T21:40:44.855593Z","shell.execute_reply.started":"2024-06-16T21:29:43.371623Z","shell.execute_reply":"2024-06-16T21:40:44.854218Z"},"trusted":true},"execution_count":378,"outputs":[{"name":"stdout","text":"Epoch    1 | Train Loss:     1.4424 | Validation Loss:     1.4241\nEpoch    2 | Train Loss:     1.4114 | Validation Loss:     1.4228\nEpoch    3 | Train Loss:     1.3985 | Validation Loss:     1.4000\nEpoch    4 | Train Loss:     1.3778 | Validation Loss:     1.3639\nEpoch    5 | Train Loss:     1.2977 | Validation Loss:     1.2301\nEpoch    6 | Train Loss:     1.0557 | Validation Loss:     0.9192\nEpoch    7 | Train Loss:     0.7739 | Validation Loss:     0.7141\nEpoch    8 | Train Loss:     0.6442 | Validation Loss:     0.6354\nEpoch    9 | Train Loss:     0.5824 | Validation Loss:     0.5909\nEpoch   10 | Train Loss:     0.5440 | Validation Loss:     0.5417\nEpoch   11 | Train Loss:     0.5130 | Validation Loss:     0.5064\nEpoch   12 | Train Loss:     0.4769 | Validation Loss:     0.4853\nEpoch   13 | Train Loss:     0.4584 | Validation Loss:     0.4604\nEpoch   14 | Train Loss:     0.4416 | Validation Loss:     0.4496\nEpoch   15 | Train Loss:     0.4344 | Validation Loss:     0.4343\nEpoch   16 | Train Loss:     0.4234 | Validation Loss:     0.4276\nEpoch   17 | Train Loss:     0.4163 | Validation Loss:     0.4190\nEpoch   18 | Train Loss:     0.4101 | Validation Loss:     0.4332\nEpoch   19 | Train Loss:     0.3991 | Validation Loss:     0.4062\nEpoch   20 | Train Loss:     0.3895 | Validation Loss:     0.3950\nEpoch   21 | Train Loss:     0.3813 | Validation Loss:     0.3796\nEpoch   22 | Train Loss:     0.3662 | Validation Loss:     0.3792\nEpoch   23 | Train Loss:     0.3547 | Validation Loss:     0.3567\nEpoch   24 | Train Loss:     0.3451 | Validation Loss:     0.3489\nEpoch   25 | Train Loss:     0.3369 | Validation Loss:     0.3539\nEpoch   26 | Train Loss:     0.3346 | Validation Loss:     0.3444\nEpoch   27 | Train Loss:     0.3276 | Validation Loss:     0.3358\nEpoch   28 | Train Loss:     0.3239 | Validation Loss:     0.3316\nEpoch   29 | Train Loss:     0.3166 | Validation Loss:     0.3229\nEpoch   30 | Train Loss:     0.3099 | Validation Loss:     0.3133\nEpoch   31 | Train Loss:     0.3028 | Validation Loss:     0.3150\nEpoch   32 | Train Loss:     0.2944 | Validation Loss:     0.2968\nEpoch   33 | Train Loss:     0.2856 | Validation Loss:     0.2924\nEpoch   34 | Train Loss:     0.2766 | Validation Loss:     0.2804\nEpoch   35 | Train Loss:     0.2709 | Validation Loss:     0.2654\nEpoch   36 | Train Loss:     0.2541 | Validation Loss:     0.2540\nEpoch   37 | Train Loss:     0.2425 | Validation Loss:     0.2593\nEpoch   38 | Train Loss:     0.2285 | Validation Loss:     0.2219\nEpoch   39 | Train Loss:     0.2119 | Validation Loss:     0.2071\nEpoch   40 | Train Loss:     0.1997 | Validation Loss:     0.1974\nEpoch   41 | Train Loss:     0.1852 | Validation Loss:     0.1835\nEpoch   42 | Train Loss:     0.1748 | Validation Loss:     0.1809\nEpoch   43 | Train Loss:     0.1604 | Validation Loss:     0.1577\nEpoch   44 | Train Loss:     0.1489 | Validation Loss:     0.1547\nEpoch   45 | Train Loss:     0.1424 | Validation Loss:     0.1444\nEpoch   46 | Train Loss:     0.1381 | Validation Loss:     0.1387\nEpoch   47 | Train Loss:     0.1392 | Validation Loss:     0.1360\nEpoch   48 | Train Loss:     0.1289 | Validation Loss:     0.1293\nEpoch   49 | Train Loss:     0.1304 | Validation Loss:     0.1299\nEpoch   50 | Train Loss:     0.1295 | Validation Loss:     0.1282\nEpoch   51 | Train Loss:     0.1231 | Validation Loss:     0.1322\nEpoch   52 | Train Loss:     0.1225 | Validation Loss:     0.1340\nEpoch   53 | Train Loss:     0.1219 | Validation Loss:     0.1260\nEpoch   54 | Train Loss:     0.1224 | Validation Loss:     0.1205\nEpoch   55 | Train Loss:     0.1159 | Validation Loss:     0.1215\nEpoch   56 | Train Loss:     0.1181 | Validation Loss:     0.1204\nEpoch   57 | Train Loss:     0.1149 | Validation Loss:     0.1174\nEpoch   58 | Train Loss:     0.1131 | Validation Loss:     0.1177\nEpoch   59 | Train Loss:     0.1155 | Validation Loss:     0.1128\nEpoch   60 | Train Loss:     0.1127 | Validation Loss:     0.1108\nEpoch   61 | Train Loss:     0.1076 | Validation Loss:     0.1102\nEpoch   62 | Train Loss:     0.1110 | Validation Loss:     0.1089\nEpoch   63 | Train Loss:     0.1069 | Validation Loss:     0.1090\nEpoch   64 | Train Loss:     0.1051 | Validation Loss:     0.1117\nEpoch   65 | Train Loss:     0.1061 | Validation Loss:     0.1218\nEpoch   66 | Train Loss:     0.1039 | Validation Loss:     0.1058\nEpoch   67 | Train Loss:     0.1050 | Validation Loss:     0.1030\nEpoch   68 | Train Loss:     0.1028 | Validation Loss:     0.1049\nEpoch   69 | Train Loss:     0.1080 | Validation Loss:     0.1004\nEpoch   70 | Train Loss:     0.1021 | Validation Loss:     0.1093\nEpoch   71 | Train Loss:     0.0999 | Validation Loss:     0.1018\nEpoch   72 | Train Loss:     0.0974 | Validation Loss:     0.0966\nEpoch   73 | Train Loss:     0.0988 | Validation Loss:     0.0963\nEpoch   74 | Train Loss:     0.0958 | Validation Loss:     0.1056\nEpoch   75 | Train Loss:     0.0956 | Validation Loss:     0.1003\nEpoch   76 | Train Loss:     0.0933 | Validation Loss:     0.0937\nEpoch   77 | Train Loss:     0.0948 | Validation Loss:     0.0923\nEpoch   78 | Train Loss:     0.0955 | Validation Loss:     0.1011\nEpoch   79 | Train Loss:     0.0934 | Validation Loss:     0.0896\nEpoch   80 | Train Loss:     0.0882 | Validation Loss:     0.0879\nEpoch   81 | Train Loss:     0.0899 | Validation Loss:     0.0874\nEpoch   82 | Train Loss:     0.0861 | Validation Loss:     0.0840\nEpoch   83 | Train Loss:     0.0849 | Validation Loss:     0.0871\nEpoch   84 | Train Loss:     0.0857 | Validation Loss:     0.0826\nEpoch   85 | Train Loss:     0.0824 | Validation Loss:     0.0800\nEpoch   86 | Train Loss:     0.0828 | Validation Loss:     0.0885\nEpoch   87 | Train Loss:     0.0768 | Validation Loss:     0.0773\nEpoch   88 | Train Loss:     0.0774 | Validation Loss:     0.0754\nEpoch   89 | Train Loss:     0.0768 | Validation Loss:     0.0962\nEpoch   90 | Train Loss:     0.0752 | Validation Loss:     0.0725\nEpoch   91 | Train Loss:     0.0693 | Validation Loss:     0.0687\nEpoch   92 | Train Loss:     0.0670 | Validation Loss:     0.0688\nEpoch   93 | Train Loss:     0.0639 | Validation Loss:     0.0739\nEpoch   94 | Train Loss:     0.0605 | Validation Loss:     0.0697\nEpoch   95 | Train Loss:     0.0589 | Validation Loss:     0.0625\nEpoch   96 | Train Loss:     0.0555 | Validation Loss:     0.0590\nEpoch   97 | Train Loss:     0.0530 | Validation Loss:     0.0538\nEpoch   98 | Train Loss:     0.0500 | Validation Loss:     0.0483\nEpoch   99 | Train Loss:     0.0457 | Validation Loss:     0.0443\nEpoch  100 | Train Loss:     0.0422 | Validation Loss:     0.0415\nEpoch  101 | Train Loss:     0.0396 | Validation Loss:     0.0380\nEpoch  102 | Train Loss:     0.0369 | Validation Loss:     0.0340\nEpoch  103 | Train Loss:     0.0324 | Validation Loss:     0.0312\nEpoch  104 | Train Loss:     0.0317 | Validation Loss:     0.0285\nEpoch  105 | Train Loss:     0.0292 | Validation Loss:     0.0304\nEpoch  106 | Train Loss:     0.0256 | Validation Loss:     0.0233\nEpoch  107 | Train Loss:     0.0227 | Validation Loss:     0.0215\nEpoch  108 | Train Loss:     0.0219 | Validation Loss:     0.0202\nEpoch  109 | Train Loss:     0.0183 | Validation Loss:     0.0201\nEpoch  110 | Train Loss:     0.0181 | Validation Loss:     0.0179\nEpoch  111 | Train Loss:     0.0155 | Validation Loss:     0.0173\nEpoch  112 | Train Loss:     0.0150 | Validation Loss:     0.0137\nEpoch  113 | Train Loss:     0.0128 | Validation Loss:     0.0143\nEpoch  114 | Train Loss:     0.0120 | Validation Loss:     0.0114\nEpoch  115 | Train Loss:     0.0116 | Validation Loss:     0.0108\nEpoch  116 | Train Loss:     0.0105 | Validation Loss:     0.0094\nEpoch  117 | Train Loss:     0.0091 | Validation Loss:     0.0086\nEpoch  118 | Train Loss:     0.0087 | Validation Loss:     0.0081\nEpoch  119 | Train Loss:     0.0081 | Validation Loss:     0.0100\nEpoch  120 | Train Loss:     0.0075 | Validation Loss:     0.0080\nEpoch  121 | Train Loss:     0.0077 | Validation Loss:     0.0074\nEpoch  122 | Train Loss:     0.0071 | Validation Loss:     0.0070\nEpoch  123 | Train Loss:     0.0068 | Validation Loss:     0.0065\nEpoch  124 | Train Loss:     0.0065 | Validation Loss:     0.0074\nEpoch  125 | Train Loss:     0.0057 | Validation Loss:     0.0072\nEpoch  126 | Train Loss:     0.0065 | Validation Loss:     0.0063\nEpoch  127 | Train Loss:     0.0058 | Validation Loss:     0.0063\nEpoch  128 | Train Loss:     0.0059 | Validation Loss:     0.0065\nEpoch  129 | Train Loss:     0.0051 | Validation Loss:     0.0072\nEpoch  130 | Train Loss:     0.0050 | Validation Loss:     0.0049\nEpoch  131 | Train Loss:     0.0045 | Validation Loss:     0.0050\nEpoch  132 | Train Loss:     0.0049 | Validation Loss:     0.0062\nEpoch  133 | Train Loss:     0.0056 | Validation Loss:     0.0046\nEpoch  134 | Train Loss:     0.0045 | Validation Loss:     0.0062\nEpoch  135 | Train Loss:     0.0048 | Validation Loss:     0.0046\nEpoch  136 | Train Loss:     0.0043 | Validation Loss:     0.0045\nEpoch  137 | Train Loss:     0.0041 | Validation Loss:     0.0042\nEpoch  138 | Train Loss:     0.0045 | Validation Loss:     0.0054\nEpoch  139 | Train Loss:     0.0041 | Validation Loss:     0.0034\nEpoch  140 | Train Loss:     0.0041 | Validation Loss:     0.0059\nEpoch  141 | Train Loss:     0.0036 | Validation Loss:     0.0034\nEpoch  142 | Train Loss:     0.0037 | Validation Loss:     0.0035\nEpoch  143 | Train Loss:     0.0035 | Validation Loss:     0.0067\nEpoch  144 | Train Loss:     0.0045 | Validation Loss:     0.0044\nEpoch  145 | Train Loss:     0.0038 | Validation Loss:     0.0037\nEpoch  146 | Train Loss:     0.0033 | Validation Loss:     0.0052\nEpoch  147 | Train Loss:     0.0034 | Validation Loss:     0.0037\nEpoch  148 | Train Loss:     0.0035 | Validation Loss:     0.0026\nEpoch  149 | Train Loss:     0.0032 | Validation Loss:     0.0047\nEpoch  150 | Train Loss:     0.0032 | Validation Loss:     0.0029\nEpoch  151 | Train Loss:     0.0032 | Validation Loss:     0.0031\nEpoch  152 | Train Loss:     0.0028 | Validation Loss:     0.0031\nEpoch  153 | Train Loss:     0.0029 | Validation Loss:     0.0045\nEpoch  154 | Train Loss:     0.0036 | Validation Loss:     0.0045\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[378], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[167], line 87\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     85\u001b[0m parameters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[0;32m---> 87\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:934\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[0;32m--> 934\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__format__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_spec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parameter.py:63\u001b[0m, in \u001b[0;36mParameter.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter containing:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__repr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    428\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:662\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    661\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_str\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 662\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    663\u001b[0m         guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m    664\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _str_intern(\u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py:83\u001b[0m, in \u001b[0;36mno_grad.__exit__\u001b[0;34m(self, exc_type, exc_value, traceback)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type: Any, exc_value: Any, traceback: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 83\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprev\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/grad_mode.py:184\u001b[0m, in \u001b[0;36mset_grad_enabled.__init__\u001b[0;34m(self, mode)\u001b[0m\n\u001b[1;32m    182\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, mode: \u001b[38;5;28mbool\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    183\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprev \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mis_grad_enabled()\n\u001b[0;32m--> 184\u001b[0m     \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_grad_enabled\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m=\u001b[39m mode\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=0.000001 * 10)\noptimizer = optim.Adam(model.parameters(), lr=0.0000001 * 10000)\nevaluate_model(model, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:13:29.828825Z","iopub.execute_input":"2024-06-16T21:13:29.829736Z","iopub.status.idle":"2024-06-16T21:19:36.377232Z","shell.execute_reply.started":"2024-06-16T21:13:29.829702Z","shell.execute_reply":"2024-06-16T21:19:36.375652Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":363,"outputs":[{"name":"stdout","text":"Epoch    1 | Train Loss:     1.4402 | Validation Loss:     1.4253\nEpoch    2 | Train Loss:     1.4109 | Validation Loss:     1.4117\nEpoch    3 | Train Loss:     1.3968 | Validation Loss:     1.3965\nEpoch    4 | Train Loss:     1.3616 | Validation Loss:     1.3395\nEpoch    5 | Train Loss:     1.2214 | Validation Loss:     1.0782\nEpoch    6 | Train Loss:     0.9047 | Validation Loss:     0.8158\nEpoch    7 | Train Loss:     0.7403 | Validation Loss:     0.6960\nEpoch    8 | Train Loss:     0.6272 | Validation Loss:     0.6261\nEpoch    9 | Train Loss:     0.5698 | Validation Loss:     0.5809\nEpoch   10 | Train Loss:     0.5241 | Validation Loss:     0.5328\nEpoch   11 | Train Loss:     0.5001 | Validation Loss:     0.5278\nEpoch   12 | Train Loss:     0.4759 | Validation Loss:     0.4757\nEpoch   13 | Train Loss:     0.4523 | Validation Loss:     0.4613\nEpoch   14 | Train Loss:     0.4424 | Validation Loss:     0.4498\nEpoch   15 | Train Loss:     0.4290 | Validation Loss:     0.4570\nEpoch   16 | Train Loss:     0.4232 | Validation Loss:     0.4280\nEpoch   17 | Train Loss:     0.4162 | Validation Loss:     0.4272\nEpoch   18 | Train Loss:     0.4089 | Validation Loss:     0.4090\nEpoch   19 | Train Loss:     0.3946 | Validation Loss:     0.4028\nEpoch   20 | Train Loss:     0.3826 | Validation Loss:     0.3896\nEpoch   21 | Train Loss:     0.3745 | Validation Loss:     0.3808\nEpoch   22 | Train Loss:     0.3591 | Validation Loss:     0.3610\nEpoch   23 | Train Loss:     0.3441 | Validation Loss:     0.3492\nEpoch   24 | Train Loss:     0.3368 | Validation Loss:     0.3444\nEpoch   25 | Train Loss:     0.3345 | Validation Loss:     0.3308\nEpoch   26 | Train Loss:     0.3197 | Validation Loss:     0.3213\nEpoch   27 | Train Loss:     0.3102 | Validation Loss:     0.3097\nEpoch   28 | Train Loss:     0.2958 | Validation Loss:     0.2971\nEpoch   29 | Train Loss:     0.2830 | Validation Loss:     0.2870\nEpoch   30 | Train Loss:     0.2672 | Validation Loss:     0.2813\nEpoch   31 | Train Loss:     0.2609 | Validation Loss:     0.2670\nEpoch   32 | Train Loss:     0.2322 | Validation Loss:     0.2267\nEpoch   33 | Train Loss:     0.2094 | Validation Loss:     0.2044\nEpoch   34 | Train Loss:     0.1944 | Validation Loss:     0.1884\nEpoch   35 | Train Loss:     0.1755 | Validation Loss:     0.1779\nEpoch   36 | Train Loss:     0.1628 | Validation Loss:     0.1604\nEpoch   37 | Train Loss:     0.1509 | Validation Loss:     0.1463\nEpoch   38 | Train Loss:     0.1406 | Validation Loss:     0.1388\nEpoch   39 | Train Loss:     0.1384 | Validation Loss:     0.1410\nEpoch   40 | Train Loss:     0.1300 | Validation Loss:     0.1280\nEpoch   41 | Train Loss:     0.1276 | Validation Loss:     0.1254\nEpoch   42 | Train Loss:     0.1290 | Validation Loss:     0.1224\nEpoch   43 | Train Loss:     0.1215 | Validation Loss:     0.1221\nEpoch   44 | Train Loss:     0.1191 | Validation Loss:     0.1196\nEpoch   45 | Train Loss:     0.1172 | Validation Loss:     0.1210\nEpoch   46 | Train Loss:     0.1133 | Validation Loss:     0.1134\nEpoch   47 | Train Loss:     0.1121 | Validation Loss:     0.1173\nEpoch   48 | Train Loss:     0.1120 | Validation Loss:     0.1128\nEpoch   49 | Train Loss:     0.1143 | Validation Loss:     0.1197\nEpoch   50 | Train Loss:     0.1058 | Validation Loss:     0.1054\nEpoch   51 | Train Loss:     0.1041 | Validation Loss:     0.1094\nEpoch   52 | Train Loss:     0.1063 | Validation Loss:     0.1311\nEpoch   53 | Train Loss:     0.1058 | Validation Loss:     0.1045\nEpoch   54 | Train Loss:     0.1038 | Validation Loss:     0.1010\nEpoch   55 | Train Loss:     0.1000 | Validation Loss:     0.1212\nEpoch   56 | Train Loss:     0.1014 | Validation Loss:     0.1078\nEpoch   57 | Train Loss:     0.0990 | Validation Loss:     0.1034\nEpoch   58 | Train Loss:     0.1056 | Validation Loss:     0.1044\nEpoch   59 | Train Loss:     0.0959 | Validation Loss:     0.1023\nEpoch   60 | Train Loss:     0.0973 | Validation Loss:     0.1060\nEpoch   61 | Train Loss:     0.0972 | Validation Loss:     0.0958\nEpoch   62 | Train Loss:     0.0989 | Validation Loss:     0.0964\nEpoch   63 | Train Loss:     0.0943 | Validation Loss:     0.0982\nEpoch   64 | Train Loss:     0.0939 | Validation Loss:     0.0915\nEpoch   65 | Train Loss:     0.0960 | Validation Loss:     0.1072\nEpoch   66 | Train Loss:     0.0986 | Validation Loss:     0.0904\nEpoch   67 | Train Loss:     0.0909 | Validation Loss:     0.0933\nEpoch   68 | Train Loss:     0.0921 | Validation Loss:     0.0960\nEpoch   69 | Train Loss:     0.0897 | Validation Loss:     0.0906\nEpoch   70 | Train Loss:     0.0896 | Validation Loss:     0.0878\nEpoch   71 | Train Loss:     0.0888 | Validation Loss:     0.0928\nEpoch   72 | Train Loss:     0.0892 | Validation Loss:     0.0889\nEpoch   73 | Train Loss:     0.0869 | Validation Loss:     0.0894\nEpoch   74 | Train Loss:     0.0874 | Validation Loss:     0.0870\nEpoch   75 | Train Loss:     0.0883 | Validation Loss:     0.0930\nEpoch   76 | Train Loss:     0.0917 | Validation Loss:     0.0877\nEpoch   77 | Train Loss:     0.0869 | Validation Loss:     0.1016\nEpoch   78 | Train Loss:     0.0867 | Validation Loss:     0.0841\nEpoch   79 | Train Loss:     0.0853 | Validation Loss:     0.0954\nEpoch   80 | Train Loss:     0.0858 | Validation Loss:     0.0846\nEpoch   81 | Train Loss:     0.0848 | Validation Loss:     0.0989\nEpoch   82 | Train Loss:     0.0887 | Validation Loss:     0.0872\nEpoch   83 | Train Loss:     0.0833 | Validation Loss:     0.0839\nEpoch   84 | Train Loss:     0.0834 | Validation Loss:     0.0831\nEpoch   85 | Train Loss:     0.0831 | Validation Loss:     0.0837\nEpoch   86 | Train Loss:     0.0830 | Validation Loss:     0.0861\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[363], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[167], line 87\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     85\u001b[0m parameters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[0;32m---> 87\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:934\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[0;32m--> 934\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__format__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_spec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parameter.py:63\u001b[0m, in \u001b[0;36mParameter.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter containing:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__repr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    428\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:664\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    663\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:595\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    594\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    598\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:347\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    343\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;28mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[1;32m    345\u001b[0m     )\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 347\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m \u001b[43m_Formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_summarized_data\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[38;5;28mself\u001b[39m, indent, summarize, formatter)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:179\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msci_mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m value \u001b[38;5;129;01min\u001b[39;00m nonzero_finite_vals:\n\u001b[0;32m--> 179\u001b[0m         value_str \u001b[38;5;241m=\u001b[39m \u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;130;43;01m{{\u001b[39;49;00m\u001b[38;5;124;43m:.\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mPRINT_OPTS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprecision\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43me\u001b[39;49m\u001b[38;5;130;43;01m}}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mformat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    180\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mmax\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_width, \u001b[38;5;28mlen\u001b[39m(value_str))\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:929\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    925\u001b[0m \u001b[38;5;129m@_handle_torch_function_and_wrap_type_error_to_not_implemented\u001b[39m\n\u001b[1;32m    926\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__rmod__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[1;32m    927\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mremainder(other, \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 929\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__format__\u001b[39m(\u001b[38;5;28mself\u001b[39m, format_spec):\n\u001b[1;32m    930\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    931\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, format_spec)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=0.000001 * 10)\noptimizer = optim.Adam(model.parameters(), lr=0.0000001 * 10000)\nevaluate_model(model, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:52:36.536732Z","iopub.execute_input":"2024-06-16T20:52:36.537308Z","iopub.status.idle":"2024-06-16T21:04:29.728680Z","shell.execute_reply.started":"2024-06-16T20:52:36.537265Z","shell.execute_reply":"2024-06-16T21:04:29.727366Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":355,"outputs":[{"name":"stdout","text":"Epoch    1 | Train Loss:     1.5047 | Validation Loss:     1.4419\nEpoch    2 | Train Loss:     1.4316 | Validation Loss:     1.4357\nEpoch    3 | Train Loss:     1.4247 | Validation Loss:     1.4286\nEpoch    4 | Train Loss:     1.4213 | Validation Loss:     1.4245\nEpoch    5 | Train Loss:     1.4159 | Validation Loss:     1.4217\nEpoch    6 | Train Loss:     1.4148 | Validation Loss:     1.4194\nEpoch    7 | Train Loss:     1.4094 | Validation Loss:     1.4148\nEpoch    8 | Train Loss:     1.4039 | Validation Loss:     1.4089\nEpoch    9 | Train Loss:     1.3955 | Validation Loss:     1.4118\nEpoch   10 | Train Loss:     1.3904 | Validation Loss:     1.3953\nEpoch   11 | Train Loss:     1.3822 | Validation Loss:     1.3894\nEpoch   12 | Train Loss:     1.3769 | Validation Loss:     1.3945\nEpoch   13 | Train Loss:     1.3692 | Validation Loss:     1.3754\nEpoch   14 | Train Loss:     1.3550 | Validation Loss:     1.3556\nEpoch   15 | Train Loss:     1.3227 | Validation Loss:     1.3298\nEpoch   16 | Train Loss:     1.2536 | Validation Loss:     1.2277\nEpoch   17 | Train Loss:     1.1303 | Validation Loss:     1.0819\nEpoch   18 | Train Loss:     0.9726 | Validation Loss:     0.9354\nEpoch   19 | Train Loss:     0.8503 | Validation Loss:     0.8265\nEpoch   20 | Train Loss:     0.7614 | Validation Loss:     0.7581\nEpoch   21 | Train Loss:     0.7090 | Validation Loss:     0.7075\nEpoch   22 | Train Loss:     0.6933 | Validation Loss:     0.6898\nEpoch   23 | Train Loss:     0.6602 | Validation Loss:     0.6705\nEpoch   24 | Train Loss:     0.6494 | Validation Loss:     0.6549\nEpoch   25 | Train Loss:     0.6349 | Validation Loss:     0.6515\nEpoch   26 | Train Loss:     0.6303 | Validation Loss:     0.6601\nEpoch   27 | Train Loss:     0.6267 | Validation Loss:     0.6405\nEpoch   28 | Train Loss:     0.6277 | Validation Loss:     0.6463\nEpoch   29 | Train Loss:     0.6193 | Validation Loss:     0.6396\nEpoch   30 | Train Loss:     0.6157 | Validation Loss:     0.6461\nEpoch   31 | Train Loss:     0.6143 | Validation Loss:     0.6367\nEpoch   32 | Train Loss:     0.6096 | Validation Loss:     0.6298\nEpoch   33 | Train Loss:     0.6155 | Validation Loss:     0.6279\nEpoch   34 | Train Loss:     0.6024 | Validation Loss:     0.6284\nEpoch   35 | Train Loss:     0.6019 | Validation Loss:     0.6448\nEpoch   36 | Train Loss:     0.6045 | Validation Loss:     0.6160\nEpoch   37 | Train Loss:     0.5989 | Validation Loss:     0.6273\nEpoch   38 | Train Loss:     0.5931 | Validation Loss:     0.6237\nEpoch   39 | Train Loss:     0.5865 | Validation Loss:     0.6059\nEpoch   40 | Train Loss:     0.5823 | Validation Loss:     0.6141\nEpoch   41 | Train Loss:     0.5843 | Validation Loss:     0.6028\nEpoch   42 | Train Loss:     0.5777 | Validation Loss:     0.6023\nEpoch   43 | Train Loss:     0.5719 | Validation Loss:     0.6038\nEpoch   44 | Train Loss:     0.5660 | Validation Loss:     0.6034\nEpoch   45 | Train Loss:     0.5586 | Validation Loss:     0.5806\nEpoch   46 | Train Loss:     0.5655 | Validation Loss:     0.5770\nEpoch   47 | Train Loss:     0.5507 | Validation Loss:     0.5838\nEpoch   48 | Train Loss:     0.5487 | Validation Loss:     0.5682\nEpoch   49 | Train Loss:     0.5445 | Validation Loss:     0.5650\nEpoch   50 | Train Loss:     0.5430 | Validation Loss:     0.5650\nEpoch   51 | Train Loss:     0.5394 | Validation Loss:     0.5539\nEpoch   52 | Train Loss:     0.5334 | Validation Loss:     0.5765\nEpoch   53 | Train Loss:     0.5258 | Validation Loss:     0.5497\nEpoch   54 | Train Loss:     0.5189 | Validation Loss:     0.5416\nEpoch   55 | Train Loss:     0.5201 | Validation Loss:     0.5435\nEpoch   56 | Train Loss:     0.5159 | Validation Loss:     0.5373\nEpoch   57 | Train Loss:     0.5084 | Validation Loss:     0.5319\nEpoch   58 | Train Loss:     0.5102 | Validation Loss:     0.5324\nEpoch   59 | Train Loss:     0.5100 | Validation Loss:     0.5294\nEpoch   60 | Train Loss:     0.5043 | Validation Loss:     0.5359\nEpoch   61 | Train Loss:     0.5038 | Validation Loss:     0.5389\nEpoch   62 | Train Loss:     0.5074 | Validation Loss:     0.5227\nEpoch   63 | Train Loss:     0.5010 | Validation Loss:     0.5325\nEpoch   64 | Train Loss:     0.5020 | Validation Loss:     0.5275\nEpoch   65 | Train Loss:     0.5019 | Validation Loss:     0.5262\nEpoch   66 | Train Loss:     0.4896 | Validation Loss:     0.5386\nEpoch   67 | Train Loss:     0.4832 | Validation Loss:     0.5035\nEpoch   68 | Train Loss:     0.4794 | Validation Loss:     0.5107\nEpoch   69 | Train Loss:     0.4755 | Validation Loss:     0.4972\nEpoch   70 | Train Loss:     0.4706 | Validation Loss:     0.4900\nEpoch   71 | Train Loss:     0.4639 | Validation Loss:     0.4920\nEpoch   72 | Train Loss:     0.4624 | Validation Loss:     0.4880\nEpoch   73 | Train Loss:     0.4502 | Validation Loss:     0.5126\nEpoch   74 | Train Loss:     0.4444 | Validation Loss:     0.4735\nEpoch   75 | Train Loss:     0.4407 | Validation Loss:     0.4666\nEpoch   76 | Train Loss:     0.4364 | Validation Loss:     0.4625\nEpoch   77 | Train Loss:     0.4345 | Validation Loss:     0.4570\nEpoch   78 | Train Loss:     0.4288 | Validation Loss:     0.4579\nEpoch   79 | Train Loss:     0.4262 | Validation Loss:     0.4550\nEpoch   80 | Train Loss:     0.4189 | Validation Loss:     0.4525\nEpoch   81 | Train Loss:     0.4235 | Validation Loss:     0.4513\nEpoch   82 | Train Loss:     0.4196 | Validation Loss:     0.4468\nEpoch   83 | Train Loss:     0.4106 | Validation Loss:     0.4567\nEpoch   84 | Train Loss:     0.4181 | Validation Loss:     0.4540\nEpoch   85 | Train Loss:     0.4104 | Validation Loss:     0.4489\nEpoch   86 | Train Loss:     0.4132 | Validation Loss:     0.4452\nEpoch   87 | Train Loss:     0.4068 | Validation Loss:     0.4384\nEpoch   88 | Train Loss:     0.4058 | Validation Loss:     0.4467\nEpoch   89 | Train Loss:     0.3921 | Validation Loss:     0.3476\nEpoch   90 | Train Loss:     0.2819 | Validation Loss:     0.2687\nEpoch   91 | Train Loss:     0.2304 | Validation Loss:     0.2480\nEpoch   92 | Train Loss:     0.2009 | Validation Loss:     0.2001\nEpoch   93 | Train Loss:     0.1874 | Validation Loss:     0.1902\nEpoch   94 | Train Loss:     0.1657 | Validation Loss:     0.1694\nEpoch   95 | Train Loss:     0.1565 | Validation Loss:     0.1559\nEpoch   96 | Train Loss:     0.1623 | Validation Loss:     0.1627\nEpoch   97 | Train Loss:     0.1451 | Validation Loss:     0.1465\nEpoch   98 | Train Loss:     0.1419 | Validation Loss:     0.1436\nEpoch   99 | Train Loss:     0.1409 | Validation Loss:     0.1453\nEpoch  100 | Train Loss:     0.1393 | Validation Loss:     0.1443\nEpoch  101 | Train Loss:     0.1387 | Validation Loss:     0.1481\nEpoch  102 | Train Loss:     0.1392 | Validation Loss:     0.1431\nEpoch  103 | Train Loss:     0.1365 | Validation Loss:     0.1429\nEpoch  104 | Train Loss:     0.1347 | Validation Loss:     0.1420\nEpoch  105 | Train Loss:     0.1374 | Validation Loss:     0.1392\nEpoch  106 | Train Loss:     0.1376 | Validation Loss:     0.1387\nEpoch  107 | Train Loss:     0.1361 | Validation Loss:     0.1373\nEpoch  108 | Train Loss:     0.1329 | Validation Loss:     0.1377\nEpoch  109 | Train Loss:     0.1370 | Validation Loss:     0.1436\nEpoch  110 | Train Loss:     0.1345 | Validation Loss:     0.1363\nEpoch  111 | Train Loss:     0.1380 | Validation Loss:     0.1412\nEpoch  112 | Train Loss:     0.1342 | Validation Loss:     0.1397\nEpoch  113 | Train Loss:     0.1347 | Validation Loss:     0.1350\nEpoch  114 | Train Loss:     0.1360 | Validation Loss:     0.1575\nEpoch  115 | Train Loss:     0.1350 | Validation Loss:     0.1354\nEpoch  116 | Train Loss:     0.1293 | Validation Loss:     0.1341\nEpoch  117 | Train Loss:     0.1289 | Validation Loss:     0.1365\nEpoch  118 | Train Loss:     0.1294 | Validation Loss:     0.1386\nEpoch  119 | Train Loss:     0.1287 | Validation Loss:     0.1372\nEpoch  120 | Train Loss:     0.1280 | Validation Loss:     0.1434\nEpoch  121 | Train Loss:     0.1292 | Validation Loss:     0.1373\nEpoch  122 | Train Loss:     0.1277 | Validation Loss:     0.1311\nEpoch  123 | Train Loss:     0.1281 | Validation Loss:     0.1309\nEpoch  124 | Train Loss:     0.1272 | Validation Loss:     0.1341\nEpoch  125 | Train Loss:     0.1317 | Validation Loss:     0.1331\nEpoch  126 | Train Loss:     0.1313 | Validation Loss:     0.1322\nEpoch  127 | Train Loss:     0.1269 | Validation Loss:     0.1338\nEpoch  128 | Train Loss:     0.1282 | Validation Loss:     0.1281\nEpoch  129 | Train Loss:     0.1277 | Validation Loss:     0.1286\nEpoch  130 | Train Loss:     0.1286 | Validation Loss:     0.1287\nEpoch  131 | Train Loss:     0.1253 | Validation Loss:     0.1402\nEpoch  132 | Train Loss:     0.1235 | Validation Loss:     0.1277\nEpoch  133 | Train Loss:     0.1234 | Validation Loss:     0.1326\nEpoch  134 | Train Loss:     0.1272 | Validation Loss:     0.1298\nEpoch  135 | Train Loss:     0.1243 | Validation Loss:     0.1271\nEpoch  136 | Train Loss:     0.1263 | Validation Loss:     0.1558\nEpoch  137 | Train Loss:     0.1268 | Validation Loss:     0.1330\nEpoch  138 | Train Loss:     0.1240 | Validation Loss:     0.1315\nEpoch  139 | Train Loss:     0.1285 | Validation Loss:     0.1294\nEpoch  140 | Train Loss:     0.1252 | Validation Loss:     0.1275\nEpoch  141 | Train Loss:     0.1248 | Validation Loss:     0.1273\nEpoch  142 | Train Loss:     0.1230 | Validation Loss:     0.1338\nEpoch  143 | Train Loss:     0.1231 | Validation Loss:     0.1406\nEpoch  144 | Train Loss:     0.1231 | Validation Loss:     0.1246\nEpoch  145 | Train Loss:     0.1293 | Validation Loss:     0.1451\nEpoch  146 | Train Loss:     0.1263 | Validation Loss:     0.1282\nEpoch  147 | Train Loss:     0.1220 | Validation Loss:     0.1242\nEpoch  148 | Train Loss:     0.1199 | Validation Loss:     0.1232\nEpoch  149 | Train Loss:     0.1237 | Validation Loss:     0.1253\nEpoch  150 | Train Loss:     0.1272 | Validation Loss:     0.1345\nEpoch  151 | Train Loss:     0.1262 | Validation Loss:     0.1249\nEpoch  152 | Train Loss:     0.1188 | Validation Loss:     0.1314\nEpoch  153 | Train Loss:     0.1202 | Validation Loss:     0.1241\nEpoch  154 | Train Loss:     0.1197 | Validation Loss:     0.1235\nEpoch  155 | Train Loss:     0.1217 | Validation Loss:     0.1229\nEpoch  156 | Train Loss:     0.1190 | Validation Loss:     0.1215\nEpoch  157 | Train Loss:     0.1203 | Validation Loss:     0.1246\nEpoch  158 | Train Loss:     0.1218 | Validation Loss:     0.1285\nEpoch  159 | Train Loss:     0.1214 | Validation Loss:     0.1259\nEpoch  160 | Train Loss:     0.1218 | Validation Loss:     0.1234\nEpoch  161 | Train Loss:     0.1183 | Validation Loss:     0.1218\nEpoch  162 | Train Loss:     0.1207 | Validation Loss:     0.1229\nEpoch  163 | Train Loss:     0.1207 | Validation Loss:     0.1249\nEpoch  164 | Train Loss:     0.1186 | Validation Loss:     0.1258\nEpoch  165 | Train Loss:     0.1197 | Validation Loss:     0.1335\nEpoch  166 | Train Loss:     0.1238 | Validation Loss:     0.1266\nEpoch  167 | Train Loss:     0.1185 | Validation Loss:     0.1247\nEpoch  168 | Train Loss:     0.1183 | Validation Loss:     0.1202\nEpoch  169 | Train Loss:     0.1231 | Validation Loss:     0.1281\nEpoch  170 | Train Loss:     0.1189 | Validation Loss:     0.1268\nEpoch  171 | Train Loss:     0.1185 | Validation Loss:     0.1213\nEpoch  172 | Train Loss:     0.1179 | Validation Loss:     0.1214\nEpoch  173 | Train Loss:     0.1176 | Validation Loss:     0.1287\nEpoch  174 | Train Loss:     0.1198 | Validation Loss:     0.1227\nEpoch  175 | Train Loss:     0.1165 | Validation Loss:     0.1196\nEpoch  176 | Train Loss:     0.1170 | Validation Loss:     0.1357\nEpoch  177 | Train Loss:     0.1203 | Validation Loss:     0.1206\nEpoch  178 | Train Loss:     0.1189 | Validation Loss:     0.1279\nEpoch  179 | Train Loss:     0.1187 | Validation Loss:     0.1201\nEpoch  180 | Train Loss:     0.1170 | Validation Loss:     0.1262\nEpoch  181 | Train Loss:     0.1168 | Validation Loss:     0.1199\nEpoch  182 | Train Loss:     0.1199 | Validation Loss:     0.1262\nEpoch  183 | Train Loss:     0.1280 | Validation Loss:     0.1204\nEpoch  184 | Train Loss:     0.1194 | Validation Loss:     0.1209\nEpoch  185 | Train Loss:     0.1169 | Validation Loss:     0.1223\nEpoch  186 | Train Loss:     0.1177 | Validation Loss:     0.1190\nEpoch  187 | Train Loss:     0.1158 | Validation Loss:     0.1191\nEpoch  188 | Train Loss:     0.1166 | Validation Loss:     0.1205\nEpoch  189 | Train Loss:     0.1191 | Validation Loss:     0.1199\nEpoch  190 | Train Loss:     0.1198 | Validation Loss:     0.1318\nEpoch  191 | Train Loss:     0.1181 | Validation Loss:     0.1209\nEpoch  192 | Train Loss:     0.1174 | Validation Loss:     0.1199\nEpoch  193 | Train Loss:     0.1160 | Validation Loss:     0.1213\nEpoch  194 | Train Loss:     0.1184 | Validation Loss:     0.1243\nEpoch  195 | Train Loss:     0.1203 | Validation Loss:     0.1244\nEpoch  196 | Train Loss:     0.1191 | Validation Loss:     0.1218\nEpoch  197 | Train Loss:     0.1157 | Validation Loss:     0.1195\nEpoch  198 | Train Loss:     0.1241 | Validation Loss:     0.1318\nEpoch  199 | Train Loss:     0.1175 | Validation Loss:     0.1220\nEpoch  200 | Train Loss:     0.1162 | Validation Loss:     0.1210\nEpoch  201 | Train Loss:     0.1209 | Validation Loss:     0.1188\nEpoch  202 | Train Loss:     0.1179 | Validation Loss:     0.1184\nEpoch  203 | Train Loss:     0.1172 | Validation Loss:     0.1221\nEpoch  204 | Train Loss:     0.1152 | Validation Loss:     0.1236\nEpoch  205 | Train Loss:     0.1228 | Validation Loss:     0.1203\nEpoch  206 | Train Loss:     0.1203 | Validation Loss:     0.1526\nEpoch  207 | Train Loss:     0.1209 | Validation Loss:     0.1264\nEpoch  208 | Train Loss:     0.1154 | Validation Loss:     0.1349\nEpoch  209 | Train Loss:     0.1169 | Validation Loss:     0.1185\nEpoch  210 | Train Loss:     0.1161 | Validation Loss:     0.1260\nEpoch  211 | Train Loss:     0.1195 | Validation Loss:     0.1199\nEpoch  212 | Train Loss:     0.1168 | Validation Loss:     0.1206\nEpoch  213 | Train Loss:     0.1159 | Validation Loss:     0.1219\nEpoch  214 | Train Loss:     0.1175 | Validation Loss:     0.1268\nEpoch  215 | Train Loss:     0.1152 | Validation Loss:     0.1251\nEpoch  216 | Train Loss:     0.1143 | Validation Loss:     0.1280\nEpoch  217 | Train Loss:     0.1161 | Validation Loss:     0.1195\nEpoch  218 | Train Loss:     0.1169 | Validation Loss:     0.1254\nEpoch  219 | Train Loss:     0.1173 | Validation Loss:     0.1190\nEpoch  220 | Train Loss:     0.1203 | Validation Loss:     0.1186\nEpoch  221 | Train Loss:     0.1198 | Validation Loss:     0.1205\nEpoch  222 | Train Loss:     0.1184 | Validation Loss:     0.1183\nEpoch  223 | Train Loss:     0.1163 | Validation Loss:     0.1225\nEpoch  224 | Train Loss:     0.1161 | Validation Loss:     0.1185\nEpoch  225 | Train Loss:     0.1152 | Validation Loss:     0.1215\nEpoch  226 | Train Loss:     0.1189 | Validation Loss:     0.1378\nEpoch  227 | Train Loss:     0.1198 | Validation Loss:     0.1236\nEpoch  228 | Train Loss:     0.1157 | Validation Loss:     0.1279\nEpoch  229 | Train Loss:     0.1160 | Validation Loss:     0.1204\nEpoch  230 | Train Loss:     0.1168 | Validation Loss:     0.1263\nEpoch  231 | Train Loss:     0.1182 | Validation Loss:     0.1182\nEpoch  232 | Train Loss:     0.1157 | Validation Loss:     0.1181\nEpoch  233 | Train Loss:     0.1151 | Validation Loss:     0.1183\nEpoch  234 | Train Loss:     0.1159 | Validation Loss:     0.1262\nEpoch  235 | Train Loss:     0.1166 | Validation Loss:     0.1206\nEpoch  236 | Train Loss:     0.1155 | Validation Loss:     0.1194\nEpoch  237 | Train Loss:     0.1163 | Validation Loss:     0.1238\nEpoch  238 | Train Loss:     0.1166 | Validation Loss:     0.1189\nEpoch  239 | Train Loss:     0.1166 | Validation Loss:     0.1192\nEpoch  240 | Train Loss:     0.1179 | Validation Loss:     0.1204\nEpoch  241 | Train Loss:     0.1186 | Validation Loss:     0.1262\nEpoch  242 | Train Loss:     0.1167 | Validation Loss:     0.1226\nEpoch  243 | Train Loss:     0.1145 | Validation Loss:     0.1203\nEpoch  244 | Train Loss:     0.1166 | Validation Loss:     0.1410\nEpoch  245 | Train Loss:     0.1216 | Validation Loss:     0.1212\nEpoch  246 | Train Loss:     0.1164 | Validation Loss:     0.1212\nEpoch  247 | Train Loss:     0.1151 | Validation Loss:     0.1172\nEpoch  248 | Train Loss:     0.1156 | Validation Loss:     0.1226\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[355], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[167], line 87\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     85\u001b[0m parameters \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[0;32m---> 87\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     89\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n\u001b[1;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:934\u001b[0m, in \u001b[0;36mTensor.__format__\u001b[0;34m(self, format_spec)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_meta \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;129;01mis\u001b[39;00m Tensor:\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitem()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__format__\u001b[39m(format_spec)\n\u001b[0;32m--> 934\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mobject\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__format__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformat_spec\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/parameter.py:63\u001b[0m, in \u001b[0;36mParameter.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 63\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mParameter containing:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__repr__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:431\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    428\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__repr__\u001b[39m, (\u001b[38;5;28mself\u001b[39m,), \u001b[38;5;28mself\u001b[39m, tensor_contents\u001b[38;5;241m=\u001b[39mtensor_contents\n\u001b[1;32m    429\u001b[0m     )\n\u001b[1;32m    430\u001b[0m \u001b[38;5;66;03m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[0;32m--> 431\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tensor_str\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:664\u001b[0m, in \u001b[0;36m_str\u001b[0;34m(self, tensor_contents)\u001b[0m\n\u001b[1;32m    662\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad(), torch\u001b[38;5;241m.\u001b[39mutils\u001b[38;5;241m.\u001b[39m_python_dispatch\u001b[38;5;241m.\u001b[39m_disable_current_modes():\n\u001b[1;32m    663\u001b[0m     guard \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_C\u001b[38;5;241m.\u001b[39m_DisableFuncTorch()\n\u001b[0;32m--> 664\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_str_intern\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor_contents\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_contents\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:595\u001b[0m, in \u001b[0;36m_str_intern\u001b[0;34m(inp, tensor_contents)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m _tensor_str(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_dense(), indent)\n\u001b[1;32m    594\u001b[0m                 \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 595\u001b[0m                     tensor_str \u001b[38;5;241m=\u001b[39m \u001b[43m_tensor_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m!=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstrided:\n\u001b[1;32m    598\u001b[0m     suffixes\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlayout=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mstr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayout))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:348\u001b[0m, in \u001b[0;36m_tensor_str\u001b[0;34m(self, indent)\u001b[0m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    347\u001b[0m     formatter \u001b[38;5;241m=\u001b[39m _Formatter(get_summarized_data(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m--> 348\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_tensor_str_with_formatter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:291\u001b[0m, in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    275\u001b[0m     slices \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m         [\n\u001b[1;32m    277\u001b[0m             _tensor_str_with_formatter(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         ]\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 291\u001b[0m     slices \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    292\u001b[0m         _tensor_str_with_formatter(\n\u001b[1;32m    293\u001b[0m             \u001b[38;5;28mself\u001b[39m[i], indent \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m, summarize, formatter1, formatter2\n\u001b[1;32m    294\u001b[0m         )\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    296\u001b[0m     ]\n\u001b[1;32m    298\u001b[0m tensor_str \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m (dim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m (indent \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(slices)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m tensor_str \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:292\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    275\u001b[0m     slices \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m         [\n\u001b[1;32m    277\u001b[0m             _tensor_str_with_formatter(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         ]\n\u001b[1;32m    289\u001b[0m     )\n\u001b[1;32m    290\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    291\u001b[0m     slices \u001b[38;5;241m=\u001b[39m [\n\u001b[0;32m--> 292\u001b[0m         \u001b[43m_tensor_str_with_formatter\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter2\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    295\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m))\n\u001b[1;32m    296\u001b[0m     ]\n\u001b[1;32m    298\u001b[0m tensor_str \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m (dim \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m (indent \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m))\u001b[38;5;241m.\u001b[39mjoin(slices)\n\u001b[1;32m    299\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m[\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m tensor_str \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:272\u001b[0m, in \u001b[0;36m_tensor_str_with_formatter\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _scalar_str(\u001b[38;5;28mself\u001b[39m, formatter1, formatter2)\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_vector_str\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindent\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msummarize\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mformatter2\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m summarize \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m0\u001b[39m) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m2\u001b[39m \u001b[38;5;241m*\u001b[39m PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems:\n\u001b[1;32m    275\u001b[0m     slices \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    276\u001b[0m         [\n\u001b[1;32m    277\u001b[0m             _tensor_str_with_formatter(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    288\u001b[0m         ]\n\u001b[1;32m    289\u001b[0m     )\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor_str.py:253\u001b[0m, in \u001b[0;36m_vector_str\u001b[0;34m(self, indent, summarize, formatter1, formatter2)\u001b[0m\n\u001b[1;32m    247\u001b[0m     data \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    248\u001b[0m         [_val_formatter(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m[: PRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems]\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[1;32m    249\u001b[0m         \u001b[38;5;241m+\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m ...\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    250\u001b[0m         \u001b[38;5;241m+\u001b[39m [_val_formatter(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m[\u001b[38;5;241m-\u001b[39mPRINT_OPTS\u001b[38;5;241m.\u001b[39medgeitems :]\u001b[38;5;241m.\u001b[39mtolist()]\n\u001b[1;32m    251\u001b[0m     )\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 253\u001b[0m     data \u001b[38;5;241m=\u001b[39m [_val_formatter(val) \u001b[38;5;28;01mfor\u001b[39;00m val \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtolist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n\u001b[1;32m    255\u001b[0m data_lines \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    256\u001b[0m     data[i : i \u001b[38;5;241m+\u001b[39m elements_per_line] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(data), elements_per_line)\n\u001b[1;32m    257\u001b[0m ]\n\u001b[1;32m    258\u001b[0m lines \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(line) \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m data_lines]\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=0.000001 * 10)\noptimizer = optim.Adam(model.parameters(), lr=0.0000001 * 100000)\nevaluate_model(model, custom_train_loader, criterion, optimizer)","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:48:52.142111Z","iopub.execute_input":"2024-06-16T20:48:52.142750Z","iopub.status.idle":"2024-06-16T20:49:32.347324Z","shell.execute_reply.started":"2024-06-16T20:48:52.142719Z","shell.execute_reply":"2024-06-16T20:49:32.345977Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":340,"outputs":[{"name":"stdout","text":"Epoch    1 | Train Loss:     1.5879 | Validation Loss:     1.4885\nEpoch    2 | Train Loss:     1.4482 | Validation Loss:     1.4438\nEpoch    3 | Train Loss:     1.4339 | Validation Loss:     1.4399\nEpoch    4 | Train Loss:     1.4330 | Validation Loss:     1.4361\nEpoch    5 | Train Loss:     1.4285 | Validation Loss:     1.4356\nEpoch    6 | Train Loss:     1.4252 | Validation Loss:     1.4321\nEpoch    7 | Train Loss:     1.4238 | Validation Loss:     1.4293\nEpoch    8 | Train Loss:     1.4215 | Validation Loss:     1.4285\nEpoch    9 | Train Loss:     1.4184 | Validation Loss:     1.4270\nEpoch   10 | Train Loss:     1.4168 | Validation Loss:     1.4275\nEpoch   11 | Train Loss:     1.4152 | Validation Loss:     1.4228\nEpoch   12 | Train Loss:     1.4131 | Validation Loss:     1.4212\nEpoch   13 | Train Loss:     1.4114 | Validation Loss:     1.4192\nEpoch   14 | Train Loss:     1.4088 | Validation Loss:     1.4172\nEpoch   15 | Train Loss:     1.4065 | Validation Loss:     1.4167\nEpoch   16 | Train Loss:     1.4045 | Validation Loss:     1.4146\nEpoch   17 | Train Loss:     1.4030 | Validation Loss:     1.4112\nEpoch   18 | Train Loss:     1.3990 | Validation Loss:     1.4083\nEpoch   19 | Train Loss:     1.3964 | Validation Loss:     1.4075\nEpoch   20 | Train Loss:     1.3946 | Validation Loss:     1.4045\nEpoch   21 | Train Loss:     1.3898 | Validation Loss:     1.4039\nEpoch   22 | Train Loss:     1.3878 | Validation Loss:     1.3993\nEpoch   23 | Train Loss:     1.3839 | Validation Loss:     1.3958\nEpoch   24 | Train Loss:     1.3814 | Validation Loss:     1.3917\nEpoch   25 | Train Loss:     1.3784 | Validation Loss:     1.3890\nEpoch   26 | Train Loss:     1.3752 | Validation Loss:     1.3871\nEpoch   27 | Train Loss:     1.3727 | Validation Loss:     1.3849\nEpoch   28 | Train Loss:     1.3707 | Validation Loss:     1.3811\nEpoch   29 | Train Loss:     1.3674 | Validation Loss:     1.3844\nEpoch   30 | Train Loss:     1.3679 | Validation Loss:     1.3780\nEpoch   31 | Train Loss:     1.3631 | Validation Loss:     1.3806\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[340], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\n","Cell \u001b[0;32mIn[167], line 89\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, param \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_parameters():\n\u001b[1;32m     87\u001b[0m     parameters\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mparam\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 89\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n\u001b[1;32m     92\u001b[0m running_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mitem()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/_tensor.py:492\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    482\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    483\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    484\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    485\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    490\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    491\u001b[0m     )\n\u001b[0;32m--> 492\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    493\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    494\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/autograd/__init__.py:251\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    248\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    250\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 251\u001b[0m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    252\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    256\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    257\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    258\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    259\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=0.000001 * 10)\noptimizer = optim.Adam(model.parameters(), lr=0.0000001 * 1000)\nevaluate_model(model, custom_train_loader, criterion, optimizer)    ","metadata":{"execution":{"iopub.status.busy":"2024-06-16T20:15:31.220807Z","iopub.execute_input":"2024-06-16T20:15:31.221462Z","iopub.status.idle":"2024-06-16T20:16:37.962568Z","shell.execute_reply.started":"2024-06-16T20:15:31.221427Z","shell.execute_reply":"2024-06-16T20:16:37.960933Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":223,"outputs":[{"name":"stdout","text":"Epoch    1 | Train Loss:     1.6880 | Validation Loss:     1.6430\nEpoch    2 | Train Loss:     1.6092 | Validation Loss:     1.5791\nEpoch    3 | Train Loss:     1.5522 | Validation Loss:     1.5328\nEpoch    4 | Train Loss:     1.5114 | Validation Loss:     1.4995\nEpoch    5 | Train Loss:     1.4826 | Validation Loss:     1.4762\nEpoch    6 | Train Loss:     1.4624 | Validation Loss:     1.4604\nEpoch    7 | Train Loss:     1.4485 | Validation Loss:     1.4501\nEpoch    8 | Train Loss:     1.4393 | Validation Loss:     1.4432\nEpoch    9 | Train Loss:     1.4333 | Validation Loss:     1.4388\nEpoch   10 | Train Loss:     1.4293 | Validation Loss:     1.4360\nEpoch   11 | Train Loss:     1.4266 | Validation Loss:     1.4339\nEpoch   12 | Train Loss:     1.4248 | Validation Loss:     1.4326\nEpoch   13 | Train Loss:     1.4233 | Validation Loss:     1.4315\nEpoch   14 | Train Loss:     1.4222 | Validation Loss:     1.4308\nEpoch   15 | Train Loss:     1.4214 | Validation Loss:     1.4300\nEpoch   16 | Train Loss:     1.4206 | Validation Loss:     1.4293\nEpoch   17 | Train Loss:     1.4198 | Validation Loss:     1.4288\nEpoch   18 | Train Loss:     1.4192 | Validation Loss:     1.4282\nEpoch   19 | Train Loss:     1.4187 | Validation Loss:     1.4277\nEpoch   20 | Train Loss:     1.4181 | Validation Loss:     1.4272\nEpoch   21 | Train Loss:     1.4175 | Validation Loss:     1.4268\nEpoch   22 | Train Loss:     1.4171 | Validation Loss:     1.4264\nEpoch   23 | Train Loss:     1.4166 | Validation Loss:     1.4259\nEpoch   24 | Train Loss:     1.4162 | Validation Loss:     1.4256\nEpoch   25 | Train Loss:     1.4157 | Validation Loss:     1.4252\nEpoch   26 | Train Loss:     1.4153 | Validation Loss:     1.4248\nEpoch   27 | Train Loss:     1.4150 | Validation Loss:     1.4244\nEpoch   28 | Train Loss:     1.4145 | Validation Loss:     1.4241\nEpoch   29 | Train Loss:     1.4141 | Validation Loss:     1.4238\nEpoch   30 | Train Loss:     1.4139 | Validation Loss:     1.4235\nEpoch   31 | Train Loss:     1.4135 | Validation Loss:     1.4231\nEpoch   32 | Train Loss:     1.4130 | Validation Loss:     1.4229\nEpoch   33 | Train Loss:     1.4127 | Validation Loss:     1.4226\nEpoch   34 | Train Loss:     1.4124 | Validation Loss:     1.4223\nEpoch   35 | Train Loss:     1.4121 | Validation Loss:     1.4221\nEpoch   36 | Train Loss:     1.4118 | Validation Loss:     1.4219\nEpoch   37 | Train Loss:     1.4114 | Validation Loss:     1.4214\nEpoch   38 | Train Loss:     1.4110 | Validation Loss:     1.4211\nEpoch   39 | Train Loss:     1.4108 | Validation Loss:     1.4209\nEpoch   40 | Train Loss:     1.4104 | Validation Loss:     1.4206\nEpoch   41 | Train Loss:     1.4101 | Validation Loss:     1.4204\nEpoch   42 | Train Loss:     1.4099 | Validation Loss:     1.4201\nEpoch   43 | Train Loss:     1.4096 | Validation Loss:     1.4197\nEpoch   44 | Train Loss:     1.4093 | Validation Loss:     1.4196\nEpoch   45 | Train Loss:     1.4091 | Validation Loss:     1.4196\nEpoch   46 | Train Loss:     1.4087 | Validation Loss:     1.4192\nEpoch   47 | Train Loss:     1.4085 | Validation Loss:     1.4190\nEpoch   48 | Train Loss:     1.4083 | Validation Loss:     1.4186\nEpoch   49 | Train Loss:     1.4078 | Validation Loss:     1.4184\nEpoch   50 | Train Loss:     1.4076 | Validation Loss:     1.4183\nEpoch   51 | Train Loss:     1.4073 | Validation Loss:     1.4179\nEpoch   52 | Train Loss:     1.4069 | Validation Loss:     1.4176\nEpoch   53 | Train Loss:     1.4067 | Validation Loss:     1.4175\nEpoch   54 | Train Loss:     1.4064 | Validation Loss:     1.4173\nEpoch   55 | Train Loss:     1.4062 | Validation Loss:     1.4170\nEpoch   56 | Train Loss:     1.4059 | Validation Loss:     1.4168\nEpoch   57 | Train Loss:     1.4055 | Validation Loss:     1.4166\nEpoch   58 | Train Loss:     1.4052 | Validation Loss:     1.4162\nEpoch   59 | Train Loss:     1.4050 | Validation Loss:     1.4161\nEpoch   60 | Train Loss:     1.4047 | Validation Loss:     1.4158\nEpoch   61 | Train Loss:     1.4044 | Validation Loss:     1.4156\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[223], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.0000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m    \n","Cell \u001b[0;32mIn[167], line 143\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m    141\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m    142\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 143\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimage_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/epoch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m04d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    146\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3374\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3375\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3376\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:457\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    459\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:400\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m RendererAgg\u001b[38;5;241m.\u001b[39mlock, \\\n\u001b[1;32m    398\u001b[0m      (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    399\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/figure.py:3175\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3175\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[1;32m   3179\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:3064\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3062\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3064\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3067\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/collections.py:972\u001b[0m, in \u001b[0;36m_CollectionWithSizes.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    969\u001b[0m \u001b[38;5;129m@artist\u001b[39m\u001b[38;5;241m.\u001b[39mallow_rasterization\n\u001b[1;32m    970\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw\u001b[39m(\u001b[38;5;28mself\u001b[39m, renderer):\n\u001b[1;32m    971\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_sizes(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sizes, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi)\n\u001b[0;32m--> 972\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/collections.py:388\u001b[0m, in \u001b[0;36mCollection.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    386\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    387\u001b[0m     combined_transform \u001b[38;5;241m=\u001b[39m transform\n\u001b[0;32m--> 388\u001b[0m extents \u001b[38;5;241m=\u001b[39m \u001b[43mpaths\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_extents\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcombined_transform\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    389\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (extents\u001b[38;5;241m.\u001b[39mwidth \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mbbox\u001b[38;5;241m.\u001b[39mwidth\n\u001b[1;32m    390\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m extents\u001b[38;5;241m.\u001b[39mheight \u001b[38;5;241m<\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mbbox\u001b[38;5;241m.\u001b[39mheight):\n\u001b[1;32m    391\u001b[0m     do_single_path_optimization \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/path.py:635\u001b[0m, in \u001b[0;36mPath.get_extents\u001b[0;34m(self, transform, **kwargs)\u001b[0m\n\u001b[1;32m    632\u001b[0m xys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m curve, code \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39miter_bezier(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    634\u001b[0m     \u001b[38;5;66;03m# places where the derivative is zero can be extrema\u001b[39;00m\n\u001b[0;32m--> 635\u001b[0m     _, dzeros \u001b[38;5;241m=\u001b[39m \u001b[43mcurve\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maxis_aligned_extrema\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    636\u001b[0m     \u001b[38;5;66;03m# as can the ends of the curve\u001b[39;00m\n\u001b[1;32m    637\u001b[0m     xys\u001b[38;5;241m.\u001b[39mappend(curve([\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m*\u001b[39mdzeros, \u001b[38;5;241m1\u001b[39m]))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/bezier.py:299\u001b[0m, in \u001b[0;36mBezierSegment.axis_aligned_extrema\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    297\u001b[0m roots \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    298\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, pi \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(dCj\u001b[38;5;241m.\u001b[39mT):\n\u001b[0;32m--> 299\u001b[0m     r \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mroots\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpi\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    300\u001b[0m     roots\u001b[38;5;241m.\u001b[39mappend(r)\n\u001b[1;32m    301\u001b[0m     dims\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39mfull_like(r, i))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/numpy/lib/polynomial.py:253\u001b[0m, in \u001b[0;36mroots\u001b[0;34m(p)\u001b[0m\n\u001b[1;32m    250\u001b[0m N \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(p)\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m N \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    252\u001b[0m     \u001b[38;5;66;03m# build companion matrix and find its eigenvalues (the roots)\u001b[39;00m\n\u001b[0;32m--> 253\u001b[0m     A \u001b[38;5;241m=\u001b[39m \u001b[43mdiag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNX\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mones\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    254\u001b[0m     A[\u001b[38;5;241m0\u001b[39m,:] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39mp[\u001b[38;5;241m1\u001b[39m:] \u001b[38;5;241m/\u001b[39m p[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    255\u001b[0m     roots \u001b[38;5;241m=\u001b[39m eigvals(A)\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"optimizer = optim.SGD(model.parameters(), lr=0.000001 * 10)\noptimizer = optim.Adam(model.parameters(), lr=0.000001 * 1000)\nevaluate_model(model, custom_train_loader, criterion, optimizer)    ","metadata":{"execution":{"iopub.status.busy":"2024-06-16T19:27:21.015186Z","iopub.execute_input":"2024-06-16T19:27:21.015579Z","iopub.status.idle":"2024-06-16T19:29:58.788104Z","shell.execute_reply.started":"2024-06-16T19:27:21.015550Z","shell.execute_reply":"2024-06-16T19:29:58.786671Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":146,"outputs":[{"name":"stdout","text":"Epoch    1 | Train Loss:     1.5817 | Validation Loss:     1.4873\nEpoch    2 | Train Loss:     1.5195 | Validation Loss:     1.4502\nEpoch    3 | Train Loss:     1.4935 | Validation Loss:     1.4238\nEpoch    4 | Train Loss:     1.4716 | Validation Loss:     1.4002\nEpoch    5 | Train Loss:     1.4519 | Validation Loss:     1.3794\nEpoch    6 | Train Loss:     1.4362 | Validation Loss:     1.3625\nEpoch    7 | Train Loss:     1.4233 | Validation Loss:     1.3490\nEpoch    8 | Train Loss:     1.4111 | Validation Loss:     1.3339\nEpoch    9 | Train Loss:     1.3990 | Validation Loss:     1.3222\nEpoch   10 | Train Loss:     1.3869 | Validation Loss:     1.3095\nEpoch   11 | Train Loss:     1.3750 | Validation Loss:     1.2967\nEpoch   12 | Train Loss:     1.3628 | Validation Loss:     1.2844\nEpoch   13 | Train Loss:     1.3487 | Validation Loss:     1.2665\nEpoch   14 | Train Loss:     1.3332 | Validation Loss:     1.2500\nEpoch   15 | Train Loss:     1.3155 | Validation Loss:     1.2346\nEpoch   16 | Train Loss:     1.2979 | Validation Loss:     1.2156\nEpoch   17 | Train Loss:     1.2782 | Validation Loss:     1.1973\nEpoch   18 | Train Loss:     1.2584 | Validation Loss:     1.1785\nEpoch   19 | Train Loss:     1.2380 | Validation Loss:     1.1597\nEpoch   20 | Train Loss:     1.2167 | Validation Loss:     1.1417\nEpoch   21 | Train Loss:     1.1975 | Validation Loss:     1.1258\nEpoch   22 | Train Loss:     1.1778 | Validation Loss:     1.1068\nEpoch   23 | Train Loss:     1.1586 | Validation Loss:     1.0908\nEpoch   24 | Train Loss:     1.1407 | Validation Loss:     1.0759\nEpoch   25 | Train Loss:     1.1237 | Validation Loss:     1.0609\nEpoch   26 | Train Loss:     1.1069 | Validation Loss:     1.0470\nEpoch   27 | Train Loss:     1.0912 | Validation Loss:     1.0330\nEpoch   28 | Train Loss:     1.0758 | Validation Loss:     1.0197\nEpoch   29 | Train Loss:     1.0613 | Validation Loss:     1.0080\nEpoch   30 | Train Loss:     1.0472 | Validation Loss:     0.9955\nEpoch   31 | Train Loss:     1.0332 | Validation Loss:     0.9830\nEpoch   32 | Train Loss:     1.0197 | Validation Loss:     0.9702\nEpoch   33 | Train Loss:     1.0065 | Validation Loss:     0.9586\nEpoch   34 | Train Loss:     0.9945 | Validation Loss:     0.9482\nEpoch   35 | Train Loss:     0.9823 | Validation Loss:     0.9378\nEpoch   36 | Train Loss:     0.9703 | Validation Loss:     0.9271\nEpoch   37 | Train Loss:     0.9585 | Validation Loss:     0.9164\nEpoch   38 | Train Loss:     0.9485 | Validation Loss:     0.9128\nEpoch   39 | Train Loss:     0.9377 | Validation Loss:     0.8982\nEpoch   40 | Train Loss:     0.9277 | Validation Loss:     0.8921\nEpoch   41 | Train Loss:     0.9189 | Validation Loss:     0.8820\nEpoch   42 | Train Loss:     0.9101 | Validation Loss:     0.8747\nEpoch   43 | Train Loss:     0.9030 | Validation Loss:     0.8676\nEpoch   44 | Train Loss:     0.8964 | Validation Loss:     0.8604\nEpoch   45 | Train Loss:     0.8902 | Validation Loss:     0.8550\nEpoch   46 | Train Loss:     0.8848 | Validation Loss:     0.8515\nEpoch   47 | Train Loss:     0.8801 | Validation Loss:     0.8462\nEpoch   48 | Train Loss:     0.8747 | Validation Loss:     0.8422\nEpoch   49 | Train Loss:     0.8697 | Validation Loss:     0.8387\nEpoch   50 | Train Loss:     0.8658 | Validation Loss:     0.8344\nEpoch   51 | Train Loss:     0.8627 | Validation Loss:     0.8308\nEpoch   52 | Train Loss:     0.8582 | Validation Loss:     0.8277\nEpoch   53 | Train Loss:     0.8547 | Validation Loss:     0.8255\nEpoch   54 | Train Loss:     0.8511 | Validation Loss:     0.8218\nEpoch   55 | Train Loss:     0.8487 | Validation Loss:     0.8231\nEpoch   56 | Train Loss:     0.8458 | Validation Loss:     0.8165\nEpoch   57 | Train Loss:     0.8424 | Validation Loss:     0.8168\nEpoch   58 | Train Loss:     0.8392 | Validation Loss:     0.8121\nEpoch   59 | Train Loss:     0.8364 | Validation Loss:     0.8100\nEpoch   60 | Train Loss:     0.8338 | Validation Loss:     0.8086\nEpoch   61 | Train Loss:     0.8316 | Validation Loss:     0.8047\nEpoch   62 | Train Loss:     0.8286 | Validation Loss:     0.8025\nEpoch   63 | Train Loss:     0.8259 | Validation Loss:     0.8072\nEpoch   64 | Train Loss:     0.8238 | Validation Loss:     0.7991\nEpoch   65 | Train Loss:     0.8220 | Validation Loss:     0.7982\nEpoch   66 | Train Loss:     0.8195 | Validation Loss:     0.7958\nEpoch   67 | Train Loss:     0.8175 | Validation Loss:     0.7995\nEpoch   68 | Train Loss:     0.8157 | Validation Loss:     0.7924\nEpoch   69 | Train Loss:     0.8140 | Validation Loss:     0.7920\nEpoch   70 | Train Loss:     0.8118 | Validation Loss:     0.7892\nEpoch   71 | Train Loss:     0.8094 | Validation Loss:     0.7877\nEpoch   72 | Train Loss:     0.8082 | Validation Loss:     0.7905\nEpoch   73 | Train Loss:     0.8071 | Validation Loss:     0.7860\nEpoch   74 | Train Loss:     0.8054 | Validation Loss:     0.7858\nEpoch   75 | Train Loss:     0.8030 | Validation Loss:     0.7832\nEpoch   76 | Train Loss:     0.8020 | Validation Loss:     0.7848\nEpoch   77 | Train Loss:     0.8006 | Validation Loss:     0.7803\nEpoch   78 | Train Loss:     0.7993 | Validation Loss:     0.7792\nEpoch   79 | Train Loss:     0.7975 | Validation Loss:     0.7797\nEpoch   80 | Train Loss:     0.7967 | Validation Loss:     0.7775\nEpoch   81 | Train Loss:     0.7955 | Validation Loss:     0.7762\nEpoch   82 | Train Loss:     0.7941 | Validation Loss:     0.7784\nEpoch   83 | Train Loss:     0.7934 | Validation Loss:     0.7769\nEpoch   84 | Train Loss:     0.7924 | Validation Loss:     0.7739\nEpoch   85 | Train Loss:     0.7910 | Validation Loss:     0.7733\nEpoch   86 | Train Loss:     0.7892 | Validation Loss:     0.7719\nEpoch   87 | Train Loss:     0.7880 | Validation Loss:     0.7717\nEpoch   88 | Train Loss:     0.7872 | Validation Loss:     0.7711\nEpoch   89 | Train Loss:     0.7874 | Validation Loss:     0.7707\nEpoch   90 | Train Loss:     0.7851 | Validation Loss:     0.7698\nEpoch   91 | Train Loss:     0.7844 | Validation Loss:     0.7680\nEpoch   92 | Train Loss:     0.7835 | Validation Loss:     0.7693\nEpoch   93 | Train Loss:     0.7824 | Validation Loss:     0.7667\nEpoch   94 | Train Loss:     0.7828 | Validation Loss:     0.7671\nEpoch   95 | Train Loss:     0.7815 | Validation Loss:     0.7659\nEpoch   96 | Train Loss:     0.7804 | Validation Loss:     0.7647\nEpoch   97 | Train Loss:     0.7796 | Validation Loss:     0.7644\nEpoch   98 | Train Loss:     0.7788 | Validation Loss:     0.7653\nEpoch   99 | Train Loss:     0.7775 | Validation Loss:     0.7629\nEpoch  100 | Train Loss:     0.7783 | Validation Loss:     0.7631\nEpoch  101 | Train Loss:     0.7768 | Validation Loss:     0.7677\nEpoch  102 | Train Loss:     0.7759 | Validation Loss:     0.7613\nEpoch  103 | Train Loss:     0.7752 | Validation Loss:     0.7642\nEpoch  104 | Train Loss:     0.7743 | Validation Loss:     0.7620\nEpoch  105 | Train Loss:     0.7746 | Validation Loss:     0.7608\nEpoch  106 | Train Loss:     0.7740 | Validation Loss:     0.7596\nEpoch  107 | Train Loss:     0.7734 | Validation Loss:     0.7592\nEpoch  108 | Train Loss:     0.7722 | Validation Loss:     0.7632\nEpoch  109 | Train Loss:     0.7720 | Validation Loss:     0.7603\nEpoch  110 | Train Loss:     0.7717 | Validation Loss:     0.7581\nEpoch  111 | Train Loss:     0.7706 | Validation Loss:     0.7598\nEpoch  112 | Train Loss:     0.7704 | Validation Loss:     0.7592\nEpoch  113 | Train Loss:     0.7698 | Validation Loss:     0.7583\nEpoch  114 | Train Loss:     0.7696 | Validation Loss:     0.7602\nEpoch  115 | Train Loss:     0.7693 | Validation Loss:     0.7573\nEpoch  116 | Train Loss:     0.7685 | Validation Loss:     0.7581\nEpoch  117 | Train Loss:     0.7680 | Validation Loss:     0.7615\nEpoch  118 | Train Loss:     0.7678 | Validation Loss:     0.7612\nEpoch  119 | Train Loss:     0.7680 | Validation Loss:     0.7552\nEpoch  120 | Train Loss:     0.7666 | Validation Loss:     0.7557\nEpoch  121 | Train Loss:     0.7665 | Validation Loss:     0.7553\nEpoch  122 | Train Loss:     0.7669 | Validation Loss:     0.7575\nEpoch  123 | Train Loss:     0.7661 | Validation Loss:     0.7570\nEpoch  124 | Train Loss:     0.7648 | Validation Loss:     0.7545\nEpoch  125 | Train Loss:     0.7649 | Validation Loss:     0.7554\nEpoch  126 | Train Loss:     0.7655 | Validation Loss:     0.7539\nEpoch  127 | Train Loss:     0.7647 | Validation Loss:     0.7544\nEpoch  128 | Train Loss:     0.7639 | Validation Loss:     0.7536\nEpoch  129 | Train Loss:     0.7642 | Validation Loss:     0.7557\nEpoch  130 | Train Loss:     0.7637 | Validation Loss:     0.7543\nEpoch  131 | Train Loss:     0.7633 | Validation Loss:     0.7539\nEpoch  132 | Train Loss:     0.7630 | Validation Loss:     0.7531\nEpoch  133 | Train Loss:     0.7626 | Validation Loss:     0.7576\nEpoch  134 | Train Loss:     0.7623 | Validation Loss:     0.7534\nEpoch  135 | Train Loss:     0.7627 | Validation Loss:     0.7575\nEpoch  136 | Train Loss:     0.7626 | Validation Loss:     0.7548\nEpoch  137 | Train Loss:     0.7617 | Validation Loss:     0.7525\nEpoch  138 | Train Loss:     0.7618 | Validation Loss:     0.7519\nEpoch  139 | Train Loss:     0.7613 | Validation Loss:     0.7542\nEpoch  140 | Train Loss:     0.7611 | Validation Loss:     0.7532\nEpoch  141 | Train Loss:     0.7605 | Validation Loss:     0.7530\nEpoch  142 | Train Loss:     0.7603 | Validation Loss:     0.7527\nEpoch  143 | Train Loss:     0.7605 | Validation Loss:     0.7539\nEpoch  144 | Train Loss:     0.7602 | Validation Loss:     0.7515\nEpoch  145 | Train Loss:     0.7599 | Validation Loss:     0.7512\nEpoch  146 | Train Loss:     0.7602 | Validation Loss:     0.7519\nEpoch  147 | Train Loss:     0.7594 | Validation Loss:     0.7512\nEpoch  148 | Train Loss:     0.7599 | Validation Loss:     0.7539\nEpoch  149 | Train Loss:     0.7594 | Validation Loss:     0.7499\nEpoch  150 | Train Loss:     0.7593 | Validation Loss:     0.7509\nEpoch  151 | Train Loss:     0.7596 | Validation Loss:     0.7519\nEpoch  152 | Train Loss:     0.7588 | Validation Loss:     0.7498\nEpoch  153 | Train Loss:     0.7589 | Validation Loss:     0.7515\nEpoch  154 | Train Loss:     0.7585 | Validation Loss:     0.7503\nEpoch  155 | Train Loss:     0.7585 | Validation Loss:     0.7504\nEpoch  156 | Train Loss:     0.7581 | Validation Loss:     0.7502\nEpoch  157 | Train Loss:     0.7588 | Validation Loss:     0.7509\nEpoch  158 | Train Loss:     0.7573 | Validation Loss:     0.7490\nEpoch  159 | Train Loss:     0.7581 | Validation Loss:     0.7495\nEpoch  160 | Train Loss:     0.7571 | Validation Loss:     0.7532\nEpoch  161 | Train Loss:     0.7583 | Validation Loss:     0.7506\nEpoch  162 | Train Loss:     0.7575 | Validation Loss:     0.7503\nEpoch  163 | Train Loss:     0.7574 | Validation Loss:     0.7506\nEpoch  164 | Train Loss:     0.7566 | Validation Loss:     0.7491\nEpoch  165 | Train Loss:     0.7568 | Validation Loss:     0.7537\nEpoch  166 | Train Loss:     0.7567 | Validation Loss:     0.7496\nEpoch  167 | Train Loss:     0.7568 | Validation Loss:     0.7490\nEpoch  168 | Train Loss:     0.7567 | Validation Loss:     0.7503\nEpoch  169 | Train Loss:     0.7570 | Validation Loss:     0.7502\nEpoch  170 | Train Loss:     0.7565 | Validation Loss:     0.7490\nEpoch  171 | Train Loss:     0.7565 | Validation Loss:     0.7486\nEpoch  172 | Train Loss:     0.7559 | Validation Loss:     0.7527\nEpoch  173 | Train Loss:     0.7566 | Validation Loss:     0.7507\nEpoch  174 | Train Loss:     0.7563 | Validation Loss:     0.7503\nEpoch  175 | Train Loss:     0.7560 | Validation Loss:     0.7523\nEpoch  176 | Train Loss:     0.7561 | Validation Loss:     0.7492\nEpoch  177 | Train Loss:     0.7555 | Validation Loss:     0.7487\nEpoch  178 | Train Loss:     0.7558 | Validation Loss:     0.7528\nEpoch  179 | Train Loss:     0.7553 | Validation Loss:     0.7487\nEpoch  180 | Train Loss:     0.7556 | Validation Loss:     0.7484\nEpoch  181 | Train Loss:     0.7572 | Validation Loss:     0.7489\nEpoch  182 | Train Loss:     0.7554 | Validation Loss:     0.7507\nEpoch  183 | Train Loss:     0.7556 | Validation Loss:     0.7500\nEpoch  184 | Train Loss:     0.7558 | Validation Loss:     0.7481\nEpoch  185 | Train Loss:     0.7553 | Validation Loss:     0.7494\nEpoch  186 | Train Loss:     0.7553 | Validation Loss:     0.7499\nEpoch  187 | Train Loss:     0.7557 | Validation Loss:     0.7513\nEpoch  188 | Train Loss:     0.7553 | Validation Loss:     0.7486\nEpoch  189 | Train Loss:     0.7549 | Validation Loss:     0.7479\nEpoch  190 | Train Loss:     0.7555 | Validation Loss:     0.7491\nEpoch  191 | Train Loss:     0.7548 | Validation Loss:     0.7500\nEpoch  192 | Train Loss:     0.7542 | Validation Loss:     0.7480\nEpoch  193 | Train Loss:     0.7545 | Validation Loss:     0.7484\nEpoch  194 | Train Loss:     0.7549 | Validation Loss:     0.7477\nEpoch  195 | Train Loss:     0.7546 | Validation Loss:     0.7493\nEpoch  196 | Train Loss:     0.7543 | Validation Loss:     0.7483\nEpoch  197 | Train Loss:     0.7542 | Validation Loss:     0.7507\nEpoch  198 | Train Loss:     0.7540 | Validation Loss:     0.7485\nEpoch  199 | Train Loss:     0.7548 | Validation Loss:     0.7481\nEpoch  200 | Train Loss:     0.7546 | Validation Loss:     0.7489\nEpoch  201 | Train Loss:     0.7550 | Validation Loss:     0.7502\nEpoch  202 | Train Loss:     0.7537 | Validation Loss:     0.7501\nEpoch  203 | Train Loss:     0.7537 | Validation Loss:     0.7486\nEpoch  204 | Train Loss:     0.7552 | Validation Loss:     0.7517\nEpoch  205 | Train Loss:     0.7541 | Validation Loss:     0.7478\nEpoch  206 | Train Loss:     0.7543 | Validation Loss:     0.7505\nEpoch  207 | Train Loss:     0.7544 | Validation Loss:     0.7483\nEpoch  208 | Train Loss:     0.7539 | Validation Loss:     0.7488\nEpoch  209 | Train Loss:     0.7543 | Validation Loss:     0.7524\nEpoch  210 | Train Loss:     0.7536 | Validation Loss:     0.7483\nEpoch  211 | Train Loss:     0.7534 | Validation Loss:     0.7494\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[146], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mSGD(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m10\u001b[39m)\n\u001b[1;32m      2\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.000001\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m1000\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcustom_train_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m    \n","Cell \u001b[0;32mIn[54], line 143\u001b[0m, in \u001b[0;36mevaluate_model\u001b[0;34m(model, custom_train_loader, criterion, optimizer)\u001b[0m\n\u001b[1;32m    141\u001b[0m     plt\u001b[38;5;241m.\u001b[39mlegend()\n\u001b[1;32m    142\u001b[0m     plt\u001b[38;5;241m.\u001b[39mgrid(\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 143\u001b[0m     \u001b[43mplt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mimage_folder\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/epoch_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m:\u001b[39;49;00m\u001b[38;5;124;43m04d\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.png\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    144\u001b[0m     plt\u001b[38;5;241m.\u001b[39mclose()\n\u001b[1;32m    146\u001b[0m images \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/pyplot.py:1023\u001b[0m, in \u001b[0;36msavefig\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;129m@_copy_docstring_and_deprecators\u001b[39m(Figure\u001b[38;5;241m.\u001b[39msavefig)\n\u001b[1;32m   1021\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msavefig\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m   1022\u001b[0m     fig \u001b[38;5;241m=\u001b[39m gcf()\n\u001b[0;32m-> 1023\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msavefig\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1024\u001b[0m     fig\u001b[38;5;241m.\u001b[39mcanvas\u001b[38;5;241m.\u001b[39mdraw_idle()  \u001b[38;5;66;03m# Need this if 'transparent=True', to reset colors.\u001b[39;00m\n\u001b[1;32m   1025\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m res\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/figure.py:3378\u001b[0m, in \u001b[0;36mFigure.savefig\u001b[0;34m(self, fname, transparent, **kwargs)\u001b[0m\n\u001b[1;32m   3374\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maxes:\n\u001b[1;32m   3375\u001b[0m         stack\u001b[38;5;241m.\u001b[39menter_context(\n\u001b[1;32m   3376\u001b[0m             ax\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39m_cm_set(facecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m, edgecolor\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[0;32m-> 3378\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcanvas\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprint_figure\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backend_bases.py:2366\u001b[0m, in \u001b[0;36mFigureCanvasBase.print_figure\u001b[0;34m(self, filename, dpi, facecolor, edgecolor, orientation, format, bbox_inches, pad_inches, bbox_extra_artists, backend, **kwargs)\u001b[0m\n\u001b[1;32m   2362\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2363\u001b[0m     \u001b[38;5;66;03m# _get_renderer may change the figure dpi (as vector formats\u001b[39;00m\n\u001b[1;32m   2364\u001b[0m     \u001b[38;5;66;03m# force the figure dpi to 72), so we need to set it again here.\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m-> 2366\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mprint_method\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2367\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2368\u001b[0m \u001b[43m            \u001b[49m\u001b[43mfacecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfacecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2369\u001b[0m \u001b[43m            \u001b[49m\u001b[43medgecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medgecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2370\u001b[0m \u001b[43m            \u001b[49m\u001b[43morientation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morientation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2371\u001b[0m \u001b[43m            \u001b[49m\u001b[43mbbox_inches_restore\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m_bbox_inches_restore\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2372\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2373\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   2374\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bbox_inches \u001b[38;5;129;01mand\u001b[39;00m restore_bbox:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backend_bases.py:2232\u001b[0m, in \u001b[0;36mFigureCanvasBase._switch_canvas_and_return_print_method.<locals>.<lambda>\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m   2228\u001b[0m     optional_kws \u001b[38;5;241m=\u001b[39m {  \u001b[38;5;66;03m# Passed by print_figure for other renderers.\u001b[39;00m\n\u001b[1;32m   2229\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdpi\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124medgecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124morientation\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2230\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbbox_inches_restore\u001b[39m\u001b[38;5;124m\"\u001b[39m}\n\u001b[1;32m   2231\u001b[0m     skip \u001b[38;5;241m=\u001b[39m optional_kws \u001b[38;5;241m-\u001b[39m {\u001b[38;5;241m*\u001b[39minspect\u001b[38;5;241m.\u001b[39msignature(meth)\u001b[38;5;241m.\u001b[39mparameters}\n\u001b[0;32m-> 2232\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m functools\u001b[38;5;241m.\u001b[39mwraps(meth)(\u001b[38;5;28;01mlambda\u001b[39;00m \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[43mmeth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2233\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mv\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   2234\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:  \u001b[38;5;66;03m# Let third-parties do as they see fit.\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     print_method \u001b[38;5;241m=\u001b[39m meth\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:509\u001b[0m, in \u001b[0;36mFigureCanvasAgg.print_png\u001b[0;34m(self, filename_or_obj, metadata, pil_kwargs)\u001b[0m\n\u001b[1;32m    462\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprint_png\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, \u001b[38;5;241m*\u001b[39m, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, pil_kwargs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    463\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    464\u001b[0m \u001b[38;5;124;03m    Write the figure to a PNG file.\u001b[39;00m\n\u001b[1;32m    465\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    507\u001b[0m \u001b[38;5;124;03m        *metadata*, including the default 'Software' key.\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 509\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_print_pil\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilename_or_obj\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mpng\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpil_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:457\u001b[0m, in \u001b[0;36mFigureCanvasAgg._print_pil\u001b[0;34m(self, filename_or_obj, fmt, pil_kwargs, metadata)\u001b[0m\n\u001b[1;32m    452\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_print_pil\u001b[39m(\u001b[38;5;28mself\u001b[39m, filename_or_obj, fmt, pil_kwargs, metadata\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m    453\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;124;03m    Draw the canvas, then save it using `.image.imsave` (to which\u001b[39;00m\n\u001b[1;32m    455\u001b[0m \u001b[38;5;124;03m    *pil_kwargs* and *metadata* are forwarded).\u001b[39;00m\n\u001b[1;32m    456\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 457\u001b[0m     \u001b[43mFigureCanvasAgg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     mpl\u001b[38;5;241m.\u001b[39mimage\u001b[38;5;241m.\u001b[39mimsave(\n\u001b[1;32m    459\u001b[0m         filename_or_obj, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuffer_rgba(), \u001b[38;5;28mformat\u001b[39m\u001b[38;5;241m=\u001b[39mfmt, origin\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mupper\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    460\u001b[0m         dpi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39mdpi, metadata\u001b[38;5;241m=\u001b[39mmetadata, pil_kwargs\u001b[38;5;241m=\u001b[39mpil_kwargs)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/backends/backend_agg.py:400\u001b[0m, in \u001b[0;36mFigureCanvasAgg.draw\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    396\u001b[0m \u001b[38;5;66;03m# Acquire a lock on the shared font cache.\u001b[39;00m\n\u001b[1;32m    397\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m RendererAgg\u001b[38;5;241m.\u001b[39mlock, \\\n\u001b[1;32m    398\u001b[0m      (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\u001b[38;5;241m.\u001b[39m_wait_cursor_for_draw_cm() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtoolbar\n\u001b[1;32m    399\u001b[0m       \u001b[38;5;28;01melse\u001b[39;00m nullcontext()):\n\u001b[0;32m--> 400\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    401\u001b[0m     \u001b[38;5;66;03m# A GUI class may be need to update a window using this draw, so\u001b[39;00m\n\u001b[1;32m    402\u001b[0m     \u001b[38;5;66;03m# don't forget to call the superclass.\u001b[39;00m\n\u001b[1;32m    403\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mdraw()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:95\u001b[0m, in \u001b[0;36m_finalize_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(draw)\n\u001b[1;32m     94\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdraw_wrapper\u001b[39m(artist, renderer, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 95\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m renderer\u001b[38;5;241m.\u001b[39m_rasterizing:\n\u001b[1;32m     97\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstop_rasterizing()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/figure.py:3175\u001b[0m, in \u001b[0;36mFigure.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3172\u001b[0m         \u001b[38;5;66;03m# ValueError can occur when resizing a window.\u001b[39;00m\n\u001b[1;32m   3174\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpatch\u001b[38;5;241m.\u001b[39mdraw(renderer)\n\u001b[0;32m-> 3175\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3176\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3178\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m sfig \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msubfigs:\n\u001b[1;32m   3179\u001b[0m     sfig\u001b[38;5;241m.\u001b[39mdraw(renderer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axes/_base.py:3064\u001b[0m, in \u001b[0;36m_AxesBase.draw\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m   3061\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artists_rasterized:\n\u001b[1;32m   3062\u001b[0m     _draw_rasterized(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, artists_rasterized, renderer)\n\u001b[0;32m-> 3064\u001b[0m \u001b[43mmimage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_draw_list_compositing_images\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3065\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martists\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfigure\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msuppressComposite\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3067\u001b[0m renderer\u001b[38;5;241m.\u001b[39mclose_group(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maxes\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m   3068\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstale \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/image.py:131\u001b[0m, in \u001b[0;36m_draw_list_compositing_images\u001b[0;34m(renderer, parent, artists, suppress_composite)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m not_composite \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m has_images:\n\u001b[1;32m    130\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m artists:\n\u001b[0;32m--> 131\u001b[0m         \u001b[43ma\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;66;03m# Composite any adjacent images together\u001b[39;00m\n\u001b[1;32m    134\u001b[0m     image_group \u001b[38;5;241m=\u001b[39m []\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/artist.py:72\u001b[0m, in \u001b[0;36mallow_rasterization.<locals>.draw_wrapper\u001b[0;34m(artist, renderer)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     70\u001b[0m         renderer\u001b[38;5;241m.\u001b[39mstart_filter()\n\u001b[0;32m---> 72\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdraw\u001b[49m\u001b[43m(\u001b[49m\u001b[43martist\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     73\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     74\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m artist\u001b[38;5;241m.\u001b[39mget_agg_filter() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axis.py:1389\u001b[0m, in \u001b[0;36mAxis.draw\u001b[0;34m(self, renderer, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1386\u001b[0m renderer\u001b[38;5;241m.\u001b[39mopen_group(\u001b[38;5;18m__name__\u001b[39m, gid\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_gid())\n\u001b[1;32m   1388\u001b[0m ticks_to_draw \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_ticks()\n\u001b[0;32m-> 1389\u001b[0m tlb1, tlb2 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_ticklabel_bboxes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mticks_to_draw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1391\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks_to_draw:\n\u001b[1;32m   1392\u001b[0m     tick\u001b[38;5;241m.\u001b[39mdraw(renderer)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axis.py:1316\u001b[0m, in \u001b[0;36mAxis._get_ticklabel_bboxes\u001b[0;34m(self, ticks, renderer)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[0;32m-> 1316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1317\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[1;32m   1318\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1319\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/axis.py:1316\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m renderer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     renderer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure\u001b[38;5;241m.\u001b[39m_get_renderer()\n\u001b[0;32m-> 1316\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m ([\u001b[43mtick\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlabel1\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_window_extent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrenderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1317\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel1\u001b[38;5;241m.\u001b[39mget_visible()],\n\u001b[1;32m   1318\u001b[0m         [tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_window_extent(renderer)\n\u001b[1;32m   1319\u001b[0m          \u001b[38;5;28;01mfor\u001b[39;00m tick \u001b[38;5;129;01min\u001b[39;00m ticks \u001b[38;5;28;01mif\u001b[39;00m tick\u001b[38;5;241m.\u001b[39mlabel2\u001b[38;5;241m.\u001b[39mget_visible()])\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/text.py:959\u001b[0m, in \u001b[0;36mText.get_window_extent\u001b[0;34m(self, renderer, dpi)\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    955\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot get window extent of text w/o renderer. You likely \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    956\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwant to call \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfigure.draw_without_rendering()\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m first.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    958\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m cbook\u001b[38;5;241m.\u001b[39m_setattr_cm(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfigure, dpi\u001b[38;5;241m=\u001b[39mdpi):\n\u001b[0;32m--> 959\u001b[0m     bbox, info, descent \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_layout\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_renderer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    960\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_unitless_position()\n\u001b[1;32m    961\u001b[0m     x, y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_transform()\u001b[38;5;241m.\u001b[39mtransform((x, y))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/matplotlib/text.py:512\u001b[0m, in \u001b[0;36mText._get_layout\u001b[0;34m(self, renderer)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m# now rotate the positions around the first (x, y) position\u001b[39;00m\n\u001b[1;32m    510\u001b[0m xys \u001b[38;5;241m=\u001b[39m M\u001b[38;5;241m.\u001b[39mtransform(offset_layout) \u001b[38;5;241m-\u001b[39m (offsetx, offsety)\n\u001b[0;32m--> 512\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m bbox, \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mlines\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mzip\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mws\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mxys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[43m)\u001b[49m), descent\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"},{"output_type":"display_data","data":{"text/plain":"<Figure size 1000x500 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"import cv2\nimage_folder = 'training_images'\n\nnum_epochs = 154\nframe = cv2.imread(f\"{image_folder}/epoch_0001.png\")\nheight, width, layers = frame.shape\n\nvideo = cv2.VideoWriter('training_progress_154_linear_RELU_fixed.mp4', cv2.VideoWriter_fourcc(*'mp4v'), 30, (width, height))\n\nfor epoch in range(num_epochs):\n    filename = f\"{image_folder}/epoch_{epoch+1:04d}.png\"\n    video.write(cv2.imread(filename))\n\nvideo.release()","metadata":{"execution":{"iopub.status.busy":"2024-06-16T21:41:08.791943Z","iopub.execute_input":"2024-06-16T21:41:08.792311Z","iopub.status.idle":"2024-06-16T21:41:10.282652Z","shell.execute_reply.started":"2024-06-16T21:41:08.792283Z","shell.execute_reply":"2024-06-16T21:41:10.281658Z"},"trusted":true},"execution_count":380,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}