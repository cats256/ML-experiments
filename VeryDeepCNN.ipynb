{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6c47847",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchinfo import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de180b2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mps\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"mps\" if torch.backends.mps.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca9fd81a",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c11c0d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 10000\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "train_data = train_dataset.data.to(device).float() / 255.0\n",
    "train_targets = train_dataset.targets.to(device)\n",
    "\n",
    "test_data = test_dataset.data.to(device).float() / 255.0\n",
    "test_targets = test_dataset.targets.to(device)\n",
    "\n",
    "train_data = train_data.unsqueeze(1)\n",
    "test_data = test_data.unsqueeze(1)\n",
    "\n",
    "def get_batches(data, targets, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size], targets[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "2ab19f9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "class ExperimentalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "\n",
    "        self.conv1 = nn.Conv2d(1, 2, kernel_size=2, padding=0)\n",
    "        self.conv2 = nn.Conv2d(2, 4, kernel_size=2, padding=0)\n",
    "        self.conv3 = nn.Conv2d(4, 8, kernel_size=2, padding=0)\n",
    "        self.conv4 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv5 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv6 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv7 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv8 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv9 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv10 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv11 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv12 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv13 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv14 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv15 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv16 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv17 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "        self.conv18 = nn.Conv2d(8, 8, kernel_size=3, padding=1)\n",
    "\n",
    "        self.fc = nn.Linear(5000, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = F.relu(self.conv1(x))\n",
    "        x2 = F.relu(self.conv2(x1))\n",
    "        x3 = F.relu(self.conv3(x2))\n",
    "        rolling = x3\n",
    "        x4 = F.relu(self.conv4(rolling))\n",
    "        rolling = rolling + x4\n",
    "        x5 = F.relu(self.conv5(rolling / 2))\n",
    "        rolling = rolling + x5\n",
    "        x6 = F.relu(self.conv6(rolling / 3))\n",
    "        rolling = rolling + x6\n",
    "        x7 = F.relu(self.conv7(rolling / 4))\n",
    "        rolling = rolling + x7\n",
    "        x8 = F.relu(self.conv8(rolling / 5))\n",
    "        rolling = rolling + x8\n",
    "        x9 = F.relu(self.conv9(rolling / 6))\n",
    "        rolling = rolling + x9\n",
    "        x10 = F.relu(self.conv10(rolling / 7))\n",
    "        rolling = rolling + x10\n",
    "        x11 = F.relu(self.conv11(rolling / 8))\n",
    "        rolling = rolling + x11\n",
    "        x12 = F.relu(self.conv12(rolling / 9))\n",
    "        rolling = rolling + x12\n",
    "        x13 = F.relu(self.conv13(rolling / 10))\n",
    "        rolling = rolling + x13\n",
    "        x14 = F.relu(self.conv14(rolling / 11))\n",
    "        rolling = rolling + x14\n",
    "        x15 = F.relu(self.conv15(rolling / 12))\n",
    "        rolling = rolling + x15\n",
    "        x16 = F.relu(self.conv16(rolling / 13))\n",
    "        rolling = rolling + x16\n",
    "        x17 = F.relu(self.conv17(rolling / 14))\n",
    "        rolling = rolling + x17\n",
    "        x18 = F.relu(self.conv18(rolling / 15))\n",
    "        rolling = rolling + x18\n",
    "\n",
    "        rolling = rolling / 16\n",
    "\n",
    "        x_flat = rolling.view(rolling.size(0), -1)\n",
    "        out = self.fc(x_flat)\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "2b257366",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 0.001 * 1\n",
    "epochs = 1000\n",
    "\n",
    "model = ExperimentalModel().to(device)\n",
    "model \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "53f62588",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv1.weight: 8 params, requires_grad=True\n",
      "conv1.bias: 2 params, requires_grad=True\n",
      "conv2.weight: 32 params, requires_grad=True\n",
      "conv2.bias: 4 params, requires_grad=True\n",
      "conv3.weight: 128 params, requires_grad=True\n",
      "conv3.bias: 8 params, requires_grad=True\n",
      "conv4.weight: 576 params, requires_grad=True\n",
      "conv4.bias: 8 params, requires_grad=True\n",
      "conv5.weight: 576 params, requires_grad=True\n",
      "conv5.bias: 8 params, requires_grad=True\n",
      "conv6.weight: 576 params, requires_grad=True\n",
      "conv6.bias: 8 params, requires_grad=True\n",
      "conv7.weight: 576 params, requires_grad=True\n",
      "conv7.bias: 8 params, requires_grad=True\n",
      "conv8.weight: 576 params, requires_grad=True\n",
      "conv8.bias: 8 params, requires_grad=True\n",
      "conv9.weight: 576 params, requires_grad=True\n",
      "conv9.bias: 8 params, requires_grad=True\n",
      "conv10.weight: 576 params, requires_grad=True\n",
      "conv10.bias: 8 params, requires_grad=True\n",
      "conv11.weight: 576 params, requires_grad=True\n",
      "conv11.bias: 8 params, requires_grad=True\n",
      "conv12.weight: 576 params, requires_grad=True\n",
      "conv12.bias: 8 params, requires_grad=True\n",
      "conv13.weight: 576 params, requires_grad=True\n",
      "conv13.bias: 8 params, requires_grad=True\n",
      "conv14.weight: 576 params, requires_grad=True\n",
      "conv14.bias: 8 params, requires_grad=True\n",
      "conv15.weight: 576 params, requires_grad=True\n",
      "conv15.bias: 8 params, requires_grad=True\n",
      "conv16.weight: 576 params, requires_grad=True\n",
      "conv16.bias: 8 params, requires_grad=True\n",
      "conv17.weight: 576 params, requires_grad=True\n",
      "conv17.bias: 8 params, requires_grad=True\n",
      "conv18.weight: 576 params, requires_grad=True\n",
      "conv18.bias: 8 params, requires_grad=True\n",
      "fc.weight: 50000 params, requires_grad=True\n",
      "fc.bias: 10 params, requires_grad=True\n",
      "\n",
      "58952\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    print(f\"{name}: {param.numel()} params, requires_grad={param.requires_grad}\")\n",
    "\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print()\n",
    "print(total_params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b1ddb698",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1000], Training Loss: 2.3062\n",
      "Epoch [1/1000], Validation Loss: 2.3045, Validation Accuracy: 10.00%\n",
      "Output Summary: Max=0.1133, Min=-0.1266, Median=0.0067, Mean=-0.0032\n",
      "\n",
      "Epoch [2/1000], Training Loss: 2.3030\n",
      "Epoch [2/1000], Validation Loss: 2.3012, Validation Accuracy: 10.00%\n",
      "Output Summary: Max=0.0618, Min=-0.0863, Median=-0.0363, Mean=-0.0177\n",
      "\n",
      "Epoch [3/1000], Training Loss: 2.2994\n",
      "Epoch [3/1000], Validation Loss: 2.2967, Validation Accuracy: 10.09%\n",
      "Output Summary: Max=0.0488, Min=-0.0505, Median=-0.0032, Mean=-0.0068\n",
      "\n",
      "Epoch [4/1000], Training Loss: 2.2935\n",
      "Epoch [4/1000], Validation Loss: 2.2869, Validation Accuracy: 15.29%\n",
      "Output Summary: Max=0.0887, Min=-0.0598, Median=-0.0167, Mean=-0.0097\n",
      "\n",
      "Epoch [5/1000], Training Loss: 2.2783\n",
      "Epoch [5/1000], Validation Loss: 2.2617, Validation Accuracy: 53.51%\n",
      "Output Summary: Max=0.0953, Min=-0.1250, Median=-0.0109, Mean=-0.0102\n",
      "\n",
      "Epoch [6/1000], Training Loss: 2.2377\n",
      "Epoch [6/1000], Validation Loss: 2.1900, Validation Accuracy: 53.48%\n",
      "Output Summary: Max=0.2581, Min=-0.2558, Median=-0.0144, Mean=-0.0067\n",
      "\n",
      "Epoch [7/1000], Training Loss: 2.1235\n",
      "Epoch [7/1000], Validation Loss: 1.9992, Validation Accuracy: 55.06%\n",
      "Output Summary: Max=0.6910, Min=-0.6417, Median=-0.0289, Mean=-0.0027\n",
      "\n",
      "Epoch [8/1000], Training Loss: 1.8543\n",
      "Epoch [8/1000], Validation Loss: 1.6239, Validation Accuracy: 58.20%\n",
      "Output Summary: Max=1.6570, Min=-1.6601, Median=-0.0310, Mean=0.0231\n",
      "\n",
      "Epoch [9/1000], Training Loss: 1.4266\n",
      "Epoch [9/1000], Validation Loss: 1.1786, Validation Accuracy: 64.93%\n",
      "Output Summary: Max=3.7323, Min=-3.5714, Median=-0.0337, Mean=0.0817\n",
      "\n",
      "Epoch [10/1000], Training Loss: 1.0487\n",
      "Epoch [10/1000], Validation Loss: 0.9267, Validation Accuracy: 68.41%\n",
      "Output Summary: Max=6.5828, Min=-5.9635, Median=-0.0378, Mean=0.1907\n",
      "\n",
      "Epoch [11/1000], Training Loss: 0.8632\n",
      "Epoch [11/1000], Validation Loss: 0.8253, Validation Accuracy: 70.60%\n",
      "Output Summary: Max=9.6269, Min=-8.1728, Median=-0.0288, Mean=0.2859\n",
      "\n",
      "Epoch [12/1000], Training Loss: 0.7805\n",
      "Epoch [12/1000], Validation Loss: 0.7657, Validation Accuracy: 72.39%\n",
      "Output Summary: Max=11.5527, Min=-9.9640, Median=0.0704, Mean=0.3284\n",
      "\n",
      "Epoch [13/1000], Training Loss: 0.7228\n",
      "Epoch [13/1000], Validation Loss: 0.7136, Validation Accuracy: 73.90%\n",
      "Output Summary: Max=12.0302, Min=-11.1274, Median=0.2652, Mean=0.3617\n",
      "\n",
      "Epoch [14/1000], Training Loss: 0.6755\n",
      "Epoch [14/1000], Validation Loss: 0.6741, Validation Accuracy: 74.79%\n",
      "Output Summary: Max=12.5346, Min=-11.9184, Median=0.4652, Mean=0.4160\n",
      "\n",
      "Epoch [15/1000], Training Loss: 0.6404\n",
      "Epoch [15/1000], Validation Loss: 0.6464, Validation Accuracy: 75.84%\n",
      "Output Summary: Max=13.1975, Min=-12.6604, Median=0.6047, Mean=0.4689\n",
      "\n",
      "Epoch [16/1000], Training Loss: 0.6137\n",
      "Epoch [16/1000], Validation Loss: 0.6244, Validation Accuracy: 76.95%\n",
      "Output Summary: Max=14.1696, Min=-13.4504, Median=0.7243, Mean=0.5422\n",
      "\n",
      "Epoch [17/1000], Training Loss: 0.5915\n",
      "Epoch [17/1000], Validation Loss: 0.6067, Validation Accuracy: 77.57%\n",
      "Output Summary: Max=14.9934, Min=-14.0063, Median=0.8149, Mean=0.6311\n",
      "\n",
      "Epoch [18/1000], Training Loss: 0.5733\n",
      "Epoch [18/1000], Validation Loss: 0.5918, Validation Accuracy: 78.09%\n",
      "Output Summary: Max=15.5066, Min=-14.1355, Median=0.8945, Mean=0.7004\n",
      "\n",
      "Epoch [19/1000], Training Loss: 0.5579\n",
      "Epoch [19/1000], Validation Loss: 0.5785, Validation Accuracy: 78.59%\n",
      "Output Summary: Max=15.9168, Min=-13.9561, Median=1.0253, Mean=0.7579\n",
      "\n",
      "Epoch [20/1000], Training Loss: 0.5441\n",
      "Epoch [20/1000], Validation Loss: 0.5667, Validation Accuracy: 79.15%\n",
      "Output Summary: Max=16.5323, Min=-14.2029, Median=1.1782, Mean=0.8110\n",
      "\n",
      "Epoch [21/1000], Training Loss: 0.5317\n",
      "Epoch [21/1000], Validation Loss: 0.5555, Validation Accuracy: 79.59%\n",
      "Output Summary: Max=17.2125, Min=-14.8863, Median=1.3461, Mean=0.8664\n",
      "\n",
      "Epoch [22/1000], Training Loss: 0.5203\n",
      "Epoch [22/1000], Validation Loss: 0.5446, Validation Accuracy: 80.00%\n",
      "Output Summary: Max=17.7802, Min=-15.5071, Median=1.4948, Mean=0.9175\n",
      "\n",
      "Epoch [23/1000], Training Loss: 0.5098\n",
      "Epoch [23/1000], Validation Loss: 0.5348, Validation Accuracy: 80.58%\n",
      "Output Summary: Max=18.3375, Min=-16.1467, Median=1.6206, Mean=0.9661\n",
      "\n",
      "Epoch [24/1000], Training Loss: 0.5001\n",
      "Epoch [24/1000], Validation Loss: 0.5261, Validation Accuracy: 80.93%\n",
      "Output Summary: Max=18.7588, Min=-16.7533, Median=1.7563, Mean=1.0183\n",
      "\n",
      "Epoch [25/1000], Training Loss: 0.4911\n",
      "Epoch [25/1000], Validation Loss: 0.5180, Validation Accuracy: 81.20%\n",
      "Output Summary: Max=19.0807, Min=-17.2724, Median=1.8930, Mean=1.0764\n",
      "\n",
      "Epoch [26/1000], Training Loss: 0.4828\n",
      "Epoch [26/1000], Validation Loss: 0.5111, Validation Accuracy: 81.48%\n",
      "Output Summary: Max=19.2543, Min=-17.6975, Median=2.0545, Mean=1.1449\n",
      "\n",
      "Epoch [27/1000], Training Loss: 0.4758\n",
      "Epoch [27/1000], Validation Loss: 0.5052, Validation Accuracy: 81.71%\n",
      "Output Summary: Max=19.6119, Min=-18.1492, Median=2.1965, Mean=1.2149\n",
      "\n",
      "Epoch [28/1000], Training Loss: 0.4697\n",
      "Epoch [28/1000], Validation Loss: 0.4981, Validation Accuracy: 82.08%\n",
      "Output Summary: Max=20.1186, Min=-18.4480, Median=2.3108, Mean=1.2840\n",
      "\n",
      "Epoch [29/1000], Training Loss: 0.4635\n",
      "Epoch [29/1000], Validation Loss: 0.4926, Validation Accuracy: 82.19%\n",
      "Output Summary: Max=20.8249, Min=-18.7657, Median=2.3734, Mean=1.3459\n",
      "\n",
      "Epoch [30/1000], Training Loss: 0.4578\n",
      "Epoch [30/1000], Validation Loss: 0.4875, Validation Accuracy: 82.30%\n",
      "Output Summary: Max=21.1099, Min=-19.0087, Median=2.4898, Mean=1.4143\n",
      "\n",
      "Epoch [31/1000], Training Loss: 0.4528\n",
      "Epoch [31/1000], Validation Loss: 0.4833, Validation Accuracy: 82.50%\n",
      "Output Summary: Max=21.3620, Min=-19.2224, Median=2.6125, Mean=1.4843\n",
      "\n",
      "Epoch [32/1000], Training Loss: 0.4485\n",
      "Epoch [32/1000], Validation Loss: 0.4797, Validation Accuracy: 82.65%\n",
      "Output Summary: Max=21.6951, Min=-19.4087, Median=2.7135, Mean=1.5503\n",
      "\n",
      "Epoch [33/1000], Training Loss: 0.4447\n",
      "Epoch [33/1000], Validation Loss: 0.4762, Validation Accuracy: 82.78%\n",
      "Output Summary: Max=22.0010, Min=-19.5106, Median=2.8040, Mean=1.6117\n",
      "\n",
      "Epoch [34/1000], Training Loss: 0.4410\n",
      "Epoch [34/1000], Validation Loss: 0.4723, Validation Accuracy: 82.94%\n",
      "Output Summary: Max=22.3724, Min=-19.6006, Median=2.8721, Mean=1.6666\n",
      "\n",
      "Epoch [35/1000], Training Loss: 0.4374\n",
      "Epoch [35/1000], Validation Loss: 0.4682, Validation Accuracy: 83.14%\n",
      "Output Summary: Max=22.9380, Min=-19.6496, Median=2.9300, Mean=1.7155\n",
      "\n",
      "Epoch [36/1000], Training Loss: 0.4336\n",
      "Epoch [36/1000], Validation Loss: 0.4650, Validation Accuracy: 83.17%\n",
      "Output Summary: Max=23.5433, Min=-19.6825, Median=2.9929, Mean=1.7642\n",
      "\n",
      "Epoch [37/1000], Training Loss: 0.4302\n",
      "Epoch [37/1000], Validation Loss: 0.4623, Validation Accuracy: 83.36%\n",
      "Output Summary: Max=23.9896, Min=-19.6877, Median=3.0766, Mean=1.8176\n",
      "\n",
      "Epoch [38/1000], Training Loss: 0.4271\n",
      "Epoch [38/1000], Validation Loss: 0.4601, Validation Accuracy: 83.41%\n",
      "Output Summary: Max=24.3131, Min=-19.6650, Median=3.1711, Mean=1.8729\n",
      "\n",
      "Epoch [39/1000], Training Loss: 0.4246\n",
      "Epoch [39/1000], Validation Loss: 0.4584, Validation Accuracy: 83.57%\n",
      "Output Summary: Max=24.6363, Min=-19.6511, Median=3.2648, Mean=1.9283\n",
      "\n",
      "Epoch [40/1000], Training Loss: 0.4223\n",
      "Epoch [40/1000], Validation Loss: 0.4571, Validation Accuracy: 83.69%\n",
      "Output Summary: Max=24.9628, Min=-19.6399, Median=3.3513, Mean=1.9827\n",
      "\n",
      "Epoch [41/1000], Training Loss: 0.4202\n",
      "Epoch [41/1000], Validation Loss: 0.4556, Validation Accuracy: 83.87%\n",
      "Output Summary: Max=25.2924, Min=-19.5658, Median=3.4226, Mean=2.0300\n",
      "\n",
      "Epoch [42/1000], Training Loss: 0.4182\n",
      "Epoch [42/1000], Validation Loss: 0.4537, Validation Accuracy: 83.99%\n",
      "Output Summary: Max=25.6530, Min=-19.6591, Median=3.4916, Mean=2.0772\n",
      "\n",
      "Epoch [43/1000], Training Loss: 0.4162\n",
      "Epoch [43/1000], Validation Loss: 0.4508, Validation Accuracy: 84.14%\n",
      "Output Summary: Max=26.1085, Min=-19.7608, Median=3.5316, Mean=2.1131\n",
      "\n",
      "Epoch [44/1000], Training Loss: 0.4140\n",
      "Epoch [44/1000], Validation Loss: 0.4476, Validation Accuracy: 84.32%\n",
      "Output Summary: Max=26.6431, Min=-19.8445, Median=3.5556, Mean=2.1451\n",
      "\n",
      "Epoch [45/1000], Training Loss: 0.4115\n",
      "Epoch [45/1000], Validation Loss: 0.4455, Validation Accuracy: 84.41%\n",
      "Output Summary: Max=27.0442, Min=-20.0528, Median=3.5859, Mean=2.1782\n",
      "\n",
      "Epoch [46/1000], Training Loss: 0.4092\n",
      "Epoch [46/1000], Validation Loss: 0.4438, Validation Accuracy: 84.46%\n",
      "Output Summary: Max=27.2980, Min=-20.2210, Median=3.6480, Mean=2.2171\n",
      "\n",
      "Epoch [47/1000], Training Loss: 0.4074\n",
      "Epoch [47/1000], Validation Loss: 0.4426, Validation Accuracy: 84.63%\n",
      "Output Summary: Max=27.4987, Min=-20.3783, Median=3.7204, Mean=2.2619\n",
      "\n",
      "Epoch [48/1000], Training Loss: 0.4057\n",
      "Epoch [48/1000], Validation Loss: 0.4419, Validation Accuracy: 84.48%\n",
      "Output Summary: Max=27.6763, Min=-20.6330, Median=3.7939, Mean=2.3048\n",
      "\n",
      "Epoch [49/1000], Training Loss: 0.4044\n",
      "Epoch [49/1000], Validation Loss: 0.4411, Validation Accuracy: 84.48%\n",
      "Output Summary: Max=27.8941, Min=-20.8494, Median=3.8552, Mean=2.3434\n",
      "\n",
      "Epoch [50/1000], Training Loss: 0.4031\n",
      "Epoch [50/1000], Validation Loss: 0.4398, Validation Accuracy: 84.50%\n",
      "Output Summary: Max=28.1622, Min=-20.9943, Median=3.8982, Mean=2.3764\n",
      "\n",
      "Epoch [51/1000], Training Loss: 0.4017\n",
      "Epoch [51/1000], Validation Loss: 0.4381, Validation Accuracy: 84.54%\n",
      "Output Summary: Max=28.4262, Min=-21.0986, Median=3.9315, Mean=2.4053\n",
      "\n",
      "Epoch [52/1000], Training Loss: 0.4003\n",
      "Epoch [52/1000], Validation Loss: 0.4366, Validation Accuracy: 84.62%\n",
      "Output Summary: Max=28.6637, Min=-21.2052, Median=3.9703, Mean=2.4333\n",
      "\n",
      "Epoch [53/1000], Training Loss: 0.3989\n",
      "Epoch [53/1000], Validation Loss: 0.4353, Validation Accuracy: 84.67%\n",
      "Output Summary: Max=28.8862, Min=-21.3313, Median=4.0087, Mean=2.4610\n",
      "\n",
      "Epoch [54/1000], Training Loss: 0.3975\n",
      "Epoch [54/1000], Validation Loss: 0.4343, Validation Accuracy: 84.65%\n",
      "Output Summary: Max=29.0786, Min=-21.4679, Median=4.0428, Mean=2.4885\n",
      "\n",
      "Epoch [55/1000], Training Loss: 0.3963\n",
      "Epoch [55/1000], Validation Loss: 0.4333, Validation Accuracy: 84.68%\n",
      "Output Summary: Max=29.2668, Min=-21.6143, Median=4.0816, Mean=2.5157\n",
      "\n",
      "Epoch [56/1000], Training Loss: 0.3951\n",
      "Epoch [56/1000], Validation Loss: 0.4325, Validation Accuracy: 84.69%\n",
      "Output Summary: Max=29.4353, Min=-21.7584, Median=4.1205, Mean=2.5417\n",
      "\n",
      "Epoch [57/1000], Training Loss: 0.3940\n",
      "Epoch [57/1000], Validation Loss: 0.4317, Validation Accuracy: 84.73%\n",
      "Output Summary: Max=29.5907, Min=-21.9007, Median=4.1580, Mean=2.5661\n",
      "\n",
      "Epoch [58/1000], Training Loss: 0.3930\n",
      "Epoch [58/1000], Validation Loss: 0.4310, Validation Accuracy: 84.75%\n",
      "Output Summary: Max=29.7426, Min=-22.0378, Median=4.1923, Mean=2.5890\n",
      "\n",
      "Epoch [59/1000], Training Loss: 0.3919\n",
      "Epoch [59/1000], Validation Loss: 0.4304, Validation Accuracy: 84.75%\n",
      "Output Summary: Max=29.8710, Min=-22.1702, Median=4.2283, Mean=2.6105\n",
      "\n",
      "Epoch [60/1000], Training Loss: 0.3909\n",
      "Epoch [60/1000], Validation Loss: 0.4299, Validation Accuracy: 84.69%\n",
      "Output Summary: Max=29.9965, Min=-22.2955, Median=4.2600, Mean=2.6305\n",
      "\n",
      "Epoch [61/1000], Training Loss: 0.3900\n",
      "Epoch [61/1000], Validation Loss: 0.4294, Validation Accuracy: 84.73%\n",
      "Output Summary: Max=30.1225, Min=-22.4171, Median=4.2947, Mean=2.6501\n",
      "\n",
      "Epoch [62/1000], Training Loss: 0.3891\n",
      "Epoch [62/1000], Validation Loss: 0.4287, Validation Accuracy: 84.79%\n",
      "Output Summary: Max=30.2579, Min=-22.5155, Median=4.3219, Mean=2.6675\n",
      "\n",
      "Epoch [63/1000], Training Loss: 0.3883\n",
      "Epoch [63/1000], Validation Loss: 0.4276, Validation Accuracy: 84.79%\n",
      "Output Summary: Max=30.4010, Min=-22.5771, Median=4.3376, Mean=2.6822\n",
      "\n",
      "Epoch [64/1000], Training Loss: 0.3875\n",
      "Epoch [64/1000], Validation Loss: 0.4261, Validation Accuracy: 84.91%\n",
      "Output Summary: Max=30.5852, Min=-22.5845, Median=4.3439, Mean=2.6935\n",
      "\n",
      "Epoch [65/1000], Training Loss: 0.3865\n",
      "Epoch [65/1000], Validation Loss: 0.4243, Validation Accuracy: 84.91%\n",
      "Output Summary: Max=30.8190, Min=-22.5437, Median=4.3431, Mean=2.7021\n",
      "\n",
      "Epoch [66/1000], Training Loss: 0.3854\n",
      "Epoch [66/1000], Validation Loss: 0.4229, Validation Accuracy: 85.05%\n",
      "Output Summary: Max=31.0552, Min=-22.6702, Median=4.3490, Mean=2.7107\n",
      "\n",
      "Epoch [67/1000], Training Loss: 0.3842\n",
      "Epoch [67/1000], Validation Loss: 0.4220, Validation Accuracy: 85.18%\n",
      "Output Summary: Max=31.2439, Min=-22.8152, Median=4.3596, Mean=2.7213\n",
      "\n",
      "Epoch [68/1000], Training Loss: 0.3831\n",
      "Epoch [68/1000], Validation Loss: 0.4211, Validation Accuracy: 85.22%\n",
      "Output Summary: Max=31.3584, Min=-22.9393, Median=4.3845, Mean=2.7351\n",
      "\n",
      "Epoch [69/1000], Training Loss: 0.3822\n",
      "Epoch [69/1000], Validation Loss: 0.4204, Validation Accuracy: 85.15%\n",
      "Output Summary: Max=31.4927, Min=-23.0242, Median=4.4094, Mean=2.7501\n",
      "\n",
      "Epoch [70/1000], Training Loss: 0.3813\n",
      "Epoch [70/1000], Validation Loss: 0.4197, Validation Accuracy: 85.16%\n",
      "Output Summary: Max=31.5668, Min=-23.1056, Median=4.4387, Mean=2.7647\n",
      "\n",
      "Epoch [71/1000], Training Loss: 0.3805\n",
      "Epoch [71/1000], Validation Loss: 0.4192, Validation Accuracy: 85.12%\n",
      "Output Summary: Max=31.6902, Min=-23.2007, Median=4.4676, Mean=2.7787\n",
      "\n",
      "Epoch [72/1000], Training Loss: 0.3797\n",
      "Epoch [72/1000], Validation Loss: 0.4189, Validation Accuracy: 85.11%\n",
      "Output Summary: Max=31.7592, Min=-23.2640, Median=4.4910, Mean=2.7922\n",
      "\n",
      "Epoch [73/1000], Training Loss: 0.3789\n",
      "Epoch [73/1000], Validation Loss: 0.4186, Validation Accuracy: 85.09%\n",
      "Output Summary: Max=31.8743, Min=-23.3688, Median=4.5188, Mean=2.8036\n",
      "\n",
      "Epoch [74/1000], Training Loss: 0.3781\n",
      "Epoch [74/1000], Validation Loss: 0.4181, Validation Accuracy: 85.10%\n",
      "Output Summary: Max=31.9752, Min=-23.4643, Median=4.5400, Mean=2.8146\n",
      "\n",
      "Epoch [75/1000], Training Loss: 0.3774\n",
      "Epoch [75/1000], Validation Loss: 0.4175, Validation Accuracy: 85.09%\n",
      "Output Summary: Max=32.0840, Min=-23.5606, Median=4.5553, Mean=2.8230\n",
      "\n",
      "Epoch [76/1000], Training Loss: 0.3766\n",
      "Epoch [76/1000], Validation Loss: 0.4168, Validation Accuracy: 85.13%\n",
      "Output Summary: Max=32.1972, Min=-23.6582, Median=4.5631, Mean=2.8299\n",
      "\n",
      "Epoch [77/1000], Training Loss: 0.3759\n",
      "Epoch [77/1000], Validation Loss: 0.4160, Validation Accuracy: 85.27%\n",
      "Output Summary: Max=32.3308, Min=-23.7654, Median=4.5744, Mean=2.8373\n",
      "\n",
      "Epoch [78/1000], Training Loss: 0.3751\n",
      "Epoch [78/1000], Validation Loss: 0.4151, Validation Accuracy: 85.28%\n",
      "Output Summary: Max=32.4645, Min=-23.8668, Median=4.5862, Mean=2.8448\n",
      "\n",
      "Epoch [79/1000], Training Loss: 0.3743\n",
      "Epoch [79/1000], Validation Loss: 0.4143, Validation Accuracy: 85.31%\n",
      "Output Summary: Max=32.6071, Min=-23.9664, Median=4.6018, Mean=2.8519\n",
      "\n",
      "Epoch [80/1000], Training Loss: 0.3736\n",
      "Epoch [80/1000], Validation Loss: 0.4133, Validation Accuracy: 85.33%\n",
      "Output Summary: Max=32.7624, Min=-24.0676, Median=4.6098, Mean=2.8590\n",
      "\n",
      "Epoch [81/1000], Training Loss: 0.3728\n",
      "Epoch [81/1000], Validation Loss: 0.4124, Validation Accuracy: 85.35%\n",
      "Output Summary: Max=32.9159, Min=-24.1602, Median=4.6162, Mean=2.8657\n",
      "\n",
      "Epoch [82/1000], Training Loss: 0.3721\n",
      "Epoch [82/1000], Validation Loss: 0.4115, Validation Accuracy: 85.36%\n",
      "Output Summary: Max=33.0796, Min=-24.2537, Median=4.6220, Mean=2.8722\n",
      "\n",
      "Epoch [83/1000], Training Loss: 0.3713\n",
      "Epoch [83/1000], Validation Loss: 0.4107, Validation Accuracy: 85.44%\n",
      "Output Summary: Max=33.2299, Min=-24.3424, Median=4.6292, Mean=2.8791\n",
      "\n",
      "Epoch [84/1000], Training Loss: 0.3706\n",
      "Epoch [84/1000], Validation Loss: 0.4100, Validation Accuracy: 85.50%\n",
      "Output Summary: Max=33.3673, Min=-24.4258, Median=4.6388, Mean=2.8864\n",
      "\n",
      "Epoch [85/1000], Training Loss: 0.3699\n",
      "Epoch [85/1000], Validation Loss: 0.4095, Validation Accuracy: 85.53%\n",
      "Output Summary: Max=33.4862, Min=-24.5024, Median=4.6533, Mean=2.8944\n",
      "\n",
      "Epoch [86/1000], Training Loss: 0.3693\n",
      "Epoch [86/1000], Validation Loss: 0.4089, Validation Accuracy: 85.50%\n",
      "Output Summary: Max=33.5921, Min=-24.5776, Median=4.6685, Mean=2.9030\n",
      "\n",
      "Epoch [87/1000], Training Loss: 0.3687\n",
      "Epoch [87/1000], Validation Loss: 0.4084, Validation Accuracy: 85.56%\n",
      "Output Summary: Max=33.7076, Min=-24.6557, Median=4.6867, Mean=2.9110\n",
      "\n",
      "Epoch [88/1000], Training Loss: 0.3681\n",
      "Epoch [88/1000], Validation Loss: 0.4078, Validation Accuracy: 85.58%\n",
      "Output Summary: Max=33.8223, Min=-24.7318, Median=4.6988, Mean=2.9181\n",
      "\n",
      "Epoch [89/1000], Training Loss: 0.3675\n",
      "Epoch [89/1000], Validation Loss: 0.4073, Validation Accuracy: 85.58%\n",
      "Output Summary: Max=33.9122, Min=-24.8003, Median=4.7153, Mean=2.9250\n",
      "\n",
      "Epoch [90/1000], Training Loss: 0.3669\n",
      "Epoch [90/1000], Validation Loss: 0.4068, Validation Accuracy: 85.62%\n",
      "Output Summary: Max=34.0017, Min=-24.8708, Median=4.7295, Mean=2.9315\n",
      "\n",
      "Epoch [91/1000], Training Loss: 0.3664\n",
      "Epoch [91/1000], Validation Loss: 0.4062, Validation Accuracy: 85.65%\n",
      "Output Summary: Max=34.1041, Min=-24.9445, Median=4.7430, Mean=2.9374\n",
      "\n",
      "Epoch [92/1000], Training Loss: 0.3658\n",
      "Epoch [92/1000], Validation Loss: 0.4058, Validation Accuracy: 85.62%\n",
      "Output Summary: Max=34.1971, Min=-25.0168, Median=4.7533, Mean=2.9436\n",
      "\n",
      "Epoch [93/1000], Training Loss: 0.3653\n",
      "Epoch [93/1000], Validation Loss: 0.4053, Validation Accuracy: 85.62%\n",
      "Output Summary: Max=34.2842, Min=-25.0781, Median=4.7622, Mean=2.9486\n",
      "\n",
      "Epoch [94/1000], Training Loss: 0.3648\n",
      "Epoch [94/1000], Validation Loss: 0.4048, Validation Accuracy: 85.67%\n",
      "Output Summary: Max=34.3700, Min=-25.1384, Median=4.7707, Mean=2.9533\n",
      "\n",
      "Epoch [95/1000], Training Loss: 0.3642\n",
      "Epoch [95/1000], Validation Loss: 0.4043, Validation Accuracy: 85.68%\n",
      "Output Summary: Max=34.4621, Min=-25.1991, Median=4.7817, Mean=2.9576\n",
      "\n",
      "Epoch [96/1000], Training Loss: 0.3637\n",
      "Epoch [96/1000], Validation Loss: 0.4039, Validation Accuracy: 85.71%\n",
      "Output Summary: Max=34.5476, Min=-25.2594, Median=4.7945, Mean=2.9625\n",
      "\n",
      "Epoch [97/1000], Training Loss: 0.3632\n",
      "Epoch [97/1000], Validation Loss: 0.4033, Validation Accuracy: 85.73%\n",
      "Output Summary: Max=34.6498, Min=-25.3245, Median=4.8036, Mean=2.9672\n",
      "\n",
      "Epoch [98/1000], Training Loss: 0.3627\n",
      "Epoch [98/1000], Validation Loss: 0.4029, Validation Accuracy: 85.78%\n",
      "Output Summary: Max=34.7485, Min=-25.3879, Median=4.8136, Mean=2.9724\n",
      "\n",
      "Epoch [99/1000], Training Loss: 0.3622\n",
      "Epoch [99/1000], Validation Loss: 0.4024, Validation Accuracy: 85.76%\n",
      "Output Summary: Max=34.8468, Min=-25.4459, Median=4.8221, Mean=2.9770\n",
      "\n",
      "Epoch [100/1000], Training Loss: 0.3616\n",
      "Epoch [100/1000], Validation Loss: 0.4019, Validation Accuracy: 85.76%\n",
      "Output Summary: Max=34.9460, Min=-25.5040, Median=4.8312, Mean=2.9820\n",
      "\n",
      "Epoch [101/1000], Training Loss: 0.3611\n",
      "Epoch [101/1000], Validation Loss: 0.4014, Validation Accuracy: 85.78%\n",
      "Output Summary: Max=35.0451, Min=-25.5614, Median=4.8393, Mean=2.9869\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[93]\u001b[39m\u001b[32m, line 19\u001b[39m\n\u001b[32m     15\u001b[39m loss = criterion(output, target)\n\u001b[32m     16\u001b[39m loss.backward()\n\u001b[32m---> \u001b[39m\u001b[32m19\u001b[39m \u001b[43moptimizer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     20\u001b[39m running_loss += loss.item()\n\u001b[32m     21\u001b[39m num_batches += \u001b[32m1\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/optim/optimizer.py:478\u001b[39m, in \u001b[36mOptimizer.profile_hook_step.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    476\u001b[39m \u001b[38;5;28mself\u001b[39m = cast(Optimizer, \u001b[38;5;28mself\u001b[39m)\n\u001b[32m    477\u001b[39m profile_name = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mOptimizer.step#\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m.step\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m478\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mprofiler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecord_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprofile_name\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m    479\u001b[39m     \u001b[38;5;66;03m# call optimizer step pre hooks\u001b[39;00m\n\u001b[32m    480\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m pre_hook \u001b[38;5;129;01min\u001b[39;00m chain(\n\u001b[32m    481\u001b[39m         _global_optimizer_pre_hooks.values(),\n\u001b[32m    482\u001b[39m         \u001b[38;5;28mself\u001b[39m._optimizer_step_pre_hooks.values(),\n\u001b[32m    483\u001b[39m     ):\n\u001b[32m    484\u001b[39m         result = pre_hook(\u001b[38;5;28mself\u001b[39m, args, kwargs)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Downloads/All_Mac/Code/ML_experiments/.venv/lib/python3.11/site-packages/torch/autograd/profiler.py:740\u001b[39m, in \u001b[36mrecord_function.__init__\u001b[39m\u001b[34m(self, name, args)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;28;01mclass\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mrecord_function\u001b[39;00m(_ContextDecorator):\n\u001b[32m    703\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Context manager/function decorator that adds a label to a code block/function when running autograd profiler.\u001b[39;00m\n\u001b[32m    704\u001b[39m \u001b[33;03m    Label will only appear if CPU activity tracing is enabled.\u001b[39;00m\n\u001b[32m    705\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    737\u001b[39m \n\u001b[32m    738\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m740\u001b[39m     \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m, args: Optional[\u001b[38;5;28mstr\u001b[39m] = \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    741\u001b[39m         \u001b[38;5;28mself\u001b[39m.name: \u001b[38;5;28mstr\u001b[39m = name\n\u001b[32m    742\u001b[39m         \u001b[38;5;28mself\u001b[39m.args: Optional[\u001b[38;5;28mstr\u001b[39m] = args\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "patience = 20\n",
    "best_val_loss = float('inf')\n",
    "no_improvement_epochs = 0\n",
    "\n",
    "all_outputs = []\n",
    "\n",
    "for epoch in range(200):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    num_batches = 0\n",
    "    \n",
    "    for data, target in get_batches(train_data, train_targets, batch_size):\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "        num_batches += 1\n",
    "\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Training Loss: {running_loss / num_batches:.4f}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    num_batches = 0\n",
    "    epoch_outputs = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data, target in get_batches(test_data, test_targets, batch_size):\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += target.size(0)\n",
    "            num_batches += 1\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "            epoch_outputs.append(outputs)\n",
    "\n",
    "    all_outputs_tensor = torch.cat(epoch_outputs, dim=0)\n",
    "    all_outputs.append(all_outputs_tensor)\n",
    "\n",
    "    max_val = torch.max(all_outputs_tensor).item()\n",
    "    min_val = torch.min(all_outputs_tensor).item()\n",
    "    median_val = torch.median(all_outputs_tensor).item()\n",
    "    mean_val = torch.mean(all_outputs_tensor).item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= num_batches\n",
    "    print(f\"Epoch [{epoch + 1}/{epochs}], Validation Loss: {val_loss:.4f}, Validation Accuracy: {accuracy:.2f}%\")\n",
    "    print(f\"Output Summary: Max={max_val:.4f}, Min={min_val:.4f}, Median={median_val:.4f}, Mean={mean_val:.4f}\")\n",
    "    print()\n",
    "\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        no_improvement_epochs = 0\n",
    "    else:\n",
    "        no_improvement_epochs += 1\n",
    "\n",
    "    if no_improvement_epochs >= patience:\n",
    "        print(f\"Early stopping triggered after {epoch + 1} epochs.\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d812b1c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
